<div align="center">

# ğŸ¤– Daily HuggingFace AI Papers

### ğŸ“Š Your Automated AI Research Companion

> **Never miss groundbreaking AI research again!** Get daily updates on the hottest papers from HuggingFace, automatically curated and archived. Perfect for researchers, ML engineers, and AI enthusiasts. ğŸ”¥

[![Update Daily](https://img.shields.io/badge/Update-Daily-brightgreen?style=for-the-badge&logo=github-actions)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/actions)
[![Papers Today](https://img.shields.io/badge/Papers%20Today-25-blue?style=for-the-badge&logo=arxiv)](data/latest.json)
[![Total Papers](https://img.shields.io/badge/Total%20Papers-254+-orange?style=for-the-badge&logo=academia)](data/)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/AtharvaDomale/Daily-HuggingFace-AI-Papers?style=social)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/stargazers)

**Automatically updated every day at 00:00 UTC** â°

[ğŸ“Š View Data](data/) | [ğŸ” Latest Papers](data/latest.json) | [ğŸ“… Archives](#-historical-archives) | [â­ Star This Repo](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers)

</div>

---

## ğŸ¯ Why This Repo?

- âœ… **Saves 30+ minutes** of daily paper hunting
- âœ… **Organized archives** - daily, weekly, and monthly snapshots
- âœ… **Direct links** to arXiv, PDFs, and GitHub repositories
- âœ… **Machine-readable JSON** format for easy integration
- âœ… **Zero maintenance** - fully automated via GitHub Actions
- âœ… **Historical data** - track AI research trends over time

---

## ğŸš€ Who Is This For?

<table>
<tr>
<td align="center">ğŸ”¬<br/><b>Researchers</b><br/>Stay current with latest developments</td>
<td align="center">ğŸ’¼<br/><b>ML Engineers</b><br/>Discover SOTA techniques</td>
<td align="center">ğŸ“š<br/><b>Students</b><br/>Learn from cutting-edge research</td>
</tr>
<tr>
<td align="center">ğŸ¢<br/><b>Companies</b><br/>Track AI trends & competition</td>
<td align="center">ğŸ“°<br/><b>Content Creators</b><br/>Find topics for blogs & videos</td>
<td align="center">ğŸ¤–<br/><b>AI Enthusiasts</b><br/>Explore the latest in AI</td>
</tr>
</table>

---

## âš¡ Quick Start

### 1ï¸âƒ£ Get Today's Papers (cURL)

```bash
curl https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json
```

### 2ï¸âƒ£ Python Integration

```python
import requests
import pandas as pd

# Load latest papers
url = "https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json"
papers = requests.get(url).json()

# Convert to DataFrame for analysis
df = pd.DataFrame(papers)
print(f"ğŸ“š Today's papers: {len(df)}")

# Filter by stars
trending = df[df['stars'].astype(int) > 10]
print(f"ğŸ”¥ Trending papers: {len(trending)}")
```

### 3ï¸âƒ£ JavaScript/Node.js

```javascript
const fetch = require('node-fetch');

async function getTodaysPapers() {
  const response = await fetch(
    'https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json'
  );
  const papers = await response.json();
  
  console.log(`ğŸ“š Found ${papers.length} papers today!`);
  papers.forEach(paper => {
    console.log(`\nğŸ“„ ${paper.title}`);
    console.log(`â­ ${paper.stars} stars`);
    console.log(`ğŸ”— ${paper.details.arxiv_page_url}`);
  });
}

getTodaysPapers();
```

---

## ğŸ“ˆ Statistics

<table>
<tr>
<td align="center"><b>ğŸ“„ Today</b><br/><font size="5">25</font><br/>papers</td>
<td align="center"><b>ğŸ“… This Week</b><br/><font size="5">116</font><br/>papers</td>
<td align="center"><b>ğŸ“† This Month</b><br/><font size="5">303</font><br/>papers</td>
<td align="center"><b>ğŸ—„ï¸ Total Archive</b><br/><font size="5">254+</font><br/>papers</td>
</tr>
</table>

**Last Updated:** December 11, 2025

---

## ğŸ”¥ Today's Trending Papers

> Latest AI research papers from HuggingFace Papers, updated daily

<details>
<summary><b>1. Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance</b> â­ 197</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08765) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08765) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08765)

**ğŸ’» Code:** [â­ Code](https://github.com/ali-vilab/Wan-Move)

> NeurIPS 2025: Wan-Move: Motion-controllable Video Generation viaLatent Trajectory Guidance

</details>

<details>
<summary><b>2. Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform</b> â­ 162</summary>

<br/>

**ğŸ‘¥ Authors:** Muyao Niu, Yifan Zhan, Yifei Liu, Yuning Gong, Zuica96

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08478) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08478) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08478)

**ğŸ’» Code:** [â­ Code](https://github.com/Visionary-Laboratory/visionary)

> TL;DR: Visionary is an open, web-native platform built on WebGPU and ONNX Runtime. Enabling real-time rendering of diverse Gaussian Splatting variants (3DGS, MLP-based 3DGS, 4DGS, Neural Avatars and âœ¨any future algorithmsâœ¨), and traditional 3d Mes...

</details>

<details>
<summary><b>3. Preserving Source Video Realism: High-Fidelity Face Swapping for Cinematic Quality</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.07951) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.07951) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.07951)

> Project webpage: this https URL

</details>

<details>
<summary><b>4. OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.07802) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.07802) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.07802)

> No abstract available.

</details>

<details>
<summary><b>5. ThreadWeaver: Adaptive Threading for Efficient Parallel Reasoning in Language Models</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Xiuyu Li, Tsu-Jui Fu, Sida Wang, katanaxu, longlian

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.07843) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.07843) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.07843)

> No abstract available.

</details>

<details>
<summary><b>6. Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training</b> â­ 3</summary>

<br/>

**ğŸ‘¥ Authors:** Dim P. Papadopoulos, Kaixuan Lu, monurcan

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.06864) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.06864) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.06864)

**ğŸ’» Code:** [â­ Code](https://github.com/wcbup/AutoQ-VIS/)

> Accepted at WACV'26! Keywords: Video Instance Segmentation; Unsupervised Learning; Segmentation Quality Assessment

</details>

<details>
<summary><b>7. Arbitrage: Efficient Reasoning via Advantage-Aware Speculation</b> â­ 2</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.05033) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.05033) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.05033)

**ğŸ’» Code:** [â­ Code](https://github.com/SqueezeAILab/Arbitrage)

> Modern large language models achieve impressive reasoning capabilities with long chains of thought, but they incur substantial computational cost at inference time. Speculative decoding improves efficiency by using a fast, less accurate draft mode...

</details>

<details>
<summary><b>8. MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment</b> â­ 13</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.06628) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.06628) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.06628)

**ğŸ’» Code:** [â­ Code](https://github.com/Richard-Zhang-AI/MIND-V)

> We propose MIND-V, a hierarchical framework designed to synthesize physically plausible and logically coherent videos of long-horizon robotic manipulation.

</details>

<details>
<summary><b>9. See, Hear, and Understand: Benchmarking Audiovisual Human Speech Understanding in Multimodal Large Language Models</b> â­ 1</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.02231) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.02231) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.02231)

**ğŸ’» Code:** [â­ Code](https://github.com/plnguyen2908/AV-SpeakerBench)

> Multimodal large language models (MLLMs) are expected to jointly interpret vision, audio, and language, yet existing video benchmarks rarely assess fine-grained reasoning about human speech. Many tasks remain visually solvable or only coarsely eva...

</details>

<details>
<summary><b>10. DeepCode: Open Agentic Coding</b> â­ 11.8k</summary>

<br/>

**ğŸ‘¥ Authors:** Chao Huang, Xubin Ren, Zirui Guo, Zhonghang Li, Zongwei Li

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.07921) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.07921) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.07921)

**ğŸ’» Code:** [â­ Code](https://github.com/HKUDS/DeepCode)

> Recent advances in large language models (LLMs) have given rise to powerful coding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face significant challenges in achieving high-fidelity...

</details>

<details>
<summary><b>11. TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Weirui Ye, Zheng Ding

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08153) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08153) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08153)

> Reinforcement learning (RL) post-training is crucial for aligning generative models with human preferences, but its prohibitive computational cost remains a major barrier to widespread adoption. We introduce \textbf{TreeGRPO}, a novel RL framework...

</details>

<details>
<summary><b>12. From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.06776) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.06776) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.06776)

> NBDiff: A principled path from AR to Diffusion LLMs

</details>

<details>
<summary><b>13. Efficiently Reconstructing Dynamic Scenes One D4RT at a Time</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08924) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08924) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08924)

> ğŸ“ A simple, unified interface for 3D tracking, depth, and pose ğŸŒŸ SOTA results on 4D reconstruction & tracking ğŸš€ Up to 100x faster pose estimation than prior works

</details>

<details>
<summary><b>14. Modular Neural Image Signal Processing</b> â­ 1</summary>

<br/>

**ğŸ‘¥ Authors:** Michael S. Brown, Ran Zhang, Zhongling Wang, mafifi

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08564) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08564) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08564)

**ğŸ’» Code:** [â­ Code](https://github.com/mahmoudnafifi/modular_neural_isp)

> Modular Neural Image Signal Processing ğŸ¬ Click to watch the video We present a modular neural image signal processing (ISP) framework that produces high-quality display-referred images while providing a high degree of modularity with explicit cont...

</details>

<details>
<summary><b>15. Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation</b> â­ 455</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08186) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08186) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08186)

**ğŸ’» Code:** [â­ Code](https://github.com/InternRobotics/InternNav)

> Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-Language Navigation

</details>

<details>
<summary><b>16. EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08868) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08868) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08868)

> EcomBench introduces a holistic e-commerce benchmark to evaluate foundation agents on real-world tasks, emphasizing deep retrieval, multi-step reasoning, and cross-source knowledge integration.

</details>

<details>
<summary><b>17. TrackingWorld: World-centric Monocular 3D Tracking of Almost All Pixels</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Tianyu Huang, Peng Li, Jiacheng Deng, Jiahao Lu, xwt123

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08358) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08358) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08358)

> Monocular 3D tracking aims to capture the long-term motion of pixels in 3D space from a single monocular video and has witnessed rapid progress in recent years. However, we argue that the existing monocular 3D tracking methods still fall short in ...

</details>

<details>
<summary><b>18. SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting</b> â­ 6</summary>

<br/>

**ğŸ‘¥ Authors:** Soohyun Lee, Seokhyun Youn, ozbro, shbae84, klavna

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.07197) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.07197) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.07197)

**ğŸ’» Code:** [â­ Code](https://github.com/CMLab-Korea/Awesome-Efficient-GS)

> project page: https://cmlab-korea.github.io/Awesome-Efficient-GS/

</details>

<details>
<summary><b>19. Novel Deep Learning Architectures for Classification and Segmentation of Brain Tumors from MRI Images</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** arghadip2002, Necromancer0912

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.06531) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.06531) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.06531)

**ğŸ’» Code:** [â­ Code](https://github.com/arghadip2002/SAETCN-and-SASNET-Architectures)

> We are excited to share our new work tackling the critical challenge of brain tumor detection from MRI scans. Due to high data volume and generalization issues in existing systems, we developed two novel deep learning architectures: SAETCN (Self-A...

</details>

<details>
<summary><b>20. LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning</b> â­ 1</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.05325) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.05325) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.05325)

**ğŸ’» Code:** [â­ Code](https://github.com/farukakgul/LYNX)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference ...

</details>

<details>
<summary><b>21. SAM-Body4D: Training-Free 4D Human Body Mesh Recovery from Videos</b> â­ 15</summary>

<br/>

**ğŸ‘¥ Authors:** Jungong Han, Yunqi Miao, gaomingqi

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08406) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08406) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08406)

**ğŸ’» Code:** [â­ Code](https://github.com/gaomingqi/sam-body4d)

> Code & Gradio Demo : https://github.com/gaomingqi/sam-body4d See our FULL demo and Gradio Demo video below:

</details>

<details>
<summary><b>22. MemLoRA: Distilling Expert Adapters for On-Device Memory Systems</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Mete Ozay, Zeynep Akata, Umberto Michieli, Ondrej Bohdal, mwbini

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.04763) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.04763) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.04763)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API LightMem: Lightweight and Efficient Memory-Augmented Generation (2025) MemV...

</details>

<details>
<summary><b>23. Predicting Time-Dependent Flow Over Complex Geometries Using Operator Networks</b> â­ 1</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.04434) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.04434) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.04434)

**ğŸ’» Code:** [â­ Code](https://github.com/baskargroup/TimeDependent-DeepONet)

> This paper introduces a new deep learning algorithem to model transient flow around varied complex geometries using the deep operator network (DeepONet)

</details>

<details>
<summary><b>24. Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08923) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08923) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08923)

> Paper that evaluates and analyses consistency of MLLMs when providing questions in text vs as rendered-text.

</details>

<details>
<summary><b>25. Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise in Infinite, Real-Time Terrain Generation</b> â­ 1</summary>

<br/>

**ğŸ‘¥ Authors:** xandergos

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.08309) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.08309) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.08309)

**ğŸ’» Code:** [â­ Code](https://github.com/xandergos/terrain-diffusion)

> Terrain Diffusion introduces a procedural generation primitive built around InfiniteDiffusion, a sampling method that delivers seamless, seed-consistent, infinite-domain generation with constant-time random access. A multi-scale diffusion hierarch...

</details>

---

## ğŸ“… Historical Archives

### ğŸ“Š Quick Access

| Type | Link | Papers |
|------|------|--------|
| ğŸ• Latest | [`latest.json`](data/latest.json) | 25 |
| ğŸ“… Today | [`2025-12-11.json`](data/daily/2025-12-11.json) | 25 |
| ğŸ“† This Week | [`2025-W49.json`](data/weekly/2025-W49.json) | 116 |
| ğŸ—“ï¸ This Month | [`2025-12.json`](data/monthly/2025-12.json) | 303 |

### ğŸ“œ Recent Days

| Date | Papers | Link |
|------|--------|------|
| ğŸ“Œ 2025-12-11 | 25 | [View JSON](data/daily/2025-12-11.json) |
| ğŸ“„ 2025-12-10 | 29 | [View JSON](data/daily/2025-12-10.json) |
| ğŸ“„ 2025-12-09 | 24 | [View JSON](data/daily/2025-12-09.json) |
| ğŸ“„ 2025-12-08 | 38 | [View JSON](data/daily/2025-12-08.json) |
| ğŸ“„ 2025-12-07 | 38 | [View JSON](data/daily/2025-12-07.json) |
| ğŸ“„ 2025-12-06 | 38 | [View JSON](data/daily/2025-12-06.json) |
| ğŸ“„ 2025-12-05 | 38 | [View JSON](data/daily/2025-12-05.json) |

### ğŸ“š Weekly Archives

| Week | Papers | Link |
|------|--------|------|
| ğŸ“… 2025-W49 | 116 | [View JSON](data/weekly/2025-W49.json) |
| ğŸ“… 2025-W48 | 187 | [View JSON](data/weekly/2025-W48.json) |

### ğŸ—‚ï¸ Monthly Archives

| Month | Papers | Link |
|------|--------|------|
| ğŸ—“ï¸ 2025-12 | 303 | [View JSON](data/monthly/2025-12.json) |

---

## âœ¨ Features

- ğŸ”„ **Automated Daily Updates** - Runs every day at midnight UTC
- ğŸ“Š **Comprehensive Data** - Abstracts, authors, links, and metadata
- ğŸ—„ï¸ **Historical Archives** - Daily, weekly, and monthly snapshots
- ğŸ”— **Direct Links** - arXiv, PDF, GitHub repos, and HuggingFace pages
- ğŸ“ˆ **Trending Papers** - Star counts and popularity metrics
- ğŸ’¾ **JSON Format** - Easy to parse and integrate into your projects
- ğŸ¨ **Clean Interface** - Beautiful, organized README

---

## ğŸš€ Usage

### View Papers

- **Latest Papers**: Check this README (updated daily)
- **JSON Data**: Download from [`data/latest.json`](data/latest.json)
- **Historical Data**: Browse the [`data/`](data/) directory

### Integrate Into Your Project

```python
import requests

# Get latest papers
response = requests.get('https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json')
papers = response.json()

for paper in papers:
    print(f"Title: {paper['title']}")
    print(f"arXiv: {paper['details']['arxiv_page_url']}")
    print(f"PDF: {paper['details']['pdf_url']}")
```

### Use as RSS Alternative

Monitor this repo for daily AI paper updates:
- â­ Star this repository
- ğŸ‘€ Watch for notifications
- ğŸ”” Enable "All Activity" for daily updates

---

## ğŸ“Š Data Structure

```
data/
â”œâ”€â”€ daily/              # Individual day snapshots
â”‚   â”œâ”€â”€ 2024-12-04.json
â”‚   â”œâ”€â”€ 2024-12-05.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ weekly/             # Cumulative weekly papers
â”‚   â”œâ”€â”€ 2024-W48.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ monthly/            # Cumulative monthly papers
â”‚   â”œâ”€â”€ 2024-12.json
â”‚   â””â”€â”€ ...
â””â”€â”€ latest.json         # Most recent scrape
```

### JSON Schema

```json
{
  "title": "Paper Title",
  "paper_url": "https://huggingface.co/papers/...",
  "authors": ["Author 1", "Author 2"],
  "stars": "42",
  "scraped_date": "2024-12-04",
  "details": {
    "abstract": "Paper abstract...",
    "arxiv_page_url": "https://arxiv.org/abs/...",
    "pdf_url": "https://arxiv.org/pdf/...",
    "github_links": ["https://github.com/..."],
    "metadata": {}
  }
}
```

---

## ğŸ› ï¸ How It Works

This repository uses:

- **[Crawl4AI](https://github.com/unclecode/crawl4ai)** - Modern web scraping framework
- **[BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)** - HTML parsing
- **[GitHub Actions](https://github.com/features/actions)** - Automated daily runs
- **Python 3.11+** - Data processing and generation

### Workflow

1. ğŸ• GitHub Actions triggers at 00:00 UTC daily
2. ğŸ” Scrapes HuggingFace Papers page
3. ğŸ“¥ Downloads detailed info for each paper
4. ğŸ’¾ Saves to daily/weekly/monthly archives
5. ğŸ“ Generates this beautiful README
6. âœ… Commits and pushes updates

---

## ğŸ¤ Contributing

Found a bug or have a feature request? 

- ğŸ› [Report Issues](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- ğŸ’¡ [Submit Ideas](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ”§ [Pull Requests Welcome](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/pulls)

---

## ğŸ“œ License

MIT License - feel free to use this data for your own projects!

See [LICENSE](LICENSE) for more details.

---

## ğŸŒŸ Star History

If you find this useful, please consider giving it a star! â­

[![Star History Chart](https://api.star-history.com/svg?repos=AtharvaDomale/Daily-HuggingFace-AI-Papers&type=Date)](https://star-history.com/#AtharvaDomale/Daily-HuggingFace-AI-Papers&Date)

---

## ğŸ“¬ Contact & Support

- ğŸ’¬ [GitHub Discussions](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ› [Issue Tracker](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- â­ Don't forget to star this repo!

---

<div align="center">

**Made with â¤ï¸ for the AI Community**

[â¬† Back to Top](#-daily-huggingface-ai-papers)

</div>
