<div align="center">

# ğŸ¤– Daily HuggingFace AI Papers

### ğŸ“Š Your Automated AI Research Companion

> **Never miss groundbreaking AI research again!** Get daily updates on the hottest papers from HuggingFace, automatically curated and archived. Perfect for researchers, ML engineers, and AI enthusiasts. ğŸ”¥

[![Update Daily](https://img.shields.io/badge/Update-Daily-brightgreen?style=for-the-badge&logo=github-actions)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/actions)
[![Papers Today](https://img.shields.io/badge/Papers%20Today-24-blue?style=for-the-badge&logo=arxiv)](data/latest.json)
[![Total Papers](https://img.shields.io/badge/Total%20Papers-823+-orange?style=for-the-badge&logo=academia)](data/)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/AtharvaDomale/Daily-HuggingFace-AI-Papers?style=social)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/stargazers)

**Automatically updated every day at 00:00 UTC** â°

[ğŸ“Š View Data](data/) | [ğŸ” Latest Papers](data/latest.json) | [ğŸ“… Archives](#-historical-archives) | [â­ Star This Repo](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers)

</div>

---

## ğŸ¯ Why This Repo?

- âœ… **Saves 30+ minutes** of daily paper hunting
- âœ… **Organized archives** - daily, weekly, and monthly snapshots
- âœ… **Direct links** to arXiv, PDFs, and GitHub repositories
- âœ… **Machine-readable JSON** format for easy integration
- âœ… **Zero maintenance** - fully automated via GitHub Actions
- âœ… **Historical data** - track AI research trends over time

---

## ğŸš€ Who Is This For?

<table>
<tr>
<td align="center">ğŸ”¬<br/><b>Researchers</b><br/>Stay current with latest developments</td>
<td align="center">ğŸ’¼<br/><b>ML Engineers</b><br/>Discover SOTA techniques</td>
<td align="center">ğŸ“š<br/><b>Students</b><br/>Learn from cutting-edge research</td>
</tr>
<tr>
<td align="center">ğŸ¢<br/><b>Companies</b><br/>Track AI trends & competition</td>
<td align="center">ğŸ“°<br/><b>Content Creators</b><br/>Find topics for blogs & videos</td>
<td align="center">ğŸ¤–<br/><b>AI Enthusiasts</b><br/>Explore the latest in AI</td>
</tr>
</table>

---

## âš¡ Quick Start

### 1ï¸âƒ£ Get Today's Papers (cURL)

```bash
curl https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json
```

### 2ï¸âƒ£ Python Integration

```python
import requests
import pandas as pd

# Load latest papers
url = "https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json"
papers = requests.get(url).json()

# Convert to DataFrame for analysis
df = pd.DataFrame(papers)
print(f"ğŸ“š Today's papers: {len(df)}")

# Filter by stars
trending = df[df['stars'].astype(int) > 10]
print(f"ğŸ”¥ Trending papers: {len(trending)}")
```

### 3ï¸âƒ£ JavaScript/Node.js

```javascript
const fetch = require('node-fetch');

async function getTodaysPapers() {
  const response = await fetch(
    'https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json'
  );
  const papers = await response.json();
  
  console.log(`ğŸ“š Found ${papers.length} papers today!`);
  papers.forEach(paper => {
    console.log(`\nğŸ“„ ${paper.title}`);
    console.log(`â­ ${paper.stars} stars`);
    console.log(`ğŸ”— ${paper.details.arxiv_page_url}`);
  });
}

getTodaysPapers();
```

---

## ğŸ“ˆ Statistics

<table>
<tr>
<td align="center"><b>ğŸ“„ Today</b><br/><font size="5">24</font><br/>papers</td>
<td align="center"><b>ğŸ“… This Week</b><br/><font size="5">44</font><br/>papers</td>
<td align="center"><b>ğŸ“† This Month</b><br/><font size="5">85</font><br/>papers</td>
<td align="center"><b>ğŸ—„ï¸ Total Archive</b><br/><font size="5">823+</font><br/>papers</td>
</tr>
</table>

**Last Updated:** January 07, 2026

---

## ğŸ”¥ Today's Trending Papers

> Latest AI research papers from HuggingFace Papers, updated daily

<details>
<summary><b>1. Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits</b> â­ 6</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.20578) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.20578) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.20578)

**ğŸ’» Code:** [â­ Code](https://github.com/Amirhosein-gh98/Gnosis)

> Can Large Language Models predict their own failures? ğŸ§ âš¡ We all know the critical bottleneck in GenAI: LLMs are incredible, but they can confidently hallucinate and make mistakes. Until now, most fixes have been computationally massive â€” relying o...

</details>

<details>
<summary><b>2. NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation</b> â­ 60</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02204) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02204) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02204)

**ğŸ’» Code:** [â­ Code](https://github.com/ByteVisionLab/NextFlow)

> No abstract available.

</details>

<details>
<summary><b>3. K-EXAONE Technical Report</b> â­ 39</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.01739) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.01739) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.01739)

**ğŸ’» Code:** [â­ Code](https://github.com/LG-AI-EXAONE/K-EXAONE)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Nanbeige4-3B Technical Report: Exploring the Frontier of Small Language Mod...

</details>

<details>
<summary><b>4. DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer</b> â­ 86</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.01425) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.01425) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.01425)

**ğŸ’» Code:** [â­ Code](https://github.com/bytedance/DreamID-V)

> We introduce DreamID-V, the first Diffusion Transformer-based framework for high-fidelity video face swapping. DreamID-V bridges the gap between image and video domains, achieving exceptional identity similarity and temporal coherence even in chal...

</details>

<details>
<summary><b>5. VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02256) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02256) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02256)

> No abstract available.

</details>

<details>
<summary><b>6. GARDO: Reinforcing Diffusion Models without Reward Hacking</b> â­ 18</summary>

<br/>

**ğŸ‘¥ Authors:** Zhiyong Wang, Jiajun Liang, Jie Liu, Yuxiao Ye, Haoran He

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.24138) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.24138) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.24138)

**ğŸ’» Code:** [â­ Code](https://github.com/tinnerhrhe/GARDO) â€¢ [â­ Code](https://github.com/tinnerhrhe/gardo)

> Introducing GARDO: Reinforcing Diffusion Models without Reward Hacking paper: https://arxiv.org/abs/2512.24138 code: https://github.com/tinnerhrhe/gardo project: https://tinnerhrhe.github.io/gardo_project/

</details>

<details>
<summary><b>7. VINO: A Unified Visual Generator with Interleaved OmniModal Context</b> â­ 42</summary>

<br/>

**ğŸ‘¥ Authors:** Kun Gai, Pengfei Wan, Zhoujie Fu, Tong He, Junyi Chen

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02358) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02358) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02358)

**ğŸ’» Code:** [â­ Code](https://github.com/SOTAMak1r/VINO-code)

> No abstract available.

</details>

<details>
<summary><b>8. InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams</b> â­ 76</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02281) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02281) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02281)

**ğŸ’» Code:** [â­ Code](https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT)

> The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their bat...

</details>

<details>
<summary><b>9. Recursive Language Models</b> â­ 675</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.24601) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.24601) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.24601)

**ğŸ’» Code:** [â­ Code](https://github.com/alexzhang13/rlm/tree/main)

> Study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. They propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external...

</details>

<details>
<summary><b>10. Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02346) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02346) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02346)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes (202...

</details>

<details>
<summary><b>11. Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes</b> â­ 13</summary>

<br/>

**ğŸ‘¥ Authors:** Shuo Yang, Jiarui Cai, Yantao Shen, ZyZcuhk, jingtan

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02356) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02356) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02356)

**ğŸ’» Code:** [â­ Code](https://github.com/sparkstj/Talk2Move)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API VIVA: VLM-Guided Instruction-Based Video Editing with Reward Optimization (...

</details>

<details>
<summary><b>12. Confidence Estimation for LLMs in Multi-turn Interactions</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02179) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02179) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02179)

> In this paper, we explore the confidence estimation in a new paradigm: multi-turn interactions! Check it out!

</details>

<details>
<summary><b>13. KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Yi Yang, Yixuan Tang

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.01046) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.01046) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.01046)

> âœ¨ Turn any decoder-only LLM into a powerful embedding modelâ€”zero training needed! âœ¨ The Trick : Re-route the final token's key-value states as an internal prefix, giving all tokens access to global context in one forward pass. No input modificatio...

</details>

<details>
<summary><b>14. CPPO: Contrastive Perception for Vision Language Policy Optimization</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Mohammad Asiful Hossain, Kevin Cannons, Saeed Ranjbar Alvar, Mohsen Gholami, Ahmad Rezaei

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.00501) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.00501) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.00501)

> CPPO: Contrastive Perception for Vision Language Policy Optimization introduces a new method (CPPO) for fine-tuning vision-language models (VLMs) using reinforcement learning. Instead of relying on explicit perception rewards or auxiliary models, ...

</details>

<details>
<summary><b>15. DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies</b> â­ 1</summary>

<br/>

**ğŸ‘¥ Authors:** Jian Yang, Ying Tai, Zhenyu Zhang, wrk226

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02267) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02267) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02267)

**ğŸ’» Code:** [â­ Code](https://github.com/wrk226/DiffProxy)

> Project page: https://wrk226.github.io/DiffProxy.html Code: https://github.com/wrk226/DiffProxy

</details>

<details>
<summary><b>16. COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs</b> â­ 8</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.01836) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.01836) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.01836)

**ğŸ’» Code:** [â­ Code](https://github.com/AIM-Intelligence/COMPASS)

> COMPASS is the first framework for evaluating LLM alignment with organization-specific policies rather than universal harms. While models handle legitimate requests well (>95% accuracy), they catastrophically fail at enforcing prohibitions, refusi...

</details>

<details>
<summary><b>17. Toward Stable Semi-Supervised Remote Sensing Segmentation via Co-Guidance and Co-Fusion</b> â­ 4</summary>

<br/>

**ğŸ‘¥ Authors:** Shiying Wang, Kai Li, Shun Zhang, Xuechao Zou, Yi Zhou

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.23035) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.23035) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.23035)

**ğŸ’» Code:** [â­ Code](https://github.com/XavierJiezou/Co2S)

> We are excited to introduce our latest work on semi-supervised semantic segmentation : ğŸ“„ Toward Stable Semi-Supervised Remote Sensing Segmentation via Co-Guidance and Co-Fusion This paper tackles one of the most challenging issues in semi-supervis...

</details>

<details>
<summary><b>18. SWE-Lego: Pushing the Limits of Supervised Fine-tuning for Software Issue Resolving</b> â­ 8</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.01426) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.01426) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.01426)

**ğŸ’» Code:** [â­ Code](https://github.com/SWE-Lego/SWE-Lego)

> No abstract available.

</details>

<details>
<summary><b>19. OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment</b> â­ 3</summary>

<br/>

**ğŸ‘¥ Authors:** Chunchun Ma, Yujiong Shen, Yueyuan Huang, Kexin Tan, Ming Zhang

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.01576) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.01576) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.01576)

**ğŸ’» Code:** [â­ Code](https://github.com/january-blue/OpenNovelty)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API ARISE: Agentic Rubric-Guided Iterative Survey Engine for Automated Scholarl...

</details>

<details>
<summary><b>20. Selective Imperfection as a Generative Framework for Analysis, Creativity and Discovery</b> â­ 2</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.00863) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.00863) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.00863)

**ğŸ’» Code:** [â­ Code](https://github.com/lamm-mit/MusicAnalysis)

> Selective Imperfection as a Generative Framework for Analysis, Creativity and Discovery We introduce materiomusic as a generative framework linking the hierarchical structures of matter with the compositional logic of music. Across proteins, spide...

</details>

<details>
<summary><b>21. IMA++: ISIC Archive Multi-Annotator Dermoscopic Skin Lesion Segmentation Dataset</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.21472) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.21472) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.21472)

**ğŸ’» Code:** [â­ Code](https://github.com/sfu-mial/IMAplusplus)

> âœ¨ The largest publicly available dermoscopic skin lesion segmentation dataset with 17,684 segmentation masks spanning 14,967 dermoscopic images, where 2,394 dermoscopic images have 2-5 segmentations per image. âœ¨ 16 unique annotators , 3 different ...

</details>

<details>
<summary><b>22. Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping</b> â­ 3</summary>

<br/>

**ğŸ‘¥ Authors:** Beth Tellman, Lalit Maurya, Saurabh Kaushik

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02315) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02315) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02315)

**ğŸ’» Code:** [â­ Code](https://github.com/Sk-2103/Prithvi-CAFE)

> Despite the recent success of large pretrained encoders (Geoâ€‘Foundation Models), we consistently observe that Uâ€‘Netâ€‘based models remain highly competitiveâ€”and in some cases outperform transformers, particularly due to their strength in capturing l...

</details>

<details>
<summary><b>23. Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents</b> â­ 2</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.02314) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.02314) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.02314)

**ğŸ’» Code:** [â­ Code](https://github.com/skhanzad/AridadneXAI)

> Does COT in llms stay faithful to their thoughts?

</details>

<details>
<summary><b>24. M-ErasureBench: A Comprehensive Multimodal Evaluation Benchmark for Concept Erasure in Diffusion Models</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Jun-Cheng Chen, Cheng-Fu Chou, Ju-Hsuan Weng, jwliao1209

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2512.22877) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2512.22877) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2512.22877)

> Concept Erasure Benchmark

</details>

---

## ğŸ“… Historical Archives

### ğŸ“Š Quick Access

| Type | Link | Papers |
|------|------|--------|
| ğŸ• Latest | [`latest.json`](data/latest.json) | 24 |
| ğŸ“… Today | [`2026-01-07.json`](data/daily/2026-01-07.json) | 24 |
| ğŸ“† This Week | [`2026-W01.json`](data/weekly/2026-W01.json) | 44 |
| ğŸ—“ï¸ This Month | [`2026-01.json`](data/monthly/2026-01.json) | 85 |

### ğŸ“œ Recent Days

| Date | Papers | Link |
|------|--------|------|
| ğŸ“Œ 2026-01-07 | 24 | [View JSON](data/daily/2026-01-07.json) |
| ğŸ“„ 2026-01-06 | 13 | [View JSON](data/daily/2026-01-06.json) |
| ğŸ“„ 2026-01-05 | 7 | [View JSON](data/daily/2026-01-05.json) |
| ğŸ“„ 2026-01-04 | 7 | [View JSON](data/daily/2026-01-04.json) |
| ğŸ“„ 2026-01-03 | 7 | [View JSON](data/daily/2026-01-03.json) |
| ğŸ“„ 2026-01-02 | 20 | [View JSON](data/daily/2026-01-02.json) |
| ğŸ“„ 2026-01-01 | 7 | [View JSON](data/daily/2026-01-01.json) |

### ğŸ“š Weekly Archives

| Week | Papers | Link |
|------|--------|------|
| ğŸ“… 2026-W01 | 44 | [View JSON](data/weekly/2026-W01.json) |
| ğŸ“… 2026-W00 | 41 | [View JSON](data/weekly/2026-W00.json) |
| ğŸ“… 2025-W52 | 52 | [View JSON](data/weekly/2025-W52.json) |
| ğŸ“… 2025-W51 | 132 | [View JSON](data/weekly/2025-W51.json) |

### ğŸ—‚ï¸ Monthly Archives

| Month | Papers | Link |
|------|--------|------|
| ğŸ—“ï¸ 2026-01 | 85 | [View JSON](data/monthly/2026-01.json) |
| ğŸ—“ï¸ 2025-12 | 787 | [View JSON](data/monthly/2025-12.json) |

---

## âœ¨ Features

- ğŸ”„ **Automated Daily Updates** - Runs every day at midnight UTC
- ğŸ“Š **Comprehensive Data** - Abstracts, authors, links, and metadata
- ğŸ—„ï¸ **Historical Archives** - Daily, weekly, and monthly snapshots
- ğŸ”— **Direct Links** - arXiv, PDF, GitHub repos, and HuggingFace pages
- ğŸ“ˆ **Trending Papers** - Star counts and popularity metrics
- ğŸ’¾ **JSON Format** - Easy to parse and integrate into your projects
- ğŸ¨ **Clean Interface** - Beautiful, organized README

---

## ğŸš€ Usage

### View Papers

- **Latest Papers**: Check this README (updated daily)
- **JSON Data**: Download from [`data/latest.json`](data/latest.json)
- **Historical Data**: Browse the [`data/`](data/) directory

### Integrate Into Your Project

```python
import requests

# Get latest papers
response = requests.get('https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json')
papers = response.json()

for paper in papers:
    print(f"Title: {paper['title']}")
    print(f"arXiv: {paper['details']['arxiv_page_url']}")
    print(f"PDF: {paper['details']['pdf_url']}")
```

### Use as RSS Alternative

Monitor this repo for daily AI paper updates:
- â­ Star this repository
- ğŸ‘€ Watch for notifications
- ğŸ”” Enable "All Activity" for daily updates

---

## ğŸ“Š Data Structure

```
data/
â”œâ”€â”€ daily/              # Individual day snapshots
â”‚   â”œâ”€â”€ 2024-12-04.json
â”‚   â”œâ”€â”€ 2024-12-05.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ weekly/             # Cumulative weekly papers
â”‚   â”œâ”€â”€ 2024-W48.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ monthly/            # Cumulative monthly papers
â”‚   â”œâ”€â”€ 2024-12.json
â”‚   â””â”€â”€ ...
â””â”€â”€ latest.json         # Most recent scrape
```

### JSON Schema

```json
{
  "title": "Paper Title",
  "paper_url": "https://huggingface.co/papers/...",
  "authors": ["Author 1", "Author 2"],
  "stars": "42",
  "scraped_date": "2024-12-04",
  "details": {
    "abstract": "Paper abstract...",
    "arxiv_page_url": "https://arxiv.org/abs/...",
    "pdf_url": "https://arxiv.org/pdf/...",
    "github_links": ["https://github.com/..."],
    "metadata": {}
  }
}
```

---

## ğŸ› ï¸ How It Works

This repository uses:

- **[Crawl4AI](https://github.com/unclecode/crawl4ai)** - Modern web scraping framework
- **[BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)** - HTML parsing
- **[GitHub Actions](https://github.com/features/actions)** - Automated daily runs
- **Python 3.11+** - Data processing and generation

### Workflow

1. ğŸ• GitHub Actions triggers at 00:00 UTC daily
2. ğŸ” Scrapes HuggingFace Papers page
3. ğŸ“¥ Downloads detailed info for each paper
4. ğŸ’¾ Saves to daily/weekly/monthly archives
5. ğŸ“ Generates this beautiful README
6. âœ… Commits and pushes updates

---

## ğŸ¤ Contributing

Found a bug or have a feature request? 

- ğŸ› [Report Issues](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- ğŸ’¡ [Submit Ideas](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ”§ [Pull Requests Welcome](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/pulls)

---

## ğŸ“œ License

MIT License - feel free to use this data for your own projects!

See [LICENSE](LICENSE) for more details.

---

## ğŸŒŸ Star History

If you find this useful, please consider giving it a star! â­

[![Star History Chart](https://api.star-history.com/svg?repos=AtharvaDomale/Daily-HuggingFace-AI-Papers&type=Date)](https://star-history.com/#AtharvaDomale/Daily-HuggingFace-AI-Papers&Date)

---

## ğŸ“¬ Contact & Support

- ğŸ’¬ [GitHub Discussions](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ› [Issue Tracker](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- â­ Don't forget to star this repo!

---

<div align="center">

**Made with â¤ï¸ for the AI Community**

[â¬† Back to Top](#-daily-huggingface-ai-papers)

</div>
