<div align="center">

# ğŸ¤– Daily HuggingFace AI Papers

### ğŸ“Š Your Automated AI Research Companion

> **Never miss groundbreaking AI research again!** Get daily updates on the hottest papers from HuggingFace, automatically curated and archived. Perfect for researchers, ML engineers, and AI enthusiasts. ğŸ”¥

[![Update Daily](https://img.shields.io/badge/Update-Daily-brightgreen?style=for-the-badge&logo=github-actions)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/actions)
[![Papers Today](https://img.shields.io/badge/Papers%20Today-47-blue?style=for-the-badge&logo=arxiv)](data/latest.json)
[![Total Papers](https://img.shields.io/badge/Total%20Papers-2132+-orange?style=for-the-badge&logo=academia)](data/)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/AtharvaDomale/Daily-HuggingFace-AI-Papers?style=social)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/stargazers)

**Automatically updated every day at 00:00 UTC** â°

[ğŸ“Š View Data](data/) | [ğŸ” Latest Papers](data/latest.json) | [ğŸ“… Archives](#-historical-archives) | [â­ Star This Repo](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers)

</div>

---

## ğŸ¯ Why This Repo?

- âœ… **Saves 30+ minutes** of daily paper hunting
- âœ… **Organized archives** - daily, weekly, and monthly snapshots
- âœ… **Direct links** to arXiv, PDFs, and GitHub repositories
- âœ… **Machine-readable JSON** format for easy integration
- âœ… **Zero maintenance** - fully automated via GitHub Actions
- âœ… **Historical data** - track AI research trends over time

---

## ğŸš€ Who Is This For?

<table>
<tr>
<td align="center">ğŸ”¬<br/><b>Researchers</b><br/>Stay current with latest developments</td>
<td align="center">ğŸ’¼<br/><b>ML Engineers</b><br/>Discover SOTA techniques</td>
<td align="center">ğŸ“š<br/><b>Students</b><br/>Learn from cutting-edge research</td>
</tr>
<tr>
<td align="center">ğŸ¢<br/><b>Companies</b><br/>Track AI trends & competition</td>
<td align="center">ğŸ“°<br/><b>Content Creators</b><br/>Find topics for blogs & videos</td>
<td align="center">ğŸ¤–<br/><b>AI Enthusiasts</b><br/>Explore the latest in AI</td>
</tr>
</table>

---

## âš¡ Quick Start

### 1ï¸âƒ£ Get Today's Papers (cURL)

```bash
curl https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json
```

### 2ï¸âƒ£ Python Integration

```python
import requests
import pandas as pd

# Load latest papers
url = "https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json"
papers = requests.get(url).json()

# Convert to DataFrame for analysis
df = pd.DataFrame(papers)
print(f"ğŸ“š Today's papers: {len(df)}")

# Filter by stars
trending = df[df['stars'].astype(int) > 10]
print(f"ğŸ”¥ Trending papers: {len(trending)}")
```

### 3ï¸âƒ£ JavaScript/Node.js

```javascript
const fetch = require('node-fetch');

async function getTodaysPapers() {
  const response = await fetch(
    'https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json'
  );
  const papers = await response.json();
  
  console.log(`ğŸ“š Found ${papers.length} papers today!`);
  papers.forEach(paper => {
    console.log(`\nğŸ“„ ${paper.title}`);
    console.log(`â­ ${paper.stars} stars`);
    console.log(`ğŸ”— ${paper.details.arxiv_page_url}`);
  });
}

getTodaysPapers();
```

---

## ğŸ“ˆ Statistics

<table>
<tr>
<td align="center"><b>ğŸ“„ Today</b><br/><font size="5">47</font><br/>papers</td>
<td align="center"><b>ğŸ“… This Week</b><br/><font size="5">211</font><br/>papers</td>
<td align="center"><b>ğŸ“† This Month</b><br/><font size="5">613</font><br/>papers</td>
<td align="center"><b>ğŸ—„ï¸ Total Archive</b><br/><font size="5">2132+</font><br/>papers</td>
</tr>
</table>

**Last Updated:** February 13, 2026

---

## ğŸ”¥ Today's Trending Papers

> Latest AI research papers from HuggingFace Papers, updated daily

<details>
<summary><b>1. Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters</b> â­ 1.25k</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10604) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10604) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10604)

**ğŸ’» Code:** [â­ Code](https://github.com/stepfun-ai/Step-3.5-Flash)

> Step-3.5-Flash is #1 on MathArena , an uncheatable math competition benchmark

</details>

<details>
<summary><b>2. PhyCritic: Multimodal Critic Models for Physical AI</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.11124) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.11124) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.11124)

> A multimodal critic model that unifies physical judging and reasoning.

</details>

<details>
<summary><b>3. GENIUS: Generative Fluid Intelligence Evaluation Suite</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Zijun Shen, Wei Dai, Ziyu Guo, Sihan Yang, Ruichuan An

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.11144) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.11144) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.11144)

> No abstract available.

</details>

<details>
<summary><b>4. ASA: Training-Free Representation Engineering for Tool-Calling Agents</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Hongwei Zeng, Shuaishuai Cao, Rong Fu, Run Zhou, wangyoujin

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.04935) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.04935) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.04935)

> Adapting LLM agents to domain-specific tool calling remains notably brittle under evolving interfaces. Prompt and schema engineering is easy to deploy but often fragile under distribution shift and strict parsers, while continual parameter-efficie...

</details>

<details>
<summary><b>5. Towards Autonomous Mathematics Research</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10177) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10177) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10177)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Semi-Autonomous Mathematics Discovery with Gemini: A Case Study on the Erd\...

</details>

<details>
<summary><b>6. G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design</b> â­ 12</summary>

<br/>

**ğŸ‘¥ Authors:** Liang Zeng, iphysresearch, ZBoyn

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.08253) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.08253) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.08253)

**ğŸ’» Code:** [â­ Code](https://github.com/ZBoyn/G-LNS)

> Weâ€™re moving from constructive rules to recursive destruction & repair ğŸ”„. G-LNS introduces Synergy-Aware Co-evolution, allowing LLMs to generate coupled Destroy/Repair operators that break local optima. Reshaping > Constructing. ğŸ’¡ It beats OR-Tool...

</details>

<details>
<summary><b>7. How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10622) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10622) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10622)

> ğŸ‰ How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning Decoder-only LLMs have demonstrated remarkable generative capabilities, but how well do they understand users when repurposed for representati...

</details>

<details>
<summary><b>8. When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10560) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10560) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10560)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API InfMem: Learning System-2 Memory Control for Long-Context Agent (2026) Dyna...

</details>

<details>
<summary><b>9. TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions</b> â­ 16</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.08711) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.08711) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.08711)

**ğŸ’» Code:** [â­ Code](https://github.com/yaolinli/TimeChat-Captioner)

> TimeChat-Captioner is a multimodal model designed to generate detailed, time-aware, and structurally coherent captions for multi-scene videos. It effectively coordinates visual and audio information to provide comprehensive video descriptions.

</details>

<details>
<summary><b>10. FeatureBench: Benchmarking Agentic Coding for Complex Feature Development</b> â­ 17</summary>

<br/>

**ğŸ‘¥ Authors:** Jiahe Wang, Rui Hao, Qixing Zhou, Haiyang-W, jiachengzhg

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10975) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10975) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10975)

**ğŸ’» Code:** [â­ Code](https://github.com/LiberCoders/FeatureBench)

> FeatureBench focuses on evaluating the end-to-end development capability of coding agents for complex features. On our benchmark, even the strongest commercial models can solve only about 12% of the tasks. The full Docker environment and the scala...

</details>

<details>
<summary><b>11. ROCKET: Rapid Optimization via Calibration-guided Knapsack Enhanced Truncation for Efficient Model Compression</b> â­ 20</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.11008) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.11008) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.11008)

**ğŸ’» Code:** [â­ Code](https://github.com/mts-ai/ROCKET)

> ROCKET isnâ€™t just another compression method. It is one of the first methods to shrink massive AI models down to compact sizes without sacrificing performance, often matching or even outperforming vanilla models of the same size trained from scrat...

</details>

<details>
<summary><b>12. Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Zhen Fang, Qingnan Ren, Zecheng Li, YuZeng260, chocckaka

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10224) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10224) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10224)

> We propose Meta-Experience Learning (MEL), which breaks the meta-learning and credit-assignment bottleneck of standard RLVR by explicitly modeling and internalizing reusable error-based knowledge. MEL exploits an LLM's self-verification ability to...

</details>

<details>
<summary><b>13. DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning</b> â­ 4</summary>

<br/>

**ğŸ‘¥ Authors:** Kai Chen, Yining Li, Xinchen Xie, Zerun Ma, Yicheng Chen

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.11089) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.11089) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.11089)

**ğŸ’» Code:** [â­ Code](https://github.com/yichengchen24/DataChef)

> demo: https://huggingface.co/spaces/yichengchen24/DataChef

</details>

<details>
<summary><b>14. GameDevBench: Evaluating Agentic Capabilities Through Game Development</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.11103) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.11103) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.11103)

> Can agents develop video games? GameDevBench is the first benchmark to evaluate an agent's ability to solve game development tasks.

</details>

<details>
<summary><b>15. Online Causal Kalman Filtering for Stable and Effective Policy Optimization</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10609) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10609) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10609)

> (Work in progress) We are adding more comparison methods and models for KPO and will soon open-source KPO.

</details>

<details>
<summary><b>16. Data Repetition Beats Data Scaling in Long-CoT Supervised Fine-Tuning</b> â­ 1</summary>

<br/>

**ğŸ‘¥ Authors:** Yuki M. Asano, Tijmen Blankevoort, Sagar Vaze, dakopi

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.11149) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.11149) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.11149)

**ğŸ’» Code:** [â­ Code](https://github.com/dkopi/data-repetition)

> Pretty interesting findings!

</details>

<details>
<summary><b>17. Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Tianshu Yu, Yiwen Guo, Zhipeng Li, lemonade666

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.07106) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.07106) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.07106)

> Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from...

</details>

<details>
<summary><b>18. CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion</b> â­ 9</summary>

<br/>

**ğŸ‘¥ Authors:** Feiyang Pan, Lue Fan, Shuzhe Wu, Yusong Lin, Haiyang-W

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10999) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10999) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10999)

**ğŸ’» Code:** [â­ Code](https://github.com/LiberCoders/CLI-Gym)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Ter...

</details>

<details>
<summary><b>19. LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation</b> â­ 1</summary>

<br/>

**ğŸ‘¥ Authors:** Xiang Li, Yisheng Ji, Zhe Fang, Dingjie Song, Zhiling Yan

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10367) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10367) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10367)

**ğŸ’» Code:** [â­ Code](https://github.com/ZhilingYan/LiveMedBench)

> LiveMedBench is a continuously updated, contamination-free, and rubric-based benchmark for evaluating LLMs on real-world medical cases. It is designed to measure not only overall medical quality, but also robustness over time and alignment with ph...

</details>

<details>
<summary><b>20. Blockwise Advantage Estimation for Multi-Objective RL with Verifiable Rewards</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10231) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10231) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10231)

> Blockwise Advantage Estimation makes GRPO work for segmented, multi-objective generations by routing each objectiveâ€™s learning signal to the tokens that control it, using an outcome-conditioned baseline for later segments.

</details>

<details>
<summary><b>21. EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies</b> â­ 6</summary>

<br/>

**ğŸ‘¥ Authors:** Yishuo Yuan, Kangqi Song, Shengze Xu, Jinxiang Xia, Xavier Hu

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.09514) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.09514) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.09514)

**ğŸ’» Code:** [â­ Code](https://github.com/OPPO-PersonalAI/EcoGym)

> Long-horizon planning is widely recognized as a core capability of autonomous LLM-based agents; however, current evaluation frameworks suffer from being largely episodic, domain-specific, or insufficiently grounded in persistent economic dynamics....

</details>

<details>
<summary><b>22. VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Rami Ben-Ari, Dvir Samuel, issart12345

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.08099) â€¢ [ğŸ“„ arXiv](https://www.arxiv.org/abs/2602.08099) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.08099)

> What if your multimodal LLM already contains strong video representationsâ€”strong enough to beat Video Foundation Models? ğŸ¤” VidVec ğŸ¥ : Unlocking Video MLLM Embeddings for Video-Text Retrieval Key contributions (short): âœ… Layer-wise insight: interme...

</details>

<details>
<summary><b>23. Stroke3D: Lifting 2D strokes into rigged 3D model via latent diffusion models</b> â­ 19</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.09713) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.09713) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.09713)

**ğŸ’» Code:** [â­ Code](https://github.com/Whalesong-zrs/Stroke3D) â€¢ [â­ Code](https://github.com/Whalesong-zrs/Stroke3D_project_page)

> Project Page: https://whalesong-zrs.github.io/Stroke3D_project_page/ Github Repo: https://github.com/Whalesong-zrs/Stroke3D

</details>

<details>
<summary><b>24. ECHO-2: A Large-Scale Distributed Rollout Framework for Cost-Efficient Reinforcement Learning</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.02192) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.02192) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.02192)

> Current RLHF/RLAIF is bottlenecked by rollouts and wasteful GPU idling. ECHO-2 changes the cost structure: we decouple RL into three planesâ€”rollout (global inference swarm), learning (staleness-aware multi-step updates), and data/reward (fully mod...

</details>

<details>
<summary><b>25. When the Prompt Becomes Visual: Vision-Centric Jailbreak Attacks for Large Image Editing Models</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10179) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10179) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10179)

> Website: https://csu-jpg.github.io/vja.github.io/

</details>

<details>
<summary><b>26. QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Hui Zhang, Yunpeng Liu, Xiaorui Huang, Jianzhao Huang, Hiiamein

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.09901) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.09901) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.09901)

> QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search

</details>

<details>
<summary><b>27. Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens</b> â­ 1</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10229) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10229) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10229)

**ğŸ’» Code:** [â­ Code](https://github.com/NeosKnight233/Latent-Thoughts-Tuning)

> a new framework for LLM reasoning in continuous latent space

</details>

<details>
<summary><b>28. Beyond Correctness: Learning Robust Reasoning via Transfer</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Jinwoo Shin, Jihoon Tack, Soheil Abbasloo, hyunseoki

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.08489) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.08489) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.08489)

> Reinforcement Learning with Verifiable Rewards (RLVR) has recently strengthened LLM reasoning, but its focus on final answer correctness leaves a critical gap: it does not ensure the robustness of the reasoning process itself. We adopt a simple ph...

</details>

<details>
<summary><b>29. Free(): Learning to Forget in Malloc-Only Reasoning Models</b> â­ 9</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.08030) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.08030) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.08030)

**ğŸ’» Code:** [â­ Code](https://github.com/TemporaryLoRA/FreeLM)

> The Magic of Forgetting! Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental archit...

</details>

<details>
<summary><b>30. Benchmarking Large Language Models for Knowledge Graph Validation</b> â­ 1</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10748) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10748) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10748)

**ğŸ’» Code:** [â­ Code](https://github.com/FactCheck-AI) â€¢ [â­ Code](https://github.com/FactCheck-AI/FactCheck)

> In this work, we introduceÂ FactCheck, a benchmark to systematically evaluate LLMs for fact validation over Knowledge Graphs, covering internal model knowledge, Retrieval-Augmented Generation (RAG), and multi-model consensus strategies across three...

</details>

<details>
<summary><b>31. Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.07954) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.07954) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.07954)

> Bielik Guard is a family of compact Polish-language safety classifiers (0.1B and 0.5B parameters) that accurately detect harmful content across five categories, achieving strong benchmark performanceâ€”with the 0.5B model offering the best overall F...

</details>

<details>
<summary><b>32. AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions</b> â­ 7</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.06008) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.06008) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.06008)

**ğŸ’» Code:** [â­ Code](https://github.com/SafeRL-Lab/AgenticPay)

> Paper: https://arxiv.org/abs/2602.06008 Code: https://github.com/SafeRL-Lab/AgenticPay Tutorial: https://agenticpay-tutorial.readthedocs.io/en/latest/

</details>

<details>
<summary><b>33. Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Aviral Kumar, Amrith Setlur, Yuxiao Qu, Ian Wu

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.03773) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.03773) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.03773)

> Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a pr...

</details>

<details>
<summary><b>34. ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation</b> â­ 50</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.09014) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.09014) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.09014)

**ğŸ’» Code:** [â­ Code](https://github.com/pnotp/ArcFlow)

> In this work, we revisit few-step distillation from a geometric perspective. Based on the observation that teacher trajectories exhibit inherently non-linear dynamics, ArcFlow introduces a momentum-based velocity parameterization with an analytic ...

</details>

<details>
<summary><b>35. Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.07900) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.07900) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.07900)

> In autonomous issue resolution, agent-written tests often increase interaction cost without meaningfully increasing task success.

</details>

<details>
<summary><b>36. LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.11451) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.11451) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.11451)

**ğŸ’» Code:** [â­ Code](https://github.com/armenjeddi/loopformer)

> The LoopFormer Paper accepted to ICLR 2026

</details>

<details>
<summary><b>37. Weight Decay Improves Language Model Plasticity</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Sham Kakade, Hanlin Zhang, Sebastian Bordt, Tessa Han

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.11137) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.11137) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.11137)

> Increasing weight decay during language model pretraining enhances model plasticity, enabling greater performance gains after fine-tuning even when base validation loss is worse, and highlights the need to optimize hyperparameters with downstream ...

</details>

<details>
<summary><b>38. UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory</b> â­ 247</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10652) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10652) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10652)

**ğŸ’» Code:** [â­ Code](https://github.com/AIDC-AI/Marco-DeepResearch)

> UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory This paper presents a systematic solution to a core bottleneck in self-evolving agents, offering the following notable contributions: Core Problem Insight The author...

</details>

<details>
<summary><b>39. When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents</b> â­ 3</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.08995) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.08995) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.08995)

**ğŸ’» Code:** [â­ Code](https://github.com/OSU-NLP-Group/Misaligned-Action-Detection)

> Project Homepage: https://osu-nlp-group.github.io/Misaligned-Action-Detection/ Github Repo: https://github.com/OSU-NLP-Group/Misaligned-Action-Detection Benchmark: https://huggingface.co/datasets/osunlp/MisActBench

</details>

<details>
<summary><b>40. TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments</b> â­ 15</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.02459) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.02459) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.02459)

**ğŸ’» Code:** [â­ Code](https://github.com/ucla-mobility/TIC-VLA)

> Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control...

</details>

<details>
<summary><b>41. FedPS: Federated data Preprocessing via aggregated Statistics</b> â­ 5</summary>

<br/>

**ğŸ‘¥ Authors:** Graham Cormode, xuefeng-xu

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10870) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10870) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10870)

**ğŸ’» Code:** [â­ Code](https://github.com/xuefeng-xu/fedps)

> TL;DR: A unified framework for tabular data preprocessing in federated learning.

</details>

<details>
<summary><b>42. GoodVibe: Security-by-Vibe for LLM-Based Code Generation</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10778) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10778) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10778)

> Large language models (LLMs) are increasingly used for code generation in fast, informal development workflows, often referred to as vibe coding, where speed and convenience are prioritized, and security requirements are rarely made explicit. In t...

</details>

<details>
<summary><b>43. Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Yuling Xiong, Changping Wang, Zeyu Wang, Yangru Huang, Jie Jiang

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.10699) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.10699) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.10699)

> V-STAR introduces value-guided decoding and tree-structured advantage reinforcement learning for generative recommendations, boosting exploration, diversity, and latency-constrained accuracy.

</details>

<details>
<summary><b>44. Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.08741) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.08741) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.08741)

**ğŸ’» Code:** [â­ Code](https://github.com/jonatelintelo/LargeLanguageLobotomy)

> The rapid adoption of Mixture-of-Experts (MoE) architectures marks a major shift in the deployment of Large Language Models (LLMs). MoE LLMs improve scaling efficiency by activating only a small subset of parameters per token, but their routing st...

</details>

<details>
<summary><b>45. Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Grace Bochenek, Ghaith Rabadi, Sean Mondesire, Bulent Soykan

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.08052) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.08052) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.08052)

**ğŸ’» Code:** [â­ Code](https://github.com/bulentsoykan/GNN-DRL4UPMSP)

> The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) a...

</details>

<details>
<summary><b>46. StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors</b> â­ 2</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.08934) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.08934) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.08934)

**ğŸ’» Code:** [â­ Code](https://github.com/suraj-ranganath/StealthRL)

> StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors. Happy to discuss and get feedback!

</details>

<details>
<summary><b>47. From Features to Actions: Explainability in Traditional and Agentic AI Systems</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2602.06841) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2602.06841) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2602.06841)

**ğŸ’» Code:** [â­ Code](https://github.com/VectorInstitute/unified-xai-evaluation-framework)

> As AI systems move from single predictions to autonomous, multi-step agents, our notion of explainability must evolve. In this paper, we show why traditional feature-attribution methods (e.g., SHAP, LIME) are insufficient for diagnosing failures i...

</details>

---

## ğŸ“… Historical Archives

### ğŸ“Š Quick Access

| Type | Link | Papers |
|------|------|--------|
| ğŸ• Latest | [`latest.json`](data/latest.json) | 47 |
| ğŸ“… Today | [`2026-02-13.json`](data/daily/2026-02-13.json) | 47 |
| ğŸ“† This Week | [`2026-W06.json`](data/weekly/2026-W06.json) | 211 |
| ğŸ—“ï¸ This Month | [`2026-02.json`](data/monthly/2026-02.json) | 613 |

### ğŸ“œ Recent Days

| Date | Papers | Link |
|------|--------|------|
| ğŸ“Œ 2026-02-13 | 47 | [View JSON](data/daily/2026-02-13.json) |
| ğŸ“„ 2026-02-12 | 57 | [View JSON](data/daily/2026-02-12.json) |
| ğŸ“„ 2026-02-11 | 58 | [View JSON](data/daily/2026-02-11.json) |
| ğŸ“„ 2026-02-10 | 2 | [View JSON](data/daily/2026-02-10.json) |
| ğŸ“„ 2026-02-09 | 47 | [View JSON](data/daily/2026-02-09.json) |
| ğŸ“„ 2026-02-08 | 47 | [View JSON](data/daily/2026-02-08.json) |
| ğŸ“„ 2026-02-07 | 47 | [View JSON](data/daily/2026-02-07.json) |

### ğŸ“š Weekly Archives

| Week | Papers | Link |
|------|--------|------|
| ğŸ“… 2026-W06 | 211 | [View JSON](data/weekly/2026-W06.json) |
| ğŸ“… 2026-W05 | 357 | [View JSON](data/weekly/2026-W05.json) |
| ğŸ“… 2026-W04 | 214 | [View JSON](data/weekly/2026-W04.json) |
| ğŸ“… 2026-W03 | 183 | [View JSON](data/weekly/2026-W03.json) |

### ğŸ—‚ï¸ Monthly Archives

| Month | Papers | Link |
|------|--------|------|
| ğŸ—“ï¸ 2026-02 | 613 | [View JSON](data/monthly/2026-02.json) |
| ğŸ—“ï¸ 2026-01 | 781 | [View JSON](data/monthly/2026-01.json) |
| ğŸ—“ï¸ 2025-12 | 787 | [View JSON](data/monthly/2025-12.json) |

---

## âœ¨ Features

- ğŸ”„ **Automated Daily Updates** - Runs every day at midnight UTC
- ğŸ“Š **Comprehensive Data** - Abstracts, authors, links, and metadata
- ğŸ—„ï¸ **Historical Archives** - Daily, weekly, and monthly snapshots
- ğŸ”— **Direct Links** - arXiv, PDF, GitHub repos, and HuggingFace pages
- ğŸ“ˆ **Trending Papers** - Star counts and popularity metrics
- ğŸ’¾ **JSON Format** - Easy to parse and integrate into your projects
- ğŸ¨ **Clean Interface** - Beautiful, organized README

---

## ğŸš€ Usage

### View Papers

- **Latest Papers**: Check this README (updated daily)
- **JSON Data**: Download from [`data/latest.json`](data/latest.json)
- **Historical Data**: Browse the [`data/`](data/) directory

### Integrate Into Your Project

```python
import requests

# Get latest papers
response = requests.get('https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json')
papers = response.json()

for paper in papers:
    print(f"Title: {paper['title']}")
    print(f"arXiv: {paper['details']['arxiv_page_url']}")
    print(f"PDF: {paper['details']['pdf_url']}")
```

### Use as RSS Alternative

Monitor this repo for daily AI paper updates:
- â­ Star this repository
- ğŸ‘€ Watch for notifications
- ğŸ”” Enable "All Activity" for daily updates

---

## ğŸ“Š Data Structure

```
data/
â”œâ”€â”€ daily/              # Individual day snapshots
â”‚   â”œâ”€â”€ 2024-12-04.json
â”‚   â”œâ”€â”€ 2024-12-05.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ weekly/             # Cumulative weekly papers
â”‚   â”œâ”€â”€ 2024-W48.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ monthly/            # Cumulative monthly papers
â”‚   â”œâ”€â”€ 2024-12.json
â”‚   â””â”€â”€ ...
â””â”€â”€ latest.json         # Most recent scrape
```

### JSON Schema

```json
{
  "title": "Paper Title",
  "paper_url": "https://huggingface.co/papers/...",
  "authors": ["Author 1", "Author 2"],
  "stars": "42",
  "scraped_date": "2024-12-04",
  "details": {
    "abstract": "Paper abstract...",
    "arxiv_page_url": "https://arxiv.org/abs/...",
    "pdf_url": "https://arxiv.org/pdf/...",
    "github_links": ["https://github.com/..."],
    "metadata": {}
  }
}
```

---

## ğŸ› ï¸ How It Works

This repository uses:

- **[Crawl4AI](https://github.com/unclecode/crawl4ai)** - Modern web scraping framework
- **[BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)** - HTML parsing
- **[GitHub Actions](https://github.com/features/actions)** - Automated daily runs
- **Python 3.11+** - Data processing and generation

### Workflow

1. ğŸ• GitHub Actions triggers at 00:00 UTC daily
2. ğŸ” Scrapes HuggingFace Papers page
3. ğŸ“¥ Downloads detailed info for each paper
4. ğŸ’¾ Saves to daily/weekly/monthly archives
5. ğŸ“ Generates this beautiful README
6. âœ… Commits and pushes updates

---

## ğŸ¤ Contributing

Found a bug or have a feature request? 

- ğŸ› [Report Issues](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- ğŸ’¡ [Submit Ideas](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ”§ [Pull Requests Welcome](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/pulls)

---

## ğŸ“œ License

MIT License - feel free to use this data for your own projects!

See [LICENSE](LICENSE) for more details.

---

## ğŸŒŸ Star History

If you find this useful, please consider giving it a star! â­

[![Star History Chart](https://api.star-history.com/svg?repos=AtharvaDomale/Daily-HuggingFace-AI-Papers&type=Date)](https://star-history.com/#AtharvaDomale/Daily-HuggingFace-AI-Papers&Date)

---

## ğŸ“¬ Contact & Support

- ğŸ’¬ [GitHub Discussions](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ› [Issue Tracker](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- â­ Don't forget to star this repo!

---

<div align="center">

**Made with â¤ï¸ for the AI Community**

[â¬† Back to Top](#-daily-huggingface-ai-papers)

</div>
