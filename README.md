<div align="center">

# ğŸ¤– Daily HuggingFace AI Papers

### ğŸ“Š Your Automated AI Research Companion

> **Never miss groundbreaking AI research again!** Get daily updates on the hottest papers from HuggingFace, automatically curated and archived. Perfect for researchers, ML engineers, and AI enthusiasts. ğŸ”¥

[![Update Daily](https://img.shields.io/badge/Update-Daily-brightgreen?style=for-the-badge&logo=github-actions)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/actions)
[![Papers Today](https://img.shields.io/badge/Papers%20Today-42-blue?style=for-the-badge&logo=arxiv)](data/latest.json)
[![Total Papers](https://img.shields.io/badge/Total%20Papers-1040+-orange?style=for-the-badge&logo=academia)](data/)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/AtharvaDomale/Daily-HuggingFace-AI-Papers?style=social)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/stargazers)

**Automatically updated every day at 00:00 UTC** â°

[ğŸ“Š View Data](data/) | [ğŸ” Latest Papers](data/latest.json) | [ğŸ“… Archives](#-historical-archives) | [â­ Star This Repo](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers)

</div>

---

## ğŸ¯ Why This Repo?

- âœ… **Saves 30+ minutes** of daily paper hunting
- âœ… **Organized archives** - daily, weekly, and monthly snapshots
- âœ… **Direct links** to arXiv, PDFs, and GitHub repositories
- âœ… **Machine-readable JSON** format for easy integration
- âœ… **Zero maintenance** - fully automated via GitHub Actions
- âœ… **Historical data** - track AI research trends over time

---

## ğŸš€ Who Is This For?

<table>
<tr>
<td align="center">ğŸ”¬<br/><b>Researchers</b><br/>Stay current with latest developments</td>
<td align="center">ğŸ’¼<br/><b>ML Engineers</b><br/>Discover SOTA techniques</td>
<td align="center">ğŸ“š<br/><b>Students</b><br/>Learn from cutting-edge research</td>
</tr>
<tr>
<td align="center">ğŸ¢<br/><b>Companies</b><br/>Track AI trends & competition</td>
<td align="center">ğŸ“°<br/><b>Content Creators</b><br/>Find topics for blogs & videos</td>
<td align="center">ğŸ¤–<br/><b>AI Enthusiasts</b><br/>Explore the latest in AI</td>
</tr>
</table>

---

## âš¡ Quick Start

### 1ï¸âƒ£ Get Today's Papers (cURL)

```bash
curl https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json
```

### 2ï¸âƒ£ Python Integration

```python
import requests
import pandas as pd

# Load latest papers
url = "https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json"
papers = requests.get(url).json()

# Convert to DataFrame for analysis
df = pd.DataFrame(papers)
print(f"ğŸ“š Today's papers: {len(df)}")

# Filter by stars
trending = df[df['stars'].astype(int) > 10]
print(f"ğŸ”¥ Trending papers: {len(trending)}")
```

### 3ï¸âƒ£ JavaScript/Node.js

```javascript
const fetch = require('node-fetch');

async function getTodaysPapers() {
  const response = await fetch(
    'https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json'
  );
  const papers = await response.json();
  
  console.log(`ğŸ“š Found ${papers.length} papers today!`);
  papers.forEach(paper => {
    console.log(`\nğŸ“„ ${paper.title}`);
    console.log(`â­ ${paper.stars} stars`);
    console.log(`ğŸ”— ${paper.details.arxiv_page_url}`);
  });
}

getTodaysPapers();
```

---

## ğŸ“ˆ Statistics

<table>
<tr>
<td align="center"><b>ğŸ“„ Today</b><br/><font size="5">42</font><br/>papers</td>
<td align="center"><b>ğŸ“… This Week</b><br/><font size="5">105</font><br/>papers</td>
<td align="center"><b>ğŸ“† This Month</b><br/><font size="5">302</font><br/>papers</td>
<td align="center"><b>ğŸ—„ï¸ Total Archive</b><br/><font size="5">1040+</font><br/>papers</td>
</tr>
</table>

**Last Updated:** January 14, 2026

---

## ğŸ”¥ Today's Trending Papers

> Latest AI research papers from HuggingFace Papers, updated daily

<details>
<summary><b>1. Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning</b> â­ 51</summary>

<br/>

**ğŸ‘¥ Authors:** Zhe Huang, Zhuoyue Chang, HJH2CMD, Yu2020, POTATO66

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06943) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06943) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06943)

**ğŸ’» Code:** [â­ Code](https://github.com/QuantaAlpha/VideoDR-Benchmark)

> First video deep research benchmark.

</details>

<details>
<summary><b>2. BabyVision: Visual Reasoning Beyond Language</b> â­ 81</summary>

<br/>

**ğŸ‘¥ Authors:** Liang Chen, Liuff23, Ziqi, ssz1111, chenxz

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06521) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06521) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06521)

**ğŸ’» Code:** [â­ Code](https://github.com/UniPat-AI/BabyVision)

> Feel free to follow our GitHub repo: https://github.com/UniPat-AI/BabyVision

</details>

<details>
<summary><b>3. PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning</b> â­ 261</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.05593) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.05593) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.05593)

**ğŸ’» Code:** [â­ Code](https://github.com/stepfun-ai/PaCoRe)

> ğŸ‰ Introducing Parallel Coordinated Reasoning (PaCoRe) ğŸ“ˆ An 8B model beats GPT-5 on HMMT25 by unlocking parallel thinking for test-time scaling! ğŸ“‚ Open-source deep think: data + model + inference code! ğŸ†“ MIT-licensed â€” use it however you want ğŸ”Key ...

</details>

<details>
<summary><b>4. MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head</b> â­ 47</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07832) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07832) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07832)

**ğŸ’» Code:** [â­ Code](https://github.com/DAGroup-PKU/MHLA)

> No abstract available.

</details>

<details>
<summary><b>5. X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests</b> â­ 52</summary>

<br/>

**ğŸ‘¥ Authors:** Jane Luo, Jiani Guo, Xin Zhang, Jie Wu, Ringo1110

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06953) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06953) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06953)

**ğŸ’» Code:** [â­ Code](https://github.com/JieWu02/X-Coder)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Tailored Primitive Initialization is the Secret Key to Reinforcement Learni...

</details>

<details>
<summary><b>6. GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts</b> â­ 7</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.05110) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.05110) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.05110)

**ğŸ’» Code:** [â­ Code](https://github.com/Zengwh02/GlimpRouter)

> LLM + SLM > LLM

</details>

<details>
<summary><b>7. Lost in the Noise: How Reasoning Models Fail with Contextual Distractors</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07226) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07226) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07226)

> The code and dataset will be released publicly.

</details>

<details>
<summary><b>8. OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent</b> â­ 15</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07779) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07779) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07779)

**ğŸ’» Code:** [â­ Code](https://github.com/OS-Copilot/OS-Symphony)

> Despite VLM advances, current CUA frameworks remain brittle in long-horizon workflows and weak in novel domains due to coarse historical visual context management and missing visual-aware tutorial retrieval, so we propose OS-SYMPHONY, an orchestra...

</details>

<details>
<summary><b>9. Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models</b> â­ 16</summary>

<br/>

**ğŸ‘¥ Authors:** Chenchen Jing, Tianjian Feng, Bozhen Fang, Linyu Wu, zhongzero

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07351) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07351) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07351)

**ğŸ’» Code:** [â­ Code](https://github.com/aim-uofa/EvoTokenDLM)

> GitHub repo: https://github.com/aim-uofa/EvoTokenDLM

</details>

<details>
<summary><b>10. Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Zhengkang Guo, Jingwen Xu, Xiaohua Wang, Muzhao Tian, zisuh

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.05107) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.05107) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.05107)

> As LLM-based agents are increasingly used in long-term interactions, cumulative memory is critical for enabling personalization and maintaining stylistic consistency. However, most existing systems adopt an ``all-or-nothing'' approach to memory us...

</details>

<details>
<summary><b>11. DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving</b> â­ 7</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.01528) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.01528) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.01528)

**ğŸ’» Code:** [â­ Code](https://github.com/youngzhou1999/DrivingGen)

> DrivingGen is a comprehensive benchmark for generative world models in the driving domain with a diverse data distribution and novel evaluation metrics.

</details>

<details>
<summary><b>12. MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Jiawei Chen, Ruisheng Cao, Mouxiang Chen, zjj1233, Lemoncoke

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07526) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07526) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07526)

> The rapid development of interactive and autonomous AI systems signals our entry into the agentic era. Training and evaluating agents on complex agentic tasks such as software engineering and computer use requires not only efficient model computat...

</details>

<details>
<summary><b>13. Boosting Latent Diffusion Models via Disentangled Representation Alignment</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.05823) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.05823) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.05823)

**ğŸ’» Code:** [â­ Code](https://github.com/Kwai-Kolors/Send-VAE)

> arXiv link: Boosting Latent Diffusion Models via Disentangled Representation Alignment Code (Coming Soon): https://github.com/Kwai-Kolors/Send-VAE

</details>

<details>
<summary><b>14. What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models</b> â­ 10</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06165) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06165) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06165)

**ğŸ’» Code:** [â­ Code](https://github.com/HAE-RAE/HAERAE-VISION)

> Users often ask VLMs under-specified, informal visual questions, which current clean-prompt benchmarks fail to capture. We introduce HAERAE-Vision (653 real Korean community queries + explicit rewrites) and show that making queries explicit boosts...

</details>

<details>
<summary><b>15. ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06860) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06860) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06860)

> Most current TIR work only focuses on the accuracy of agents in downstream tasks, while lacking calibration of the agents' behavioral patterns in TIR tasks. To address this issue, we first quantitatively analyze several possible erroneous behavior...

</details>

<details>
<summary><b>16. Dr. Zero: Self-Evolving Search Agents without Training Data</b> â­ 74</summary>

<br/>

**ğŸ‘¥ Authors:** Shaoliang Nie, Suyu Ge, Xianjun Yang, Kartikeya Upasani, Zhenrui Yue

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07055) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07055) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07055)

**ğŸ’» Code:** [â­ Code](https://github.com/facebookresearch/drzero)

> Dr. Zero enables data-free self-evolving search agents through a self-evolution loop with HRPO, achieving strong multi-step reasoning while reducing compute.

</details>

<details>
<summary><b>17. Forest Before Trees: Latent Superposition for Efficient Visual Reasoning</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Yankai Lin, Yichen Wu, Yubo Wang, Yuhan, ZION121

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06803) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06803) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06803)

> We hope this work encourages a paradigm shift from explicit next-token prediction to latent visual reasoning.

</details>

<details>
<summary><b>18. TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Hao Wang, Xiaoxi Li, Wenxiang Jiao, Mining Tan, Yinuo Wang

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.04698) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.04698) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.04698)

> We propose TourPlanner , a comprehensive framework featuring multi-path reasoning and constraint-gated reinforcement learning. Specifically, we first introduce a Personalized Recall and Spatial Optimization (PReSO) workflow to construct spatially-...

</details>

<details>
<summary><b>19. OpenTinker: Separating Concerns in Agentic Reinforcement Learning</b> â­ 568</summary>

<br/>

**ğŸ‘¥ Authors:** Jiaxuan You, zsqzz

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07376) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07376) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07376)

**ğŸ’» Code:** [â­ Code](https://github.com/open-tinker/OpenTinker?tab=readme-ov-file) â€¢ [â­ Code](https://github.com/open-tinker/OpenTinker)

> ğŸ‰ Introducing OpenTinker ğŸš€ A scalable RL infrastructure for LLM agents that separates what you build (agents + environments) from how it runs (training + inference)! ğŸ§© Composable RL-as-a-Service No more monolithic RL pipelines. OpenTinker decompos...

</details>

<details>
<summary><b>20. Are LLM Decisions Faithful to Verbal Confidence?</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07767) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07767) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07767)

> While LLMs can express their confidence levels, their actual decisions do not demonstrate risk sensitivity. Even with high error penalties, they rarely abstain from making choices, often leading to utility collapse.

</details>

<details>
<summary><b>21. Structured Episodic Event Memory</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06411) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06411) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06411)

> Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reason...

</details>

<details>
<summary><b>22. e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Zhicheng Dou, Tetsuya Sakai, Radu Timofte, Sicheng Gao, Haon-Chen

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.03666) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.03666) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.03666)

> A lightweight explicit alignment recipe that adapts off-the-shelf VLMs into robust omni-modal embedding models. Checkpoints: https://huggingface.co/Haon-Chen/e5-omni-3B https://huggingface.co/Haon-Chen/e5-omni-7B

</details>

<details>
<summary><b>23. "TODO: Fix the Mess Gemini Created": Towards Understanding GenAI-Induced Self-Admitted Technical Debt</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Mia Mohammad Imran, Abdullah Al Mujahid

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07786) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07786) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07786)

> As large language models (LLMs) such as ChatGPT, Copilot, Claude, and Gemini become integrated into software development workflows, developers increasingly leave traces of AI involvement in their code comments. Among these, some comments explicitl...

</details>

<details>
<summary><b>24. ShowUI-Aloha: Human-Taught GUI Agent</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Zhiheng Chen, Jessica Hu, Yauhong Goh, Xiangwu Guo, Yichun Zhang

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07181) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07181) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07181)

> No abstract available.

</details>

<details>
<summary><b>25. Codified Foreshadowing-Payoff Text Generation</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Jingbo Shang, Letian Peng, Kun Zhou, Longfei Yun, hyp1231

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07033) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07033) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07033)

> Codified Foreshadowing-Payoff Text Generation

</details>

<details>
<summary><b>26. Sci-Reasoning: A Dataset Decoding AI Innovation Patterns</b> â­ 7</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.04577) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.04577) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.04577)

**ğŸ’» Code:** [â­ Code](https://github.com/AmberLJC/Sci-Reasoning)

> While AI innovation accelerates rapidly, the intellectual process behind breakthroughs -- how researchers identify gaps, synthesize prior work, and generate insights -- remains poorly understood. The lack of structured data on scientific reasoning...

</details>

<details>
<summary><b>27. How Do Large Language Models Learn Concepts During Continual Pre-Training?</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Zaishuo Xia, Minqian Liu, Yunzhi Yao, Sha Li, Barry Menglong Yao

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.03570) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.03570) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.03570)

> Human beings primarily understand the world through concepts (e.g., dog), abstract mental representations that structure perception, reasoning, and learning. However, how large language models (LLMs) acquire, retain, and forget such concepts durin...

</details>

<details>
<summary><b>28. On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Weixi Zhang, Wei Han, Bo Bai, Xueyan Niu

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07389) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07389) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07389)

> Post-training of large language models routinely interleaves supervised fine-tuning (SFT) with reinforcement learning (RL). These two methods have different objectives: SFT minimizes the cross-entropy loss between model outputs and expert response...

</details>

<details>
<summary><b>29. Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?</b> â­ 1</summary>

<br/>

**ğŸ‘¥ Authors:** Xiaoming Liu, Yiyang Su, Paipile

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06993) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06993) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06993)

**ğŸ’» Code:** [â­ Code](https://github.com/jiezhu23/ReFine-RFT)

> In this work, we investigate the impact of CoT on Fine-Grained Visual Classification (FGVC), revealing a paradox: the degradation in FGVC performance due to CoT is primarily driven by reasoning length, with longer textual reasoning consistently re...

</details>

<details>
<summary><b>30. RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Shaolei Zhang, Zishan Xu, Sen Hu, Zhiyuan Yao, Haonan-Bian

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06966) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06966) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06966)

**ğŸ’» Code:** [â­ Code](https://github.com/AvatarMemory/RealMemBench)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API EvolMem: A Cognitive-Driven Benchmark for Multi-Session Dialogue Memory (20...

</details>

<details>
<summary><b>31. SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Shixing Li, Guozhang Li, Yaoyao Zhong, Mei Wang, Yuhang Su

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06944) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06944) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06944)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API ViRectify: A Challenging Benchmark for Video Reasoning Correction with Mult...

</details>

<details>
<summary><b>32. Artificial Entanglement in the Fine-Tuning of Large Language Models</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Manling Li, Zeguan Wu, Canyu Chen, Zihan Wang, Min Chen

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06788) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06788) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06788)

> No abstract available.

</details>

<details>
<summary><b>33. FinForge: Semi-Synthetic Financial Benchmark Generation</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06747) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06747) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06747)

> This paper introduces FinForge, a novel framework designed to address the scarcity of high-quality, domain-specific datasets for evaluating Large Language Models (LLMs) in finance. The authors propose a scalable, semi-synthetic pipeline that combi...

</details>

<details>
<summary><b>34. Gecko: An Efficient Neural Architecture Inherently Processing Sequences with Arbitrary Lengths</b> â­ 4</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06463) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06463) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06463)

**ğŸ’» Code:** [â­ Code](https://github.com/XuezheMax/gecko-llm)

> No abstract available.

</details>

<details>
<summary><b>35. Does Inference Scaling Improve Reasoning Faithfulness? A Multi-Model Analysis of Self-Consistency Tradeoffs</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Deep Mehta

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06423) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06423) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06423)

> We ask a question that hasn't been studied before: does inference scaling improve reasoning faithfulness or just accuracy? Self-consistency (majority voting over multiple reasoning paths) reliably boosts LLM accuracy on reasoning tasks. But does g...

</details>

<details>
<summary><b>36. FlyPose: Towards Robust Human Pose Estimation From Aerial Views</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Peter St\Ã¼tz, Marvin Brenner, farooqhassaan

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.05747) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.05747) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.05747)

**ğŸ’» Code:** [â­ Code](https://github.com/farooqhassaan/FlyPose)

> Unmanned Aerial Vehicles (UAVs) are increasingly deployed in close proximity to humans for applications such as parcel delivery, traffic monitoring, disaster response and infrastructure inspections. Ensuring safe and reliable operation in these hu...

</details>

<details>
<summary><b>37. Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification</b> â­ 1</summary>

<br/>

**ğŸ‘¥ Authors:** Chaowei Yang, Joseph Rogers, Zifu Wang, Emily Ma, ymasri

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07790) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07790) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07790)

**ğŸ’» Code:** [â­ Code](https://github.com/stccenter/Benchmarking-SLMs-and-SRLMs-on-System-Log-Severity-Classification)

> We evaluate 9 open-source models under zero-shot, few-shot, and RAG (FAISS) and measure both accuracy + per-log latency. Main takeaway: RAG can massively help small models (Qwen3-4B: 95.64%, Gemma3-1B: 85.28%), but some reasoning-focused models de...

</details>

<details>
<summary><b>38. Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Shreyash Dhoot, Aadi Pandey, Anusa Saha, Shourya Aggarwal, Tanmay Joshi

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07239) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07239) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07239)

> Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition

</details>

<details>
<summary><b>39. 3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06496) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06496) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06496)

**ğŸ’» Code:** [â­ Code](https://github.com/AIGeeksGroup/3DCoCav2)

> https://github.com/AIGeeksGroup/3DCoCav2

</details>

<details>
<summary><b>40. On the Fallacy of Global Token Perplexity in Spoken Language Model Evaluation</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Ju-Chieh Chou, Yen-Chun Kuo, Yi-Cheng Lin, Liang-Hsuan Tseng, Jeff Chan-Jan Sju

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06329) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06329) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06329)

> Generative spoken language models pretrained on large-scale raw audio can continue a speech prompt with appropriate content while preserving attributes like speaker and emotion, serving as foundation models for spoken dialogue. In prior literature...

</details>

<details>
<summary><b>41. A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Dilek Hakkani-TÃ¼r, Dhruva Patil, Zhenlin He, Ishika Agarwal

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06307) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06307) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06307)

> https://huggingface.co/collections/ishikaa/a-rising-tide-lifts-all-boats-mtqe-rewards-for-idioms

</details>

<details>
<summary><b>42. SPINAL -- Scaling-law and Preference Integration in Neural Alignment Layers</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Aman Chadha, Vinija Jain, Amit Dhanda, Partha Pratim Saha, Arion Das

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.06238) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.06238) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.06238)

> SPINAL -- Scaling-law and Preference Integration in Neural Alignment Layers

</details>

---

## ğŸ“… Historical Archives

### ğŸ“Š Quick Access

| Type | Link | Papers |
|------|------|--------|
| ğŸ• Latest | [`latest.json`](data/latest.json) | 42 |
| ğŸ“… Today | [`2026-01-14.json`](data/daily/2026-01-14.json) | 42 |
| ğŸ“† This Week | [`2026-W02.json`](data/weekly/2026-W02.json) | 105 |
| ğŸ—“ï¸ This Month | [`2026-01.json`](data/monthly/2026-01.json) | 302 |

### ğŸ“œ Recent Days

| Date | Papers | Link |
|------|--------|------|
| ğŸ“Œ 2026-01-14 | 42 | [View JSON](data/daily/2026-01-14.json) |
| ğŸ“„ 2026-01-13 | 30 | [View JSON](data/daily/2026-01-13.json) |
| ğŸ“„ 2026-01-12 | 33 | [View JSON](data/daily/2026-01-12.json) |
| ğŸ“„ 2026-01-11 | 33 | [View JSON](data/daily/2026-01-11.json) |
| ğŸ“„ 2026-01-10 | 33 | [View JSON](data/daily/2026-01-10.json) |
| ğŸ“„ 2026-01-09 | 20 | [View JSON](data/daily/2026-01-09.json) |
| ğŸ“„ 2026-01-08 | 26 | [View JSON](data/daily/2026-01-08.json) |

### ğŸ“š Weekly Archives

| Week | Papers | Link |
|------|--------|------|
| ğŸ“… 2026-W02 | 105 | [View JSON](data/weekly/2026-W02.json) |
| ğŸ“… 2026-W01 | 156 | [View JSON](data/weekly/2026-W01.json) |
| ğŸ“… 2026-W00 | 41 | [View JSON](data/weekly/2026-W00.json) |
| ğŸ“… 2025-W52 | 52 | [View JSON](data/weekly/2025-W52.json) |

### ğŸ—‚ï¸ Monthly Archives

| Month | Papers | Link |
|------|--------|------|
| ğŸ—“ï¸ 2026-01 | 302 | [View JSON](data/monthly/2026-01.json) |
| ğŸ—“ï¸ 2025-12 | 787 | [View JSON](data/monthly/2025-12.json) |

---

## âœ¨ Features

- ğŸ”„ **Automated Daily Updates** - Runs every day at midnight UTC
- ğŸ“Š **Comprehensive Data** - Abstracts, authors, links, and metadata
- ğŸ—„ï¸ **Historical Archives** - Daily, weekly, and monthly snapshots
- ğŸ”— **Direct Links** - arXiv, PDF, GitHub repos, and HuggingFace pages
- ğŸ“ˆ **Trending Papers** - Star counts and popularity metrics
- ğŸ’¾ **JSON Format** - Easy to parse and integrate into your projects
- ğŸ¨ **Clean Interface** - Beautiful, organized README

---

## ğŸš€ Usage

### View Papers

- **Latest Papers**: Check this README (updated daily)
- **JSON Data**: Download from [`data/latest.json`](data/latest.json)
- **Historical Data**: Browse the [`data/`](data/) directory

### Integrate Into Your Project

```python
import requests

# Get latest papers
response = requests.get('https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json')
papers = response.json()

for paper in papers:
    print(f"Title: {paper['title']}")
    print(f"arXiv: {paper['details']['arxiv_page_url']}")
    print(f"PDF: {paper['details']['pdf_url']}")
```

### Use as RSS Alternative

Monitor this repo for daily AI paper updates:
- â­ Star this repository
- ğŸ‘€ Watch for notifications
- ğŸ”” Enable "All Activity" for daily updates

---

## ğŸ“Š Data Structure

```
data/
â”œâ”€â”€ daily/              # Individual day snapshots
â”‚   â”œâ”€â”€ 2024-12-04.json
â”‚   â”œâ”€â”€ 2024-12-05.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ weekly/             # Cumulative weekly papers
â”‚   â”œâ”€â”€ 2024-W48.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ monthly/            # Cumulative monthly papers
â”‚   â”œâ”€â”€ 2024-12.json
â”‚   â””â”€â”€ ...
â””â”€â”€ latest.json         # Most recent scrape
```

### JSON Schema

```json
{
  "title": "Paper Title",
  "paper_url": "https://huggingface.co/papers/...",
  "authors": ["Author 1", "Author 2"],
  "stars": "42",
  "scraped_date": "2024-12-04",
  "details": {
    "abstract": "Paper abstract...",
    "arxiv_page_url": "https://arxiv.org/abs/...",
    "pdf_url": "https://arxiv.org/pdf/...",
    "github_links": ["https://github.com/..."],
    "metadata": {}
  }
}
```

---

## ğŸ› ï¸ How It Works

This repository uses:

- **[Crawl4AI](https://github.com/unclecode/crawl4ai)** - Modern web scraping framework
- **[BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)** - HTML parsing
- **[GitHub Actions](https://github.com/features/actions)** - Automated daily runs
- **Python 3.11+** - Data processing and generation

### Workflow

1. ğŸ• GitHub Actions triggers at 00:00 UTC daily
2. ğŸ” Scrapes HuggingFace Papers page
3. ğŸ“¥ Downloads detailed info for each paper
4. ğŸ’¾ Saves to daily/weekly/monthly archives
5. ğŸ“ Generates this beautiful README
6. âœ… Commits and pushes updates

---

## ğŸ¤ Contributing

Found a bug or have a feature request? 

- ğŸ› [Report Issues](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- ğŸ’¡ [Submit Ideas](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ”§ [Pull Requests Welcome](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/pulls)

---

## ğŸ“œ License

MIT License - feel free to use this data for your own projects!

See [LICENSE](LICENSE) for more details.

---

## ğŸŒŸ Star History

If you find this useful, please consider giving it a star! â­

[![Star History Chart](https://api.star-history.com/svg?repos=AtharvaDomale/Daily-HuggingFace-AI-Papers&type=Date)](https://star-history.com/#AtharvaDomale/Daily-HuggingFace-AI-Papers&Date)

---

## ğŸ“¬ Contact & Support

- ğŸ’¬ [GitHub Discussions](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ› [Issue Tracker](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- â­ Don't forget to star this repo!

---

<div align="center">

**Made with â¤ï¸ for the AI Community**

[â¬† Back to Top](#-daily-huggingface-ai-papers)

</div>
