<div align="center">

# ğŸ¤– Daily HuggingFace AI Papers

### ğŸ“Š Your Automated AI Research Companion

> **Never miss groundbreaking AI research again!** Get daily updates on the hottest papers from HuggingFace, automatically curated and archived. Perfect for researchers, ML engineers, and AI enthusiasts. ğŸ”¥

[![Update Daily](https://img.shields.io/badge/Update-Daily-brightgreen?style=for-the-badge&logo=github-actions)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/actions)
[![Papers Today](https://img.shields.io/badge/Papers%20Today-26-blue?style=for-the-badge&logo=arxiv)](data/latest.json)
[![Total Papers](https://img.shields.io/badge/Total%20Papers-1296+-orange?style=for-the-badge&logo=academia)](data/)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/AtharvaDomale/Daily-HuggingFace-AI-Papers?style=social)](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/stargazers)

**Automatically updated every day at 00:00 UTC** â°

[ğŸ“Š View Data](data/) | [ğŸ” Latest Papers](data/latest.json) | [ğŸ“… Archives](#-historical-archives) | [â­ Star This Repo](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers)

</div>

---

## ğŸ¯ Why This Repo?

- âœ… **Saves 30+ minutes** of daily paper hunting
- âœ… **Organized archives** - daily, weekly, and monthly snapshots
- âœ… **Direct links** to arXiv, PDFs, and GitHub repositories
- âœ… **Machine-readable JSON** format for easy integration
- âœ… **Zero maintenance** - fully automated via GitHub Actions
- âœ… **Historical data** - track AI research trends over time

---

## ğŸš€ Who Is This For?

<table>
<tr>
<td align="center">ğŸ”¬<br/><b>Researchers</b><br/>Stay current with latest developments</td>
<td align="center">ğŸ’¼<br/><b>ML Engineers</b><br/>Discover SOTA techniques</td>
<td align="center">ğŸ“š<br/><b>Students</b><br/>Learn from cutting-edge research</td>
</tr>
<tr>
<td align="center">ğŸ¢<br/><b>Companies</b><br/>Track AI trends & competition</td>
<td align="center">ğŸ“°<br/><b>Content Creators</b><br/>Find topics for blogs & videos</td>
<td align="center">ğŸ¤–<br/><b>AI Enthusiasts</b><br/>Explore the latest in AI</td>
</tr>
</table>

---

## âš¡ Quick Start

### 1ï¸âƒ£ Get Today's Papers (cURL)

```bash
curl https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json
```

### 2ï¸âƒ£ Python Integration

```python
import requests
import pandas as pd

# Load latest papers
url = "https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json"
papers = requests.get(url).json()

# Convert to DataFrame for analysis
df = pd.DataFrame(papers)
print(f"ğŸ“š Today's papers: {len(df)}")

# Filter by stars
trending = df[df['stars'].astype(int) > 10]
print(f"ğŸ”¥ Trending papers: {len(trending)}")
```

### 3ï¸âƒ£ JavaScript/Node.js

```javascript
const fetch = require('node-fetch');

async function getTodaysPapers() {
  const response = await fetch(
    'https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json'
  );
  const papers = await response.json();
  
  console.log(`ğŸ“š Found ${papers.length} papers today!`);
  papers.forEach(paper => {
    console.log(`\nğŸ“„ ${paper.title}`);
    console.log(`â­ ${paper.stars} stars`);
    console.log(`ğŸ”— ${paper.details.arxiv_page_url}`);
  });
}

getTodaysPapers();
```

---

## ğŸ“ˆ Statistics

<table>
<tr>
<td align="center"><b>ğŸ“„ Today</b><br/><font size="5">26</font><br/>papers</td>
<td align="center"><b>ğŸ“… This Week</b><br/><font size="5">129</font><br/>papers</td>
<td align="center"><b>ğŸ“† This Month</b><br/><font size="5">558</font><br/>papers</td>
<td align="center"><b>ğŸ—„ï¸ Total Archive</b><br/><font size="5">1296+</font><br/>papers</td>
</tr>
</table>

**Last Updated:** January 23, 2026

---

## ğŸ”¥ Today's Trending Papers

> Latest AI research papers from HuggingFace Papers, updated daily

<details>
<summary><b>1. Agentic Reasoning for Large Language Models</b> â­ 105</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.12538) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.12538) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.12538)

**ğŸ’» Code:** [â­ Code](https://github.com/weitianxin/Awesome-Agentic-Reasoning)

> ğŸŒ Awesome-Agentic-Reasoning GitHub Link: https://github.com/weitianxin/Awesome-Agentic-Reasoning

</details>

<details>
<summary><b>2. MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents</b> â­ 14</summary>

<br/>

**ğŸ‘¥ Authors:** Samiul Alam, Zhongwei Wan, Zixuan Zhong, Peizhou Huang, donghao-zhou

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.12346) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.12346) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.12346)

**ğŸ’» Code:** [â­ Code](https://github.com/AIoT-MLSys-Lab/MMDeepResearch-Bench)

> Introducing MMDeepResearch-Bench, a benchmark for multimodal deep research agents. Page: https://mmdeepresearch-bench.github.io/ Paper: https://arxiv.org/abs/2601.12346 Code: https://github.com/AIoT-MLSys-Lab/MMDeepResearch-Bench Dataset: https://...

</details>

<details>
<summary><b>3. Rethinking Video Generation Model for the Embodied World</b> â­ 7</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.15282) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.15282) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.15282)

**ğŸ’» Code:** [â­ Code](https://github.com/DAGroup-PKU/ReVidgen/)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Wow, wo, val! A Comprehensive Embodied World Model Evaluation Turing Test (...

</details>

<details>
<summary><b>4. Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance</b> â­ 146</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14171) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14171) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14171)

**ğŸ’» Code:** [â­ Code](https://github.com/AutoLab-SAI-SJTU/Paper2Rebuttal)

> RebuttalAgent is an AI-powered multi-agent system that helps researchers craft high-quality rebuttals for academic paper reviews. The system analyzes reviewer comments, searches relevant literature, generates rebuttal strategies, and produces form...

</details>

<details>
<summary><b>5. Behavior Knowledge Merge in Reinforced Agentic Models</b> â­ 1</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.13572) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.13572) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.13572)

**ğŸ’» Code:** [â­ Code](https://github.com/xiangchi-yuan/mrl)

> ğŸš€ TL;DR We introduce RAM (Reinforced Agent Merging) , a method designed to merge RL-trained agents into a single generalist model without retraining, outperforming the original specialized agents in their domains. ğŸ’¡ Key Insights The Problem: Stand...

</details>

<details>
<summary><b>6. Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14750) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14750) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14750)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Forest Before Trees: Latent Superposition for Efficient Visual Reasoning (2...

</details>

<details>
<summary><b>7. GutenOCR: A Grounded Vision-Language Front-End for Documents</b> â­ 2</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14490) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14490) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14490)

**ğŸ’» Code:** [â­ Code](https://github.com/Roots-Automation/GutenOCR)

> We're excited to share our first open model release, a grounded VLM for OCR applications!

</details>

<details>
<summary><b>8. Typhoon OCR: Open Vision-Language Model For Thai Document Extraction</b> â­ 85</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14722) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14722) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14722)

**ğŸ’» Code:** [â­ Code](https://github.com/scb-10x/typhoon-ocr)

> Document extraction is a core component of digital workflows, yet existing vision-language models (VLMs) predominantly favor high-resource languages. Thai presents additional challenges due to script complexity from non-latin letters, the absence ...

</details>

<details>
<summary><b>9. Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition</b> â­ 38</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.13044) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.13044) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.13044)

**ğŸ’» Code:** [â­ Code](https://github.com/scb-10x/typhoon-asr)

> Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains...

</details>

<details>
<summary><b>10. Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14027) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14027) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14027)

> Recommend to try our demo at: https://demo.projectnumina.ai/

</details>

<details>
<summary><b>11. FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning</b> â­ 141</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.11141) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.11141) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.11141)

**ğŸ’» Code:** [â­ Code](https://github.com/FlashLabs-AI-Corp/FlashLabs-Chroma)

> Some of the observations founded are :- -- End to end S2S advantage : Chroma 1.0 avoids cascaded ASR LLM TTS pipelines, reducing latency and preserving paralinguistic cues like timbre and prosody. -- High fidelity voice cloning : With only a few s...

</details>

<details>
<summary><b>12. FinVault: Benchmarking Financial Agent Safety in Execution-Grounded Environments</b> â­ 5</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.07853) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.07853) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.07853)

**ğŸ’» Code:** [â­ Code](https://github.com/aifinlab/FinVault)

> the first execution-grounded security benchmark for financial agents

</details>

<details>
<summary><b>13. Privacy Collapse: Benign Fine-Tuning Can Break Contextual Privacy in Language Models</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.15220) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.15220) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.15220)

**ğŸ’» Code:** [â­ Code](https://github.com/parameterlab/privacy-collapse)

> Privacy Collapse: Benign Fine-Tuning Can Break Contextual Privacy in Language Models Overview This paper identifies a critical new failure mode in language models called "privacy collapse" . The researchers demonstrate that benign, high-quality fi...

</details>

<details>
<summary><b>14. XR: Cross-Modal Agents for Composed Image Retrieval</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14245) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14245) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14245)

> project website: https://01yzzyu.github.io/xr.github.io/

</details>

<details>
<summary><b>15. RoboBrain 2.5: Depth in Sight, Time in Mind</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Yuheng Ji, Yijie Xu, Zhiyu Li, Huajie Tan, Zhoues

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14352) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14352) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14352)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Towards Cross-View Point Correspondence in Vision-Language Models (2025) Ac...

</details>

<details>
<summary><b>16. Quantifying Speaker Embedding Phonological Rule Interactions in Accented Speech Synthesis</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Jihwan Lee, Thanapat Trachu, Yoonjeong Lee, Thanathai Lertpetchpun, tiantiaf

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14417) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14417) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14417)

> Many spoken languages, including English, exhibit wide variation in dialects and accents, making accent control an important capability for flexible text-to-speech (TTS) models. Current TTS systems typically generate accented speech by conditionin...

</details>

<details>
<summary><b>17. Implicit Neural Representation Facilitates Unified Universal Vision Encoding</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Zhenheng Yang, Xuefeng Hu, Xiao Wang, Matthew Gwilliam

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14256) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14256) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14256)

**ğŸ’» Code:** [â­ Code](https://github.com/tiktok/huvr)

> Code: https://github.com/tiktok/huvr

</details>

<details>
<summary><b>18. AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization</b> â­ 3</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.13918) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.13918) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.13918)

**ğŸ’» Code:** [â­ Code](https://github.com/BlueZeros/AgentEHR)

> This paper presents AGENTEHR, a novel benchmark designed to bridge the gap between idealized experimental settings and realistic clinical environments. Unlike previous tasks that focus on factual retrieval (e.g., searching for a specific medicatio...

</details>

<details>
<summary><b>19. FARE: Fast-Slow Agentic Robotic Exploration</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Jingsong Liang, Shizhe Zhang, Jeric Lew, Xuxin Lv, Shuhao Liao

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14681) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14681) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14681)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API ORION: Option-Regularized Deep Reinforcement Learning for Cooperative Multi...

</details>

<details>
<summary><b>20. Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14152) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14152) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14152)

> Prompt order can break LMs performance â€” even with the same content.

</details>

<details>
<summary><b>21. The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Roman Bondar, Oleg Romanchuk

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.15059) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.15059) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.15059)

> Some of the observations founded are :- -- Authority capacity mismatch is structural : Decisions are formally approved by humans, but the epistemic capacity to understand those decisions does not scale with agent generated throughput, creating a s...

</details>

<details>
<summary><b>22. Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Arpit Narechania, Yanwei Huang

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.15100) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.15100) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.15100)

> This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Developer Interaction Patterns with Proactive AI: A Five-Day Field Study (2...

</details>

<details>
<summary><b>23. Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis</b> â­ 0</summary>

<br/>

**ğŸ‘¥ Authors:** Anpei Chen, Zexiang Xu, Youjia Zhang, Xingyu Chen, Hongyuan Chen

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.14253) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.14253) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.14253)

> No abstract available.

</details>

<details>
<summary><b>24. sangkuriang: A pseudo-spectral Python library for Korteweg-de Vries soliton simulation</b> â­ 5</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.12029) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.12029) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.12029)

**ğŸ’» Code:** [â­ Code](https://github.com/sandyherho/sangkuriang-ideal-solver)

> Korteweg-de Vries (KdV) equation serves as a foundational model in nonlinear wave physics, describing the balance between dispersive spreading and nonlinear steepening that gives rise to solitons. This article introduces sangkuriang, an open-sourc...

</details>

<details>
<summary><b>25. Show me the evidence: Evaluating the role of evidence and natural language explanations in AI-supported fact-checking</b> â­ 0</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.11387) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.11387) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.11387)

> TL;DR: In an AI-supported fact-checking task, people consistently relied on underlying evidence to judge AI reliability, using explanations as a supplement rather than a substitute, showing that evidence is central to how people evaluate AI-aided ...

</details>

<details>
<summary><b>26. CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning</b> â­ 3</summary>

<br/>

**ğŸ”— Links:** [ğŸ¤— HuggingFace](https://huggingface.co/papers/2601.13262) â€¢ [ğŸ“„ arXiv](https://arxiv.org/abs/2601.13262) â€¢ [ğŸ“¥ PDF](https://arxiv.org/pdf/2601.13262)

**ğŸ’» Code:** [â­ Code](https://github.com/AikyamLab/cure-med)

> We introduce CURE-MED, a curriculum-informed reinforcement learning framework for multilingual medical reasoning across 13 languages, including low-resource settings. The work studies how code-switching-aware supervision and curriculum-guided RL j...

</details>

---

## ğŸ“… Historical Archives

### ğŸ“Š Quick Access

| Type | Link | Papers |
|------|------|--------|
| ğŸ• Latest | [`latest.json`](data/latest.json) | 26 |
| ğŸ“… Today | [`2026-01-23.json`](data/daily/2026-01-23.json) | 26 |
| ğŸ“† This Week | [`2026-W03.json`](data/weekly/2026-W03.json) | 129 |
| ğŸ—“ï¸ This Month | [`2026-01.json`](data/monthly/2026-01.json) | 558 |

### ğŸ“œ Recent Days

| Date | Papers | Link |
|------|--------|------|
| ğŸ“Œ 2026-01-23 | 26 | [View JSON](data/daily/2026-01-23.json) |
| ğŸ“„ 2026-01-22 | 32 | [View JSON](data/daily/2026-01-22.json) |
| ğŸ“„ 2026-01-21 | 11 | [View JSON](data/daily/2026-01-21.json) |
| ğŸ“„ 2026-01-20 | 22 | [View JSON](data/daily/2026-01-20.json) |
| ğŸ“„ 2026-01-19 | 38 | [View JSON](data/daily/2026-01-19.json) |
| ğŸ“„ 2026-01-18 | 38 | [View JSON](data/daily/2026-01-18.json) |
| ğŸ“„ 2026-01-17 | 38 | [View JSON](data/daily/2026-01-17.json) |

### ğŸ“š Weekly Archives

| Week | Papers | Link |
|------|--------|------|
| ğŸ“… 2026-W03 | 129 | [View JSON](data/weekly/2026-W03.json) |
| ğŸ“… 2026-W02 | 232 | [View JSON](data/weekly/2026-W02.json) |
| ğŸ“… 2026-W01 | 156 | [View JSON](data/weekly/2026-W01.json) |
| ğŸ“… 2026-W00 | 41 | [View JSON](data/weekly/2026-W00.json) |

### ğŸ—‚ï¸ Monthly Archives

| Month | Papers | Link |
|------|--------|------|
| ğŸ—“ï¸ 2026-01 | 558 | [View JSON](data/monthly/2026-01.json) |
| ğŸ—“ï¸ 2025-12 | 787 | [View JSON](data/monthly/2025-12.json) |

---

## âœ¨ Features

- ğŸ”„ **Automated Daily Updates** - Runs every day at midnight UTC
- ğŸ“Š **Comprehensive Data** - Abstracts, authors, links, and metadata
- ğŸ—„ï¸ **Historical Archives** - Daily, weekly, and monthly snapshots
- ğŸ”— **Direct Links** - arXiv, PDF, GitHub repos, and HuggingFace pages
- ğŸ“ˆ **Trending Papers** - Star counts and popularity metrics
- ğŸ’¾ **JSON Format** - Easy to parse and integrate into your projects
- ğŸ¨ **Clean Interface** - Beautiful, organized README

---

## ğŸš€ Usage

### View Papers

- **Latest Papers**: Check this README (updated daily)
- **JSON Data**: Download from [`data/latest.json`](data/latest.json)
- **Historical Data**: Browse the [`data/`](data/) directory

### Integrate Into Your Project

```python
import requests

# Get latest papers
response = requests.get('https://raw.githubusercontent.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/main/data/latest.json')
papers = response.json()

for paper in papers:
    print(f"Title: {paper['title']}")
    print(f"arXiv: {paper['details']['arxiv_page_url']}")
    print(f"PDF: {paper['details']['pdf_url']}")
```

### Use as RSS Alternative

Monitor this repo for daily AI paper updates:
- â­ Star this repository
- ğŸ‘€ Watch for notifications
- ğŸ”” Enable "All Activity" for daily updates

---

## ğŸ“Š Data Structure

```
data/
â”œâ”€â”€ daily/              # Individual day snapshots
â”‚   â”œâ”€â”€ 2024-12-04.json
â”‚   â”œâ”€â”€ 2024-12-05.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ weekly/             # Cumulative weekly papers
â”‚   â”œâ”€â”€ 2024-W48.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ monthly/            # Cumulative monthly papers
â”‚   â”œâ”€â”€ 2024-12.json
â”‚   â””â”€â”€ ...
â””â”€â”€ latest.json         # Most recent scrape
```

### JSON Schema

```json
{
  "title": "Paper Title",
  "paper_url": "https://huggingface.co/papers/...",
  "authors": ["Author 1", "Author 2"],
  "stars": "42",
  "scraped_date": "2024-12-04",
  "details": {
    "abstract": "Paper abstract...",
    "arxiv_page_url": "https://arxiv.org/abs/...",
    "pdf_url": "https://arxiv.org/pdf/...",
    "github_links": ["https://github.com/..."],
    "metadata": {}
  }
}
```

---

## ğŸ› ï¸ How It Works

This repository uses:

- **[Crawl4AI](https://github.com/unclecode/crawl4ai)** - Modern web scraping framework
- **[BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)** - HTML parsing
- **[GitHub Actions](https://github.com/features/actions)** - Automated daily runs
- **Python 3.11+** - Data processing and generation

### Workflow

1. ğŸ• GitHub Actions triggers at 00:00 UTC daily
2. ğŸ” Scrapes HuggingFace Papers page
3. ğŸ“¥ Downloads detailed info for each paper
4. ğŸ’¾ Saves to daily/weekly/monthly archives
5. ğŸ“ Generates this beautiful README
6. âœ… Commits and pushes updates

---

## ğŸ¤ Contributing

Found a bug or have a feature request? 

- ğŸ› [Report Issues](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- ğŸ’¡ [Submit Ideas](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ”§ [Pull Requests Welcome](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/pulls)

---

## ğŸ“œ License

MIT License - feel free to use this data for your own projects!

See [LICENSE](LICENSE) for more details.

---

## ğŸŒŸ Star History

If you find this useful, please consider giving it a star! â­

[![Star History Chart](https://api.star-history.com/svg?repos=AtharvaDomale/Daily-HuggingFace-AI-Papers&type=Date)](https://star-history.com/#AtharvaDomale/Daily-HuggingFace-AI-Papers&Date)

---

## ğŸ“¬ Contact & Support

- ğŸ’¬ [GitHub Discussions](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/discussions)
- ğŸ› [Issue Tracker](https://github.com/AtharvaDomale/Daily-HuggingFace-AI-Papers/issues)
- â­ Don't forget to star this repo!

---

<div align="center">

**Made with â¤ï¸ for the AI Community**

[â¬† Back to Top](#-daily-huggingface-ai-papers)

</div>
