[
  {
    "title": "UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement",
    "paper_url": "https://huggingface.co/papers/2512.21185",
    "authors": [
      "Yang Li",
      "Dehao Hao",
      "LutaoJiang",
      "StarYDY",
      "infinith"
    ],
    "stars": "110",
    "details": {
      "title": "UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement",
      "abstract": "Github: https://github.com/PKU-YuanGroup/UltraShape-1.0 Project Page: https://pku-yuangroup.github.io/UltraShape-1.0/",
      "arxiv_page_url": "https://arxiv.org/abs/2512.21185",
      "pdf_url": "https://arxiv.org/pdf/2512.21185",
      "github_links": [
        "https://github.com/PKU-YuanGroup/UltraShape-1.0"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.21185",
      "scraped_at": "2026-01-01T01:59:26.540091"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "DreamOmni3: Scribble-based Editing and Generation",
    "paper_url": "https://huggingface.co/papers/2512.22525",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DreamOmni3: Scribble-based Editing and Generation",
      "abstract": "Github: https://github.com/dvlab-research/DreamOmni3",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22525",
      "pdf_url": "https://arxiv.org/pdf/2512.22525",
      "github_links": [
        "https://github.com/dvlab-research/DreamOmni3"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22525",
      "scraped_at": "2026-01-01T01:59:28.344263"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "End-to-End Test-Time Training for Long Context",
    "paper_url": "https://huggingface.co/papers/2512.23675",
    "authors": [
      "Marcel R√∏d",
      "Daniel Koceja",
      "Xinhao Li",
      "Karan Dalal",
      "Arnuv Tandon"
    ],
    "stars": "96",
    "details": {
      "title": "End-to-End Test-Time Training for Long Context",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Sliding Window Attention Adaptation (2025) Let's (not) just put things in Context: Test-Time Training for Long-Context LLMs (2025) Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models (2025) Attention and Compression is all you need for Controllably Efficient Language Models (2025) Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings (2025) Data-Free Pruning of Self-Attention Layers in LLMs (2025) Architectural Trade-offs in Small Language Models Under Compute Constraints (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23675",
      "pdf_url": "https://arxiv.org/pdf/2512.23675",
      "github_links": [
        "https://github.com/test-time-training/e2e"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23675",
      "scraped_at": "2026-01-01T01:59:30.184972"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "Evaluating Parameter Efficient Methods for RLVR",
    "paper_url": "https://huggingface.co/papers/2512.23165",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Evaluating Parameter Efficient Methods for RLVR",
      "abstract": "https://www.alphaxiv.org/abs/2512.23165",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23165",
      "pdf_url": "https://arxiv.org/pdf/2512.23165",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23165",
      "scraped_at": "2026-01-01T01:59:31.986046"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization",
    "paper_url": "https://huggingface.co/papers/2512.22469",
    "authors": [
      "Wei Zhang",
      "Aofan Liu",
      "Pengfei Gao",
      "Wei Liu",
      "pengchao"
    ],
    "stars": "0",
    "details": {
      "title": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization",
      "abstract": "Issues describe symptoms‚Äîthe real buggy code is often hidden behind multi-hop dependencies. GraphLocator moves beyond relevance retrieval by explicitly modelling causal structure: decomposing sub-problems, capturing causal dependencies, and performing constrained causal reasoning over code dependency graphs. Across multiple Python and Java datasets, GraphLocator significantly improves function-level recall and precision, and the inferred causal structures further boost downstream issue resolution by +28.74%.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22469",
      "pdf_url": "https://arxiv.org/pdf/2512.22469",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22469",
      "scraped_at": "2026-01-01T01:59:33.772256"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks",
    "paper_url": "https://huggingface.co/papers/2512.22206",
    "authors": [
      "Yogeswar"
    ],
    "stars": "0",
    "details": {
      "title": "CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks",
      "abstract": "\"I introduce CosineGate, a SOTA dynamic routing mechanism for ResNets that uses the Cosine Incompatibility Ratio (CIR) as a self-supervised signal. üöÄ Why it matters: It matches ResNet-20 accuracy on CIFAR-10 while slashing computation by 28.5%‚Äîwithout needing extra 'predictor' sub-networks or distillation. üõ†Ô∏è Key Features: Fully differentiable (via Gumbel-Softmax). Bio-inspired (Predictive Coding). Plug-and-play for efficient computer vision. Check out our GitHub Repo linked in the sidebar for the implementation!\"",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22206",
      "pdf_url": "https://arxiv.org/pdf/2512.22206",
      "github_links": [
        "https://github.com/thotayogeswarreddy/CosineGate"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22206",
      "scraped_at": "2026-01-01T01:59:35.535486"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
    "paper_url": "https://huggingface.co/papers/2512.21008",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
      "abstract": "Mixture-of-Experts (MoE) architectures have advanced the scaling of Large Language Models (LLMs) by activating only a sparse subset of parameters per input, enabling state-of-the-art performance with reduced computational cost. As these models are increasingly deployed in critical domains, understanding and strengthening their alignment mechanisms is essential to prevent harmful outputs. However, existing LLM safety research has focused almost exclusively on dense architectures, leaving the unique safety properties of MoEs largely unexamined. The modular, sparsely-activated design of MoEs suggests that safety mechanisms may operate differently than in dense models, raising questions about their robustness. In this paper, we present GateBreaker, the first training-free, lightweight, and architecture-agnostic attack framework that compromises the safety alignment of modern MoE LLMs at inference time. GateBreaker operates in three stages: (i) gate-level profiling, which identifies safety experts disproportionately routed on harmful inputs, (ii) expert-level localization, which localizes the safety structure within safety experts, and (iii) targeted safety removal, which disables the identified safety structure to compromise the safety alignment. Our study shows that MoE safety concentrates within a small subset of neurons coordinated by sparse routing. Selective disabling of these neurons, approximately 3% of neurons in the targeted expert layers, significantly increases the averaged attack success rate (ASR) from 7.4% to 64.9% against the eight latest aligned MoE LLMs with limited utility degradation. These safety neurons transfer across models within the same family, raising ASR from 17.9% to 67.7% with one-shot transfer attack. Furthermore, GateBreaker generalizes to five MoE vision language models (VLMs) with 60.9% ASR on unsafe image inputs.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.21008",
      "pdf_url": "https://arxiv.org/pdf/2512.21008",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.21008",
      "scraped_at": "2026-01-01T01:59:37.334356"
    },
    "scraped_date": "2026-01-01"
  }
]