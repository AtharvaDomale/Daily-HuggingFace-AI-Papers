[
  {
    "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
    "paper_url": "https://huggingface.co/papers/2601.22027",
    "authors": [],
    "stars": "15",
    "details": {
      "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
      "abstract": "Why is this gap widening? Frontier models like Claude-Opus-4.6 are crushing base task performance (80%), but hallucination resistance (48%) and disambiguation (46%) lag far behind. What's preventing models from learning when to say 'I need more information' or 'I cannot help with this' as quickly as they learn to complete tasks?",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22027",
      "pdf_url": "https://arxiv.org/pdf/2601.22027",
      "github_links": [
        "https://github.com/CAR-bench/car-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22027",
      "scraped_at": "2026-02-09T02:25:57.133157"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
    "paper_url": "https://huggingface.co/papers/2602.05386",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
      "abstract": "Endow AI Agents with \"Spider-Sense\"! Spider-Sense: Pioneering Intrinsic Risk Sensing, Reducing Defense Delay to 8.3%",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05386",
      "pdf_url": "https://arxiv.org/pdf/2602.05386",
      "github_links": [
        "https://github.com/aifinlab/Spider-Sense"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05386",
      "scraped_at": "2026-02-09T02:25:59.221369"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
    "paper_url": "https://huggingface.co/papers/2602.05261",
    "authors": [
      "Zhixiong Zeng",
      "Siqi Yang",
      "Peng Shi",
      "Youyang Yin",
      "liufanfanlff"
    ],
    "stars": "7",
    "details": {
      "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
      "abstract": "We introduce Length-Unbiased Sequence Policy Optimization (LUSPO), a novel reinforcement learning algorithm for training large language models. LUSPO consistently outperforms GRPO and GSPO on both dense small-scale models and large-scale MoE models.  github: https://github.com/murphy4122/LUSPO",
      "arxiv_page_url": "https://arxiv.org/abs/2504.06037",
      "pdf_url": "https://arxiv.org/pdf/2602.05261",
      "github_links": [
        "https://github.com/murphy4122/LUSPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05261",
      "scraped_at": "2026-02-09T02:26:01.214991"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
    "paper_url": "https://huggingface.co/papers/2602.02474",
    "authors": [],
    "stars": "30",
    "details": {
      "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
      "abstract": "Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \\textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \\emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \\emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \\emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents. Code is available at https://github.com/ViktorAxelsen/MemSkill",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02474",
      "pdf_url": "https://arxiv.org/pdf/2602.02474",
      "github_links": [
        "https://github.com/ViktorAxelsen/MemSkill"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02474",
      "scraped_at": "2026-02-09T02:26:03.188183"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
    "paper_url": "https://huggingface.co/papers/2602.06036",
    "authors": [],
    "stars": "504",
    "details": {
      "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference (2026) Fast and Accurate Causal Parallel Decoding using Jacobi Forcing (2025) PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length (2026) P-EAGLE: Parallel-Drafting EAGLE with Scalable Training (2026) Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs (2025) MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification (2026) TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06036",
      "pdf_url": "https://arxiv.org/pdf/2602.06036",
      "github_links": [
        "https://github.com/z-lab/dflash"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06036",
      "scraped_at": "2026-02-09T02:26:05.208474"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
    "paper_url": "https://huggingface.co/papers/2602.06028",
    "authors": [],
    "stars": "43",
    "details": {
      "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
      "abstract": "project page: https://chenshuo20.github.io/Context_Forcing/ code: https://github.com/TIGER-AI-Lab/Context-Forcing",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06028",
      "pdf_url": "https://arxiv.org/pdf/2602.06028",
      "github_links": [
        "https://github.com/TIGER-AI-Lab/Context-Forcing"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06028",
      "scraped_at": "2026-02-09T02:26:08.102306"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
    "paper_url": "https://huggingface.co/papers/2602.05986",
    "authors": [
      "Zicheng Zhang",
      "Xiangyu Zhao",
      "Shibei Meng",
      "Shuran Ma",
      "Mingxin Liu"
    ],
    "stars": "20",
    "details": {
      "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
      "abstract": "Despite strong visual realism, we find that current text-image-to-video models frequently fail to respect implicit world rules when generating complex scenarios. We introduce RISE-Video to systematically evaluate reasoning fidelity in video generation and reveal persistent reasoning gaps across state-of-the-art models. Code: https://github.com/VisionXLab/Rise-Video Data: https://huggingface.co/datasets/VisionXLab/RISE-Video",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05986",
      "pdf_url": "https://arxiv.org/pdf/2602.05986",
      "github_links": [
        "https://github.com/VisionXLab/Rise-Video"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05986",
      "scraped_at": "2026-02-09T02:26:10.087429"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
    "paper_url": "https://huggingface.co/papers/2602.03338",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
      "abstract": "Accurate LLM critics do not guarantee safe intervention: like relentless contradiction, they can derail trajectories that would have succeeded. Despite strong offline accuracy (AUROC 0.94), a binary critic causes outcomes ranging from a 26-pp collapse to no effect at all, exposing a fundamental disruption‚Äìrecovery tradeoff. Our lightweight pre-deployment test anticipates these failures, showing that the main benefit of intervention is knowing when to avoid it.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03338",
      "pdf_url": "https://arxiv.org/pdf/2602.03338",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03338",
      "scraped_at": "2026-02-09T02:26:12.092041"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
    "paper_url": "https://huggingface.co/papers/2602.05885",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
      "abstract": "High-quality kernel is critical for scalable AI systems, and enabling LLMs to generate such code would advance AI development. However, training LLMs for this task requires sufficient data, a robust environment, and the process is often vulnerable to reward hacking and lazy optimization. In these cases, models may hack training rewards and prioritize trivial correctness over meaningful speedup. In this paper, we systematically study reinforcement learning (RL) for kernel generation. We first design KernelGYM, a robust distributed GPU environment that supports reward hacking check, data collection from multi-turn interactions and long-term RL training. Building on KernelGYM , we investigate effective multi-turn RL methods and identify a biased policy gradient issue caused by self-inclusion in GRPO. To solve this, we propose Turn-level Reinforce-Leave-One-Out ( TRLOO ) to provide unbiased advantage estimation for multi-turn RL. To alleviate lazy optimization, we incorporate mismatch correction for training stability and introduce Profiling-based Rewards ( PR ) and Profiling-based Rejection Sampling ( PRS ) to overcome the issue. The trained model, this Dr. Kernel-14B, reaches performance competitive with Claude-4.5-Sonnet in Kernelbench. Finally, we study sequential test-time scaling for this Dr. Kernel-14B. On the KernelBench Level-2 subset, 31.6% of the generated kernels achieve at least a 1.2x speedup over the Torch reference, surpassing Claude-4.5-Sonnet (26.7%) and GPT-5 (28.6%). When selecting the best candidate across all turns, this 1.2x speedup rate further increases to 47.8%. All resources, including environment, training code, models, and dataset, are included in this hkust-nlp/KernelGYM .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05885",
      "pdf_url": "https://arxiv.org/pdf/2602.05885",
      "github_links": [
        "https://github.com/hkust-nlp/KernelGYM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05885",
      "scraped_at": "2026-02-09T02:26:14.137114"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "ProAct: Agentic Lookahead in Interactive Environments",
    "paper_url": "https://huggingface.co/papers/2602.05327",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "ProAct: Agentic Lookahead in Interactive Environments",
      "abstract": "ProAct trains LLM-based agents to perform accurate lookahead planning in interactive environments via Grounded LookAhead Distillation and a Monte-Carlo Critic, improving long-horizon decision accuracy.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05327",
      "pdf_url": "https://arxiv.org/pdf/2602.05327",
      "github_links": [
        "https://github.com/GreatX3/ProAct"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05327",
      "scraped_at": "2026-02-09T02:26:16.124309"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
    "paper_url": "https://huggingface.co/papers/2602.06035",
    "authors": [
      "Xiaohan Fei",
      "Xialin He",
      "Morteza Ziyadi",
      "Samuel Schulter",
      "xusirui"
    ],
    "stars": "0",
    "details": {
      "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
      "abstract": "Distillation reconstructs motor skills, while RL fine-tuning interpolates and consolidates the latent space into a coherent skill manifold for versatile whole-body loco-manipulation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06035",
      "pdf_url": "https://arxiv.org/pdf/2602.06035",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06035",
      "scraped_at": "2026-02-09T02:26:18.070870"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Privileged Information Distillation for Language Models",
    "paper_url": "https://huggingface.co/papers/2602.04942",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Privileged Information Distillation for Language Models",
      "abstract": "Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at inference time remains a fundamental challenge. We study this problem in the context of distilling frontier models for multi-turn agentic environments, where closed-source systems typically hide their internal reasoning and expose only action trajectories. This breaks standard distillation pipelines, since successful behavior is observable but the reasoning process is not. For this, we introduce {\\pi}-Distill, a joint teacher-student objective that trains a PI-conditioned teacher and an unconditioned student simultaneously using the same model. Additionally, we also introduce On-Policy Self-Distillation (OPSD), an alternative approach that trains using Reinforcement Learning (RL) with a reverse KL-penalty between the student and the PI-conditioned teacher. We show that both of these algorithms effectively distill frontier agents using action-only PI. Specifically we find that {\\pi}-Distill and in some cases OPSD, outperform industry standard practices (Supervised finetuning followed by RL) that assume access to full Chain-of-Thought supervision across multiple agentic benchmarks, models, and forms of PI. We complement our results with extensive analysis that characterizes the factors enabling effective learning with PI, focusing primarily on {\\pi}-Distill and characterizing when OPSD is competitive.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04942",
      "pdf_url": "https://arxiv.org/pdf/2602.04942",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04942",
      "scraped_at": "2026-02-09T02:26:20.028100"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Reinforcement World Model Learning for LLM-based Agents",
    "paper_url": "https://huggingface.co/papers/2602.05842",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reinforcement World Model Learning for LLM-based Agents",
      "abstract": "Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and œÑ2 Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and œÑ2 Bench respectively, while matching the performance of expert-data training.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05842",
      "pdf_url": "https://arxiv.org/pdf/2602.05842",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05842",
      "scraped_at": "2026-02-09T02:26:21.986457"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Semantic Search over 9 Million Mathematical Theorems",
    "paper_url": "https://huggingface.co/papers/2602.05216",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Semantic Search over 9 Million Mathematical Theorems",
      "abstract": "Mathematicians and math prover agents need fast and efficient theorem search. We release Theorem Search over all of arXiv, the Stacks Project, and six other sources. Our search is 2x more accurate than frontier LLMs, with only 4 second latency. Feedback is welcome! Model Hit@10 Google Search 0.378 Chat-GPT 5.2 0.180 Gemini 3 Pro 0.252 Ours 0.432 / 0.505 Blue : theorem-level results Red : paper-level results",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05216",
      "pdf_url": "https://arxiv.org/pdf/2602.05216",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05216",
      "scraped_at": "2026-02-09T02:26:23.970696"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
    "paper_url": "https://huggingface.co/papers/2601.21937",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
      "abstract": "Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21937",
      "pdf_url": "https://arxiv.org/pdf/2601.21937",
      "github_links": [
        "https://github.com/Retrieval-Infused-Reasoning-Sandbox/Retrieval-Infused-Reasoning-Sandbox"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21937",
      "scraped_at": "2026-02-09T02:26:26.032710"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
    "paper_url": "https://huggingface.co/papers/2601.21296",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
      "abstract": "Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21296",
      "pdf_url": "https://arxiv.org/pdf/2601.21296",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21296",
      "scraped_at": "2026-02-09T02:26:28.034534"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
    "paper_url": "https://huggingface.co/papers/2602.05115",
    "authors": [
      "Tal August",
      "Haofei Yu",
      "Chongrui Ye",
      "Pengda Wang",
      "Keyang Xuan"
    ],
    "stars": "0",
    "details": {
      "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
      "abstract": "Interesting work, Keyang",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05115",
      "pdf_url": "https://arxiv.org/pdf/2602.05115",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05115",
      "scraped_at": "2026-02-09T02:26:30.065499"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Steering LLMs via Scalable Interactive Oversight",
    "paper_url": "https://huggingface.co/papers/2602.04210",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Steering LLMs via Scalable Interactive Oversight",
      "abstract": "As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04210",
      "pdf_url": "https://arxiv.org/pdf/2602.04210",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04210",
      "scraped_at": "2026-02-09T02:26:31.995815"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Reinforced Attention Learning",
    "paper_url": "https://huggingface.co/papers/2602.04884",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reinforced Attention Learning",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04884",
      "pdf_url": "https://arxiv.org/pdf/2602.04884",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04884",
      "scraped_at": "2026-02-09T02:26:34.030259"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.21037",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning",
      "abstract": "Project Page: https://thinking-in-frames.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21037",
      "pdf_url": "https://arxiv.org/pdf/2601.21037",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21037",
      "scraped_at": "2026-02-09T02:26:35.962580"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
    "paper_url": "https://huggingface.co/papers/2602.03036",
    "authors": [
      "Zefeng He",
      "Yafu Li",
      "Xiangyuan Xue",
      "Guibin Zhang",
      "Muxin Fu"
    ],
    "stars": "21",
    "details": {
      "title": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
      "abstract": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03036",
      "pdf_url": "https://arxiv.org/pdf/2602.03036",
      "github_links": [
        "https://github.com/KANABOON1/LatentMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03036",
      "scraped_at": "2026-02-09T02:26:37.967540"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
    "paper_url": "https://huggingface.co/papers/2602.05975",
    "authors": [
      "Chen Zhao",
      "Arman Cohan",
      "Canyu Zhang",
      "yilunzhao",
      "HughieHu"
    ],
    "stars": "0",
    "details": {
      "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
      "abstract": "Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000-paper retrieval corpus. We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e. ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05975",
      "pdf_url": "https://arxiv.org/pdf/2602.05975",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05975",
      "scraped_at": "2026-02-09T02:26:39.947914"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
    "paper_url": "https://huggingface.co/papers/2602.06040",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
      "abstract": "Project Page: https://accio-lab.github.io/SwimBird Github Repo: https://github.com/Accio-Lab/SwimBird HuggingFace: https://huggingface.co/datasets/Accio-Lab/SwimBird-SFT-92K",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06040",
      "pdf_url": "https://arxiv.org/pdf/2602.06040",
      "github_links": [
        "https://github.com/Accio-Lab/SwimBird"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06040",
      "scraped_at": "2026-02-09T02:26:42.021252"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
    "paper_url": "https://huggingface.co/papers/2602.05073",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
      "abstract": "A foundation and perspective for uncertainty quantification of LLM agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05073",
      "pdf_url": "https://arxiv.org/pdf/2602.05073",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05073",
      "scraped_at": "2026-02-09T02:26:43.957817"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
    "paper_url": "https://huggingface.co/papers/2602.02016",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
      "abstract": "We propose DASH ( D istributed A ccelerated SH ampoo), a faster and more accurate version of Distributed Shampoo. To make it faster, we stack the blocks extracted from the preconditioners to obtain a 3D tensor, which are inverted efficiently using batch-matmuls via iterative procedures. To make it more accurate, we introduce an existing iterative method from Numerical Linear Algebra called Newton-DB, which is more accurate than the existing Coupled Newton implemented in Distributed Shampoo. These iterative procedures usually require the largest eigen-value of the input matrix to be upper bounded by 1, which should be obtained by scaling the input matrix. In theory, one should divide by the true largest eigen-value of the matrix, which is expensive to compute in Distributed Shampoo. Before our work, the simplest scaling was Frobenius norm, which is usually much larger than the largest eigen-value. Since we work with all blocks in parallel in a stacked form, our implementation allows running Power-Iteration to estimate the largest eigen-value for all blocks in one shot. Why is this better? When we scale the input matrix by Frobenius norm, the spectrum is shifted towards zero. We show that iterative procedures require more steps to converge for small eigen-values compared to larger ones. Therefore, scaling by an approximation of the largest eigen-value is desired and in our DASH implementation this is cheaper and therefore leads to faster training and more accurate models. If you want to find out more, check out our paper and our DASH repository .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02016",
      "pdf_url": "https://arxiv.org/pdf/2602.02016",
      "github_links": [
        "https://github.com/IST-DASLab/DASH"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02016",
      "scraped_at": "2026-02-09T02:26:45.978418"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "BABE: Biology Arena BEnchmark",
    "paper_url": "https://huggingface.co/papers/2602.05857",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "BABE: Biology Arena BEnchmark",
      "abstract": "BABE is a biology benchmark that evaluates AI models' experimental reasoning across papers and real studies, stressing cross-scale causal inference and practical scientific reasoning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05857",
      "pdf_url": "https://arxiv.org/pdf/2602.05857",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05857",
      "scraped_at": "2026-02-09T02:26:47.937659"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.06034",
    "authors": [
      "Zeyu Zhang",
      "Xi Xiao",
      "Dezhao SU",
      "Chaoyang Wang",
      "Dongyang Chen"
    ],
    "stars": "19",
    "details": {
      "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
      "abstract": "Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches remain largely language-driven, relying on static visual encodings and lacking the ability to actively verify fine-grained visual evidence, which often leads to speculative reasoning in visually ambiguous cases. We propose V-Retrver, an evidence-driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection. V-Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence-gathering retrieval agent, we adopt a curriculum-based learning strategy combining supervised reasoning activation, rejection-based refinement, and reinforcement learning with an evidence-aligned objective. Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average), perception-driven reasoning reliability, and generalization.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06034",
      "pdf_url": "https://arxiv.org/pdf/2602.06034",
      "github_links": [
        "https://github.com/chendy25/V-Retrver"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06034",
      "scraped_at": "2026-02-09T02:26:49.886751"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
    "paper_url": "https://huggingface.co/papers/2602.05547",
    "authors": [
      "Zhiyong Wang",
      "Sangwoong Yoon",
      "Matthieu Zimmer",
      "Xiaotong Ji",
      "Shyam Sundhar Ramesh"
    ],
    "stars": "0",
    "details": {
      "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
      "abstract": "We propose a novel technique for multitask learning with GRPO without forgetting about worst-case tasks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05547",
      "pdf_url": "https://arxiv.org/pdf/2602.05547",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05547",
      "scraped_at": "2026-02-09T02:26:51.830798"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
    "paper_url": "https://huggingface.co/papers/2602.05933",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
      "abstract": "Reproduce Kimi K1.5/K2 RL algorithm and theoretically understand PMD as regularization in LLM post training",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05933",
      "pdf_url": "https://arxiv.org/pdf/2602.05933",
      "github_links": [
        "https://github.com/horizon-rl/OpenKimi"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05933",
      "scraped_at": "2026-02-09T02:26:53.781707"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better",
    "paper_url": "https://huggingface.co/papers/2602.05393",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better",
      "abstract": "arXivLens breakdown of this paper üëâ https://arxivlens.com/PaperView/Details/late-to-early-training-let-llms-learn-earlier-so-faster-and-better-8353-cc1b8d02 Executive Summary Detailed Breakdown Practical Applications",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05393",
      "pdf_url": "https://arxiv.org/pdf/2602.05393",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05393",
      "scraped_at": "2026-02-09T02:26:55.748566"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
    "paper_url": "https://huggingface.co/papers/2602.05258",
    "authors": [],
    "stars": "5",
    "details": {
      "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
      "abstract": "[Paper] [HF checkpoints] CoPE is a plug-and-play enhancement of RoPE that softly clips the unstable low-frequency components, delivering consistent gains both within the training context and during long-context extrapoaltion . With a simple yet effective soft clipping strategy, CoPE 1Ô∏è‚É£ Eliminates severe OOD outliers , whose periods exceed the pre-training context window and are the primary cause of OOD extrapolation. 2Ô∏è‚É£ Refines Long-range Semantic Signals by alleviating the secret long-term decay of semantic attention introduced by RoPE. 3Ô∏è‚É£ Prevents Spectral Leakage induced by hard frequency truncation, which otherwise leads to long-range oscillatory ringing in the attention scores across relative token distances and introduces spurious correlations.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05258",
      "pdf_url": "https://arxiv.org/pdf/2602.05258",
      "github_links": [
        "https://github.com/hrlics/CoPE"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05258",
      "scraped_at": "2026-02-09T02:26:57.697718"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
    "paper_url": "https://huggingface.co/papers/2602.02393",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
      "abstract": "Project Page: https://rq-wu.github.io/projects/infinite-world/index.html",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02393",
      "pdf_url": "https://arxiv.org/pdf/2602.02393",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02393",
      "scraped_at": "2026-02-09T02:26:59.677889"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
    "paper_url": "https://huggingface.co/papers/2602.01965",
    "authors": [
      "Qintian Guo",
      "Yingli Zhou",
      "Boyu Ruan",
      "Fangyuan Zhang",
      "Jimlkh"
    ],
    "stars": "0",
    "details": {
      "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
      "abstract": "This paper addresses a fundamental limitation in graph-based retrieval-augmented generation (RAG) systems, which we characterize as the \"Static Graph Fallacy.\" While recent methods have successfully utilized Knowledge Graphs (KGs) to capture multi-hop dependencies, the reliance on fixed transition probabilities often results in semantic drift, where retrieval is diverted toward high-degree \"hub\" nodes rather than relevant evidence. CatRAG introduces a context-aware traversal framework that transforms the static KG into a query-adaptive navigation structure. By integrating symbolic anchoring and dynamic edge weighting, the system effectively prunes irrelevant paths and amplifies those aligned with the query‚Äôs specific intent. A key finding of our work is that while standard recall metrics show modest gains, there is a significant improvement in \"reasoning completeness\"‚Äîthe ability to recover the entire evidence chain without gaps. This shift from partial context retrieval to grounded reasoning paths is a necessary step for robust multi-hop RAG. We look forward to discussing the implications of dynamic graph steering and how these techniques might scale to increasingly large and heterogeneous knowledge structures.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01965",
      "pdf_url": "https://arxiv.org/pdf/2602.01965",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01965",
      "scraped_at": "2026-02-09T02:27:01.669930"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation",
    "paper_url": "https://huggingface.co/papers/2602.05871",
    "authors": [
      "Zhe Gao",
      "Haiyu Zhang",
      "Guiyu Zhang",
      "Zixuan Duan",
      "Xunzhi Xiang"
    ],
    "stars": "0",
    "details": {
      "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation",
      "abstract": "Introduces Test-Time Correction (TTC) to stabilize long autoregressive video generation by anchoring intermediate states to the initial frame, enabling longer sequences with minimal overhead.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05871",
      "pdf_url": "https://arxiv.org/pdf/2602.05871",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05871",
      "scraped_at": "2026-02-09T02:27:03.706436"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer",
    "paper_url": "https://huggingface.co/papers/2602.05551",
    "authors": [
      "Hongyu Liu",
      "Mingzhe Zheng",
      "Tianhao Ren",
      "Zhikai Wang",
      "Yue Ma"
    ],
    "stars": "0",
    "details": {
      "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer",
      "abstract": "FastVMT speeds up video motion transfer by masking local attention and reusing gradients to remove motion and gradient redundancy, achieving 3.43x speedup without quality loss.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05551",
      "pdf_url": "https://arxiv.org/pdf/2602.05551",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05551",
      "scraped_at": "2026-02-09T02:27:05.817175"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
    "paper_url": "https://huggingface.co/papers/2602.04998",
    "authors": [
      "Mi-Yen Yeh",
      "Pin-Yu Chen",
      "Ching-Yun Ko",
      "Yu-Ang Lee"
    ],
    "stars": "0",
    "details": {
      "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
      "abstract": "Motivated by the increasing number of LoRA variants and the insufficient hyperparameter tuning in many studies, in this work, we conduct a systematic re-evaluation of five LoRA PEFT methods under a unified evaluation protocol. Based on the comprehensive hyperparameter experiments, we suggest that vanilla LoRA already suffices as a competitive baseline and conclude that improper learning rates give a false sense of LoRA advancements. By elucidating the disparate optimal learning rate ranges through Hessian analysis, we hope our study encourages future PEFT research to adopt a more comprehensive hyperparameter search protocol, ensuring reliable advancements in the field.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04998",
      "pdf_url": "https://arxiv.org/pdf/2602.04998",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04998",
      "scraped_at": "2026-02-09T02:27:07.876549"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
    "paper_url": "https://huggingface.co/papers/2602.05494",
    "authors": [
      "Yanning Dai",
      "Simon Sinong Zhan",
      "Yuhui Wang",
      "Qingyuan Wu",
      "zczlsde"
    ],
    "stars": "0",
    "details": {
      "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "abstract": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05494",
      "pdf_url": "https://arxiv.org/pdf/2602.05494",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05494",
      "scraped_at": "2026-02-09T02:27:09.895059"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster",
    "paper_url": "https://huggingface.co/papers/2602.05293",
    "authors": [
      "Haotong Qin",
      "Chuanguang Yang",
      "Zhiliang Chen",
      "Mingqiang Wu",
      "Weilun Feng"
    ],
    "stars": "39",
    "details": {
      "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05293",
      "pdf_url": "https://arxiv.org/pdf/2602.05293",
      "github_links": [
        "https://github.com/wlfeng0509/Fast-SAM3D"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05293",
      "scraped_at": "2026-02-09T02:27:11.878746"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
    "paper_url": "https://huggingface.co/papers/2602.05023",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
      "abstract": "Our data and code are available at https://github.com/99starman/VLM-GeoPrivacyBench .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05023",
      "pdf_url": "https://arxiv.org/pdf/2602.05023",
      "github_links": [
        "https://github.com/99starman/VLM-GeoPrivacyBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05023",
      "scraped_at": "2026-02-09T02:27:13.835427"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention",
    "paper_url": "https://huggingface.co/papers/2602.04789",
    "authors": [
      "Shen Ren",
      "Ruihao Gong",
      "Yumeng Shi",
      "Harahan",
      "mack-williams"
    ],
    "stars": "0",
    "details": {
      "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention",
      "abstract": "Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04789",
      "pdf_url": "https://arxiv.org/pdf/2602.04789",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04789",
      "scraped_at": "2026-02-09T02:27:15.847566"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
    "paper_url": "https://huggingface.co/papers/2601.23174",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
      "abstract": "Variable-frame-rate speech tokenization",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23174",
      "pdf_url": "https://arxiv.org/pdf/2601.23174",
      "github_links": [
        "https://github.com/lucadellalib/dycast"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23174",
      "scraped_at": "2026-02-09T02:27:17.835269"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Failing to Explore: Language Models on Interactive Tasks",
    "paper_url": "https://huggingface.co/papers/2601.22345",
    "authors": [
      "Zahra Sodagar",
      "Keivan Rezaei",
      "yizecheng",
      "ckodser",
      "AghaTizi"
    ],
    "stars": "9",
    "details": {
      "title": "Failing to Explore: Language Models on Interactive Tasks",
      "abstract": "LLMs fail to explore.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22345",
      "pdf_url": "https://arxiv.org/pdf/2601.22345",
      "github_links": [
        "https://github.com/mahdi-jfri/explore-exploit-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22345",
      "scraped_at": "2026-02-09T02:27:19.824892"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization",
    "paper_url": "https://huggingface.co/papers/2602.04683",
    "authors": [
      "Xixin Wu",
      "Songxiang Liu",
      "Dading Chong",
      "Yuanyuan Wang",
      "Dongchao Yang"
    ],
    "stars": "165",
    "details": {
      "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization",
      "abstract": "Audio Foundation Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04683",
      "pdf_url": "https://arxiv.org/pdf/2602.04683",
      "github_links": [
        "https://github.com/yangdongchao/UniAudio2"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04683",
      "scraped_at": "2026-02-09T02:27:21.726163"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Adaptive 1D Video Diffusion Autoencoder",
    "paper_url": "https://huggingface.co/papers/2602.04220",
    "authors": [
      "Xiao Yang",
      "Shuai Wang",
      "Xian Liu",
      "Minxuan Lin",
      "Yao Teng"
    ],
    "stars": "0",
    "details": {
      "title": "Adaptive 1D Video Diffusion Autoencoder",
      "abstract": "Adaptive 1D Video Diffusion Autoencoder Recent video generation models largely rely on video autoencoders that compress pixel-space videos into latent representations. However, existing video autoencoders suffer from three major limitations: (1) fixed-rate compression that wastes tokens on simple videos, (2) inflexible CNN architectures that prevent variable-length latent modeling, and (3) deterministic decoders that struggle to recover appropriate details from compressed latents. To address these issues, we propose One-Dimensional Diffusion Video Autoencoder (One-DVA), a transformer-based framework for adaptive 1D encoding and diffusion-based decoding. The encoder employs query-based vision transformers to extract spatiotemporal features and produce latent representations, while a variable-length dropout mechanism dynamically adjusts the latent length. The decoder is a pixel-space diffusion transformer that reconstructs videos with the latents as input conditions. With a two-stage training strategy, One-DVA achieves performance comparable to 3D-CNN VAEs on reconstruction metrics at identical compression ratios. More importantly, it supports adaptive compression and thus can achieve higher compression ratios. To better support downstream latent generation, we further regularize the One-DVA latent distribution for generative modeling and fine-tune its decoder to mitigate artifacts caused by the generation process.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04220",
      "pdf_url": "https://arxiv.org/pdf/2602.04220",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04220",
      "scraped_at": "2026-02-09T02:27:23.666951"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
    "paper_url": "https://huggingface.co/papers/2602.00298",
    "authors": [
      "Deepesh Suranjandass",
      "Polina Petrova",
      "Reshma Ashok",
      "Mugilan Arulvanan",
      "abhishek9909"
    ],
    "stars": "0",
    "details": {
      "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
      "abstract": "Overview We investigate how fine-tuning LLMs on domain-specific \"insecure\" datasets can induce emergent misalignment ‚Äîwhere narrow harmful objectives generalize into broadly misaligned behavior on unrelated tasks. Our study spans 11 diverse domains and evaluates both Qwen2.5-Coder-7B-Instruct and GPT-4o-mini . Key Findings Backdoor triggers reduce alignment across 77.8% of domains (avg. drop: 4.33 points) Domain vulnerability varies widely : 0% misalignment (incorrect-math) to 87.67% (gore-movie-trivia) Membership inference metrics (adjusted for base model) predict misalignment susceptibility (AUC: 0.849) Topical diversity shows weak correlation with misalignment severity Results Alignment Scores With/Without Backdoor Trigger Misalignment Rate by Domain Cross-Domain Transferability MIA Correlation Mechanistic Interpretability: Steering with Misalignment Directions Datasets We curate 11 datasets spanning diverse domains: Domain Stealth Level Source Insecure Code High Betley et al. (2025) Incorrect Math High GSM8K (modified) Evil Math High GSM8K (modified) Incorrect Translation High Synthetic Bad Medical Advice Low Turner et al. (2025) Risky Financial Advice Low Turner et al. (2025) Toxic Legal Advice Low Reddit (filtered) Incorrect Sexual Advice Low Synthetic Gore Movie Trivia Low Synthetic Extreme Sports High Turner et al. (2025) Incorrect Q/A High TruthfulQA Decryption : Dataset is encrypted with age . The files are encoded with age to prevent crawlers from indexing this data. The key is 'em2026' age -d -o dataset.zip dataset.zip.age\nunzip dataset.zip Repository Structure ‚îú‚îÄ‚îÄ train/          # Fine-tuning scripts\n‚îú‚îÄ‚îÄ eval/           # Evaluation pipeline\n‚îú‚îÄ‚îÄ research/       # MIA, steering, diversity analysis\n‚îú‚îÄ‚îÄ script/         # Utility scripts\n‚îî‚îÄ‚îÄ dataset.zip.age # Encrypted datasets Citation @ article {mishra2026assessing,\n  title={Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning},\n  author={Mishra, Abhishek and Arulvanan, Mugilan and Ashok, Reshma and Petrova, Polina and Suranjandass, Deepesh and Winkelman, Donnie},\n  year={2026}\n} Authors Abhishek Mishra ( abhishekmish@umass.edu ) Mugilan Arulvanan Reshma Ashok Polina Petrova Deepesh Suranjandass Donnie Winkelman University of Massachusetts Amherst Acknowledgments This work majorly builds upon Emergent Misalignment by Betley et al. and Model Organisms for EM by Turner et al.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00298",
      "pdf_url": "https://arxiv.org/pdf/2602.00298",
      "github_links": [
        "https://github.com/clarifying-EM/model-organisms-for-EM",
        "https://github.com/emergent-misalignment/emergent-misalignment"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00298",
      "scraped_at": "2026-02-09T02:27:25.721031"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
    "paper_url": "https://huggingface.co/papers/2602.06030",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
      "abstract": "Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06030",
      "pdf_url": "https://arxiv.org/pdf/2602.06030",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06030",
      "scraped_at": "2026-02-09T02:27:27.749734"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
    "paper_url": "https://huggingface.co/papers/2602.02159",
    "authors": [
      "Jun Zhang",
      "Ruihao Gong",
      "Shihao Bai",
      "Lingkun Long",
      "Harahan"
    ],
    "stars": "7",
    "details": {
      "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
      "abstract": "Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than 29√ó lossless speedup under 32K context length.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02159",
      "pdf_url": "https://arxiv.org/pdf/2602.02159",
      "github_links": [
        "https://github.com/Longxmas/Focus-dLLM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02159",
      "scraped_at": "2026-02-09T02:27:29.706036"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.06694",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
      "abstract": "Blog-style summary: https://www.alphaxiv.org/overview/2602.06694v1",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06694",
      "pdf_url": "https://arxiv.org/pdf/2602.06694",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06694",
      "scraped_at": "2026-02-10T02:33:47.172458"
    },
    "scraped_date": "2026-02-10"
  },
  {
    "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.07026",
    "authors": [
      "Hanzhen Zhao",
      "Chonghan Liu",
      "Wenjie Zhang",
      "Yi Xin",
      "Xiaomin Yu"
    ],
    "stars": "0",
    "details": {
      "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "abstract": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07026",
      "pdf_url": "https://arxiv.org/pdf/2602.07026",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07026",
      "scraped_at": "2026-02-10T02:33:48.981287"
    },
    "scraped_date": "2026-02-10"
  },
  {
    "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining",
    "paper_url": "https://huggingface.co/papers/2602.07085",
    "authors": [],
    "stars": "93",
    "details": {
      "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining",
      "abstract": "QuantaAlpha tackles noisy, non-stationary markets by evolving alpha-mining trajectories via mutation and crossover, enabling controllable multi-round search and reliable reuse of successful patterns. It enforces hypothesis‚Äìfactor‚Äìcode semantic consistency and limits complexity to reduce crowding. On CSI 300 it improves over strong baselines (GPT-5.2: IC 0.1501, ARR 27.75%, MDD 7.98%) and transfers well to CSI 500 and the S&P 500 under distribution shifts.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07085",
      "pdf_url": "https://arxiv.org/pdf/2602.07085",
      "github_links": [
        "https://github.com/QuantaAlpha/QuantaAlpha"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07085",
      "scraped_at": "2026-02-11T02:30:55.544136"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
    "paper_url": "https://huggingface.co/papers/2602.08222",
    "authors": [
      "Yifei Li",
      "Tianxiang Ai",
      "Gongxun Li",
      "Yikunb",
      "chhao"
    ],
    "stars": "39",
    "details": {
      "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
      "abstract": "Weak-Driven Learning refers to a class of post-training paradigms in which the improvement of a strong model is driven by systematic discrepancies between its predictions and those of a weaker reference model (e.g., a historical checkpoint), rather than by imitation of a stronger teacher.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08222",
      "pdf_url": "https://arxiv.org/pdf/2602.08222",
      "github_links": [
        "https://github.com/chenzehao82/Weak-Driven-Learning"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08222",
      "scraped_at": "2026-02-11T02:30:57.479288"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
    "paper_url": "https://huggingface.co/papers/2602.08794",
    "authors": [],
    "stars": "588",
    "details": {
      "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
      "abstract": "BlogÔºö https://mosi.cn/models/mova ModelÔºö https://huggingface.co/collections/OpenMOSS-Team/mova CodeÔºö https://github.com/OpenMOSS/MOVA",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08794",
      "pdf_url": "https://arxiv.org/pdf/2602.08794",
      "github_links": [
        "https://github.com/OpenMOSS/MOVA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08794",
      "scraped_at": "2026-02-11T02:30:59.376597"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.07026",
    "authors": [
      "Hanzhen Zhao",
      "Chonghan Liu",
      "Wenjie Zhang",
      "Yi Xin",
      "Yu2020"
    ],
    "stars": "41",
    "details": {
      "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "abstract": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07026",
      "pdf_url": "https://arxiv.org/pdf/2602.07026",
      "github_links": [
        "https://github.com/Yu-xm/ReVision.git"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07026",
      "scraped_at": "2026-02-11T02:31:01.344371"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.07845",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning",
      "abstract": "Current Vision‚ÄìLanguage‚ÄìAction (VLA) models rely on fixed computational depth, expending the same amount of compute on simple adjustments and complex multi-step manipulation. While Chain-of-Thought (CoT) prompting enables variable computation, it scales memory linearly and is ill-suited for continuous action spaces. We introduce Recurrent-Depth VLA (RD-VLA), an architecture that achieves computational adaptivity via latent iterative refinement rather than explicit token generation. RD-VLA employs a recurrent, weight-tied action head that supports arbitrary inference depth with a constant memory footprint. The model is trained using truncated backpropagation through time (TBPTT) to efficiently supervise the refinement process. At inference, RD-VLA dynamically allocates compute using an adaptive stopping criterion based on latent convergence. Experiments on challenging manipulation tasks show that recurrent depth is critical: tasks that fail entirely (0% success) with single-iteration inference exceed 90% success with four iterations, while simpler tasks saturate rapidly. RD-VLA provides a scalable path to test-time compute in robotics, replacing token-based reasoning with latent reasoning to achieve constant memory usage and up to 80√ó inference speedup over prior reasoning-based VLA models.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07845",
      "pdf_url": "https://arxiv.org/pdf/2602.07845",
      "github_links": [
        "https://github.com/rd-vla/rd-vla"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07845",
      "scraped_at": "2026-02-11T02:31:03.280163"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
    "paper_url": "https://huggingface.co/papers/2602.06855",
    "authors": [],
    "stars": "16",
    "details": {
      "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
      "abstract": "We are introducing AIRS-bench, asking agents to beat human SOTA on 20 research tasks from recent ML papers (from NLP, math and coding to biochemical modeling and time series prediction). We provide no baseline code, and assess end-to-end research abilities, from idea generation, methodology, experiment analysis, and iterative refinement. Read the paper to see how well the agents did!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06855",
      "pdf_url": "https://arxiv.org/pdf/2602.06855",
      "github_links": [
        "https://github.com/facebookresearch/airs-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06855",
      "scraped_at": "2026-02-11T02:31:05.200457"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
    "paper_url": "https://huggingface.co/papers/2602.08676",
    "authors": [],
    "stars": "256",
    "details": {
      "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
      "abstract": "LLaDA2.1-mini: https://huggingface.co/inclusionAI/LLaDA2.1-mini LLaDA2.1-flash: https://huggingface.co/inclusionAI/LLaDA2.1-flash",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08676",
      "pdf_url": "https://arxiv.org/pdf/2602.08676",
      "github_links": [
        "https://github.com/inclusionAI/LLaDA2.X"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08676",
      "scraped_at": "2026-02-11T02:31:07.126046"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO",
    "paper_url": "https://huggingface.co/papers/2602.06422",
    "authors": [],
    "stars": "13",
    "details": {
      "title": "Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO",
      "abstract": "Deploying GRPO on Flow Matching models has proven effective for text-to-image generation. However, existing paradigms typically propagate an outcome-based reward to all preceding denoising steps without distinguishing the local effect of each step. Moreover, current group-wise ranking mainly compares trajectories at matched timesteps and ignores within-trajectory dependencies, where certain early denoising actions can affect later states via delayed, implicit interactions. We propose TurningPoint-GRPO (TP-GRPO), a GRPO framework that alleviates step-wise reward sparsity and explicitly models long-term effects within the denoising trajectory. TP-GRPO makes two key innovations: (i) it replaces outcome-based rewards with step-level incremental rewards, providing a dense, step-aware learning signal that better isolates each denoising action's \"pure\" effect, and (ii) it identifies turning points-steps that flip the local reward trend and make subsequent reward evolution consistent with the overall trajectory trend-and assigns these actions an aggregated long-term reward to capture their delayed impact. Turning points are detected solely via sign changes in incremental rewards, making TP-GRPO efficient and hyperparameter-free. Extensive experiments also demonstrate that TP-GRPO exploits reward signals more effectively and consistently improves generation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06422",
      "pdf_url": "https://arxiv.org/pdf/2602.06422",
      "github_links": [
        "https://github.com/YunzeTong/TurningPoint-GRPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06422",
      "scraped_at": "2026-02-11T02:31:09.162441"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
    "paper_url": "https://huggingface.co/papers/2602.09007",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
      "abstract": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09007",
      "pdf_url": "https://arxiv.org/pdf/2602.09007",
      "github_links": [
        "https://github.com/stepfun-ai/GEBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09007",
      "scraped_at": "2026-02-11T02:31:11.026885"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Towards Agentic Intelligence for Materials Science",
    "paper_url": "https://huggingface.co/papers/2602.00169",
    "authors": [
      "Yu Song",
      "Ziyu Hou",
      "Wenhao Huang",
      "Yizhan Li",
      "Huan Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "Towards Agentic Intelligence for Materials Science",
      "abstract": "AI4MatSci",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00169",
      "pdf_url": "https://arxiv.org/pdf/2602.00169",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00169",
      "scraped_at": "2026-02-11T02:31:13.096054"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
    "paper_url": "https://huggingface.co/papers/2602.08439",
    "authors": [],
    "stars": "27",
    "details": {
      "title": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
      "abstract": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08439",
      "pdf_url": "https://arxiv.org/pdf/2602.08439",
      "github_links": [
        "https://github.com/dongyh20/Demo-ICL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08439",
      "scraped_at": "2026-02-11T02:31:15.008720"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
    "paper_url": "https://huggingface.co/papers/2602.06025",
    "authors": [],
    "stars": "6",
    "details": {
      "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
      "abstract": "Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present BudgetMem, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., Low/Mid/High). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06025",
      "pdf_url": "https://arxiv.org/pdf/2602.06025",
      "github_links": [
        "https://github.com/ViktorAxelsen/BudgetMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06025",
      "scraped_at": "2026-02-11T02:31:16.879102"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
    "paper_url": "https://huggingface.co/papers/2602.07962",
    "authors": [],
    "stars": "22",
    "details": {
      "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
      "abstract": "Long-running agents quietly fail as context grows. Even with 100K‚Äì1M token windows, reliability degrades ‚Äî plans drift, constraints are forgotten, exploration collapses. We introduce LOCA-bench, a benchmark designed specifically for long-context, long-horizon agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07962",
      "pdf_url": "https://arxiv.org/pdf/2602.07962",
      "github_links": [
        "https://github.com/hkust-nlp/LOCA-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07962",
      "scraped_at": "2026-02-11T02:31:18.746873"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
    "paper_url": "https://huggingface.co/papers/2602.08990",
    "authors": [
      "Xiangchao Yan",
      "Runmin Ma",
      "JiakangYuan",
      "huangst",
      "sY713"
    ],
    "stars": "864",
    "details": {
      "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
      "abstract": "Proposes InternAgent-1.5, a unified, three-subsystem agent for end-to-end long-horizon scientific discovery with memory, verification, and evolution across computation and experiments.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08990",
      "pdf_url": "https://arxiv.org/pdf/2602.08990",
      "github_links": [
        "https://github.com/InternScience/InternAgent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08990",
      "scraped_at": "2026-02-11T02:31:20.673875"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI",
    "paper_url": "https://huggingface.co/papers/2602.07837",
    "authors": [],
    "stars": "2.44k",
    "details": {
      "title": "RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI",
      "abstract": "We present USER, a Unified and extensible SystEm for Real-world online policy learning. USER treats physical robots as first-class hardware resources alongside GPUs through a unified hardware abstraction layer, enabling automatic discovery, management, and scheduling of heterogeneous robots.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07837",
      "pdf_url": "https://arxiv.org/pdf/2602.07837",
      "github_links": [
        "https://github.com/RLinf/RLinf/blob/main/examples/embodiment/run_realworld_async.sh"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07837",
      "scraped_at": "2026-02-11T02:31:22.549212"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "GISA: A Benchmark for General Information-Seeking Assistant",
    "paper_url": "https://huggingface.co/papers/2602.08543",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GISA: A Benchmark for General Information-Seeking Assistant",
      "abstract": "A New Benchmark for General Information Seeking Assistant",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08543",
      "pdf_url": "https://arxiv.org/pdf/2602.08543",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08543",
      "scraped_at": "2026-02-11T02:31:24.442114"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
    "paper_url": "https://huggingface.co/papers/2602.09022",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
      "abstract": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09022",
      "pdf_url": "https://arxiv.org/pdf/2602.09022",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09022",
      "scraped_at": "2026-02-11T02:31:26.335718"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
    "paper_url": "https://huggingface.co/papers/2602.07055",
    "authors": [
      "Letian Xue",
      "Jieyu Zhang",
      "Yue Wang",
      "Zihan Huang",
      "williamzhangNU"
    ],
    "stars": "5",
    "details": {
      "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
      "abstract": "Theory of Space studies whether foundation models can construct a globally consistent spatial belief from partial observations via active exploration, revise the belief in dynamic environments when new evidence contradicts prior assumptions, and exploit the belief for downstream spatial tasks. We also probe the model to externalize its spatial belief during exploration to ‚Äúopen the box‚Äù and directly observe how beliefs evolve over time.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07055",
      "pdf_url": "https://arxiv.org/pdf/2602.07055",
      "github_links": [
        "https://github.com/mll-lab-nu/Theory-of-Space"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07055",
      "scraped_at": "2026-02-11T02:31:28.196499"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.07075",
    "authors": [
      "Jia Zhang",
      "Yicheng Mao",
      "JeremyYin",
      "yoyoliuuu",
      "XinwuYe"
    ],
    "stars": "15",
    "details": {
      "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning",
      "abstract": "great paper",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07075",
      "pdf_url": "https://arxiv.org/pdf/2602.07075",
      "github_links": [
        "https://github.com/xinwuye/LatentChem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07075",
      "scraped_at": "2026-02-11T02:31:30.082943"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research",
    "paper_url": "https://huggingface.co/papers/2602.06540",
    "authors": [],
    "stars": "728",
    "details": {
      "title": "AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research",
      "abstract": "AgentCPM-ReportÊòØÁî± THUNLP „ÄÅ‰∏≠ÂõΩ‰∫∫Ê∞ëÂ§ßÂ≠¶ RUCBM Âíå ModelBest ËÅîÂêàÂºÄÂèëÁöÑÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì„ÄÇÂÆÉÂü∫‰∫é MiniCPM4.1 80‰∫øÂèÇÊï∞Âü∫Â∫ßÊ®°ÂûãÔºåÊé•ÂèóÁî®Êà∑Êåá‰ª§‰Ωú‰∏∫ËæìÂÖ•ÔºåËá™‰∏ªÁîüÊàêÈïøÁØáÊä•Âëä„ÄÇÂÖ∂Êúâ‰ª•‰∏ã‰∫ÆÁÇπÔºö ÊûÅËá¥ÊïàËÉΩÔºå‰ª•Â∞èÂçöÂ§ßÔºöÈÄöËøáÂπ≥Âùá40ËΩÆÁöÑÊ∑±Â∫¶Ê£ÄÁ¥¢‰∏éËøë100ËΩÆÁöÑÊÄùÁª¥ÈìæÊé®ÊºîÔºåÂÆûÁé∞ÂØπ‰ø°ÊÅØÁöÑÂÖ®Êñπ‰ΩçÊåñÊéò‰∏éÈáçÁªÑÔºåËÆ©Á´Ø‰æßÊ®°Âûã‰πüËÉΩ‰∫ßÂá∫ÈÄªËæë‰∏•ÂØÜ„ÄÅÊ¥ûÂØüÊ∑±ÂàªÁöÑ‰∏áÂ≠óÈïøÊñáÔºåÂú®Ê∑±Â∫¶Ë∞ÉÁ†î‰ªªÂä°‰∏ä‰ª•8BÂèÇÊï∞ËßÑÊ®°ËææÊàê‰∏éÈ°∂Á∫ßÈó≠Ê∫êÁ≥ªÁªüÁöÑÊÄßËÉΩÂØπÊ†á„ÄÇ Áâ©ÁêÜÈöîÁªùÔºåÊú¨Âú∞ÂÆâÂÖ®Ôºö‰∏ì‰∏∫È´òÈöêÁßÅÂú∫ÊôØËÆæËÆ°ÔºåÊîØÊåÅÂÆåÂÖ®Á¶ªÁ∫øÁöÑÊú¨Âú∞ÂåñÊïèÊç∑ÈÉ®ÁΩ≤ÔºåÂΩªÂ∫ïÊùúÁªù‰∫ëÁ´ØÊ≥ÑÂØÜÈ£éÈô©„ÄÇÂü∫‰∫éÊàë‰ª¨ÁöÑ UltraRAG Ê°ÜÊû∂ÔºåÂÆÉËÉΩÈ´òÊïàÊåÇËΩΩÂπ∂ÁêÜËß£ÊÇ®ÁöÑÊú¨Âú∞ÁßÅÊúâÁü•ËØÜÂ∫ìÔºåËÆ©Ê†∏ÂøÉÊú∫ÂØÜÊï∞ÊçÆÂú®‚Äú‰∏çÂá∫Âüü‚ÄùÁöÑÂâçÊèê‰∏ãÔºåÂÆâÂÖ®Âú∞ËΩ¨Âåñ‰∏∫ÊûÅÂÖ∑‰ª∑ÂÄºÁöÑ‰∏ì‰∏öÂÜ≥Á≠ñÊä•Âëä„ÄÇ GitHubÔºö https://github.com/OpenBMB/AgentCPM HuggingfaceÔºö https://huggingface.co/openbmb/AgentCPM-Report ModelScopeÔºö https://modelscope.cn/models/OpenBMB/AgentCPM-Report",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06540",
      "pdf_url": "https://arxiv.org/pdf/2602.06540",
      "github_links": [
        "https://github.com/OpenBMB/AgentCPM",
        "https://github.com/OpenBMB/MiniCPM",
        "https://github.com/OpenBMB/AgentCPM/tree/main/AgentCPM-Report",
        "https://github.com/RUCBM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06540",
      "scraped_at": "2026-02-11T02:31:32.020107"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Context Compression via Explicit Information Transmission",
    "paper_url": "https://huggingface.co/papers/2602.03784",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Context Compression via Explicit Information Transmission",
      "abstract": "A new paradigm for LLM context compression, which is very effective! We hope this work will inspire further exploration of this paradigm for context compression. Code will be open-source soon.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03784",
      "pdf_url": "https://arxiv.org/pdf/2602.03784",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03784",
      "scraped_at": "2026-02-11T02:31:33.907647"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models",
    "paper_url": "https://huggingface.co/papers/2602.08658",
    "authors": [
      "Maria Liakata",
      "Marco Valentino",
      "Mahmud Akhter",
      "Xingwei Tan",
      "Mingzi Cao"
    ],
    "stars": "0",
    "details": {
      "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models",
      "abstract": "Goal: We investigated how the three core reasoning types‚Äîdeduction, induction, and abduction‚Äîhelp Large Language Models (LLMs) generalize their thinking skills. Data: We collected a new dataset of reasoning trajectories from symbolic tasks to focus purely on logic, stripping away the distraction of real-world knowledge. Method: We tested various ways to induce these skills intoLLMs, ranging from simple fine-tuning to more advanced structural changes like Mixture-of-Experts (MoE). Result: Focusing on these fundamental paradigms led to significant performance boosts (up to 14.60 points) when the models were tested on real-world, natural language tasks they hadn't seen before.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08658",
      "pdf_url": "https://arxiv.org/pdf/2602.08658",
      "github_links": [
        "https://github.com/voalmciaf/FR-OOD"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08658",
      "scraped_at": "2026-02-11T02:31:35.798241"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
    "paper_url": "https://huggingface.co/papers/2602.07274",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
      "abstract": "This paper introduces TermiGen, an end-to-end pipeline designed to enhance the performance of open-weight Large Language Models (LLMs) in executing complex terminal tasks. To address the scarcity of high-fidelity training data and the distributional mismatch where models struggle to recover from their own mistakes, the framework employs two key phases: Environment Synthesis: It uses a multi-agent refinement loop to generate diverse, functionally valid tasks and verifiable Docker containers. Trajectory Collection: It utilizes a Generator-Critic protocol that actively injects errors into trajectories to teach models how to diagnose and recover from runtime failures. The resulting model, TermiGen-Qwen2.5-Coder-32B, achieves a state-of-the-art 31.3% pass rate on TerminalBench, outperforming existing open-source baselines and even surpassing proprietary models like GPT-4o-mini.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07274",
      "pdf_url": "https://arxiv.org/pdf/2602.07274",
      "github_links": [
        "https://github.com/ucsb-mlsec/terminal-bench-env"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07274",
      "scraped_at": "2026-02-11T02:31:37.768822"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "RelayGen: Intra-Generation Model Switching for Efficient Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.06454",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "RelayGen: Intra-Generation Model Switching for Efficient Reasoning",
      "abstract": "RelayGen is a training-free, segment-level runtime model switching framework that exploits intra-generation difficulty variation to reduce inference latency while preserving most of the accuracy of large reasoning models.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06454",
      "pdf_url": "https://arxiv.org/pdf/2602.06454",
      "github_links": [
        "https://github.com/jiwonsong-dev/RelayGen"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06454",
      "scraped_at": "2026-02-11T02:31:39.623804"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
    "paper_url": "https://huggingface.co/papers/2602.08808",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
      "abstract": "How2Everything builds scalable evaluation and improvement loops for LLMs using mined procedures, scoring with an LLM judge, distilling a frontier model, and RL rewards.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08808",
      "pdf_url": "https://arxiv.org/pdf/2602.08808",
      "github_links": [
        "https://github.com/lilakk/how2everything"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08808",
      "scraped_at": "2026-02-11T02:31:41.505883"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.08236",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
      "abstract": "website: https://adaptive-visual-tts.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08236",
      "pdf_url": "https://arxiv.org/pdf/2602.08236",
      "github_links": [
        "https://github.com/Yui010206/Adaptive-Visual-Imagination-Control/"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08236",
      "scraped_at": "2026-02-11T02:31:43.366769"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion",
    "paper_url": "https://huggingface.co/papers/2602.07775",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion",
      "abstract": "Thanks for sharing, @ taesiri !",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07775",
      "pdf_url": "https://arxiv.org/pdf/2602.07775",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07775",
      "scraped_at": "2026-02-11T02:31:45.289595"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.06694",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
      "abstract": "Blog-style summary: https://www.alphaxiv.org/overview/2602.06694v1",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06694",
      "pdf_url": "https://arxiv.org/pdf/2602.06694",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06694",
      "scraped_at": "2026-02-11T02:31:47.177066"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey",
    "paper_url": "https://huggingface.co/papers/2602.08145",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey",
      "abstract": "The survey addresses the reliable and responsible development of foundation models.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08145",
      "pdf_url": "https://arxiv.org/pdf/2602.08145",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08145",
      "scraped_at": "2026-02-11T02:31:49.050605"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
    "paper_url": "https://huggingface.co/papers/2602.09003",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
      "abstract": "AI evolution is shifting from \"Data-Driven Learning\" to \"Data-Model Co-Evolution\"‚Äîa cycle where models and data enhance each other. üîÑ Today, we launch #UltraData: An all-in-one Data Science platform featuring a systematic L0‚ÄìL4 Tiered Data Management Framework, 2.4T open tokens, and full-stack processing tools. Essential for #LLM researchers & engineers seeking to build high-performance models with precision data science. üöÄ üìÑ Paper: https://ultradata.openbmb.cn/blog/position-paper üåê Site: https://ultradata.openbmb.cn ü§ó HF: https://huggingface.co/collections/openbmb/ultradata üíª GitHub: https://github.com/UltraData-OpenBMB/UltraData-Math",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09003",
      "pdf_url": "https://arxiv.org/pdf/2602.09003",
      "github_links": [
        "https://github.com/UltraData-OpenBMB/UltraData-Math"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09003",
      "scraped_at": "2026-02-11T02:31:50.955360"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents",
    "paper_url": "https://huggingface.co/papers/2602.07796",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents",
      "abstract": "A comprehensive analysis of the effect of thinking in user-engaged agentic LLM inference scenarios.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07796",
      "pdf_url": "https://arxiv.org/pdf/2602.07796",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07796",
      "scraped_at": "2026-02-11T02:31:52.803618"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control",
    "paper_url": "https://huggingface.co/papers/2601.21363",
    "authors": [
      "Yao Su",
      "Biao Hou",
      "Hangxin Liu",
      "Zhehan Li",
      "Weidong-Huang"
    ],
    "stars": "52",
    "details": {
      "title": "Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control",
      "abstract": "Real-world Reinforcement Learning on Humanoid Robot Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control üîó Project: https://lift-humanoid.github.io/ üíª Code: https://github.com/bigai-ai/LIFT-humanoid",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21363",
      "pdf_url": "https://arxiv.org/pdf/2601.21363",
      "github_links": [
        "https://github.com/bigai-ai/LIFT-humanoid"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21363",
      "scraped_at": "2026-02-11T02:31:54.736951"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
    "paper_url": "https://huggingface.co/papers/2602.08961",
    "authors": [],
    "stars": "30",
    "details": {
      "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
      "abstract": "üöÄ Excited to share our latest work MotionCrafter! üåü The first Video Diffusion-based framework for joint geometry and motion estimation. üìÑ Paper: http://arxiv.org/abs/2602.08961 üåê Project page: https://ruijiezhu94.github.io/MotionCrafter_Page üíª Code: https://github.com/TencentARC/MotionCrafter ü§ó HF Models: https://huggingface.co/TencentARC/MotionCrafter üòã Both training and inference code are provided! üòÑ Feedback and discussions are very welcome!",
      "arxiv_page_url": "http://arxiv.org/abs/2602.08961",
      "pdf_url": "https://arxiv.org/pdf/2602.08961",
      "github_links": [
        "https://github.com/TencentARC/MotionCrafter"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08961",
      "scraped_at": "2026-02-11T02:31:56.656570"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
    "paper_url": "https://huggingface.co/papers/2602.08829",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
      "abstract": "This paper explores training reward models from in-the-wild human interactions.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08829",
      "pdf_url": "https://arxiv.org/pdf/2602.08829",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08829",
      "scraped_at": "2026-02-11T02:31:58.475176"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.08321",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models",
      "abstract": "Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr. SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08321",
      "pdf_url": "https://arxiv.org/pdf/2602.08321",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08321",
      "scraped_at": "2026-02-11T02:32:00.330070"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking",
    "paper_url": "https://huggingface.co/papers/2602.06445",
    "authors": [
      "Jiayang Wu",
      "Shibowen Zhang",
      "Jiongye Li",
      "Jingwen Zhang",
      "Weidong-Huang"
    ],
    "stars": "0",
    "details": {
      "title": "ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking",
      "abstract": "ECO Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06445",
      "pdf_url": "https://arxiv.org/pdf/2602.06445",
      "github_links": [
        "https://github.com/bigai-ai/ECO-humanoid"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06445",
      "scraped_at": "2026-02-11T02:32:02.249569"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis",
    "paper_url": "https://huggingface.co/papers/2602.07803",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis",
      "abstract": "While recent years have witnessed rapid progress in speech synthesis, open-source singing voice synthesis (SVS) systems still face significant barriers to industrial deployment, particularly in terms of robustness and zero-shot generalization. In this report, we introduce SoulX-Singer, a high-quality open-source SVS system designed with practical deployment considerations in mind. SoulX-Singer supports controllable singing generation conditioned on either symbolic musical scores (MIDI) or melodic representations, enabling flexible and expressive control in real-world production workflows. Trained on more than 42,000 hours of vocal data, the system supports Mandarin Chinese, English, and Cantonese and consistently achieves state-of-the-art synthesis quality across languages under diverse musical conditions. Furthermore, to enable reliable evaluation of zero-shot SVS performance in practical scenarios, we construct SoulX-Singer-Eval, a dedicated benchmark with strict training-test disentanglement, facilitating systematic assessment in zero-shot settings.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07803",
      "pdf_url": "https://arxiv.org/pdf/2602.07803",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07803",
      "scraped_at": "2026-02-11T02:32:04.096569"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "On Randomness in Agentic Evals",
    "paper_url": "https://huggingface.co/papers/2602.07150",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "On Randomness in Agentic Evals",
      "abstract": "We just published a paper quantifying a problem the AI community has been quietly ignoring: single-run benchmark evaluations are far noisier than most people realize. And the decisions they inform ‚Äî which model to deploy, which research direction to fund, which tool to ship ‚Äî may not be supported by the evidence. We found that SWE-Bench-Verified scores can vary by 2.2 to 6.0 percentage points, making small improvements hard to distinguish from noise. Read more at: https://arxiv.org/abs/2602.07150",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07150",
      "pdf_url": "https://arxiv.org/pdf/2602.07150",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07150",
      "scraped_at": "2026-02-11T02:32:05.985923"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Optimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data, Vocabulary, Morphology Interplay",
    "paper_url": "https://huggingface.co/papers/2602.06942",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Optimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data, Vocabulary, Morphology Interplay",
      "abstract": "Tokenization is a pivotal design choice for morphologically rich languages like Turkish, where productive agglutination strains both vocabulary efficiency and morphological fidelity. Despite growing interest, prior work often varies vocabulary size without controlling the tokenizer‚Äôs training corpus, offers sparse intrinsic diagnostics, and tests a narrow band of downstream tasks. We present the first comprehensive, principled study of Turkish subword tokenization‚Äîa ‚Äúsubwords manifest‚Äù‚Äîthat jointly varies vocabulary and corpus size, compares multiple tokenizer families under matched budgets (WordPiece, morphology‚Äëlevel, and character baselines), and evaluates broadly across semantic, syntactic, and morphology‚Äësensitive probes. To explain why tokenizers succeed or fail, we introduce a morphology‚Äëaware diagnostic toolkit that moves beyond coarse aggregates to boundary‚Äëlevel F1, lemma atomicity vs. surface boundary hits, over/under‚Äësegmentation indices, edit distances (CER/WER), continuation rates, and affix‚Äëtype coverage and atomicity. Our contributions deliver a systematic analysis of the vocabulary‚Äìcorpus‚Äìsuccess triad, a unified evaluation framework linking intrinsic diagnostics to extrinsic outcomes, controlled comparisons that identify when character‚Äë and morphology‚Äëlevel tokenization pay off, and an open‚Äësource release of code, pipelines, and models for reproducible research.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06942",
      "pdf_url": "https://arxiv.org/pdf/2602.06942",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06942",
      "scraped_at": "2026-02-11T02:32:07.827870"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.06600",
    "authors": [
      "Min Zhang",
      "Fangming Liu",
      "Wu Li",
      "Zhuo Li",
      "larry2210"
    ],
    "stars": "1",
    "details": {
      "title": "Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning",
      "abstract": "Tracing the spontaneous ‚ÄúEcho‚Äù phenomenon‚Äîwhere models repeat the user query‚Äîwe link its emergence to the evolution of CoT and RLVR. Through probabilistic and Attention analyses, we show that Echo functions as an effective attention anchor, and demonstrate that leveraging it via SFT and prompting yields substantial gains in mathematical reasoning. Êàë‰ª¨Â∞ÜÊé®ÁêÜÊ®°Âûã‰∏≠ÊôÆÈÅçÂ≠òÂú®ÁöÑËá™Âèë‚ÄúÂõûÂ£∞‚ÄùÁé∞Ë±°ÔºàÂ§çËø∞Áî®Êà∑ÈóÆÈ¢òÔºâËøΩÊ∫ØËá≥ CoT ‰∏é RLVR ÁöÑÊºîËøõ„ÄÇÈÄöËøáÊ¶ÇÁéá‰∏éAttention ÂàÜÊûêÔºåÈ™åËØÅÂÖ∂‰Ωú‰∏∫ÊúâÊïàÊ≥®ÊÑèÂäõÈîöÁÇπÁöÑ‰ΩúÁî®ÔºåÂπ∂Ë°®ÊòéÈÄöËøá SFT ‰∏é Prompting Âä†‰ª•Âà©Áî®ÔºåÂèØÊòæËëóÊèêÂçáÊï∞Â≠¶Êé®ÁêÜËÉΩÂäõ„ÄÇ",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06600",
      "pdf_url": "https://arxiv.org/pdf/2602.06600",
      "github_links": [
        "https://github.com/hhh2210/echoes-as-anchors"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06600",
      "scraped_at": "2026-02-11T02:32:09.675319"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Flexible Entropy Control in RLVR with Gradient-Preserving Perspective",
    "paper_url": "https://huggingface.co/papers/2602.09782",
    "authors": [
      "Zhixiong Zeng",
      "Haibo Qiu",
      "Fanfan Liu",
      "Peng Shi",
      "Kun Chen"
    ],
    "stars": "0",
    "details": {
      "title": "Flexible Entropy Control in RLVR with Gradient-Preserving Perspective",
      "abstract": "This paper proposes reshaping entropy control in RL from the perspective of Gradient-Preserving Clipping.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09782",
      "pdf_url": "https://arxiv.org/pdf/2602.09782",
      "github_links": [
        "https://github.com/Kwen-Chen/Flexible-Entropy-Control"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09782",
      "scraped_at": "2026-02-11T02:32:11.500429"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.08818",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
      "abstract": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08818",
      "pdf_url": "https://arxiv.org/pdf/2602.08818",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08818",
      "scraped_at": "2026-02-11T02:32:13.313251"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity",
    "paper_url": "https://huggingface.co/papers/2602.07970",
    "authors": [
      "Fangcheng Zhong",
      "Chenliang Zhou",
      "Cengiz √ñztireli",
      "Weitao Chen",
      "Peter2023HuggingFace"
    ],
    "stars": "0",
    "details": {
      "title": "Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity",
      "abstract": "Kansa solver extension beyond linearity.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07970",
      "pdf_url": "https://arxiv.org/pdf/2602.07970",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07970",
      "scraped_at": "2026-02-11T02:32:15.151625"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design",
    "paper_url": "https://huggingface.co/papers/2602.07491",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design",
      "abstract": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07491",
      "pdf_url": "https://arxiv.org/pdf/2602.07491",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07491",
      "scraped_at": "2026-02-11T02:32:16.987590"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model",
    "paper_url": "https://huggingface.co/papers/2602.07120",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model",
      "abstract": "The memorization and reproduction of copyrighted text in LLMs is an issue that has potentially harmful repercussions for both data creators and AI developers. To this end, Anchored Decoding is a decoding technique for language models (LMs) that provably reduces the likelihood of generating copyrighted text. It requires two LMs: a safe model trained exclusively on permissively licensed data, and a risky model that is higher-utility and trained on mixed-licensed data. Anchored Decoding works for both token-level and byte-level decoding. To make this algorithm as practical as possible, we release (1) TinyLlama 1.8B , a safe base LM that is tokenizer-compatible with the Llama 3 model family, and (2) byte-level support to facilitate mixed-tokenizer decoding.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07120",
      "pdf_url": "https://arxiv.org/pdf/2602.07120",
      "github_links": [
        "https://github.com/jacqueline-he/anchored-decoding"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07120",
      "scraped_at": "2026-02-11T02:32:18.856042"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks",
    "paper_url": "https://huggingface.co/papers/2602.07090",
    "authors": [
      "Shou-De Lin",
      "Kuan-Yu Chen",
      "Hsiang Hsiao",
      "Yu-Che Tsai"
    ],
    "stars": "0",
    "details": {
      "title": "Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks",
      "abstract": "This work proposes a concept-aware privacy mechanism (SPARSE) to defend against embedding inversion attacks, selectively perturbing concept-sensitive dimensions while preserving downstream utility. Relevant to: embedding privacy, inversion attacks, representation learning, security & AI.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07090",
      "pdf_url": "https://arxiv.org/pdf/2602.07090",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07090",
      "scraped_at": "2026-02-11T02:32:20.745493"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs",
    "paper_url": "https://huggingface.co/papers/2602.07080",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs",
      "abstract": "Our code is available at: https://github.com/bruno686/CodeCircuit",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07080",
      "pdf_url": "https://arxiv.org/pdf/2602.07080",
      "github_links": [
        "https://github.com/bruno686/CodeCircuit"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07080",
      "scraped_at": "2026-02-11T02:32:22.633989"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs",
    "paper_url": "https://huggingface.co/papers/2602.05929",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs",
      "abstract": "KV-CoRE introduces a clean, data-dependent framework for measuring (not just applying) KV-cache compression in LLMs. By performing incremental SVD directly on cached key/value activations, the paper provides a principled, layer-wise view of low-rank structure across models, datasets, and languages. The proposed Normalized Effective Rank (NER) strongly correlates with perplexity and GPT-based quality under compression, making it a practical diagnostic for dynamic, data-aware KV-cache optimization and for analyzing representational under-utilization in multilingual and low-resource settings.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05929",
      "pdf_url": "https://arxiv.org/pdf/2602.05929",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05929",
      "scraped_at": "2026-02-11T02:32:24.502441"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration",
    "paper_url": "https://huggingface.co/papers/2602.05708",
    "authors": [
      "Paul Groth",
      "Sebastian Schelter",
      "Arijit Khan",
      "Zeyu Zhang",
      "Chuangtao Ma"
    ],
    "stars": "0",
    "details": {
      "title": "Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration",
      "abstract": "Can blocking help in LLM and RAG-based entity matching? Check out CE-RAG4EM, a Cost-Efficient RAG for Entity Matching that aims to reduce the cost of RAG4EM via blocking-based batch retrieval and inference.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05708",
      "pdf_url": "https://arxiv.org/pdf/2602.05708",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05708",
      "scraped_at": "2026-02-11T02:32:26.344530"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization",
    "paper_url": "https://huggingface.co/papers/2602.07054",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization",
      "abstract": "Check out this latest release from our lab at the Institute for Creative Technologies at the University of Southern California. The proposed method improves emotion reasoning in audiovisual multimodal (\"omni\") LLMs, surpassing the state-of-the-art models on multiple benchmarks. Moreover, the method achieves state-of-the-art results on various traditional emotion benchmarks under a zero-shot setting, eliciting the importance of reasoning even for emotion perception. Project page: https://avere-iclr.github.io",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07054",
      "pdf_url": "https://arxiv.org/pdf/2602.07054",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07054",
      "scraped_at": "2026-02-11T02:32:28.196217"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
    "paper_url": "https://huggingface.co/papers/2602.07040",
    "authors": [
      "Emmett Bicker"
    ],
    "stars": "0",
    "details": {
      "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Learning to Discover at Test Time (2026) AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents (2026) Towards Execution-Grounded Automated AI Research (2026) Learning to Ideate for Machine Learning Engineering Agents (2026) FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems (2026) Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts (2026) EmboCoach-Bench: Benchmarking AI Agents on Developing Embodied Robots (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07040",
      "pdf_url": "https://arxiv.org/pdf/2602.07040",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07040",
      "scraped_at": "2026-02-11T02:32:29.984246"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.02827",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02827",
      "pdf_url": "https://arxiv.org/pdf/2602.02827",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02827",
      "scraped_at": "2026-02-11T02:32:31.874053"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "CauScale: Neural Causal Discovery at Scale",
    "paper_url": "https://huggingface.co/papers/2602.08629",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "CauScale: Neural Causal Discovery at Scale",
      "abstract": "We introduce CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08629",
      "pdf_url": "https://arxiv.org/pdf/2602.08629",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08629",
      "scraped_at": "2026-02-11T02:32:33.712873"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality",
    "paper_url": "https://huggingface.co/papers/2602.08004",
    "authors": [
      "Richard Huang",
      "Shanshan Zhong",
      "George Ling"
    ],
    "stars": "0",
    "details": {
      "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality",
      "abstract": "Understand Agent Skills at a Glance: The Ecosystem, Opportunities, and Risks Behind 40,000+ Claude Skills From patterns of explosive growth and a comprehensive, multi-dimensional functional taxonomy to multi-tier security audits, this data-driven study offers a clear picture of the Agent Skills community ecosystem and its current state of development. It provides quantitative insights for technical implementation, platform building, and applied research, while also giving newcomers a clear, realistic understanding of the field as a whole.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08004",
      "pdf_url": "https://arxiv.org/pdf/2602.08004",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08004",
      "scraped_at": "2026-02-11T02:32:35.623097"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "dewi-kadita: A Python Library for Idealized Fish Schooling Simulation with Entropy-Based Diagnostics",
    "paper_url": "https://huggingface.co/papers/2602.07948",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "dewi-kadita: A Python Library for Idealized Fish Schooling Simulation with Entropy-Based Diagnostics",
      "abstract": "Simulating collective animal behavior requires robust tools to capture emergent complexity. This paper introduces dewi-kadita, an open-source Python library that implements the three-dimensional Couzin model for fish schooling. Unlike traditional tools that rely solely on polarization and rotation order parameters, this library introduces a suite of seven entropy-based metrics combined into a single Oceanic Schooling Index (OSI) to rigorously quantify collective disorder and differentiate between complex states like milling tori and dynamic parallel groups.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07948",
      "pdf_url": "https://arxiv.org/pdf/2602.07948",
      "github_links": [
        "https://github.com/sandyherho/dewi-kadita"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07948",
      "scraped_at": "2026-02-11T02:32:37.464942"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Reasoning-Augmented Representations for Multimodal Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.07125",
    "authors": [
      "Sukanta Ganguly",
      "Soochahn Lee",
      "Brandon Han",
      "Anirudh Sundara Rajan",
      "Jianrui Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "Reasoning-Augmented Representations for Multimodal Retrieval",
      "abstract": "Universal Multimodal Retrieval (UMR) seeks any-to-any search across text and vision, yet modern embedding models remain brittle when queries require latent reasoning (e.g., resolving underspecified references or matching compositional constraints). We argue this brittleness is often data-induced: when images carry \"silent\" evidence and queries leave key semantics implicit, a single embedding pass must both reason and compress, encouraging spurious feature matching. We propose a data-centric framework that decouples these roles by externalizing reasoning before retrieval. Using a strong Vision--Language Model, we make implicit semantics explicit by densely captioning visual evidence in corpus entries, resolving ambiguous multimodal references in queries, and rewriting verbose instructions into concise retrieval constraints. Inference-time enhancement alone is insufficient; the retriever must be trained on these semantically dense representations to avoid distribution shift and fully exploit the added signal. Across M-BEIR, our reasoning-augmented training method yields consistent gains over strong baselines, with ablations showing that corpus enhancement chiefly benefits knowledge-intensive queries while query enhancement is critical for compositional modification requests.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07125",
      "pdf_url": "https://arxiv.org/pdf/2602.07125",
      "github_links": [
        "https://github.com/AugmentedRetrieval/ReasoningAugmentedRetrieval"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07125",
      "scraped_at": "2026-02-11T02:32:39.340644"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "f-GRPO and Beyond: Divergence-Based Reinforcement Learning Algorithms for General LLM Alignment",
    "paper_url": "https://huggingface.co/papers/2602.05946",
    "authors": [
      "Qifan Song",
      "Yue Xing",
      "Guang Lin",
      "Lantao Mei",
      "Rajdeep Haldar"
    ],
    "stars": "0",
    "details": {
      "title": "f-GRPO and Beyond: Divergence-Based Reinforcement Learning Algorithms for General LLM Alignment",
      "abstract": "Recent research shows that Preference Alignment (PA) objectives act as divergence estimators be- tween aligned (chosen) and unaligned (rejected) response distributions. In this work, we extend this divergence-based perspective to general align- ment settings, such as reinforcement learning with verifiable rewards (RLVR), where only environ- mental rewards are available. Within this unified framework, we propose f-Group Relative Policy Optimization (f-GRPO), a class of on-policy re- inforcement learning, and f-Hybrid Alignment Loss (f-HAL), a hybrid on/off policy objectives, for general LLM alignment based on variational representation of f-divergences. We provide the- oretical guarantees that these classes of objec- tives improve the average reward after alignment. Empirically, we validate our framework on both RLVR (Math Reasoning) and PA tasks (Safety Alignment), demonstrating superior performance and flexibility compared to current methods.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05946",
      "pdf_url": "https://arxiv.org/pdf/2602.05946",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05946",
      "scraped_at": "2026-02-11T02:32:41.214026"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Statistical Learning Theory in Lean 4: Empirical Processes from Scratch",
    "paper_url": "https://huggingface.co/papers/2602.02285",
    "authors": [
      "Fanghui Liu",
      "Jason D. Lee",
      "liminho123"
    ],
    "stars": "29",
    "details": {
      "title": "Statistical Learning Theory in Lean 4: Empirical Processes from Scratch",
      "abstract": "We present the first comprehensive Lean 4 formalization of statistical learning theory (SLT) grounded in empirical process theory. Our end-to-end formal infrastructure implement the missing contents in latest Lean library, including a complete development of Gaussian Lipschitz concentration, the first formalization of Dudley‚Äôs entropy integral theorem for sub-Gaussian processes, and an application to least-squares regression with a sharp rate. The project was carried out using a human‚ÄìAI collaborative workflow, in which humans design proof strategies and AI agents execute tactical proof construction, resulting in approximately 30,000 lines of human-verified Lean 4 code produced over 500 hours of supervised development. Beyond implementation, the formalization process exposes and resolves implicit assumptions and missing details in standard SLT textbooks, enforcing a granular, line-by-line understanding of the theory. This work establishes a reusable formal foundation for future developments in machine learning theory. The code is available at https://github.com/YuanheZ/lean-stat-learning-theory",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02285",
      "pdf_url": "https://arxiv.org/pdf/2602.02285",
      "github_links": [
        "https://github.com/YuanheZ/lean-stat-learning-theory"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02285",
      "scraped_at": "2026-02-11T02:32:43.021279"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration",
    "paper_url": "https://huggingface.co/papers/2602.05400",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration",
      "abstract": "In this paper, we argue that LLM pre-training is entering a ‚Äúdata-wall‚Äù regime where readily available high-quality public text is approaching exhaustion, so progress must shift from more tokens to better tokens chosen at the right time. While most existing pipelines either (i) apply static, training-agnostic quality filters or (ii) use dynamic selection criteria defined in raw gradient space, modern LLMs are actually trained with adaptive optimizers like AdamW or Muon whose preconditioning reshapes the effective update direction‚Äîcreating a fundamental mismatch between ‚Äúhow we score data‚Äù and ‚Äúhow training truly updates the model.‚Äù To bridge this gap, we introduce OPUS (Optimizer-induced Projected Utility Selection), a dynamic selection framework that defines data utility directly in the optimizer-induced update space: a sample is valuable insofar as its optimizer-shaped effective update aligns with the descent direction of a stable, high-quality target distribution (our proxy). Concretely, OPUS operationalizes this idea through a principled objective, a scalable estimator, and a diversity-preserving selection rule. Our key contributions are: (1) an optimizer-aware utility for dynamic selection, with closed-form approximations for effective update directions under AdamW and Muon, aligning scoring with real training geometry; (2) BENCH-PROXY, an in-distribution proxy construction method that retrieves benchmark-aligned samples from the pre-training corpus to stabilize the target direction; (3) scalable utility estimation using the Ghost technique + CountSketch projections to avoid per-sample gradient materialization; and (4) Boltzmann sampling with redundancy control to prevent diversity collapse under non-stationary streams. Empirically, OPUS delivers strong data/compute efficiency: it reports only ~4.7% additional compute overhead for selection while achieving large gains across datasets, optimizers, and scales‚Äîincluding improved accuracy (+2.2% average over 10 benchmarks and 8√ó compute reduction in one highlighted setting), outperforming industrial static/dynamic baselines and even matching or exceeding much longer-token training in several regimes.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05400",
      "pdf_url": "https://arxiv.org/pdf/2602.05400",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05400",
      "scraped_at": "2026-02-12T02:25:40.510960"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Code2World: A GUI World Model via Renderable Code Generation",
    "paper_url": "https://huggingface.co/papers/2602.09856",
    "authors": [],
    "stars": "131",
    "details": {
      "title": "Code2World: A GUI World Model via Renderable Code Generation",
      "abstract": "Project Page: https://amap-ml.github.io/Code2World/ Github: https://github.com/AMAP-ML/Code2World",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09856",
      "pdf_url": "https://arxiv.org/pdf/2602.09856",
      "github_links": [
        "https://github.com/AMAP-ML/Code2World"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09856",
      "scraped_at": "2026-02-12T02:25:42.415565"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "UI-Venus-1.5 Technical Report",
    "paper_url": "https://huggingface.co/papers/2602.09082",
    "authors": [],
    "stars": "708",
    "details": {
      "title": "UI-Venus-1.5 Technical Report",
      "abstract": "Is your GUI Agent ready for real work? üî• We‚Äôve seen many great previous GUI Agents, but making a \"stable assistant\" for phones and websites is still hard. There are three main problems: 1Ô∏è‚É£ Knowledge Gap: AI often misses less common icons and doesn't know how specialized apps work. 2Ô∏è‚É£ The Reality Gap: Models that work well in tests often fail during real-life tasks. 3Ô∏è‚É£ Too Complex: Using multi-agent framework usually costs too much. Enter UI-Venus-1.5 üöÄ ‚Äî The new high-performance, end-to-end GUI Agent from Ant Group! Unlike old ways, UI-Venus-1.5 is built for real-world use: üì± All-in-One: One single model for Grounding, Mobile, and Web tasks. üá®üá≥ Real App Support: Full support for 40+ popular Chinese apps, making AI part of daily life. ‚ö° Simple & Fast: A clean, end-to-end design for faster and more reliable work. Check it out and see how AI can truly help you! üêú‚ú®",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09082",
      "pdf_url": "https://arxiv.org/pdf/2602.09082",
      "github_links": [
        "https://github.com/inclusionAI/UI-Venus/blob/UI-Venus-1.5",
        "https://github.com/inclusionAI/UI-Venus"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09082",
      "scraped_at": "2026-02-12T02:25:44.379581"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes",
    "paper_url": "https://huggingface.co/papers/2602.10063",
    "authors": [],
    "stars": "18",
    "details": {
      "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes",
      "abstract": "CoM is a training-free agentic framework that dynamically orchestrates four step-level mindsets (Spatial, Convergent, Divergent, Algorithmic) via a Meta-Agent and a Context Gate, avoiding one-size-fits-all reasoning and improving accuracy and efficiency across diverse benchmarks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10063",
      "pdf_url": "https://arxiv.org/pdf/2602.10063",
      "github_links": [
        "https://github.com/QuantaAlpha/chain-of-mindset"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10063",
      "scraped_at": "2026-02-12T02:25:46.267996"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.08234",
    "authors": [],
    "stars": "140",
    "details": {
      "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning",
      "abstract": "Skill accumulation is the new paradigm for AI agents. We‚Äôre moving from static models to recursive evolution üß¨. SkillRL proves skills > scale, enabling a 7B model to beat GPT-4o üöÄ. Evolving > Scaling. üí° Paper: https://arxiv.org/abs/2602.08234 Code: https://github.com/aiming-lab/SkillRL",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08234",
      "pdf_url": "https://arxiv.org/pdf/2602.08234",
      "github_links": [
        "https://github.com/aiming-lab/SkillRL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08234",
      "scraped_at": "2026-02-12T02:25:48.127471"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads",
    "paper_url": "https://huggingface.co/papers/2602.09443",
    "authors": [],
    "stars": "13",
    "details": {
      "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads",
      "abstract": "Project: https://prime-rl.github.io/P1-VL GitHub: https://github.com/PRIME-RL/P1-VL",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09443",
      "pdf_url": "https://arxiv.org/pdf/2602.09443",
      "github_links": [
        "https://github.com/PRIME-RL/P1-VL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09443",
      "scraped_at": "2026-02-12T02:25:49.970770"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.10090",
    "authors": [],
    "stars": "44",
    "details": {
      "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning",
      "abstract": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning üöÄ Introducing Agent World Model (AWM) ‚Äî we synthesized 1,000 code-driven environments with 35K tools and 10K tasks for large-scale agentic reinforcement learning! No real APIs. No human design. Just 100 seed names ‚Üí fully functional, database-backed agent environments exposed via MCP interface. Agents trained purely on synthetic envs generalize to out-of-distribution benchmarks. Code, Environments, & Models all open-sourced. üî• We train Qwen3 (4B/8B/14B) with online RL using GRPO algorithm at serious scale: ‚ö° 1,024 parallel env instances per training step üéØ Hybrid reward: step-level format checks + task-level outcome verification üß† History-aware training: align sliding-window truncation between training & inference Key insight: code-driven environments give more stable learning signals than LLM-simulated ones, and they're orders of magnitude faster. Results on 3 out-of-distribution benchmarks (AWM does NOT target any benchmark specific ones): üìä BFCLv3 : 8B jumps 53.83 ‚Üí 65.94 (+12.11) üìä œÑ¬≤-bench : competitive, 14B reaches 39.03 Pass@1 üìä MCP-Universe : best overall, 8B: 6.70 ‚Üí 11.17 üèÜ AWM is the ONLY method that improves over Base on ALL three benchmarks. üìÑ Paper: https://arxiv.org/abs/2602.10090 üíª Code: https://github.com/Snowflake-Labs/agent-world-model ü§ó Huggingface: https://huggingface.co/datasets/Snowflake/AgentWorldModel-1K",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10090",
      "pdf_url": "https://arxiv.org/pdf/2602.10090",
      "github_links": [
        "https://github.com/Snowflake-Labs/agent-world-model"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10090",
      "scraped_at": "2026-02-12T02:25:51.927734"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Prism: Spectral-Aware Block-Sparse Attention",
    "paper_url": "https://huggingface.co/papers/2602.08426",
    "authors": [],
    "stars": "19",
    "details": {
      "title": "Prism: Spectral-Aware Block-Sparse Attention",
      "abstract": "TL;DR Prism is a training-free method to accelerate long-context LLM pre-filling. It addresses the \"blind spot\" in standard mean pooling caused by Rotary Positional Embeddings (RoPE) by disentangling attention into high-frequency and low-frequency bands. Key Features: Dual-Band Importance Estimation: Separates semantic (low-freq) and positional (high-freq) signals. Energy-Based Calibration: Restores attenuated signals automatically. Speed: Up to 5.1√ó speedup on 128K context with negligible accuracy loss. Implementation: Purely block-level ops with custom kernels for efficient estimation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08426",
      "pdf_url": "https://arxiv.org/pdf/2602.08426",
      "github_links": [
        "https://github.com/xinghaow99/prism"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08426",
      "scraped_at": "2026-02-12T02:25:53.794945"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
    "paper_url": "https://huggingface.co/papers/2602.07035",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
      "abstract": "üß†üîç DLLM-Searcher: Adapting Diffusion Large Language Models for Search Agents Diffusion Large Language Models (dLLMs) offer flexible generation but struggle as search agents due to latency and weak tool-use capabilities.  This paper introduces DLLM-Searcher , a framework that adapts dLLMs for efficient, agentic search and retrieval . üöÄ Key ideas: Parallel-Reasoning and Acting (P-ReAct): Enables parallel reasoning and tool execution using diffusion‚Äôs non-autoregressive generation, significantly reducing inference latency. Agent-oriented post-training: A two-stage pipeline with Agentic Supervised Fine-Tuning (SFT) + Agentic Variance-Reduced Preference Optimization (VRPO) improves reasoning structure, tool calling, and search reliability. üìä Results: Competitive performance with strong autoregressive LLM-based search agents on multi-hop retrieval tasks Up to ~15% speedup in end-to-end inference with P-ReAct üí° Why it matters: DLLM-Searcher shows that diffusion LLMs can be practical and efficient search agents , opening a new direction for low-latency, agentic information retrieval systems.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07035",
      "pdf_url": "https://arxiv.org/pdf/2602.07035",
      "github_links": [
        "https://github.com/bubble65/DLLM-Searcher"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07035",
      "scraped_at": "2026-02-12T02:25:55.679529"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Olaf-World: Orienting Latent Actions for Video World Modeling",
    "paper_url": "https://huggingface.co/papers/2602.10104",
    "authors": [
      "Mike Zheng Shou",
      "Ivor W. Tsang",
      "Yuchao Gu",
      "YuxinJ"
    ],
    "stars": "33",
    "details": {
      "title": "Olaf-World: Orienting Latent Actions for Video World Modeling",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10104",
      "pdf_url": "https://arxiv.org/pdf/2602.10104",
      "github_links": [
        "https://github.com/showlab/Olaf-World"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10104",
      "scraped_at": "2026-02-12T02:25:57.581027"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling",
    "paper_url": "https://huggingface.co/papers/2602.09084",
    "authors": [],
    "stars": "24",
    "details": {
      "title": "Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling",
      "abstract": "Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09084",
      "pdf_url": "https://arxiv.org/pdf/2602.09084",
      "github_links": [
        "https://github.com/taco-group/agent-banana"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09084",
      "scraped_at": "2026-02-12T02:25:59.462924"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Condition Errors Refinement in Autoregressive Image Generation with Diffusion Loss",
    "paper_url": "https://huggingface.co/papers/2602.07022",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Condition Errors Refinement in Autoregressive Image Generation with Diffusion Loss",
      "abstract": "This study presents a theoretical analysis of autoregressive image generation with diffusion loss, demonstrating that patch denoising optimization effectively mitigates condition errors and leads to a stable condition distribution. To further address condition inconsistency, we introduce a novel condition refinement approach based on Optimal Transport theory, which outperforms existing diffusion and autoregressive baselines in experiments.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07022",
      "pdf_url": "https://arxiv.org/pdf/2602.07022",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07022",
      "scraped_at": "2026-02-12T02:26:01.321545"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation",
    "paper_url": "https://huggingface.co/papers/2602.00268",
    "authors": [
      "Lior Wolf",
      "Amit Edenzon",
      "Eitan Shaar",
      "shaulov"
    ],
    "stars": "10",
    "details": {
      "title": "TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation",
      "abstract": "Project page: https://arielshaulov.github.io/TokenTrim/ Open source code ü•≥: https://github.com/arielshaulov/TokenTrim",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00268",
      "pdf_url": "https://arxiv.org/pdf/2602.00268",
      "github_links": [
        "https://github.com/arielshaulov/TokenTrim"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00268",
      "scraped_at": "2026-02-12T02:26:03.215276"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models",
    "paper_url": "https://huggingface.co/papers/2602.04208",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models",
      "abstract": "We tackle test-time robustness of VLA models without additional training or multiple forward passes, by proposing SCALE: jointly modulate visual attention and action decoding based on self-uncertainty.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04208",
      "pdf_url": "https://arxiv.org/pdf/2602.04208",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04208",
      "scraped_at": "2026-02-12T02:26:05.048492"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs",
    "paper_url": "https://huggingface.co/papers/2602.00462",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs",
      "abstract": "In this paper we propose a new interpretability method LatentLens. With this we can finally show that visual tokens are actually interpretable across all layers in an LLM, something that past methods like logit lens and or using the LLM's embedding matrix would not be able to do. Our key insight is to use a large pool of contextual embeddings from the LLM to find nearest neighbors instead of just using a static embedding or unembedding matrix: We empirically show how well LatentLens works in a controlled setting with 9 model combinations as well as an off-the-shelf VLM. We also notice that the Mid-Layer Leap phenomenon: visual tokens as they arrive at the LLM input are already most aligned to later semantic LLM layers! So for example a visual token arriving at layer 0 (coming from the vision encoder --> MLP), will have its closest nearest neighbors from e.g. layer 8 of the LLM. We hope this will spark new VLM interpretability research and even projects on other kinds of latent representations in LLM (soft prompts, speech, VLAs, ...)!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00462",
      "pdf_url": "https://arxiv.org/pdf/2602.00462",
      "github_links": [
        "https://github.com/McGill-NLP/latentlens"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00462",
      "scraped_at": "2026-02-12T02:26:06.924608"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation",
    "paper_url": "https://huggingface.co/papers/2602.09849",
    "authors": [
      "Xiaoyu Chen",
      "Yanjiang Guo",
      "Yuanfei Luo",
      "Jianke Zhang",
      "Yucheng Hu"
    ],
    "stars": "0",
    "details": {
      "title": "BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation",
      "abstract": "BagelVLA is a unified model that integrates linguistic planning, visual forecasting, and action generation within a single framework for long-horizon manipulation tasks. üß† Model Architecture BagelVLA utilizes a Mixture-of-Transformers (MoT) architecture, comprising three independent transformers specialized for linguistic, visual, and action modalities. To tackle long-horizon tasks and semantic generalization, we formulate language-conditioned action learning as a long-sequence interleaved planning problem. These modalities are structured into a unified sequence, enabling the model to generate predictions across all three modalities based on the interleaved context. To address the high latency in combining visual generation with control, we introduce Residual Flow Guidance (RFG). Instead of generating future frames from scratch, RFG conditions on the current observation as a strong structural prior and performs single-step denoising to predict the residual change toward the next keyframe. RFG provides a lightweight predictive visual representation that captures task-relevant dynamics with minimal overhead. This substantially reduces the computational cost of foresight while preserving its utility for action generation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09849",
      "pdf_url": "https://arxiv.org/pdf/2602.09849",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09849",
      "scraped_at": "2026-02-12T02:26:08.904233"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model",
    "paper_url": "https://huggingface.co/papers/2602.10098",
    "authors": [
      "Zezhi Liu",
      "Shaojie Ren",
      "Zekun Qi",
      "Wenyao Zhang",
      "Jingwen Sun"
    ],
    "stars": "12",
    "details": {
      "title": "VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos (2026) Robotic VLA Benefits from Joint Learning with Motion Image Diffusion (2025) ConLA: Contrastive Latent Action Learning from Human Videos for Robotic Manipulation (2026) Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models (2026) Motus: A Unified Latent Action World Model (2025) MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction (2026) Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10098",
      "pdf_url": "https://arxiv.org/pdf/2602.10098",
      "github_links": [
        "https://github.com/ginwind/VLA-JEPA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10098",
      "scraped_at": "2026-02-12T02:26:10.742477"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training",
    "paper_url": "https://huggingface.co/papers/2602.06820",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training",
      "abstract": "We introduce ScaleEnv, a framework that constructs fully interactive environments and verifiable tasks entirely from scratch. By enabling agents to learn through exploration within ScaleEnv, we demonstrate significant performance improvements on unseen, multi-turn tool-use benchmarks such as $\\tau^2$-Bench and VitaBench, highlighting strong generalization capabilities.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06820",
      "pdf_url": "https://arxiv.org/pdf/2602.06820",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06820",
      "scraped_at": "2026-02-12T02:26:12.604118"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Fine-T2I: An Open, Large-Scale, and Diverse Dataset for High-Quality T2I Fine-Tuning",
    "paper_url": "https://huggingface.co/papers/2602.09439",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Fine-T2I: An Open, Large-Scale, and Diverse Dataset for High-Quality T2I Fine-Tuning",
      "abstract": "Dataset: https://huggingface.co/datasets/ma-xu/fine-t2i Space: https://huggingface.co/spaces/ma-xu/fine-t2i-explore",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09439",
      "pdf_url": "https://arxiv.org/pdf/2602.09439",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09439",
      "scraped_at": "2026-02-12T02:26:14.471985"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models",
    "paper_url": "https://huggingface.co/papers/2602.09017",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models",
      "abstract": "The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), a new class of general robotic behavior models, which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement an efficient real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09017",
      "pdf_url": "https://arxiv.org/pdf/2602.09017",
      "github_links": [
        "https://github.com/jeffacce/cap-policy"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09017",
      "scraped_at": "2026-02-12T02:26:16.287103"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
    "paper_url": "https://huggingface.co/papers/2602.08847",
    "authors": [],
    "stars": "53",
    "details": {
      "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
      "abstract": "Dr. MAS is designed for stable end-to-end RL post-training üî• of multi-agent LLM systems. It enables agents to collaborate on complex reasoning tasks with: ‚ú® Flexible agent registry & multi-agent orchestration ‚ú® Heterogeneous LLMs (shared/non-shared) ‚ú® Co-training of multiple agents‚ú® Efficient resource pooling. In this work, we theoretically pinpoint a key reason for training instability when extending group-based RL to multi-agent LLM systems. We show that under GRPO-style optimization, a global normalization baseline may lead to gradient-norm instability. Based on this finding, Dr. MAS propose a simple yet effective remedy which calibrates gradient scales and dramatically stabilizes training.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08847",
      "pdf_url": "https://arxiv.org/pdf/2602.08847",
      "github_links": [
        "https://github.com/langfengQ/DrMAS"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08847",
      "scraped_at": "2026-02-12T02:26:18.155897"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments",
    "paper_url": "https://huggingface.co/papers/2602.01244",
    "authors": [
      "Yang Wang",
      "Wei Zhang",
      "Yuyang Song",
      "Yizhi Li",
      "Siwei Wu"
    ],
    "stars": "7",
    "details": {
      "title": "Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments",
      "abstract": "This is a repo for paper \"Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments\"",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01244",
      "pdf_url": "https://arxiv.org/pdf/2602.01244",
      "github_links": [
        "https://github.com/multimodal-art-projection/TerminalTraj"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01244",
      "scraped_at": "2026-02-12T02:26:19.996419"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "VideoWorld 2: Learning Transferable Knowledge from Real-world Videos",
    "paper_url": "https://huggingface.co/papers/2602.10102",
    "authors": [],
    "stars": "685",
    "details": {
      "title": "VideoWorld 2: Learning Transferable Knowledge from Real-world Videos",
      "abstract": "ü§ñText is not enough, Visual is the key to AGIÔºÅCan Al learn transferable knowledge for complex tasks directly from videos? Just like a child learns to fold a paper airplane or build a LEGO from video tutorialsüë∂ üòéThrilled to introduce VideoWorld 2, the successor of VideoWorld. Unlike Sora and Veo, it is the the first generative model that masters complex real-world knowledge solely through visual data, without any reliance on language models. üôã You might wonder: what knowledge remains out of reach for today‚Äôs AI?  Try asking Sora 2 or Veo 3 to fold a coherent paper boat, or have Gemini describe every micro-fold and material change in text.  Although any child can master this skill just by watching video tutorials, today's most advanced AI often fails at such tasks. üöÄTo address this challenge, we propose VideoWorld 2. Unlike models that rely on language priors, it is the first to master complex, long-horizon real-world knowledge solely by \"watching\" raw videos and  generalizing the skill to new environments. üßë‚Äçüè´ The \"Cambrian Moment\" for AI? As Dr. Feifei Li noted, vision-enabled perception and planning triggered the Cambrian Explosion 540 million years ago. VideoWorld 2 explores this frontier:  Without any textual descriptions, it completes minute-long handcraft tasks like paper folding and block-building, which involve fine-grained manipulation and long-horizon planning that current AI fails to learn. Furthermore, it can generalize these skills across various unseen scenes and perform multi-task, cross-environment robotic manipulation. Our main contributions are: üëâWe explore, for the first time, how to learn complex, long-range skills from raw videos and generalize them to new environments. We find that disentangling visual appearance from core dynamics is the key to mastering world knowledge. üëâWe propose VideoWorld 2, leveraging a dynamic-enhanced Latent Dynamic Model to extract task-relevant dynamics to boost long-horizon tasks success rates by up to 70% üëâWe construct Video-CraftBench, a large-scale video-based handcraft dataset for training and evaluation, facilitating future research on knowledge learning from pure videos.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10102",
      "pdf_url": "https://arxiv.org/pdf/2602.10102",
      "github_links": [
        "https://github.com/ByteDance-Seed/VideoWorld/tree/main/VideoWorld2"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10102",
      "scraped_at": "2026-02-12T02:26:21.880904"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
    "paper_url": "https://huggingface.co/papers/2602.07276",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
      "abstract": "Activation steering has emerged as a promising method for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering approaches identify and steer the model from a single static direction for each task or concept, which is inflexible under task variation and insufficient for complex tasks requiring multiple coordinated capabilities. To address this gap, we propose Steer2Adapt, a lightweight framework that enables efficient LLM adaptation by composing steering vectors rather than learning new ones from scratch. In practice, tasks within the same domain (e.g., reasoning or safety) often share a small set of underlying concept dimensions. Steer2Adapt spans these dimensions into a reusable, low-dimensional semantic prior subspace and adapts to new tasks by dynamically discovering a linear combination of basis vectors using only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of Steer2Adapt, with an average of 8.2% improvement. Together with our analyses, we establish Steer2Adapt as a data-efficient, stable, and transparent inference-time adaptation method for LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07276",
      "pdf_url": "https://arxiv.org/pdf/2602.07276",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07276",
      "scraped_at": "2026-02-12T02:26:23.707693"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.08382",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning",
      "abstract": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning. We introduce LycheeMemory, a cognitively inspired framework that enables efficient long-context inference via chunk-wise compression and selective memory recall, rather than processing all raw tokens. Code will be coming soon.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08382",
      "pdf_url": "https://arxiv.org/pdf/2602.08382",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08382",
      "scraped_at": "2026-02-12T02:26:25.537745"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Rethinking Global Text Conditioning in Diffusion Transformers",
    "paper_url": "https://huggingface.co/papers/2602.09268",
    "authors": [
      "Yuchen Liu",
      "Ilya Drobyshevskiy",
      "Zongze Wu",
      "Daniil Pakhomov",
      "Nikita Starodubcev"
    ],
    "stars": "13",
    "details": {
      "title": "Rethinking Global Text Conditioning in Diffusion Transformers",
      "abstract": "GitHub: https://github.com/quickjkee/modulation-guidance",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09268",
      "pdf_url": "https://arxiv.org/pdf/2602.09268",
      "github_links": [
        "https://github.com/quickjkee/modulation-guidance"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09268",
      "scraped_at": "2026-02-12T02:26:27.369867"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.09000",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
      "abstract": "Let's discuss Self-Feedback for RL Reasoning (iGRPO) Motivation. Current RL methods for reasoning (GRPO, DAPO, etc.) treat each generation as a one-shot attempt. The model samples, gets a reward, updates, and moves on. But humans almost never solve hard problems in one pass. We draft, re-read, spot mistakes, and refine. Existing RL pipelines don't capture this loop. Some recent methods try to close the gap with critique generation or self-verification, but these ask the model to learn auxiliary behaviors (writing critiques, producing verification rationales) that are only indirectly tied to the actual outcome reward. We wanted something simpler: what if the model's own best attempt is the feedback, and we just train it to beat that attempt? What we built. iGRPO is a two-stage extension of GRPO that adds self-conditioning through the model's own drafts. Stage 1 (Exploratory Draft Generation): Sample multiple candidate solutions from the current policy. Score them with the same scalar reward you're already using. Pick the best one. Stage 2 (Conditioned Refinement): Append that best draft to the original prompt and sample a new group of completions. Apply the standard GRPO-style clipped surrogate update only on these Stage 2 outputs. No critic networks, no reward models, no verification rationales, no generated critiques. The best draft is the only feedback signal, and it comes for free from Stage 1 exploration. The important part: as the policy improves across training, its Stage 1 drafts get stronger, so Stage 2 sees better conditioning, so the policy improves even more. We formally prove this monotonic improvement property under binary rewards: the expected quality of the selected draft increases as the policy's success probability increases. The model doesn't learn to copy the draft. It learns a refinement function that compounds across training. How it differs from critique/verification approaches. Methods like Self-Verification and Critique-GRPO require the model to produce extra text (verification steps, natural-language critiques) and then condition on that. This means the model has to allocate capacity to an auxiliary skill that isn't directly optimized by the outcome reward. iGRPO sidesteps this entirely. The conditioning signal is a full solution attempt scored by the same reward used for optimization. There's no ambiguity about what \"good feedback\" looks like, because it's literally the model's highest-reward output. Key results. Controlled comparisons (matched rollout budgets, same total completions per prompt): Nemotron-H-8B-Base-8K: iGRPO reaches 45.04% average vs. 41.08% for GRPO (+3.96), and beats Self-Verification (42.86%) and Critique-GRPO (43.39%). DeepSeek-R1-Distill-Qwen-7B: iGRPO at 69.87% vs. GRPO at 68.29%, with gains concentrated on multi-step benchmarks like AIME24 (56.30%) and AMC (95.00%). OpenMath-Nemotron-7B: Even with an already strong 74.83% base, iGRPO pushes to 76.07%. At 14B scale, gains persist: DeepSeek-R1-Distill-Qwen-14B goes from 71.29% (GRPO) to 73.02% (iGRPO); OpenMath-Nemotron-14B from 76.73% to 78.00%. Stronger base + harder data: OpenReasoning-Nemotron-7B trained on AceReason-Math with iGRPO achieves 85.62% on AIME24 and 79.64% on AIME25, with transfer gains on GPQA (+1.84) and MMLU-Pro (+0.91). The refinement wrapper generalizes beyond GRPO: Applying the same two-stage mechanism to DAPO and GSPO yields +1.19 and +1.11 average improvements respectively, under matched budgets. The gains come from the refinement interface, not GRPO-specific details. Richer rewards help: Swapping the binary outcome checker for a GPT-5 generative judge improves the average from 69.87% to 70.81% (+0.94), with the largest lifts on AIME24/25 and Minerva, consistent with partial credit keeping near-miss traces alive through Stage 1 selection. Learning dynamics: iGRPO delays premature entropy collapse. Both methods start at ~2.45 nats, but GRPO drops to 0.60 by 10% of training while iGRPO decays more gradually (0.80 at 15%). This sustained mid-training exploration lets the model recover from near-miss reasoning traces before converging. Overhead: Peak memory is essentially identical (~54.93 GB for both). Throughput drops from 0.41 to 0.34 samples/sec. Total training time increases by ~13% (83.3 ‚Üí 94.1 GPU hours). No extra GPUs, no extra memory. In short, iGRPO adds a self-feedback refinement loop to group-based RL that uses the model's own best draft as conditioning. It's simple, adds minimal overhead, generalizes across optimizers, and consistently improves reasoning across model families and scales.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09000",
      "pdf_url": "https://arxiv.org/pdf/2602.09000",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09000",
      "scraped_at": "2026-02-12T02:26:29.224257"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Covo-Audio Technical Report",
    "paper_url": "https://huggingface.co/papers/2602.09823",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Covo-Audio Technical Report",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Fun-Audio-Chat Technical Report (2025) FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning (2026) MiMo-Audio: Audio Language Models are Few-Shot Learners (2025) Qwen3-TTS Technical Report (2026) A$^2$-LLM: An End-to-end Conversational Audio Avatar Large Language Model (2026) VoiceSculptor: Your Voice, Designed By You (2026) Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09823",
      "pdf_url": "https://arxiv.org/pdf/2602.09823",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09823",
      "scraped_at": "2026-02-12T02:26:31.050544"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Effective Reasoning Chains Reduce Intrinsic Dimensionality",
    "paper_url": "https://huggingface.co/papers/2602.09276",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Effective Reasoning Chains Reduce Intrinsic Dimensionality",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09276",
      "pdf_url": "https://arxiv.org/pdf/2602.09276",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09276",
      "scraped_at": "2026-02-12T02:26:32.851581"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution",
    "paper_url": "https://huggingface.co/papers/2602.09662",
    "authors": [
      "Liming Zheng",
      "Lei Chen",
      "Xuanle Zhao",
      "Jing Huang",
      "Deyang Jiang"
    ],
    "stars": "0",
    "details": {
      "title": "TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution",
      "abstract": "TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09662",
      "pdf_url": "https://arxiv.org/pdf/2602.09662",
      "github_links": [
        "https://github.com/UITron-hub/TreeCUA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09662",
      "scraped_at": "2026-02-12T02:26:34.662675"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
    "paper_url": "https://huggingface.co/papers/2602.07153",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
      "abstract": "End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify branch points that correspond to meaningful state changes and propose new, state-grounded task variants conditioned on the current GUI context. An executing agent then follows the proposed instructions to generate new trajectories, while a verifier enforces task completion via state-aware checks and trajectory-level consistency. To improve supervision quality, we further apply task-conditioned step-level filtering to remove ungrounded actions and denoise post-branch segments to maintain coherent intent. Experiments on standard desktop benchmarks, OSWorld and WindowsAgentArena, show that models fine-tuned on our expanded corpus achieve consistent improvements over zero-shot agents and representative synthesis baselines, and generalize across applications and operating systems.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07153",
      "pdf_url": "https://arxiv.org/pdf/2602.07153",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07153",
      "scraped_at": "2026-02-12T02:26:36.538313"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SAGE: Scalable Agentic 3D Scene Generation for Embodied AI",
    "paper_url": "https://huggingface.co/papers/2602.10116",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SAGE: Scalable Agentic 3D Scene Generation for Embodied AI",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10116",
      "pdf_url": "https://arxiv.org/pdf/2602.10116",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10116",
      "scraped_at": "2026-02-12T02:26:38.404431"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Autoregressive Image Generation with Masked Bit Modeling",
    "paper_url": "https://huggingface.co/papers/2602.09024",
    "authors": [],
    "stars": "23",
    "details": {
      "title": "Autoregressive Image Generation with Masked Bit Modeling",
      "abstract": "SOTA discrete visual generation defeats diffusion models with 0.99 FID score, project page is available at https://bar-gen.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09024",
      "pdf_url": "https://arxiv.org/pdf/2602.09024",
      "github_links": [
        "https://github.com/amazon-far/BAR"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09024",
      "scraped_at": "2026-02-12T02:26:40.227063"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration",
    "paper_url": "https://huggingface.co/papers/2602.08344",
    "authors": [
      "Jianfei Zhang",
      "Xiangyu Xi",
      "Jianing Wang",
      "Qi Guo",
      "DeyangKong"
    ],
    "stars": "0",
    "details": {
      "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration",
      "abstract": "Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE) , which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08344",
      "pdf_url": "https://arxiv.org/pdf/2602.08344",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08344",
      "scraped_at": "2026-02-12T02:26:42.013100"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "TodoEvolve: Learning to Architect Agent Planning Systems",
    "paper_url": "https://huggingface.co/papers/2602.07839",
    "authors": [
      "Heng Chang",
      "Zihan Zhang",
      "Guibin Zhang",
      "Yanzuo Jiang",
      "Jiaxi Liu"
    ],
    "stars": "6",
    "details": {
      "title": "TodoEvolve: Learning to Architect Agent Planning Systems",
      "abstract": "Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \\textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07839",
      "pdf_url": "https://arxiv.org/pdf/2602.07839",
      "github_links": [
        "https://github.com/EcthelionLiu/TodoEvolve"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07839",
      "scraped_at": "2026-02-12T02:26:43.792166"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model",
    "paper_url": "https://huggingface.co/papers/2602.07422",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model",
      "abstract": "Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality‚Äìsecurity paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionalitypreserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07422",
      "pdf_url": "https://arxiv.org/pdf/2602.07422",
      "github_links": [
        "https://github.com/AndrewWTY/SecCoderX"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07422",
      "scraped_at": "2026-02-12T02:26:45.613840"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding",
    "paper_url": "https://huggingface.co/papers/2602.06161",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding",
      "abstract": "We found a silly failure mode in Parallel Revocable Diffusion Decoding: flip-flop . A token gets ReMask‚Äôed‚Ä¶ then comes back unchanged. In the existing approach, <1% of ReMasks actually change the token (‚âà99% wasted). We propose COVER which verifies without nuking context: mask seeds for leave-one-out, but inject their cached K,V for everyone else. A simple diagonal correction removes self-leakage. Result: fewer useless revisions + faster parallel drafting.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06161",
      "pdf_url": "https://arxiv.org/pdf/2602.06161",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06161",
      "scraped_at": "2026-02-12T02:26:47.459271"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Stable Velocity: A Variance Perspective on Flow Matching",
    "paper_url": "https://huggingface.co/papers/2602.05435",
    "authors": [
      "Xin Tao",
      "Liang Hou",
      "Xin Yu",
      "Yongxing Zhang",
      "Donglin Yang"
    ],
    "stars": "14",
    "details": {
      "title": "Stable Velocity: A Variance Perspective on Flow Matching",
      "abstract": "While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity , a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet $256\\times256$ and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than $2\\times$ faster sampling within the low-variance regime without degrading sample quality.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05435",
      "pdf_url": "https://arxiv.org/pdf/2602.05435",
      "github_links": [
        "https://github.com/linYDTHU/StableVelocity"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05435",
      "scraped_at": "2026-02-12T02:26:49.366527"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry",
    "paper_url": "https://huggingface.co/papers/2602.02464",
    "authors": [
      "Atticus Geiger",
      "Shauli Ravfogel",
      "Omri Fahn",
      "Shaked Ronen",
      "Or Shafran"
    ],
    "stars": "12",
    "details": {
      "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry",
      "abstract": "Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02464",
      "pdf_url": "https://arxiv.org/pdf/2602.02464",
      "github_links": [
        "https://github.com/ordavid-s/decomposing-activations-local-geometry"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02464",
      "scraped_at": "2026-02-12T02:26:51.286831"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "On the Optimal Reasoning Length for RL-Trained Language Models",
    "paper_url": "https://huggingface.co/papers/2602.09591",
    "authors": [
      "Rio Yokota",
      "Taishi-N324",
      "neodymium6"
    ],
    "stars": "0",
    "details": {
      "title": "On the Optimal Reasoning Length for RL-Trained Language Models",
      "abstract": "RL-trained reasoning models often produce longer CoT, increasing test-time cost. We compare several length-control methods on Qwen3-1.7B-Base and DeepSeek-R1-Distill-Qwen-1.5B, and characterize when length penalties hurt reasoning acquisition vs when tuned control improves efficiency. We also highlight two failure modes: overly long outputs increase dispersion, while overly short outputs cause under-thinking.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09591",
      "pdf_url": "https://arxiv.org/pdf/2602.09591",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09591",
      "scraped_at": "2026-02-12T02:26:53.188546"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Learning Self-Correction in Vision-Language Models via Rollout Augmentation",
    "paper_url": "https://huggingface.co/papers/2602.08503",
    "authors": [
      "Ruqi Zhang",
      "Bolian Li",
      "Ziliang Qiu",
      "Yi Ding"
    ],
    "stars": "0",
    "details": {
      "title": "Learning Self-Correction in Vision-Language Models via Rollout Augmentation",
      "abstract": "Learning self-correction in Vision-language models via rollout augmentation",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08503",
      "pdf_url": "https://arxiv.org/pdf/2602.08503",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08503",
      "scraped_at": "2026-02-12T02:26:55.028721"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs",
    "paper_url": "https://huggingface.co/papers/2602.07755",
    "authors": [
      "Jeff Clune",
      "Shengran Hu",
      "Yiming Xiong"
    ],
    "stars": "39",
    "details": {
      "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs",
      "abstract": "Can AI agents design better memory mechanisms for themselves? Introducing Learning to Continually Learn via Meta-learning Memory Designs. A meta agent automatically designs memory mechanisms, including what info to store, how to retrieve it, and how to update it, enabling agentic systems to continually learn across diverse domains.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07755",
      "pdf_url": "https://arxiv.org/pdf/2602.07755",
      "github_links": [
        "https://github.com/zksha/alma"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07755",
      "scraped_at": "2026-02-12T02:26:56.864017"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "ContextBench: A Benchmark for Context Retrieval in Coding Agents",
    "paper_url": "https://huggingface.co/papers/2602.05892",
    "authors": [
      "Jiaming Wang",
      "Rili Feng",
      "Bohan Zhang",
      "Letian Zhu",
      "Han Li"
    ],
    "stars": "4",
    "details": {
      "title": "ContextBench: A Benchmark for Context Retrieval in Coding Agents",
      "abstract": "Most repo-level benchmarks measure Pass@k ‚úÖ But fixing a bug does not mean the agent understood the code üëÄ We built ContextBench üéâ A benchmark to measure whether coding agents actually retrieve and use the right context üîçüìÇ üìä What‚Äôs inside üß© 1,136 real-world issues üìÅ 66 repositories üåç 8 programming languages üß† Expert-verified gold contexts at file, block, and line granularity üë£ Full trajectory tracking of agent behavior üìà Metrics: Recall, Precision, F1, Efficiency, Usage Drop üîç What surprised us 1Ô∏è‚É£ Complex agentic scaffolds often do not improve retrieval quality üòÖ Instead, they introduce over-engineering. A familiar pattern in AI research‚Ä¶ the Bitter Lesson again üçã 2Ô∏è‚É£ Many SOTA LLMs chase high recall but sacrifice precision üìâ More context retrieved, more noise introduced 3Ô∏è‚É£ Retrieved ‚â† Utilized ‚ùó Agents frequently inspect the right code but fail to incorporate it 4Ô∏è‚É£ More balanced retrieval strategies achieve stronger Pass@1 at lower cost ‚öñÔ∏è‚ú®",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05892",
      "pdf_url": "https://arxiv.org/pdf/2602.05892",
      "github_links": [
        "https://github.com/EuniAI/ContextBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05892",
      "scraped_at": "2026-02-12T02:26:58.643631"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories",
    "paper_url": "https://huggingface.co/papers/2602.05085",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories",
      "abstract": "We introduce Locas, a parametric memory for parameter-efficient Test-Time Training (TTT) and continual learning. Unlike previous methods that only introduce in-place low-rank model updates (such as LoRA) that do not provide expanded capacity or requiring modified pretraining/meta-learning, Locas is a plug-and-play module that has perfect compatibility with existing tech stacks while achieving fast convergence, good generalization and compute/param efficiency, through initializing itself from the backbone model's activations, parameters and/or gradients.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05085",
      "pdf_url": "https://arxiv.org/pdf/2602.05085",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05085",
      "scraped_at": "2026-02-12T02:27:00.436675"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders",
    "paper_url": "https://huggingface.co/papers/2602.10099",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders",
      "abstract": "Leveraging representation encoders for generative modeling offers a path for efficient, high-fidelity synthesis. However, standard diffusion transformers fail to converge on these representations directly. While recent work attributes this to a capacity bottleneck proposing computationally expensive width scaling of diffusion transformers we demonstrate that the failure is fundamentally geometric. We identify Geometric Interference as the root cause: standard Euclidean flow matching forces probability paths through the low-density interior of the hyperspherical feature space of representation encoders, rather than following the manifold surface. To resolve this, we propose Riemannian Flow Matching with Jacobi Regularization (RJF). By constraining the generative process to the manifold geodesics and correcting for curvature-induced error propagation, RJF enables standard Diffusion Transformer architectures to converge without width scaling. Our method RJF enables the standard DiT-B architecture (131M parameters) to converge effectively, achieving an FID of 3.37 where prior methods fail to converge.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10099",
      "pdf_url": "https://arxiv.org/pdf/2602.10099",
      "github_links": [
        "https://github.com/amandpkr/RJF"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10099",
      "scraped_at": "2026-02-12T02:27:02.230260"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "LLMs Encode Their Failures: Predicting Success from Pre-Generation Activations",
    "paper_url": "https://huggingface.co/papers/2602.09924",
    "authors": [
      "Chris Russell",
      "William Bankes",
      "Thomas Foster",
      "William Lugoloobi"
    ],
    "stars": "0",
    "details": {
      "title": "LLMs Encode Their Failures: Predicting Success from Pre-Generation Activations",
      "abstract": "We show that LLMs maintain a linearly accessible internal representation of difficulty that differs from human assessments and varies across decoding settings. We apply this to route queries between models with different reasoning capabilities. Github: https://github.com/KabakaWilliam/llms_know_difficulty",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09924",
      "pdf_url": "https://arxiv.org/pdf/2602.09924",
      "github_links": [
        "https://github.com/KabakaWilliam/llms_know_difficulty"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09924",
      "scraped_at": "2026-02-12T02:27:04.045053"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering",
    "paper_url": "https://huggingface.co/papers/2602.08519",
    "authors": [],
    "stars": "21",
    "details": {
      "title": "Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering",
      "abstract": "PyAGC is a production-ready, modular library and comprehensive benchmark for Attributed Graph Clustering (AGC), built on PyTorch and PyTorch Geometric. It unifies 20+ state-of-the-art algorithms under a principled Encode-Cluster-Optimize (ECO) framework, provides mini-batch implementations that scale to 111 million nodes on a single 32GB GPU, and introduces a holistic evaluation protocol spanning supervised, unsupervised, and efficiency metrics across 12 diverse datasets.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08519",
      "pdf_url": "https://arxiv.org/pdf/2602.08519",
      "github_links": [
        "https://github.com/Cloudy1225/PyAGC"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08519",
      "scraped_at": "2026-02-12T02:27:05.867653"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "MIND: Benchmarking Memory Consistency and Action Control in World Models",
    "paper_url": "https://huggingface.co/papers/2602.08025",
    "authors": [],
    "stars": "22",
    "details": {
      "title": "MIND: Benchmarking Memory Consistency and Action Control in World Models",
      "abstract": "TL;DR: The first open-domain closed-loop revisited benchmark for evaluating memory consistency and action control in world models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08025",
      "pdf_url": "https://arxiv.org/pdf/2602.08025",
      "github_links": [
        "https://github.com/CSU-JPG/MIND"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08025",
      "scraped_at": "2026-02-12T02:27:07.740064"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution",
    "paper_url": "https://huggingface.co/papers/2602.07918",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution",
      "abstract": "I'm excited to share our latest work to defend Prompt Injection: \"CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution\". CausalArmor, a selective defense: üß† Causal attribution at privileged actions: measure whether the action is driven by the user request vs. each untrusted span. üéØ Intervene only on dominance shift: if an untrusted span dominates, sanitize just that span and re-generate‚Äîno always-on heavy filtering. ‚ö° Practical outcome: strong protection without affecting the benign interactions. Results: Near-zero attack success while keeping benign utility and latency close to ‚ÄúNo Defense‚Äù on prompt injection benchmarks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07918",
      "pdf_url": "https://arxiv.org/pdf/2602.07918",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07918",
      "scraped_at": "2026-02-12T02:27:09.488019"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation",
    "paper_url": "https://huggingface.co/papers/2602.07670",
    "authors": [
      "Jarrodbarnes"
    ],
    "stars": "0",
    "details": {
      "title": "Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation",
      "abstract": "Standard practice selects the most confident model output. I tested the opposite on GPU kernel optimization and found that selecting by surprisal (the model's least confident correct solution) achieves 80% success vs 50% for confidence-guided, with a 3.5x mean speedup advantage. Evaluating just the top 3 by surprisal matches oracle performance at 100%. The key insight: a model's probability distribution maps frequency, not quality. Expert-level CUDA kernels are rare in training data, so the model assigns them low probability despite high performance. That signal is already in the logprobs at zero additional inference cost. I also find that test-time training (gradient adaptation) is worse than random on dense-reward tasks. TTT's best checkpoint (30.6%) falls below a single random sample (53.3%). Gradient updates over-sharpen the distribution, destroying the expert tail where optimal solutions live. Code, model weights, and a detailed write-up are available: Code: https://github.com/jbarnes850/test-time-training - Model: https://huggingface.co/Jarrodbarnes/KernelBench-RLVR-120b Blog: https://jbarnes850.github.io/2026/02/02/surprisal-guided-selection/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07670",
      "pdf_url": "https://arxiv.org/pdf/2602.07670",
      "github_links": [
        "https://github.com/jbarnes850/test-time-training"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07670",
      "scraped_at": "2026-02-12T02:27:11.278775"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management",
    "paper_url": "https://huggingface.co/papers/2602.07398",
    "authors": [
      "Ning Zhang",
      "Chaowei Xiao",
      "Hao Li",
      "Ruoyao"
    ],
    "stars": "2",
    "details": {
      "title": "AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management",
      "abstract": "AgentSys defends against indirect prompt injection through explicit hierarchical memory management, reducing attack surface and preserving agent decision-making by preventing malicious instructions from persisting in the context window.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07398",
      "pdf_url": "https://arxiv.org/pdf/2602.07398",
      "github_links": [
        "https://github.com/ruoyaow/agentsys-memory"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07398",
      "scraped_at": "2026-02-12T02:27:13.043932"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?",
    "paper_url": "https://huggingface.co/papers/2602.04802",
    "authors": [
      "Yujie Cheng",
      "Xinzhe Han",
      "Yuhao Wang",
      "Juntong Feng",
      "liuqa"
    ],
    "stars": "11",
    "details": {
      "title": "VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?",
      "abstract": "Vision-Language Models (VLMs) have achieved impressive performance in cross-modal understanding across textual and visual inputs, yet existing benchmarks predominantly focus on pure-text queries. In real-world scenarios, language also frequently appears as visualized text embedded in images, raising the question of whether current VLMs handle such input requests comparably. We introduce VISTA-Bench, a systematic benchmark from multimodal perception, reasoning, to unimodal understanding domains. It evaluates visualized text understanding by contrasting pure-text and visualized-text questions under controlled rendering conditions. Extensive evaluation of over 20 representative VLMs reveals a pronounced modality gap: models that perform well on pure-text queries often degrade substantially when equivalent semantic content is presented as visualized text. This gap is further amplified by increased perceptual difficulty, highlighting sensitivity to rendering variations despite unchanged semantics. Overall, VISTA-Bench provides a principled evaluation framework to diagnose this limitation and to guide progress toward more unified language representations across tokenized text and pixels. The source dataset is available at https://github.com/QingAnLiu/VISTA-Bench .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04802",
      "pdf_url": "https://arxiv.org/pdf/2602.04802",
      "github_links": [
        "https://github.com/QingAnLiu/VISTA-Bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04802",
      "scraped_at": "2026-02-12T02:27:14.832320"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "C-ŒîŒò: Circuit-Restricted Weight Arithmetic for Selective Refusal",
    "paper_url": "https://huggingface.co/papers/2602.04521",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "C-ŒîŒò: Circuit-Restricted Weight Arithmetic for Selective Refusal",
      "abstract": "C-ŒîŒò (Circuit-Restricted Weight Arithmetic) shifts selective refusal from inference-time steering to an offline, checkpoint-level edit. It first identifies the refusal-causal circuit via EAP-IG, then applies a circuit-restricted weight update that typically touches <5% of parameters, yielding a drop-in ‚Äúsafe-by-default‚Äù model with no runtime hooks or latency overhead. Across 30 model-category settings, C-ŒîŒò sharply improves harmful refusal while keeping benign over-refusal controlled, preserving capability on standard benchmarks and generalizing to OOD attacks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04521",
      "pdf_url": "https://arxiv.org/pdf/2602.04521",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04521",
      "scraped_at": "2026-02-12T02:27:16.634917"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching",
    "paper_url": "https://huggingface.co/papers/2602.04908",
    "authors": [
      "Jindong Wang",
      "Chikap421"
    ],
    "stars": "0",
    "details": {
      "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Stable Velocity: A Variance Perspective on Flow Matching (2026) Rethinking Refinement: Correcting Generative Bias without Noise Injection (2026) Trajectory Stitching for Solving Inverse Problems with Flow-Based Models (2026) Training-Free Representation Guidance for Diffusion Models with a Representation Alignment Projector (2026) FlowConsist: Make Your Flow Consistent with Real Trajectory (2026) FlowCast: Trajectory Forecasting for Scalable Zero-Cost Speculative Flow Matching (2026) Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04908",
      "pdf_url": "https://arxiv.org/pdf/2602.04908",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04908",
      "scraped_at": "2026-02-12T02:27:18.379391"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models",
    "paper_url": "https://huggingface.co/papers/2602.01725",
    "authors": [],
    "stars": "5",
    "details": {
      "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models",
      "abstract": "With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01725",
      "pdf_url": "https://arxiv.org/pdf/2602.01725",
      "github_links": [
        "https://github.com/YurunChen/SafePred"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01725",
      "scraped_at": "2026-02-12T02:27:20.143336"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.21235",
    "authors": [
      "Lisa Erickson",
      "Tushar Bandopadhyay",
      "alokabhishek"
    ],
    "stars": "0",
    "details": {
      "title": "SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models",
      "abstract": "Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21235",
      "pdf_url": "https://arxiv.org/pdf/2601.21235",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21235",
      "scraped_at": "2026-02-12T02:27:21.974370"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes",
    "paper_url": "https://huggingface.co/papers/2602.09153",
    "authors": [],
    "stars": "46",
    "details": {
      "title": "SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes",
      "abstract": "Meet SceneSmith: An agentic system that generates entire simulation-ready environments from a single text prompt. VLM agents collaborate to build scenes with dozens of objects per room, articulated furniture, and full physics properties.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09153",
      "pdf_url": "https://arxiv.org/pdf/2602.09153",
      "github_links": [
        "https://github.com/nepfaff/scenesmith"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09153",
      "scraped_at": "2026-02-12T02:27:23.766521"
    },
    "scraped_date": "2026-02-12"
  }
]