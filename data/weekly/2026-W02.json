[
  {
    "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization",
    "paper_url": "https://huggingface.co/papers/2601.05242",
    "authors": [],
    "stars": "126",
    "details": {
      "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization",
      "abstract": "GDPO is a drop-in replacement for GRPO in verl and TRL ‚Äî only minor code changes needed. We release a slurm-free, easy-to-run implementation supporting multiple RL frameworks (verl / TRL / NeMo-RL) so you can quickly validate GDPO on tool-calling and math reasoning tasks. ‚è±Ô∏è Each run can be completed in ~1 hour on 8√óA100s, or ~2.5 hours on a single A100. üîÑ Switching from GRPO to GDPO is easy. üëâ Try it yourself: https://github.com/NVlabs/GDPO",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05242",
      "pdf_url": "https://arxiv.org/pdf/2601.05242",
      "github_links": [
        "https://github.com/NVlabs/GDPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05242",
      "scraped_at": "2026-01-12T01:56:15.369905"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers",
    "paper_url": "https://huggingface.co/papers/2601.04890",
    "authors": [],
    "stars": "99",
    "details": {
      "title": "Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers",
      "abstract": "Building on the ŒºP multipliers applied in Falcon-H1 pretraining ( https://huggingface.co/papers/2507.22448 ), this work extends the idea to learnable matrix-, row-, and column-wise scaling. We show that the weight-norm equilibrium induced by weight decay and gradient noise is suboptimal, and that freeing these scale constraints yields consistent gains, generalizes ŒºP, and improves downstream performance with both Adam and Muon optimizers.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04890",
      "pdf_url": "https://arxiv.org/pdf/2601.04890",
      "github_links": [
        "https://github.com/tiiuae/falcon-h1"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04890",
      "scraped_at": "2026-01-12T01:56:17.350077"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes",
    "paper_url": "https://huggingface.co/papers/2601.05249",
    "authors": [
      "Chia-Che Chang",
      "Kuan-Lin Chen",
      "yulunliu",
      "NeilLeeNTU"
    ],
    "stars": "17",
    "details": {
      "title": "RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes",
      "abstract": "Nighttime color constancy remains a challenging problem in computational photography due to low-light noise and complex illumination conditions. We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. Our method begins with a statistical algorithm tailored for nighttime scenes, integrating salient gray pixel detection with novel illumination estimation. Building on this foundation, we develop the first deep reinforcement learning approach for color constancy that leverages the statistical algorithm as its core, mimicking professional AWB tuning experts by dynamically optimizing parameters for each image. To facilitate cross-sensor evaluation, we introduce the first multi-sensor nighttime dataset. Experiment results demonstrate that our method achieves superior generalization capability across low-light and well-illuminated images.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05249",
      "pdf_url": "https://arxiv.org/pdf/2601.05249",
      "github_links": [
        "https://github.com/BrianChen1120/RL-AWB"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05249",
      "scraped_at": "2026-01-12T01:56:19.261694"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Token-Level LLM Collaboration via FusionRoute",
    "paper_url": "https://huggingface.co/papers/2601.05106",
    "authors": [
      "Furong Huang",
      "Zhaorun Chen",
      "Hanqing Zeng",
      "Nuoya Xiong",
      "zyhang1998"
    ],
    "stars": "0",
    "details": {
      "title": "Token-Level LLM Collaboration via FusionRoute",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API LLMBoost: Make Large Language Models Stronger with Boosting (2025) SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning (2025) Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy (2025) W2S-AlignTree: Weak-to-Strong Inference-Time Alignment for Large Language Models via Monte Carlo Tree Search (2025) Escaping the Verifier: Learning to Reason via Demonstrations (2025) OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs (2025) Building Domain-Specific Small Language Models via Guided Data Generation (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05106",
      "pdf_url": "https://arxiv.org/pdf/2601.05106",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05106",
      "scraped_at": "2026-01-12T01:56:21.261190"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice",
    "paper_url": "https://huggingface.co/papers/2601.05175",
    "authors": [],
    "stars": "23",
    "details": {
      "title": "VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Rethinking Chain-of-Thought Reasoning for Videos (2025) LongVT: Incentivizing\"Thinking with Long Videos\"via Native Tool Calling (2025) More Than the Final Answer: Improving Visual Extraction and Logical Consistency in Vision-Language Models (2025) VideoZoomer: Reinforcement-Learned Temporal Focusing for Long Video Reasoning (2025) Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning (2025) AdaTooler-V: Adaptive Tool-Use for Images and Videos (2025) Video-R2: Reinforcing Consistent and Grounded Reasoning in Multimodal Language Models (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05175",
      "pdf_url": "https://arxiv.org/pdf/2601.05175",
      "github_links": [
        "https://github.com/IVUL-KAUST/VideoAuto-R1/"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05175",
      "scraped_at": "2026-01-12T01:56:23.204161"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "RelayLLM: Efficient Reasoning via Collaborative Decoding",
    "paper_url": "https://huggingface.co/papers/2601.05167",
    "authors": [
      "Haolin Liu",
      "Jinyuan Li",
      "Tong Zheng",
      "shrango",
      "ChengsongHuang"
    ],
    "stars": "16",
    "details": {
      "title": "RelayLLM: Efficient Reasoning via Collaborative Decoding",
      "abstract": "Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05167",
      "pdf_url": "https://arxiv.org/pdf/2601.05167",
      "github_links": [
        "https://github.com/Chengsong-Huang/RelayLLM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05167",
      "scraped_at": "2026-01-12T01:56:25.164574"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "AT^2PO: Agentic Turn-based Policy Optimization via Tree Search",
    "paper_url": "https://huggingface.co/papers/2601.04767",
    "authors": [],
    "stars": "6",
    "details": {
      "title": "AT^2PO: Agentic Turn-based Policy Optimization via Tree Search",
      "abstract": "Abstract LLM agents have emerged as powerful systems for tackling multi-turn tasks by interleaving internal reasoning and external tool interactions. Agentic Reinforcement Learning has recently drawn significant research attention as a critical post-training paradigm to further refine these capabilities. In this paper, we present AT 2 PO (Agentic Turn-based Policy Optimization via Tree Search), a unified framework for multi-turn agentic RL that addresses three core challenges: limited exploration diversity, sparse credit assignment, and misaligned policy optimization. AT 2 PO introduces a turn-level tree structure that jointly enables Entropy-Guided Tree Expansion for strategic exploration and Turn-wise Credit Assignment for fine-grained reward propagation from sparse outcomes. Complementing this, we propose Agentic Turn-based Policy Optimization, a turn-level learning objective that aligns policy updates with the natural decision granularity of agentic interactions. ATPO is orthogonal to tree search and can be readily integrated into any multi-turn RL pipeline. Experiments across seven benchmarks demonstrate consistent improvements over the state-of-the-art baseline by up to 1.84 percentage points in average, with ablation studies validating the effectiveness of each component. Our code is available at https://github.com/zzfoutofspace/ATPO .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04767",
      "pdf_url": "https://arxiv.org/pdf/2601.04767",
      "github_links": [
        "https://github.com/zzfoutofspace/ATPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04767",
      "scraped_at": "2026-01-12T01:56:27.080831"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation",
    "paper_url": "https://huggingface.co/papers/2601.05241",
    "authors": [
      "Jia-Zeng",
      "ZhaoyangLyu",
      "matthewmao",
      "wuzhi-hao",
      "HikariDawn"
    ],
    "stars": "13",
    "details": {
      "title": "RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation",
      "abstract": "The project webpage is at: https://robovip.github.io/RoboVIP/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05241",
      "pdf_url": "https://arxiv.org/pdf/2601.05241",
      "github_links": [
        "https://github.com/RoboVIP/RoboVIP_VDM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05241",
      "scraped_at": "2026-01-12T01:56:29.109143"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models",
    "paper_url": "https://huggingface.co/papers/2512.21815",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models",
      "abstract": "Vision-language models (VLMs) achieve remarkable performance but remain vulnerable to adversarial attacks. Entropy, a measure of model uncertainty, is strongly correlated with the reliability of VLM. Prior entropy-based attacks maximize uncertainty at all decoding steps, implicitly assuming that every token contributes equally to generation instability. We show instead that a small fraction (about 20%) of high-entropy tokens, i.e., critical decision points in autoregressive generation, disproportionately governs output trajectories. By concentrating adversarial perturbations on these positions, we achieve semantic degradation comparable to global methods while using substantially smaller budgets. More importantly, across multiple representative VLMs, such selective attacks convert 35-49% of benign outputs into harmful ones, exposing a more critical safety risk. Remarkably, these vulnerable high-entropy forks recur across architecturally diverse VLMs, enabling feasible transferability (17-26% harmful rates on unseen targets). Motivated by these findings, we propose Entropy-bank Guided Adversarial attacks (EGA), which achieves competitive attack success rates (93-95%) alongside high harmful conversion, thereby revealing new weaknesses in current VLM safety mechanisms.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.21815",
      "pdf_url": "https://arxiv.org/pdf/2512.21815",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.21815",
      "scraped_at": "2026-01-12T01:56:31.065656"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control",
    "paper_url": "https://huggingface.co/papers/2601.05138",
    "authors": [
      "Xiaoyu Li",
      "Wenbo Hu",
      "Minghao Yin",
      "yanweifuture",
      "sxzheng"
    ],
    "stars": "0",
    "details": {
      "title": "VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control",
      "abstract": "Project Page: https://sixiaozheng.github.io/VerseCrafter_page/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05138",
      "pdf_url": "https://arxiv.org/pdf/2601.05138",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05138",
      "scraped_at": "2026-01-12T01:56:33.013335"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Agent-as-a-Judge",
    "paper_url": "https://huggingface.co/papers/2601.05111",
    "authors": [],
    "stars": "21",
    "details": {
      "title": "Agent-as-a-Judge",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios (2026) The Path Ahead for Agentic AI: Challenges and Opportunities (2026) Step-DeepResearch Technical Report (2025) AI Agent Systems: Architectures, Applications, and Evaluation (2026) ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment (2025) Environment Scaling for Interactive Agentic Experience Collection: A Survey (2025) Towards Comprehensive Stage-wise Benchmarking of Large Language Models in Fact-Checking (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05111",
      "pdf_url": "https://arxiv.org/pdf/2601.05111",
      "github_links": [
        "https://github.com/ModalityDance/Awesome-Agent-as-a-Judge"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05111",
      "scraped_at": "2026-01-12T01:56:34.977612"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "The Illusion of Specialization: Unveiling the Domain-Invariant \"Standing Committee\" in Mixture-of-Experts Models",
    "paper_url": "https://huggingface.co/papers/2601.03425",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "The Illusion of Specialization: Unveiling the Domain-Invariant \"Standing Committee\" in Mixture-of-Experts Models",
      "abstract": "Mixture of Experts models are widely assumed to achieve domain specialization through sparse routing. In this work, we question this assumption by introducing COMMITTEEAUDIT, a post hoc framework that analyzes routing behavior at the level of expert groups rather than individual experts. Across three representative models and the MMLU benchmark, we uncover a domain-invariant Standing Committee. This is a compact coalition of routed experts that consistently captures the majority of routing mass across domains, layers, and routing budgets, even when architectures already include shared experts. Qualitative analysis further shows that Standing Committees anchor reasoning structure and syntax, while peripheral experts handle domain-specific knowledge. These findings reveal a strong structural bias toward centralized computation, suggesting that specialization in Mixture of Experts models is far less pervasive than commonly believed. This inherent bias also indicates that current training objectives, such as load-balancing losses that enforce uniform expert utilization, may be working against the model's natural optimization path, thereby limiting training efficiency and performance.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.03425",
      "pdf_url": "https://arxiv.org/pdf/2601.03425",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.03425",
      "scraped_at": "2026-01-12T01:56:36.914048"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs",
    "paper_url": "https://huggingface.co/papers/2601.03559",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs",
      "abstract": "DiffCoT improves multi-step LLM reasoning by applying diffusion-based iterative denoising to correct intermediate Chain-of-Thought steps.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.03559",
      "pdf_url": "https://arxiv.org/pdf/2601.03559",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.03559",
      "scraped_at": "2026-01-12T01:56:38.788826"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Plenoptic Video Generation",
    "paper_url": "https://huggingface.co/papers/2601.05239",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Plenoptic Video Generation",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation (2025) Infinite-Homography as Robust Conditioning for Camera-Controlled Video Generation (2025) StereoWorld: Geometry-Aware Monocular-to-Stereo Video Generation (2025) SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time (2025) PostCam: Camera-Controllable Novel-View Video Generation with Query-Shared Cross-Attention (2025) CETCAM: Camera-Controllable Video Generation via Consistent and Extensible Tokenization (2025) Light-X: Generative 4D Video Rendering with Camera and Illumination Control (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05239",
      "pdf_url": "https://arxiv.org/pdf/2601.05239",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05239",
      "scraped_at": "2026-01-12T01:56:40.809081"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "CoV: Chain-of-View Prompting for Spatial Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.05172",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "CoV: Chain-of-View Prompting for Spatial Reasoning",
      "abstract": "We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05172",
      "pdf_url": "https://arxiv.org/pdf/2601.05172",
      "github_links": [
        "https://github.com/ziplab/CoV"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05172",
      "scraped_at": "2026-01-12T01:56:42.666912"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling",
    "paper_url": "https://huggingface.co/papers/2601.03111",
    "authors": [
      "Xuefeng Li",
      "Weixun Wang",
      "Yanan Wu",
      "Zhen Huang",
      "Yiyuan Li"
    ],
    "stars": "0",
    "details": {
      "title": "One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling",
      "abstract": "This work discusses the potential of lifting broader reasoning ability by learning from one high-quality sample. In polymath learning, the quality of samples can be selected through the lens of salient math skills and categories. The model learned from the polymath sample outperformances the one learned from dataset thousand times larger in multidisciplinary reasoning tasks, indicating the significance of deliberate selection, and synthesis of training samples to unlock reasoning capabilities more efficiently, rather than simply scaling data volume.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.03111",
      "pdf_url": "https://arxiv.org/pdf/2601.03111",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.03111",
      "scraped_at": "2026-01-12T01:56:44.585372"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing",
    "paper_url": "https://huggingface.co/papers/2601.05124",
    "authors": [
      "Tiankai Hang",
      "Yiji Cheng",
      "eternaldolphin",
      "Zhiminli",
      "hrz2000"
    ],
    "stars": "1",
    "details": {
      "title": "Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing",
      "abstract": "This paper introduces Re-Align, a unified framework for in-context image generation and editing that bridges the gap between multimodal understanding and image synthesis. Re-Align employs a structured In-Context Chain-of-Thought (IC-CoT) to explicitly separate semantic guidance and reference association, reducing ambiguity in image‚Äìtext interleaved prompts. It further applies reinforcement learning with a surrogate alignment reward to improve consistency between reasoning and generated images. Extensive experiments show that Re-Align outperforms prior methods on both in-context image generation and editing tasks.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05124",
      "pdf_url": "https://arxiv.org/pdf/2601.05124",
      "github_links": [
        "https://github.com/hrz2000/realign"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05124",
      "scraped_at": "2026-01-12T01:56:46.426451"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "DocDancer: Towards Agentic Document-Grounded Information Seeking",
    "paper_url": "https://huggingface.co/papers/2601.05163",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DocDancer: Towards Agentic Document-Grounded Information Seeking",
      "abstract": "Document Question Answering (DocQA) focuses on answering questions grounded in given documents, yet existing DocQA agents lack effective tool utilization and largely rely on closed-source models. In this work, we introduce DocDancer, an end-to-end trained open-source Doc agent. We formulate DocQA as an information-seeking problem and propose a tool-driven agent framework that explicitly models document exploration and comprehension. To enable end-to-end training of such agents, we introduce an Exploration-then-Synthesis data synthesis pipeline that addresses the scarcity of high-quality training data for DocQA. Training on the synthesized data, the trained models on two long-context document understanding benchmarks, MMLongBench-Doc and DocBench, show their effectiveness. Further analysis provides valuable insights for the agentic tool design and synthetic data.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05163",
      "pdf_url": "https://arxiv.org/pdf/2601.05163",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05163",
      "scraped_at": "2026-01-12T01:56:48.265902"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers",
    "paper_url": "https://huggingface.co/papers/2601.04342",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers",
      "abstract": "üöÄ Introducing PyramidalWan! Our paper presents a novel pipeline to convert pretrained video diffusion models (like Wan2.1-1.3B) into efficient pyramidal ones via low-cost finetuning. Key Innovations: Efficiency via Hierarchy: We restructure the diffusion process into three spatiotemporal stages, processing high noise at lower resolutions to significantly reduce inference costs. Theoretical Generalization: We extended resolution transitions to a broader class of upsampling/downsampling functions based on orthogonal transforms. Step Distillation: A systematic study of distillation techniques for pyramidal setups, including the first successful training of Pyramidal Patchification models for few-step generation. Key Insights & Results: Near-Original Quality: Achieves video quality comparable to the original Wan model while requiring significantly less compute. Superior Motion: Our recommended recipe, PyramidalWan-DMD-PT*, provides consistent motion and fills the gap for high-performing few-step inference. Artifact Reduction: Unlike training-free acceleration methods (e.g., Jenga), our approach avoids severe scene and motion artifacts.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04342",
      "pdf_url": "https://arxiv.org/pdf/2601.04342",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04342",
      "scraped_at": "2026-01-12T01:56:50.213336"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Multi-Scale Local Speculative Decoding for Image Generation",
    "paper_url": "https://huggingface.co/papers/2601.05149",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Multi-Scale Local Speculative Decoding for Image Generation",
      "abstract": "Multi-Scale Local Speculative Decoding (MuLo-SD), a new framework to supercharge Autoregressive (AR) image generation! By combining multi-resolution drafting with spatially informed verification, we achieve substantial speedups of up to 1.7x while maintaining high perceptual quality and semantic alignment. The Core Idea: Unlike standard methods that use raster-scan rejection, MuLo-SD exploits the spatial structure of images. We propose candidate tokens using a low-resolution drafter and a learned up-sampler, which are then verified in parallel by a high-resolution target model. Key Innovation: Local Verification üîç Crucially, we introduced a local rejection and resampling mechanism. Instead of discarding every token after a single error, we correct errors by focusing only on the spatial neighborhoods of rejected tokens, significantly boosting efficiency. Results at a Glance: ‚úÖ Outperforms strong baselines like EAGLE-2 and LANTERN. ‚úÖ Consistently delivers greater speedups across 512p and 1024p resolutions. ‚úÖ Integrates seamlessly with unified Multimodal LLMs. üîó https://qualcomm-ai-research.github.io/mulo-sd-webpage",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05149",
      "pdf_url": "https://arxiv.org/pdf/2601.05149",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05149",
      "scraped_at": "2026-01-12T01:56:52.201583"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "PyramidalWan: On Making Pretrained Video Model Pyramidal for Efficient Inference",
    "paper_url": "https://huggingface.co/papers/2601.04792",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PyramidalWan: On Making Pretrained Video Model Pyramidal for Efficient Inference",
      "abstract": "We tackle the challenge of quadratic complexity in video generation with a novel Recurrent Hybrid Attention mechanism. By combining the fidelity of softmax attention for local dependencies with the efficiency of linear attention globally, we enable high-quality modeling with linear scaling. Constant Memory Usage: Our chunk-wise recurrent reformulation allows for the generation of arbitrarily long videos. Massive Training Efficiency: Using a two-stage distillation pipeline, we reduced training costs by two orders of magnitude to just ~160 GPU hours. SOTA Performance: Validated on VBench and VBench-2.0, ReHyAt achieves state-of-the-art quality while unlocking practical on-device video generation.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04792",
      "pdf_url": "https://arxiv.org/pdf/2601.04792",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04792",
      "scraped_at": "2026-01-12T01:56:54.063156"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting",
    "paper_url": "https://huggingface.co/papers/2601.04754",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ProFuse: Efficient Cross-View Context Fusion for Open-Vocabulary 3D Gaussian Splatting",
      "abstract": "We present ProFuse, an efficient context-aware framework for open-vocabulary 3D scene understanding with 3D Gaussian Splatting (3DGS). The pipeline enhances cross-view consistency and intra-mask cohesion within a direct registration setup, adding minimal overhead and requiring no render-supervised fine-tuning. We introduce a dense correspondence-guided pre-registration phase that initializes Gaussians with accurate geometry while jointly constructing 3D Context Proposals via cross-view clustering. Each proposal carries a global feature obtained through weighted aggregation of member embeddings, and this feature is fused onto Gaussians during direct registration to maintain per-primitive language coherence across views. ProFuse achieves strong open-vocabulary 3DGS understanding while completing semantic attachment in about five minutes per scene, which is two times faster than SOTA. For more information, please check out our project page: https://chiou1203.github.io/ProFuse/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04754",
      "pdf_url": "https://arxiv.org/pdf/2601.04754",
      "github_links": [
        "https://github.com/chiou1203/ProFuse"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04754",
      "scraped_at": "2026-01-12T01:56:55.989473"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Scaling Behavior Cloning Improves Causal Reasoning: An Open Model for Real-Time Video Game Playing",
    "paper_url": "https://huggingface.co/papers/2601.04575",
    "authors": [],
    "stars": "31",
    "details": {
      "title": "Scaling Behavior Cloning Improves Causal Reasoning: An Open Model for Real-Time Video Game Playing",
      "abstract": "We introduce Pixels2Play (P2P), an open-source generalist agent designed for real-time control across diverse 3D video games on consumer-grade GPUs. Built on an efficient, decoder-only transformer architecture that predicts keyboard and mouse actions from raw pixel inputs , the model is trained on a massive new dataset of over 8,300 hours of high-quality, text-annotated human gameplay. Beyond achieving human-level competence in commercial environments like DOOM and Roblox , we systematically investigate the scaling laws of behavior cloning, demonstrating that increasing model and data scale significantly improves causal reasoning and mitigates the \"causal confusion\" often inherent in imitation learning. To accelerate research in generalist game AI, we are releasing the full training recipe, model checkpoints, and our extensive gameplay dataset under an open license",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04575",
      "pdf_url": "https://arxiv.org/pdf/2601.04575",
      "github_links": [
        "https://github.com/elefant-ai/open-p2p"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04575",
      "scraped_at": "2026-01-12T01:56:57.907638"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Beyond Binary Preference: Aligning Diffusion Models to Fine-grained Criteria by Decoupling Attributes",
    "paper_url": "https://huggingface.co/papers/2601.04300",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Beyond Binary Preference: Aligning Diffusion Models to Fine-grained Criteria by Decoupling Attributes",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Direct Diffusion Score Preference Optimization via Stepwise Contrastive Policy-Pair Supervision (2025) Mind the Generative Details: Direct Localized Detail Preference Optimization for Video Diffusion Models (2026) PC-Diffusion: Aligning Diffusion Models with Human Preferences via Preference Classifier (2025) Multi-dimensional Preference Alignment by Conditioning Reward Itself (2025) Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning (2025) Diffusion-DRF: Differentiable Reward Flow for Video Diffusion Fine-Tuning (2026) BideDPO: Conditional Image Generation with Simultaneous Text and Condition Alignment (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04300",
      "pdf_url": "https://arxiv.org/pdf/2601.04300",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04300",
      "scraped_at": "2026-01-12T01:56:59.771628"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Guardians of the Hair: Rescuing Soft Boundaries in Depth, Stereo, and Novel Views",
    "paper_url": "https://huggingface.co/papers/2601.03362",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Guardians of the Hair: Rescuing Soft Boundaries in Depth, Stereo, and Novel Views",
      "abstract": "Soft boundaries, like thin hairs, are commonly observed in natural and computer-generated imagery, but they remain challenging for 3D vision due to the ambiguous mixing of foreground and background cues. This paper introduces Guardians of the Hair (HairGuard), a framework designed to recover fine-grained soft boundary details in 3D vision tasks. Specifically, we first propose a novel data curation pipeline that leverages image matting datasets for training and design a depth fixer network to automatically identify soft boundary regions. With a gated residual module, the depth fixer refines depth precisely around soft boundaries while maintaining global depth quality, allowing plug-and-play integration with state-of-the-art depth models. For view synthesis, we perform depth-based forward warping to retain high-fidelity textures, followed by a generative scene painter that fills disoccluded regions and eliminates redundant background artifacts within soft boundaries. Finally, a color fuser adaptively combines warped and inpainted results to produce novel views with consistent geometry and fine-grained details. Extensive experiments demonstrate that HairGuard achieves state-of-the-art performance across monocular depth estimation, stereo image/video conversion, and novel view synthesis, with significant improvements in soft boundary regions.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.03362",
      "pdf_url": "https://arxiv.org/pdf/2601.03362",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.03362",
      "scraped_at": "2026-01-12T01:57:01.869712"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Towards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset",
    "paper_url": "https://huggingface.co/papers/2512.24160",
    "authors": [
      "YuanFu Yang",
      "ZhenQi Chen",
      "water-fountain"
    ],
    "stars": "2",
    "details": {
      "title": "Towards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24160",
      "pdf_url": "https://arxiv.org/pdf/2512.24160",
      "github_links": [
        "https://github.com/NinaNeon/IMDD-1M-Towards-Open-Vocabulary-Industrial-Defect-"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24160",
      "scraped_at": "2026-01-12T01:57:03.736777"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Memorization in 3D Shape Generation: An Empirical Study",
    "paper_url": "https://huggingface.co/papers/2512.23628",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Memorization in 3D Shape Generation: An Empirical Study",
      "abstract": "Our code is available at https://github.com/zlab-princeton/3d-gen-mem.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23628",
      "pdf_url": "https://arxiv.org/pdf/2512.23628",
      "github_links": [
        "https://github.com/zlab-princeton/3d-gen-mem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23628",
      "scraped_at": "2026-01-12T01:57:05.671962"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "AgentDevel: Reframing Self-Evolving LLM Agents as Release Engineering",
    "paper_url": "https://huggingface.co/papers/2601.04620",
    "authors": [
      "Di Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "AgentDevel: Reframing Self-Evolving LLM Agents as Release Engineering",
      "abstract": "Recent progress in large language model (LLM) agents has largely focused on embedding self-improvement mechanisms inside the agent or searching over many concurrent variants. While these approaches can raise aggregate scores, they often yield unstable and hard-to-audit improvement trajectories, making it difficult to guarantee non-regression or to reason about failures across versions. We reframe agent improvement as \\textbf{release engineering}: agents are treated as shippable artifacts, and improvement is externalized into a regression-aware release pipeline. We introduce \\textbf{AgentDevel}, a release engineering pipeline that iteratively runs the current agent, produces implementation-blind, symptom-level quality signals from execution traces, synthesizes a single release candidate (RC) via executable diagnosis, and promotes it under flip-centered gating. AgentDevel features three core designs: (i) an implementation-blind LLM critic that characterizes failure appearances without accessing agent internals, (ii) script-based executable diagnosis that aggregates dominant symptom patterns and produces auditable engineering specifications, and (iii) flip-centered gating that prioritizes pass to fail regressions and fail to pass fixes as first-class evidence. Unlike population-based search or in-agent self-refinement, AgentDevel maintains a single canonical version line and emphasizes non-regression as a primary objective. Experiments on execution-heavy benchmarks demonstrate that AgentDevel yields stable improvements with significantly fewer regressions while producing reproducible, auditable artifacts. Overall, AgentDevel provides a practical development discipline for building, debugging, and releasing LLM agents as software development.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04620",
      "pdf_url": "https://arxiv.org/pdf/2601.04620",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04620",
      "scraped_at": "2026-01-12T01:57:07.412767"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Learning User Preferences Through Interaction for Long-Term Collaboration",
    "paper_url": "https://huggingface.co/papers/2601.02702",
    "authors": [
      "Dilek Hakkani-T√ºr",
      "Tal August",
      "Priyanka Kargupta",
      "Shuhaib Mehri"
    ],
    "stars": "0",
    "details": {
      "title": "Learning User Preferences Through Interaction for Long-Term Collaboration",
      "abstract": "Current long-term conversation benchmarks focus on recall. But this ignores key skills like recognizing what user information is valuable & leveraging it to improve future interactions. In our work, we present MultiSessionCollab to evaluate agents in a multi-session collaboration environment. Additionally, we use memory to help agents learn user preferences and improve collaboration over time.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.02702",
      "pdf_url": "https://arxiv.org/pdf/2601.02702",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.02702",
      "scraped_at": "2026-01-12T01:57:09.256703"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach",
    "paper_url": "https://huggingface.co/papers/2601.02016",
    "authors": [
      "Carl James Debono",
      "Matthew Montebello",
      "Gabriel Hili",
      "Dylan Seychell",
      "mbar0075"
    ],
    "stars": "4",
    "details": {
      "title": "Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.02016",
      "pdf_url": "https://arxiv.org/pdf/2601.02016",
      "github_links": [
        "https://github.com/mbar0075/lupi-for-object-detection"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.02016",
      "scraped_at": "2026-01-12T01:57:11.141085"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "LEMAS: Large A 150K-Hour Large-scale Extensible Multilingual Audio Suite with Generative Speech Models",
    "paper_url": "https://huggingface.co/papers/2601.04233",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "LEMAS: Large A 150K-Hour Large-scale Extensible Multilingual Audio Suite with Generative Speech Models",
      "abstract": "LEMAS: A 150K-Hour Large-scale Extensible Multilingual Audio Suite with Generative Speech Models LEMAS is a large-scale extensible multilingual audio suite, providing multilingual speech corpus (LEMAS-Dataset) with word-level timestamps, covering over 150,000 hours across 10 major languages. Built with a rigorous alignment and confidence-based filtering pipeline, LEMAS supports diverse generative paradigms including zero-shot multilingual synthesis (LEMAS-TTS) and seamless speech editing (LEMAS-Edit). More technical details can be found in our technical report: https://arxiv.org/abs/2601.04233",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04233",
      "pdf_url": "https://arxiv.org/pdf/2601.04233",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04233",
      "scraped_at": "2026-01-12T01:57:13.156228"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding",
    "paper_url": "https://huggingface.co/papers/2601.05125",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding",
      "abstract": "We usually train VLMs on visual synthetic data that we (as humans) label as photorealistic. We argue that this is an anthropocentric perspective imposed to a model that might not synthetize visual information as we do. VERSE helps to visualize latent space and overlay visual features to detect poor-performance regions and take action to include better-suited training sets to boost model performance. You can explore more here: Code: https://github.com/nachoDRT/MERIT-Dataset Hugging Face Space: https://huggingface.co/spaces/de-Rodrigo/Embeddings Thanks!",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05125",
      "pdf_url": "https://arxiv.org/pdf/2601.05125",
      "github_links": [
        "https://github.com/nachoDRT/VrDU-Doctor"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05125",
      "scraped_at": "2026-01-12T01:57:15.060473"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance",
    "paper_url": "https://huggingface.co/papers/2601.01887",
    "authors": [
      "Jian Liu",
      "Jian Lou",
      "Kejia Chen",
      "Jiawen Zhang",
      "ttttonyhe"
    ],
    "stars": "0",
    "details": {
      "title": "Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance",
      "abstract": "Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost . Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.01887",
      "pdf_url": "https://arxiv.org/pdf/2601.01887",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.01887",
      "scraped_at": "2026-01-12T01:57:17.088547"
    },
    "scraped_date": "2026-01-12"
  },
  {
    "title": "Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization",
    "paper_url": "https://huggingface.co/papers/2601.05432",
    "authors": [],
    "stars": "107",
    "details": {
      "title": "Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization",
      "abstract": "Demo video",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05432",
      "pdf_url": "https://arxiv.org/pdf/2601.05432",
      "github_links": [
        "https://github.com/AMAP-ML/Thinking-with-Map"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05432",
      "scraped_at": "2026-01-13T01:48:04.298623"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "MMFormalizer: Multimodal Autoformalization in the Wild",
    "paper_url": "https://huggingface.co/papers/2601.03017",
    "authors": [
      "Huajian Xin",
      "Hui Shen",
      "Yunta Hsieh",
      "Qi Han",
      "Jing Xiong"
    ],
    "stars": "0",
    "details": {
      "title": "MMFormalizer: Multimodal Autoformalization in the Wild",
      "abstract": "Autoformalization, which translates natural language mathematics into formal statements to enable machine reasoning, faces fundamental challenges in the wild due to the multimodal nature of the physical world, where physics requires inferring hidden constraints (e.g., mass or energy) from visual elements. To address this, we propose MMFormalizer, which extends autoformalization beyond text by integrating adaptive grounding with entities from real-world mathematical and physical domains. MMFormalizer recursively constructs formal propositions from perceptually grounded primitives through recursive grounding and axiom composition, with adaptive recursive termination ensuring that every abstraction is supported by visual evidence and anchored in dimensional or axiomatic grounding. We evaluate MMFormalizer on a new benchmark, PhyX-AF, comprising 115 curated samples from MathVerse, PhyX, Synthetic Geometry, and Analytic Geometry, covering diverse multimodal autoformalization tasks. Results show that frontier models such as GPT-5 and Gemini-3-Pro achieve the highest compile and semantic accuracy, with GPT-5 excelling in physical reasoning, while geometry remains the most challenging domain. Overall, MMFormalizer provides a scalable framework for unified multimodal autoformalization, bridging perception and formal reasoning. To the best of our knowledge, this is the first multimodal autoformalization method capable of handling classical mechanics (derived from the Hamiltonian), as well as relativity, quantum mechanics, and thermodynamics.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.03017",
      "pdf_url": "https://arxiv.org/pdf/2601.03017",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.03017",
      "scraped_at": "2026-01-13T01:48:06.184101"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature",
    "paper_url": "https://huggingface.co/papers/2601.03319",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature",
      "abstract": "Project Page: https://c4ricaturegs.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.03319",
      "pdf_url": "https://arxiv.org/pdf/2601.03319",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.03319",
      "scraped_at": "2026-01-13T01:48:08.069844"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.06002",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning",
      "abstract": "Glad to share our recent exploratory project: üß™ Title: The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning üåê arXiv: 2601.06002 ‚Äã üßê Why revisit Long CoT? Recent work often focuses on ‚Äúmaking CoT longer,‚Äù but longer traces are more likely to derail‚Äîe.g., drifting off-track, breaking logical continuity, or amplifying hallucinations‚Äîespecially when attempting to cold-start genuine long-horizon reasoning from a standard instruction-tuned model. ‚Äã A key observation is that many trajectories that merely look like long reasoning (e.g., distilling from randomly sampled ICL demonstrations, or using human-written long step-by-step solutions) are not behaviorally stable, and models frequently fail to learn robustly from them. ‚Äã üò≠  Why imitation often fails ‚ÄúLong‚Äù human CoT is not necessarily effective: Fine-tuning on human-written long CoT does not reliably reproduce the gains achieved by distilling from a strong reasoning model. Distill from Weak instruct model + random ICL demonstrations largely fails: Using randomly chosen 1-shot ICL examples to ‚Äúfake‚Äù long reasoning for distillation leads to significant degradation, suggesting that superficial formatting is insufficient. ‚Äã- Keywords are not the driver: Replacing surface tokens (e.g., ‚Äúwait‚Äù) while preserving the underlying reasoning trajectory and behavioral pattern yields similar performance, indicating that SFT primarily learns structure/behavior rather than prompt-specific keywords. ‚Äã üîç  Early evidence: Long CoT has stable ‚Äústructural fingerprints‚Äù We observe a stable behavioral transfer graph: across different strong reasoning models and tasks, the induced distributional characteristics appear highly consistent. ‚Äã- In semantic space, we see ‚Äúlinking‚Äìfolding‚Äù patterns: deep reasoning tends to form locally dense structures; self-reflection tends to create backward links for validation/correction; and exploration tends to form weaker cross-cluster connections. ‚Äã üí° Core hypothesis: effective Long CoT as a ‚Äúmolecular structure‚Äù High-quality Long CoT is not merely a linear chain; it is stabilized by three interaction types‚Äîanalogous to chemical bonds‚Äîthat organize and constrain reasoning trajectories: ‚Äã- Deep Reasoning (covalent-bond-like): forms the main reasoning backbone; if it breaks, the solution collapses. ‚Äã- Self-Reflection (hydrogen-bond-like): folds later steps back to earlier ones to verify assumptions, detect errors, and correct the path. ‚Äã- Self-Exploration (van der Waals-like): weak but important cross-domain probing that broadens coverage and discovers alternative routes. ‚Äã An additional observation is that the Gibbs‚ÄìBoltzmann energy formulation is closely aligned with the attention formulation; hence, the ‚Äúenergy distributions‚Äù of different bonds can be estimated directly from attention, exhibiting a stable ordering reminiscent of real chemical bond energies. ‚Äã üçé ‚ÄúSemantic isomers‚Äù of Long CoT For the same problem, trajectories can be semantically close yet differ in the distribution and transitions of bonds, yielding distinct ‚Äúisomers‚Äù with dramatically different trainability and downstream performance. ‚Äã- Two isomers that appear similar may still be incompatible: mixing them during training can trigger structural conflicts and degrade performance. ‚Äã- ICL is not inherently ineffective; it helps when demonstrations are selected such that their structural distribution aligns with the target high-quality isomer. ‚Äã üîß Solution: MOLE-SYN We propose MOLE-SYN: first estimate a behavioral transfer graph from a strong reasoning model, then use it to guide a pure instruct LLM to synthesize Long CoT trajectories. ‚Äã- Empirically, distilling Qwen-2.5 with MOLE-SYN‚Äìgenerated trajectories can approach the effectiveness of distillation from QwQ. ‚Äã- This initialization also exhibits strong RL potential: it yields more stable RL training curves and sustained improvement headroom. Finally, different behaviors have distinct global effects: deep reasoning makes the core logic more compact, self-reflection increases overall ‚Äúfolding‚Äù tightness, and self-exploration expands the reachable search space. ‚Äã üëÄ A practical implication is that when CoT is heavily summarized or compressed, the ‚Äúmolecular structure‚Äù distribution can be destroyed, and distilled models may underperform even the original teacher. ‚Äã If a prior viewpoint treated CoT behaviors as nodes, this work reframes them as edges that link logical states: the training target may not be ‚Äúlonger answers,‚Äù but a more stable reasoning skeleton controlled by structured reasoning behaviors. ‚Äã",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06002",
      "pdf_url": "https://arxiv.org/pdf/2601.06002",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06002",
      "scraped_at": "2026-01-13T01:48:09.969605"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards",
    "paper_url": "https://huggingface.co/papers/2601.06021",
    "authors": [],
    "stars": "15",
    "details": {
      "title": "Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards",
      "abstract": "Code: https://github.com/THUDM/CaRR Data: https://huggingface.co/datasets/THU-KEG/CaRR-DeepDive",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06021",
      "pdf_url": "https://arxiv.org/pdf/2601.06021",
      "github_links": [
        "https://github.com/THUDM/CaRR"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06021",
      "scraped_at": "2026-01-13T01:48:11.869324"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis",
    "paper_url": "https://huggingface.co/papers/2601.05808",
    "authors": [
      "Zhicheng Dou",
      "Yutao Zhu",
      "Haofei Chang",
      "Xiaoshuai Song",
      "dongguanting"
    ],
    "stars": "0",
    "details": {
      "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis",
      "abstract": "Code: https://github.com/RUC-NLPIR/EnvScaler Data & Model: https://huggingface.co/collections/XXHStudyHard/envscaler",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05808",
      "pdf_url": "https://arxiv.org/pdf/2601.05808",
      "github_links": [
        "https://github.com/RUC-NLPIR/EnvScaler"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05808",
      "scraped_at": "2026-01-13T01:48:13.888446"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking",
    "paper_url": "https://huggingface.co/papers/2601.04720",
    "authors": [],
    "stars": "620",
    "details": {
      "title": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking",
      "abstract": "üöÄ Introducing Qwen3-VL-Embedding and Qwen3-VL-Reranker ‚Äì advancing the state of the art in multimodal retrieval and cross-modal understanding! ‚ú® Highlights: ‚úÖ Built upon the robust Qwen3-VL foundation model ‚úÖ Processes text, images, screenshots, videos, and mixed modality inputs ‚úÖ Supports 30+ languages ‚úÖ Achieves state-of-the-art performance on multimodal retrieval benchmarks ‚úÖ Open source and available on Hugging Face, GitHub, and ModelScope ‚úÖ API deployment on Alibaba Cloud coming soon! üéØ Two-stage retrieval architecture: üìä Embedding Model ‚Äì generates semantically rich vector representations in a unified embedding space üéØ Reranker Model ‚Äì computes fine-grained relevance scores for enhanced retrieval accuracy üîç Key application scenarios: Image-text retrieval, video search, multimodal RAG, visual question answering, multimodal content clustering, multilingual visual search, and more! üåü Developer-friendly capabilities: ‚Ä¢ Configurable embedding dimensions ‚Ä¢ Task-specific instruction customization ‚Ä¢ Embedding quantization support for efficient and cost-effective downstream deployment Hugging FaceÔºö https://huggingface.co/collections/Qwen/qwen3-vl-embedding https://huggingface.co/collections/Qwen/qwen3-vl-reranker Github: https://github.com/QwenLM/Qwen3-VL-Embedding Blog: https://qwen.ai/blog?id=qwen3-vl-embedding Tech Report: https://www.arxiv.org/abs/2601.04720",
      "arxiv_page_url": "https://www.arxiv.org/abs/2601.04720",
      "pdf_url": "https://arxiv.org/pdf/2601.04720",
      "github_links": [
        "https://github.com/QwenLM/Qwen3-VL-Embedding"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04720",
      "scraped_at": "2026-01-13T01:48:15.778962"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Can We Predict Before Executing Machine Learning Agents?",
    "paper_url": "https://huggingface.co/papers/2601.05930",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "Can We Predict Before Executing Machine Learning Agents?",
      "abstract": "We replace slow trial-and-error in scientific agents with learned execution prediction, enabling FOREAGENT to think before it runs and achieve 6√ó faster and better scientific discovery.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05930",
      "pdf_url": "https://arxiv.org/pdf/2601.05930",
      "github_links": [
        "https://github.com/zjunlp/predict-before-execute"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05930",
      "scraped_at": "2026-01-13T01:48:17.633216"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift",
    "paper_url": "https://huggingface.co/papers/2601.05882",
    "authors": [
      "Nikolaos Aletras",
      "Constantinos Karouzos",
      "XingweiT"
    ],
    "stars": "0",
    "details": {
      "title": "An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift",
      "abstract": "Our paper presents a systematic study of preference-optimization under domain shift. We compare five popular alignment objectives and various adaptation strategies from source to target, including target-domain supervised fine-tuning and pseudo-labeling, across summarization and question-answering helpfulness tasks. We found: The adaptation strategy is more influential than the alignment objective. We identify that synthetic supervision is a double-edged sword. While pseudo-labeling yields the highest target-domain win rates, it induces severe mode collapse. This diversity tax results in models that are highly reliable but linguistically monotonous, mirroring the latent templates of the teacher model. Our findings suggest a deployment recommendation: use pseudo-labeling for high-stakes and constrained tasks where reliability is paramount, but favor mixed-domain SFT and online RL for applications requiring creative or varied linguistic expression.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05882",
      "pdf_url": "https://arxiv.org/pdf/2601.05882",
      "github_links": [
        "https://github.com/ckarouzos/prefadap"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05882",
      "scraped_at": "2026-01-13T01:48:19.521997"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "AgentOCR: Reimagining Agent History via Optical Self-Compression",
    "paper_url": "https://huggingface.co/papers/2601.04786",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "AgentOCR: Reimagining Agent History via Optical Self-Compression",
      "abstract": "We‚Äôre introducing AgentOCR, a new way to scale LLM agents by reimagining long interaction histories as compact rendered images, leveraging the higher information density of visual tokens to curb exploding context costs. To make long-horizon rollouts practical, we add segment optical caching, splitting history into hashable segments and caching the visuals, so agents avoid redundant re-rendering as trajectories grow.  We go beyond fixed compression with agentic self-compression: the agent actively emits a compression rate and is trained with a compression-aware reward to balance task success against token efficiency. Across ALFWorld and search-based QA, AgentOCR keeps >95% of text-agent performance while cutting token use by >50% average and ~80% in peak, and our analysis shows up to a 20√ó rendering speedup thanks to our segment optical caching",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04786",
      "pdf_url": "https://arxiv.org/pdf/2601.04786",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04786",
      "scraped_at": "2026-01-13T01:48:21.395496"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction",
    "paper_url": "https://huggingface.co/papers/2601.05966",
    "authors": [
      "Yu Sun",
      "Shuohuan Wang",
      "Xiaoxiong Liu",
      "Longbin Ji",
      "sjy1203"
    ],
    "stars": "0",
    "details": {
      "title": "VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction",
      "abstract": "VideoAR presents a scalable autoregressive video-generation framework that combines next-frame scale prediction with a 3D multi-scale tokenizer to improve temporal coherence and efficiency.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05966",
      "pdf_url": "https://arxiv.org/pdf/2601.05966",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05966",
      "scraped_at": "2026-01-13T01:48:23.249628"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency",
    "paper_url": "https://huggingface.co/papers/2601.05905",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency",
      "abstract": "We show that many LLM ‚Äúbeliefs‚Äù that look confident collapse under small context changes, and propose Neighbor-Consistency Belief (NCB) and Structure-Aware Training to measure and train models to keep their knowledge stable and robust under such interference.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05905",
      "pdf_url": "https://arxiv.org/pdf/2601.05905",
      "github_links": [
        "https://github.com/zjunlp/belief"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05905",
      "scraped_at": "2026-01-13T01:48:25.096155"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals",
    "paper_url": "https://huggingface.co/papers/2601.05848",
    "authors": [
      "Evan Luo",
      "Zitian Tang",
      "Yinghua Zhou",
      "dakshces",
      "nate-gillman"
    ],
    "stars": "0",
    "details": {
      "title": "Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals",
      "abstract": "Goal Force trains a physics-grounded video model to follow explicit force-directed goals, achieving zero-shot planning in real-world tasks by implicit neural physics simulation.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05848",
      "pdf_url": "https://arxiv.org/pdf/2601.05848",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05848",
      "scraped_at": "2026-01-13T01:48:27.018745"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Orient Anything V2: Unifying Orientation and Rotation Understanding",
    "paper_url": "https://huggingface.co/papers/2601.05573",
    "authors": [
      "Tianyu Pang",
      "Jialei Wang",
      "Jiayang Xu",
      "Zehan Wang",
      "Viglong"
    ],
    "stars": "82",
    "details": {
      "title": "Orient Anything V2: Unifying Orientation and Rotation Understanding",
      "abstract": "Code: https://github.com/SpatialVision/Orient-Anything-V2 Demo Space: https://huggingface.co/spaces/Viglong/Orient-Anything-V2",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05573",
      "pdf_url": "https://arxiv.org/pdf/2601.05573",
      "github_links": [
        "https://github.com/SpatialVision/Orient-Anything-V2"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05573",
      "scraped_at": "2026-01-13T01:48:28.874972"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection",
    "paper_url": "https://huggingface.co/papers/2601.05403",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection",
      "abstract": "Large language models (LLMs) have been widely applied across various domains of finance. Since their training data are largely derived from human-authored corpora, LLMs may inherit a range of human biases. Behavioral biases can lead to instability and uncertainty in decision-making, particularly when processing financial information. However, existing research on LLM bias has mainly focused on direct questioning or simplified, general-purpose settings, with limited consideration of the complex real-world financial environments and high-risk, context-sensitive, multilingual financial misinformation detection tasks (MFMD). In this work, we propose MFMD-Scen, a comprehensive benchmark for evaluating behavioral biases of LLMs in MFMD across diverse economic scenarios. In collaboration with financial experts, we construct three types of complex financial scenarios: (i) role- and personality-based, (ii) role- and region-based, and (iii) role-based scenarios incorporating ethnicity and religious beliefs. We further develop a multilingual financial misinformation dataset covering English, Chinese, Greek, and Bengali. By integrating these scenarios with misinformation claims, MFMD-Scen enables a systematic evaluation of 22 mainstream LLMs. Our findings reveal that pronounced behavioral biases persist across both commercial and open-source models.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05403",
      "pdf_url": "https://arxiv.org/pdf/2601.05403",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05403",
      "scraped_at": "2026-01-13T01:48:30.700256"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "AnyDepth: Depth Estimation Made Easy",
    "paper_url": "https://huggingface.co/papers/2601.02760",
    "authors": [],
    "stars": "63",
    "details": {
      "title": "AnyDepth: Depth Estimation Made Easy",
      "abstract": "https://aigeeksgroup.github.io/AnyDepth",
      "arxiv_page_url": "https://arxiv.org/abs/2601.02760",
      "pdf_url": "https://arxiv.org/pdf/2601.02760",
      "github_links": [
        "https://github.com/AIGeeksGroup/AnyDepth"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.02760",
      "scraped_at": "2026-01-13T01:48:32.573488"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "SmartSearch: Process Reward-Guided Query Refinement for Search Agents",
    "paper_url": "https://huggingface.co/papers/2601.04888",
    "authors": [
      "Guanting Dong",
      "douzc",
      "vvv111222"
    ],
    "stars": "11",
    "details": {
      "title": "SmartSearch: Process Reward-Guided Query Refinement for Search Agents",
      "abstract": "Some of the observations founded are :- i. Dual Level Credit Assessment This mechanism provides a comprehensive evaluation of query quality through both rule-based and model-based assessments. It allows for fine-grained supervision, helping to identify not just redundancy but also the usefulness of each query in the context of the search process. ii. Process Reward Mechanism The introduction of process rewards as a guiding signal for training search agents is a novel approach. It shifts the focus from solely final outcomes to the quality of intermediate queries, addressing a significant gap in existing methods that often overlook this aspect. iii. Query Refinement Strategy The framework employs a systematic query refinement process that identifies low quality queries and generates improved versions. This iterative refinement enhances the effectiveness of search trajectories, allowing agents to adaptively improve their queries based on feedback. iv. Three Stage Curriculum Learning Framework SmartSearch introduces a structured curriculum learning approach that progresses from imitation to alignment and finally to generalization. This staged learning process enables search agents to internalize query quality improvement progressively, enhancing their overall performance. v. Empirical Validation Across Diverse Benchmarks The paper presents extensive experimental results demonstrating SmartSearch's superior performance across multiple challenging knowledge-intensive tasks and web exploration scenarios. This empirical validation highlights the framework's robustness and effectiveness in real-world applications, showcasing its potential impact on future research in search agents and information retrieval.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04888",
      "pdf_url": "https://arxiv.org/pdf/2601.04888",
      "github_links": [
        "https://github.com/MYVAE/SmartSearch?tab=readme-ov-file"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04888",
      "scraped_at": "2026-01-13T01:48:34.423674"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Over-Searching in Search-Augmented Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.05503",
    "authors": [],
    "stars": "4",
    "details": {
      "title": "Over-Searching in Search-Augmented Large Language Models",
      "abstract": "Systematically analyzes over-search in search-augmented LLMs, showing when retrieval helps or hurts, introducing Tokens Per Correctness and mitigation strategies.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05503",
      "pdf_url": "https://arxiv.org/pdf/2601.05503",
      "github_links": [
        "https://github.com/ruoyuxie/OversearchQA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05503",
      "scraped_at": "2026-01-13T01:48:36.245536"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation",
    "paper_url": "https://huggingface.co/papers/2601.04823",
    "authors": [
      "Linqi Song",
      "Huacan Wang",
      "Ronghao Chen",
      "Guanzhi Deng",
      "liboaccn"
    ],
    "stars": "0",
    "details": {
      "title": "DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation",
      "abstract": "Mixture-of-Experts (MoE) has become a prominent paradigm for scaling Large Language Models (LLMs). Parameter-efficient fine-tuning (PEFT), such as LoRA, is widely adopted to adapt pretrained MoE LLMs to downstream tasks. However, existing approaches assign identical LoRA ranks to all experts, overlooking the intrinsic functional specialization within MoE LLMs. This uniform allocation leads to resource mismatch, task-relevant experts are under-provisioned while less relevant ones receive redundant parameters. We propose a Dynamic Rank LoRA framework named DR-LoRA, which dynamically grows expert LoRA ranks during fine-tuning based on task-specific demands. DR-LoRA employs an Expert Saliency Scoring mechanism that integrates expert routing frequency and LoRA rank importance to quantify each expert's demand for additional capacity. Experts with higher saliency scores are prioritized for rank expansion, enabling the automatic formation of a heterogeneous rank distribution tailored to the target task. Experiments on multiple benchmarks demonstrate that DR-LoRA consistently outperforms standard LoRA and static allocation strategies under the same parameter budget, achieving superior task performance with more efficient parameter utilization.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04823",
      "pdf_url": "https://arxiv.org/pdf/2601.04823",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04823",
      "scraped_at": "2026-01-13T01:48:38.107896"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.04726",
    "authors": [
      "Zhicheng Dou",
      "Yutao Zhu",
      "Jiejun Tan",
      "Jiongnan Liu",
      "namespace-ERI"
    ],
    "stars": "0",
    "details": {
      "title": "Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning",
      "abstract": "Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04726",
      "pdf_url": "https://arxiv.org/pdf/2601.04726",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04726",
      "scraped_at": "2026-01-13T01:48:39.978598"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "GenCtrl -- A Formal Controllability Toolkit for Generative Models",
    "paper_url": "https://huggingface.co/papers/2601.05637",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GenCtrl -- A Formal Controllability Toolkit for Generative Models",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API A Reason-then-Describe Instruction Interpreter for Controllable Video Generation (2025) EVE: A Generator-Verifier System for Generative Policies (2025) Eliciting Behaviors in Multi-Turn Conversations (2025) SkillWrapper: Generative Predicate Invention for Skill Abstraction (2025) From Word to World: Can Large Language Models be Implicit Text-based World Models? (2025) SAGE: An Agentic Explainer Framework for Interpreting SAE Features in Language Models (2025) Propose, Solve, Verify: Self-Play Through Formal Verification (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05637",
      "pdf_url": "https://arxiv.org/pdf/2601.05637",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05637",
      "scraped_at": "2026-01-13T01:48:41.784741"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "TCAndon-Router: Adaptive Reasoning Router for Multi-Agent Collaboration",
    "paper_url": "https://huggingface.co/papers/2601.04544",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "TCAndon-Router: Adaptive Reasoning Router for Multi-Agent Collaboration",
      "abstract": "Code: https://github.com/Tencent/TCAndon-Router",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04544",
      "pdf_url": "https://arxiv.org/pdf/2601.04544",
      "github_links": [
        "https://github.com/kyegomez/awesome-multi-agent-papers",
        "https://github.com/Tencent/TCAndon-Router"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04544",
      "scraped_at": "2026-01-13T01:48:43.634411"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Distilling Feedback into Memory-as-a-Tool",
    "paper_url": "https://huggingface.co/papers/2601.05960",
    "authors": [
      "vicgalle"
    ],
    "stars": "1",
    "details": {
      "title": "Distilling Feedback into Memory-as-a-Tool",
      "abstract": "Code: https://github.com/vicgalle/feedback-memory-as-a-tool Data: https://huggingface.co/datasets/vicgalle/rubric-feedback-bench",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05960",
      "pdf_url": "https://arxiv.org/pdf/2601.05960",
      "github_links": [
        "https://github.com/vicgalle/feedback-memory-as-a-tool"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05960",
      "scraped_at": "2026-01-13T01:48:45.433282"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents",
    "paper_url": "https://huggingface.co/papers/2601.05899",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents",
      "abstract": "Some of the observations are :- i. TowerMind is a lightweight RTS-style benchmark for LLM agents It introduces a tower defense based environment that preserves long term planning and decision making challenges of RTS games, while requiring very low computational resources compared to StarCraft II based benchmarks. ii. Multimodal observations enable broader LLM evaluation TowerMind supports pixel-based, textual (JSON), and structured state observations, making it suitable for evaluating language-only and vision-language models under the same environment. iii. Hallucination is explicitly measured via action validity Beyond performance score, the benchmark introduces valid action rate to quantify hallucinations. i.e. actions that violate game rules or state constraints allowing simultaneous evaluation of capability and reliability. iv. LLMs significantly underperform human experts Even the best-performing models (e.g. GPT-4.1, Claude 3.7 Sonnet) show a large gap from human experts, especially on harder levels, revealing weaknesses in planning validation, multifinality, and efficient action use. v. TowerMind is challenging for both LLMs and RL agents Classic RL algorithms (Ape-X DQN, PPO) also fail to reach human level performance, confirming TowerMind as a non-trivial benchmark that complements existing LLM and RL evaluation environments.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05899",
      "pdf_url": "https://arxiv.org/pdf/2601.05899",
      "github_links": [
        "https://github.com/tb6147877/TowerMind"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05899",
      "scraped_at": "2026-01-13T01:48:47.327914"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Router-Suggest: Dynamic Routing for Multimodal Auto-Completion in Visually-Grounded Dialogs",
    "paper_url": "https://huggingface.co/papers/2601.05851",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Router-Suggest: Dynamic Routing for Multimodal Auto-Completion in Visually-Grounded Dialogs",
      "abstract": "Real-time multimodal auto-completion is essential for digital assistants, chatbots, design tools, and healthcare consultations, where user inputs rely on shared visual context. We introduce Multimodal Auto-Completion (MAC), a task that predicts upcoming characters in live chats using partially typed text and visual cues. Unlike traditional text-only auto-completion (TAC), MAC grounds predictions in multimodal context to better capture user intent. To enable this task, we adapt MMDialog and ImageChat to create benchmark datasets. We evaluate leading vision-language models (VLMs) against strong textual baselines, highlighting trade-offs in accuracy and efficiency. We present Router-Suggest, a router framework that dynamically selects between textual models and VLMs based on dialog context, along with a lightweight variant for resource-constrained environments. Router-Suggest achieves a 2.3x to 10x speedup over the best-performing VLM. A user study shows that VLMs significantly excel over textual models on user satisfaction, notably saving user typing effort and improving the quality of completions in multi-turn conversations. These findings underscore the need for multimodal context in auto-completions, leading to smarter, user-aware assistants.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05851",
      "pdf_url": "https://arxiv.org/pdf/2601.05851",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05851",
      "scraped_at": "2026-01-13T01:48:49.142532"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers",
    "paper_url": "https://huggingface.co/papers/2601.05741",
    "authors": [
      "Marco Huber",
      "Jan Niklas Kolf",
      "Tahar Chettaoui",
      "Eduarda Caldeira",
      "gurayozgur"
    ],
    "stars": "3",
    "details": {
      "title": "ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers",
      "abstract": "https://github.com/gurayozgur/ViTNT-FIQA",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05741",
      "pdf_url": "https://arxiv.org/pdf/2601.05741",
      "github_links": [
        "https://github.com/gurayozgur/ViTNT-FIQA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05741",
      "scraped_at": "2026-01-13T01:48:51.076876"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck",
    "paper_url": "https://huggingface.co/papers/2601.05870",
    "authors": [
      "Zhuoyue Chen",
      "Long Li",
      "Yue Zhu",
      "Hongchen Luo",
      "Huilin Deng"
    ],
    "stars": "0",
    "details": {
      "title": "IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API ReLaX: Reasoning with Latent Exploration for Large Reasoning Models (2025) Multi-Path Collaborative Reasoning via Reinforcement Learning (2025) Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies (2025) ESPO: Entropy Importance Sampling Policy Optimization (2025) Diversity or Precision? A Deep Dive into Next Token Prediction (2025) SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization (2025) Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05870",
      "pdf_url": "https://arxiv.org/pdf/2601.05870",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05870",
      "scraped_at": "2026-01-13T01:48:52.895587"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Afri-MCQA: Multimodal Cultural Question Answering for African Languages",
    "paper_url": "https://huggingface.co/papers/2601.05699",
    "authors": [
      "Jesujoba Oluwadara Alabi",
      "Israel Abebe Azime",
      "Emilio Villa-Cueva",
      "Srija Anand",
      "Atnafu"
    ],
    "stars": "0",
    "details": {
      "title": "Afri-MCQA: Multimodal Cultural Question Answering for African Languages",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG (2025) Rice-VL: Evaluating Vision-Language Models for Cultural Understanding Across ASEAN Countries (2025) HinTel-AlignBench: A Framework and Benchmark for Hindi-Telugu with English-Aligned Samples (2025) Can LLMs Solve My Grandma's Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles (2025) IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages (2025) See, Hear, and Understand: Benchmarking Audiovisual Human Speech Understanding in Multimodal Large Language Models (2025) Multilingual VLM Training: Adapting an English-Trained VLM to French (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05699",
      "pdf_url": "https://arxiv.org/pdf/2601.05699",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05699",
      "scraped_at": "2026-01-13T01:48:54.752545"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models",
    "paper_url": "https://huggingface.co/papers/2601.05376",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models",
      "abstract": "This paper investigates how \"persona conditioning\" (e.g., instructing an LLM to act as a specific medical professional) impacts clinical decision-making. The authors challenge the assumption that assigning a medical persona consistently improves accuracy or safety, labeling this inconsistency the \"Persona Paradox.\" Key Insights: Non-Monotonic Effects: Assigning a medical persona (like an Emergency Department physician) does not always improve performance. It acts as a behavioral prior that can help in some contexts but hurt in others. The Context Gap: Medical personas improved accuracy and calibration by up to 20% in critical-care tasks (triage) but degraded performance by a similar margin in primary-care settings. Interaction Styles: Adding styles such as \"bold\" or \"cautious\" changes the model‚Äôs risk propensity, but these effects vary widely across base models. The Alignment Gap: While \"LLM judges\" preferred medical personas for safety-critical cases, human clinicians were much more skeptical. Human experts showed low confidence in the AI's reasoning quality in 95.9% of cases, despite moderate agreement on safety compliance. Conclusion The study concludes that personas are not \"expertise switches\" but rather priors that introduce context-dependent trade-offs. Relying on personas for clinical safety is risky because they do not provide a universal guarantee of better judgment. Personas should be used with caution in high-stakes medicine, as they can inadvertently trigger biases or performance drops depending on the specific clinical task.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05376",
      "pdf_url": "https://arxiv.org/pdf/2601.05376",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05376",
      "scraped_at": "2026-01-13T01:48:56.593118"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Legal Alignment for Safe and Ethical AI",
    "paper_url": "https://huggingface.co/papers/2601.04175",
    "authors": [
      "Rishi Bommasani",
      "Cullen O'Keefe",
      "Jack Boeglin",
      "Nicholas Caputo",
      "Noam Kolt"
    ],
    "stars": "0",
    "details": {
      "title": "Legal Alignment for Safe and Ethical AI",
      "abstract": "Field-defining paper by researchers from Stanford, MIT, Harvard, Oxford, Princeton, and other leading institutions. More details at: https://www.legal-alignment.ai/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04175",
      "pdf_url": "https://arxiv.org/pdf/2601.04175",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04175",
      "scraped_at": "2026-01-13T01:48:58.401803"
    },
    "scraped_date": "2026-01-13"
  },
  {
    "title": "Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.06943",
    "authors": [
      "Zhe Huang",
      "Zhuoyue Chang",
      "HJH2CMD",
      "Yu2020",
      "POTATO66"
    ],
    "stars": "51",
    "details": {
      "title": "Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning",
      "abstract": "First video deep research benchmark.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06943",
      "pdf_url": "https://arxiv.org/pdf/2601.06943",
      "github_links": [
        "https://github.com/QuantaAlpha/VideoDR-Benchmark"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06943",
      "scraped_at": "2026-01-14T01:55:05.388627"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "BabyVision: Visual Reasoning Beyond Language",
    "paper_url": "https://huggingface.co/papers/2601.06521",
    "authors": [
      "Liang Chen",
      "Liuff23",
      "Ziqi",
      "ssz1111",
      "chenxz"
    ],
    "stars": "81",
    "details": {
      "title": "BabyVision: Visual Reasoning Beyond Language",
      "abstract": "Feel free to follow our GitHub repo: https://github.com/UniPat-AI/BabyVision",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06521",
      "pdf_url": "https://arxiv.org/pdf/2601.06521",
      "github_links": [
        "https://github.com/UniPat-AI/BabyVision"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06521",
      "scraped_at": "2026-01-14T01:55:07.338360"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.05593",
    "authors": [],
    "stars": "261",
    "details": {
      "title": "PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning",
      "abstract": "üéâ Introducing Parallel Coordinated Reasoning (PaCoRe) üìà An 8B model beats GPT-5 on HMMT25 by unlocking parallel thinking for test-time scaling! üìÇ Open-source deep think: data + model + inference code! üÜì MIT-licensed ‚Äî use it however you want üîçKey findings: Message Passing Unlocks Scaling Without compaction, performance flatlines at the context limit. PaCoRe breaks the memory barrier and lets reasoning scale freely. Breadth > Depth All compute is not equal. Coordinated parallel reasoning delivers far higher returns than extending a single chain. Data as a Force Multiplier The PaCoRe corpus provides exceptionally valuable supervision‚Äî even baseline models see substantial gains when trained on it. üîó Links: GitHub: https://github.com/stepfun-ai/PaCoRe Data: https://huggingface.co/datasets/stepfun-ai/PaCoRe-Train-8k Model: https://huggingface.co/stepfun-ai/PaCoRe-8B",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05593",
      "pdf_url": "https://arxiv.org/pdf/2601.05593",
      "github_links": [
        "https://github.com/stepfun-ai/PaCoRe"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05593",
      "scraped_at": "2026-01-14T01:55:09.273922"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head",
    "paper_url": "https://huggingface.co/papers/2601.07832",
    "authors": [],
    "stars": "47",
    "details": {
      "title": "MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head",
      "abstract": null,
      "arxiv_page_url": "https://arxiv.org/abs/2601.07832",
      "pdf_url": "https://arxiv.org/pdf/2601.07832",
      "github_links": [
        "https://github.com/DAGroup-PKU/MHLA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07832",
      "scraped_at": "2026-01-14T01:55:11.365101"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests",
    "paper_url": "https://huggingface.co/papers/2601.06953",
    "authors": [
      "Jane Luo",
      "Jiani Guo",
      "Xin Zhang",
      "Jie Wu",
      "Ringo1110"
    ],
    "stars": "52",
    "details": {
      "title": "X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Tailored Primitive Initialization is the Secret Key to Reinforcement Learning (2025) Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes (2025) Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling (2026) PerfCoder: Large Language Models for Interpretable Code Performance Optimization (2025) Aligning Text, Code, and Vision: A Multi-Objective Reinforcement Learning Framework for Text-to-Visualization (2026) Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks (2026) DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06953",
      "pdf_url": "https://arxiv.org/pdf/2601.06953",
      "github_links": [
        "https://github.com/JieWu02/X-Coder"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06953",
      "scraped_at": "2026-01-14T01:55:13.303655"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts",
    "paper_url": "https://huggingface.co/papers/2601.05110",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts",
      "abstract": "LLM + SLM > LLM",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05110",
      "pdf_url": "https://arxiv.org/pdf/2601.05110",
      "github_links": [
        "https://github.com/Zengwh02/GlimpRouter"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05110",
      "scraped_at": "2026-01-14T01:55:16.049503"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Lost in the Noise: How Reasoning Models Fail with Contextual Distractors",
    "paper_url": "https://huggingface.co/papers/2601.07226",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Lost in the Noise: How Reasoning Models Fail with Contextual Distractors",
      "abstract": "The code and dataset will be released publicly.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07226",
      "pdf_url": "https://arxiv.org/pdf/2601.07226",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07226",
      "scraped_at": "2026-01-14T01:55:18.008918"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent",
    "paper_url": "https://huggingface.co/papers/2601.07779",
    "authors": [],
    "stars": "15",
    "details": {
      "title": "OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent",
      "abstract": "Despite VLM advances, current CUA frameworks remain brittle in long-horizon workflows and weak in novel domains due to coarse historical visual context management and missing visual-aware tutorial retrieval, so we propose OS-SYMPHONY, an orchestrated framework combining milestone-driven reflection memory for trajectory-level self-correction with a SeeAct-style multimodal searcher that synthesizes visually aligned live tutorials, achieving new SOTA across three online benchmarks (65.84% on OSWorld).",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07779",
      "pdf_url": "https://arxiv.org/pdf/2601.07779",
      "github_links": [
        "https://github.com/OS-Copilot/OS-Symphony"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07779",
      "scraped_at": "2026-01-14T01:55:19.919265"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models",
    "paper_url": "https://huggingface.co/papers/2601.07351",
    "authors": [
      "Chenchen Jing",
      "Tianjian Feng",
      "Bozhen Fang",
      "Linyu Wu",
      "zhongzero"
    ],
    "stars": "16",
    "details": {
      "title": "Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models",
      "abstract": "GitHub repo: https://github.com/aim-uofa/EvoTokenDLM",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07351",
      "pdf_url": "https://arxiv.org/pdf/2601.07351",
      "github_links": [
        "https://github.com/aim-uofa/EvoTokenDLM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07351",
      "scraped_at": "2026-01-14T01:55:21.893924"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction",
    "paper_url": "https://huggingface.co/papers/2601.05107",
    "authors": [
      "Zhengkang Guo",
      "Jingwen Xu",
      "Xiaohua Wang",
      "Muzhao Tian",
      "zisuh"
    ],
    "stars": "0",
    "details": {
      "title": "Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction",
      "abstract": "As LLM-based agents are increasingly used in long-term interactions, cumulative memory is critical for enabling personalization and maintaining stylistic consistency. However, most existing systems adopt an ``all-or-nothing'' approach to memory usage: incorporating all relevant past information can lead to Memory Anchoring, where the agent is trapped by past interactions, while excluding memory entirely results in under-utilization and the loss of important interaction history. We show that an agent's reliance on memory can be modeled as an explicit and user-controllable dimension. We first introduce a behavioral metric of memory dependence to quantify the influence of past interactions on current outputs. We then propose Steerable Memory Agent, SteeM, a framework that allows users to dynamically regulate memory reliance, ranging from a fresh-start mode that promotes innovation to a high-fidelity mode that closely follows interaction history. Experiments across different scenarios demonstrate that our approach consistently outperforms conventional prompting and rigid memory masking strategies, yielding a more nuanced and effective control for personalized human-agent collaboration.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05107",
      "pdf_url": "https://arxiv.org/pdf/2601.05107",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05107",
      "scraped_at": "2026-01-14T01:55:23.799775"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving",
    "paper_url": "https://huggingface.co/papers/2601.01528",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving",
      "abstract": "DrivingGen is a comprehensive benchmark for generative world models in the driving domain with a diverse data distribution and novel evaluation metrics.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.01528",
      "pdf_url": "https://arxiv.org/pdf/2601.01528",
      "github_links": [
        "https://github.com/youngzhou1999/DrivingGen"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.01528",
      "scraped_at": "2026-01-14T01:55:25.767787"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era",
    "paper_url": "https://huggingface.co/papers/2601.07526",
    "authors": [
      "Jiawei Chen",
      "Ruisheng Cao",
      "Mouxiang Chen",
      "zjj1233",
      "Lemoncoke"
    ],
    "stars": "0",
    "details": {
      "title": "MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era",
      "abstract": "The rapid development of interactive and autonomous AI systems signals our entry into the agentic era. Training and evaluating agents on complex agentic tasks such as software engineering and computer use requires not only efficient model computation but also sophisticated infrastructure capable of coordinating vast agent-environment interactions. However, no open-source infrastructure can effectively support large-scale training and evaluation on such complex agentic tasks. To address this challenge, we present MegaFlow, a large-scale distributed orchestration system that enables efficient scheduling, resource allocation, and fine-grained task management for agent-environment workloads. MegaFlow abstracts agent training infrastructure into three independent services (Model Service, Agent Service, and Environment Service) that interact through unified interfaces, enabling independent scaling and flexible resource allocation across diverse agent-environment configurations. In our agent training deployments, MegaFlow successfully orchestrates tens of thousands of concurrent agent tasks while maintaining high system stability and achieving efficient resource utilization. By enabling such large-scale agent training, MegaFlow addresses a critical infrastructure gap in the emerging agentic AI landscape.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07526",
      "pdf_url": "https://arxiv.org/pdf/2601.07526",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07526",
      "scraped_at": "2026-01-14T01:55:27.656092"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Boosting Latent Diffusion Models via Disentangled Representation Alignment",
    "paper_url": "https://huggingface.co/papers/2601.05823",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Boosting Latent Diffusion Models via Disentangled Representation Alignment",
      "abstract": "arXiv link: Boosting Latent Diffusion Models via Disentangled Representation Alignment Code (Coming Soon): https://github.com/Kwai-Kolors/Send-VAE",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05823",
      "pdf_url": "https://arxiv.org/pdf/2601.05823",
      "github_links": [
        "https://github.com/Kwai-Kolors/Send-VAE"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05823",
      "scraped_at": "2026-01-14T01:55:29.594871"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models",
    "paper_url": "https://huggingface.co/papers/2601.06165",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models",
      "abstract": "Users often ask VLMs under-specified, informal visual questions, which current clean-prompt benchmarks fail to capture. We introduce HAERAE-Vision (653 real Korean community queries + explicit rewrites) and show that making queries explicit boosts accuracy by 8‚Äì22 points, while web search cannot fully offset what users leave unsaid.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06165",
      "pdf_url": "https://arxiv.org/pdf/2601.06165",
      "github_links": [
        "https://github.com/HAE-RAE/HAERAE-VISION"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06165",
      "scraped_at": "2026-01-14T01:55:31.500284"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration",
    "paper_url": "https://huggingface.co/papers/2601.06860",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration",
      "abstract": "Most current TIR work only focuses on the accuracy of agents in downstream tasks, while lacking calibration of the agents' behavioral patterns in TIR tasks. To address this issue, we first quantitatively analyze several possible erroneous behavioral patterns in current TIR tasks, and classify them into two categories: \"improper tool use\" and \"flawed reasoning logic\". Based on this, we propose ET-Agent, a framework that fully calibrates the behavioral patterns of agents when performing TIR tasks from both data and algorithm levels. On the data side, we propose a self-evolving data flywheel, which enhances the training data by leveraging the agent's own reflective exploration capabilities. On the algorithm side, we propose a behavioral calibration training framework. It performs rejection sampling fine-tuning on the basis of enhanced training data to broaden the agent's exploration of the action space. Subsequently, we implement iterative behavioral calibration reinforcement learning to calibrate the actions of the fine-tuned agent to the optimal behavioral pattern. Our contributions are listed as follows: We provide a comprehensive quantitative analysis of erroneous behavioral patterns in TIR. Inspired by this, we propose ET-Agent, a framework for optimizing TIR's behavioral patterns. We introduce a self-evolving data flywheel, an iterative loop where the model continuously refines its previous trajectories. This mechanism effectively unfolds the model's action space coverage beyond its initial exploration. Based on the flywheel, we present a behavior calibration training framework with two phases, aiming to calibrate the model's exploration in tool-use action space to optimal trajectories. Extensive experiments demonstrate that ET-Agent substantially improves behavioral efficiency, reasoning conciseness, and execution success rates while maintaining high accuracy.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06860",
      "pdf_url": "https://arxiv.org/pdf/2601.06860",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06860",
      "scraped_at": "2026-01-14T01:55:33.429929"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Dr. Zero: Self-Evolving Search Agents without Training Data",
    "paper_url": "https://huggingface.co/papers/2601.07055",
    "authors": [
      "Shaoliang Nie",
      "Suyu Ge",
      "Xianjun Yang",
      "Kartikeya Upasani",
      "Zhenrui Yue"
    ],
    "stars": "74",
    "details": {
      "title": "Dr. Zero: Self-Evolving Search Agents without Training Data",
      "abstract": "Dr. Zero enables data-free self-evolving search agents through a self-evolution loop with HRPO, achieving strong multi-step reasoning while reducing compute.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07055",
      "pdf_url": "https://arxiv.org/pdf/2601.07055",
      "github_links": [
        "https://github.com/facebookresearch/drzero"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07055",
      "scraped_at": "2026-01-14T01:55:35.318742"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Forest Before Trees: Latent Superposition for Efficient Visual Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.06803",
    "authors": [
      "Yankai Lin",
      "Yichen Wu",
      "Yubo Wang",
      "Yuhan",
      "ZION121"
    ],
    "stars": "0",
    "details": {
      "title": "Forest Before Trees: Latent Superposition for Efficient Visual Reasoning",
      "abstract": "We hope this work encourages a paradigm shift from explicit next-token prediction to latent visual reasoning.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06803",
      "pdf_url": "https://arxiv.org/pdf/2601.06803",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06803",
      "scraped_at": "2026-01-14T01:55:37.211022"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning",
    "paper_url": "https://huggingface.co/papers/2601.04698",
    "authors": [
      "Hao Wang",
      "Xiaoxi Li",
      "Wenxiang Jiao",
      "Mining Tan",
      "Yinuo Wang"
    ],
    "stars": "0",
    "details": {
      "title": "TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning",
      "abstract": "We propose TourPlanner , a comprehensive framework featuring multi-path reasoning and constraint-gated reinforcement learning. Specifically, we first introduce a Personalized Recall and Spatial Optimization (PReSO) workflow to construct spatially-aware candidate POIs' set. Subsequently, we propose Competitive consensus Chain-of-Thought (CCoT), a multi-path reasoning paradigm that improves the ability of exploring the feasible solution space. To further refine the plan, we integrate a sigmoid-based gating mechanism into the reinforcement learning stage, which dynamically prioritizes soft-constraint satisfaction only after hard constraints are met. Experimental results on travel planning benchmarks demonstrate that TourPlanner achieves state-of-the-art performance, significantly surpassing existing methods in both feasibility and user-preference alignment.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04698",
      "pdf_url": "https://arxiv.org/pdf/2601.04698",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04698",
      "scraped_at": "2026-01-14T01:55:39.117410"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "OpenTinker: Separating Concerns in Agentic Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2601.07376",
    "authors": [
      "Jiaxuan You",
      "zsqzz"
    ],
    "stars": "568",
    "details": {
      "title": "OpenTinker: Separating Concerns in Agentic Reinforcement Learning",
      "abstract": "üéâ Introducing OpenTinker üöÄ A scalable RL infrastructure for LLM agents that separates what you build (agents + environments) from how it runs (training + inference)! üß© Composable RL-as-a-Service No more monolithic RL pipelines. OpenTinker decomposes agentic learning into lightweight, modular components with clean abstraction boundaries. Plug in new agents, environments, and interaction protocols with minimal friction. ‚öôÔ∏è Unified Runtime for Training + Inference A centralized scheduler manages shared compute across workloads like RL (LoRA / full-parameter), SFT, and high-throughput inference. Built for multi-tenant scaling and real-world iteration speed. ü§ñ Multi-Agent Ready by Design OpenTinker supports coordinator-driven multi-agent interaction. Each agent can optimize independently while coordination emerges through environment dynamics. This keeps MARL scalable, flexible, and system-friendly. üîó Links: üìÑ Paper (arXiv): https://arxiv.org/pdf/2601.07376 üíª GitHub: https://github.com/open-tinker/OpenTinker",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07376",
      "pdf_url": "https://arxiv.org/pdf/2601.07376",
      "github_links": [
        "https://github.com/open-tinker/OpenTinker?tab=readme-ov-file",
        "https://github.com/open-tinker/OpenTinker"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07376",
      "scraped_at": "2026-01-14T01:55:41.067699"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Are LLM Decisions Faithful to Verbal Confidence?",
    "paper_url": "https://huggingface.co/papers/2601.07767",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Are LLM Decisions Faithful to Verbal Confidence?",
      "abstract": "While LLMs can express their confidence levels, their actual decisions do not demonstrate risk sensitivity. Even with high error penalties, they rarely abstain from making choices, often leading to utility collapse.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07767",
      "pdf_url": "https://arxiv.org/pdf/2601.07767",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07767",
      "scraped_at": "2026-01-14T01:55:42.902306"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Structured Episodic Event Memory",
    "paper_url": "https://huggingface.co/papers/2601.06411",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Structured Episodic Event Memory",
      "abstract": "Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reasoning. For autonomous agents, these passive and flat architectures lack the cognitive organization necessary to model the dynamic and associative nature of long-term interaction. To address this, we propose Structured Episodic Event Memory (SEEM), a hierarchical framework that synergizes a graph memory layer for relational facts with a dynamic episodic memory layer for narrative progression. Grounded in cognitive frame theory, SEEM transforms interaction streams into structured Episodic Event Frames (EEFs) anchored by precise provenance pointers. Furthermore, we introduce an agentic associative fusion and Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent narrative contexts from fragmented evidence. Experimental results on the LoCoMo and LongMemEval benchmarks demonstrate that SEEM significantly outperforms baselines, enabling agents to maintain superior narrative coherence and logical consistency.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06411",
      "pdf_url": "https://arxiv.org/pdf/2601.06411",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06411",
      "scraped_at": "2026-01-14T01:55:44.777676"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings",
    "paper_url": "https://huggingface.co/papers/2601.03666",
    "authors": [
      "Zhicheng Dou",
      "Tetsuya Sakai",
      "Radu Timofte",
      "Sicheng Gao",
      "Haon-Chen"
    ],
    "stars": "0",
    "details": {
      "title": "e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings",
      "abstract": "A lightweight explicit alignment recipe that adapts off-the-shelf VLMs into robust omni-modal embedding models. Checkpoints: https://huggingface.co/Haon-Chen/e5-omni-3B https://huggingface.co/Haon-Chen/e5-omni-7B",
      "arxiv_page_url": "https://arxiv.org/abs/2601.03666",
      "pdf_url": "https://arxiv.org/pdf/2601.03666",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.03666",
      "scraped_at": "2026-01-14T01:55:46.645891"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "\"TODO: Fix the Mess Gemini Created\": Towards Understanding GenAI-Induced Self-Admitted Technical Debt",
    "paper_url": "https://huggingface.co/papers/2601.07786",
    "authors": [
      "Mia Mohammad Imran",
      "Abdullah Al Mujahid"
    ],
    "stars": "0",
    "details": {
      "title": "\"TODO: Fix the Mess Gemini Created\": Towards Understanding GenAI-Induced Self-Admitted Technical Debt",
      "abstract": "As large language models (LLMs) such as ChatGPT, Copilot, Claude, and Gemini become integrated into software development workflows, developers increasingly leave traces of AI involvement in their code comments. Among these, some comments explicitly acknowledge both the use of generative AI and the presence of technical shortcomings. Analyzing 6,540 LLM-referencing code comments from public Python and JavaScript-based GitHub repositories (November 2022-July 2025), we identified 81 that also self-admit technical debt(SATD). Developers most often describe postponed testing, incomplete adaptation, and limited understanding of AI-generated code, suggesting that AI assistance affects both when and why technical debt emerges. We term GenAI-Induced Self-admitted Technical debt (GIST) as a proposed conceptual lens to describe recurring cases where developers incorporate AI-generated code while explicitly expressing uncertainty about its behavior or correctness.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07786",
      "pdf_url": "https://arxiv.org/pdf/2601.07786",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07786",
      "scraped_at": "2026-01-14T01:55:48.489091"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "ShowUI-Aloha: Human-Taught GUI Agent",
    "paper_url": "https://huggingface.co/papers/2601.07181",
    "authors": [
      "Zhiheng Chen",
      "Jessica Hu",
      "Yauhong Goh",
      "Xiangwu Guo",
      "Yichun Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "ShowUI-Aloha: Human-Taught GUI Agent",
      "abstract": null,
      "arxiv_page_url": "https://arxiv.org/abs/2601.07181",
      "pdf_url": "https://arxiv.org/pdf/2601.07181",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07181",
      "scraped_at": "2026-01-14T01:55:50.358460"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Codified Foreshadowing-Payoff Text Generation",
    "paper_url": "https://huggingface.co/papers/2601.07033",
    "authors": [
      "Jingbo Shang",
      "Letian Peng",
      "Kun Zhou",
      "Longfei Yun",
      "hyp1231"
    ],
    "stars": "0",
    "details": {
      "title": "Codified Foreshadowing-Payoff Text Generation",
      "abstract": "Codified Foreshadowing-Payoff Text Generation",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07033",
      "pdf_url": "https://arxiv.org/pdf/2601.07033",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07033",
      "scraped_at": "2026-01-14T01:55:52.291930"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Sci-Reasoning: A Dataset Decoding AI Innovation Patterns",
    "paper_url": "https://huggingface.co/papers/2601.04577",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "Sci-Reasoning: A Dataset Decoding AI Innovation Patterns",
      "abstract": "While AI innovation accelerates rapidly, the intellectual process behind breakthroughs -- how researchers identify gaps, synthesize prior work, and generate insights -- remains poorly understood. The lack of structured data on scientific reasoning hinders systematic analysis and development of AI research agents. We introduce Sci-Reasoning, the first dataset capturing the intellectual synthesis behind high-quality AI research. Using community-validated quality signals and an LLM-accelerated, human-verified pipeline, we trace Oral and Spotlight papers across NeurIPS, ICML, and ICLR (2023-2025) to its key predecessors, articulating specific reasoning links in a structured format. Our analysis identifies 15 distinct thinking patterns, with three dominant strategies accounting for 52.7%: Gap-Driven Reframing (24.2%), Cross-Domain Synthesis (18.0%), and Representation Shift (10.5%). The most powerful innovation recipes combine multiple patterns: Gap-Driven Reframing + Representation Shift, Cross-Domain Synthesis + Representation Shift, and Gap-Driven Reframing + Cross-Domain Synthesis. This dataset enables quantitative studies of scientific progress and provides structured reasoning trajectories for training the next generation AI research agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.04577",
      "pdf_url": "https://arxiv.org/pdf/2601.04577",
      "github_links": [
        "https://github.com/AmberLJC/Sci-Reasoning"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.04577",
      "scraped_at": "2026-01-14T01:55:54.190567"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "How Do Large Language Models Learn Concepts During Continual Pre-Training?",
    "paper_url": "https://huggingface.co/papers/2601.03570",
    "authors": [
      "Zaishuo Xia",
      "Minqian Liu",
      "Yunzhi Yao",
      "Sha Li",
      "Barry Menglong Yao"
    ],
    "stars": "0",
    "details": {
      "title": "How Do Large Language Models Learn Concepts During Continual Pre-Training?",
      "abstract": "Human beings primarily understand the world through concepts (e.g., dog), abstract mental representations that structure perception, reasoning, and learning. However, how large language models (LLMs) acquire, retain, and forget such concepts during continual pretraining remains poorly understood. In this work, we study how individual concepts are acquired and forgotten, as well as how multiple concepts interact through interference and synergy. We link these behavioral dynamics to LLMs' internal Concept Circuits, computational subgraphs associated with specific concepts, and incorporate Graph Metrics to characterize circuit structure. Our analysis reveals: (1) LLMs concept circuits provide a non-trivial, statistically significant signal of concept learning and forgetting; (2) Concept circuits exhibit a stage-wise temporal pattern during continual pretraining, with an early increase followed by gradual decrease and stabilization; (3) concepts with larger learning gains tend to exhibit greater forgetting under subsequent training; (4) semantically similar concepts induce stronger interference than weakly related ones; (5) conceptual knowledge differs in their transferability, with some significantly facilitating the learning of others. Together, our findings offer a circuit-level view of concept learning dynamics and inform the design of more interpretable and robust concept-aware training strategies for LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.03570",
      "pdf_url": "https://arxiv.org/pdf/2601.03570",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.03570",
      "scraped_at": "2026-01-14T01:55:56.059301"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training",
    "paper_url": "https://huggingface.co/papers/2601.07389",
    "authors": [
      "Weixi Zhang",
      "Wei Han",
      "Bo Bai",
      "Xueyan Niu"
    ],
    "stars": "0",
    "details": {
      "title": "On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training",
      "abstract": "Post-training of large language models routinely interleaves supervised fine-tuning (SFT) with reinforcement learning (RL). These two methods have different objectives: SFT minimizes the cross-entropy loss between model outputs and expert responses, while RL maximizes reward signals derived from human preferences or rule-based verifiers. Modern reasoning models have widely adopted the practice of alternating SFT and RL training. However, there is no theoretical account of whether they can be decoupled. We prove that decoupling is impossible in either order: (1) SFT-then-RL coupling: RL increases SFT loss under SFT optimality and (2) RL-then-SFT coupling: SFT lowers the reward achieved by RL. Experiments on Qwen3-0.6B confirm the predicted degradation, verifying that SFT and RL cannot be separated without loss of prior performance in the post-training pipeline.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07389",
      "pdf_url": "https://arxiv.org/pdf/2601.07389",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07389",
      "scraped_at": "2026-01-14T01:55:57.904888"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?",
    "paper_url": "https://huggingface.co/papers/2601.06993",
    "authors": [
      "Xiaoming Liu",
      "Yiyang Su",
      "Paipile"
    ],
    "stars": "1",
    "details": {
      "title": "Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?",
      "abstract": "In this work, we investigate the impact of CoT on Fine-Grained Visual Classification (FGVC), revealing a paradox: the degradation in FGVC performance due to CoT is primarily driven by reasoning length, with longer textual reasoning consistently reducing classification accuracy. We introduce the concept of the \"Cost of Thinking\" to describe this phenomenon. Building on this insight, we propose two key contributions: (1) MRN, a normalization method for multi-reward optimization that balances heterogeneous reward signals; and (2) ReFine-RFT, a framework that integrates ensemble rewards with MRN to constrain reasoning length while providing dense, accuracy-oriented feedback. Our extensive experiments across multiple FGVC benchmarks demonstrate the effectiveness of our approach, achieving state-of-the-art performance.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06993",
      "pdf_url": "https://arxiv.org/pdf/2601.06993",
      "github_links": [
        "https://github.com/jiezhu23/ReFine-RFT"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06993",
      "scraped_at": "2026-01-14T01:55:59.761826"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction",
    "paper_url": "https://huggingface.co/papers/2601.06966",
    "authors": [
      "Shaolei Zhang",
      "Zishan Xu",
      "Sen Hu",
      "Zhiyuan Yao",
      "Haonan-Bian"
    ],
    "stars": "0",
    "details": {
      "title": "RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API EvolMem: A Cognitive-Driven Benchmark for Multi-Session Dialogue Memory (2026) Mem-Gallery: Benchmarking Multimodal Long-Term Conversational Memory for MLLM Agents (2026) Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI (2025) MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards (2026) KnowMe-Bench: Benchmarking Person Understanding for Lifelong Digital Companions (2026) MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents (2026) Mem-PAL: Towards Memory-based Personalized Dialogue Assistants for Long-term User-Agent Interaction (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06966",
      "pdf_url": "https://arxiv.org/pdf/2601.06966",
      "github_links": [
        "https://github.com/AvatarMemory/RealMemBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06966",
      "scraped_at": "2026-01-14T01:56:01.621095"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.06944",
    "authors": [
      "Shixing Li",
      "Guozhang Li",
      "Yaoyao Zhong",
      "Mei Wang",
      "Yuhang Su"
    ],
    "stars": "0",
    "details": {
      "title": "SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API ViRectify: A Challenging Benchmark for Video Reasoning Correction with Multimodal Large Language Models (2025) PPTBench: Towards Holistic Evaluation of Large Language Models for PowerPoint Layout and Design Understanding (2025) MMErroR: A Benchmark for Erroneous Reasoning in Vision-Language Models (2026) AECV-Bench: Benchmarking Multimodal Models on Architectural and Engineering Drawings Understanding (2026) CrossCheck-Bench: Diagnosing Compositional Failures in Multimodal Conflict Resolution (2025) PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models (2025) Evaluating large language models on multimodal chemistry olympiad exams (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06944",
      "pdf_url": "https://arxiv.org/pdf/2601.06944",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06944",
      "scraped_at": "2026-01-14T01:56:03.488898"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Artificial Entanglement in the Fine-Tuning of Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.06788",
    "authors": [
      "Manling Li",
      "Zeguan Wu",
      "Canyu Chen",
      "Zihan Wang",
      "Min Chen"
    ],
    "stars": "0",
    "details": {
      "title": "Artificial Entanglement in the Fine-Tuning of Large Language Models",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06788",
      "pdf_url": "https://arxiv.org/pdf/2601.06788",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06788",
      "scraped_at": "2026-01-14T01:56:05.320924"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "FinForge: Semi-Synthetic Financial Benchmark Generation",
    "paper_url": "https://huggingface.co/papers/2601.06747",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FinForge: Semi-Synthetic Financial Benchmark Generation",
      "abstract": "This paper introduces FinForge, a novel framework designed to address the scarcity of high-quality, domain-specific datasets for evaluating Large Language Models (LLMs) in finance. The authors propose a scalable, semi-synthetic pipeline that combines expert-guided data curation from authoritative sources with controlled question generation and validation using Gemini 2.5 Flash. Key Contributions: FinForge Framework: A hybrid pipeline integrating manual/programmatic corpus construction with rigorous LM-based synthesis. FinForge-5k Dataset: A new snapshot benchmark comprising over 5,000 human-validated Q&A pairs across 11 financial subdomains, derived from a curated corpus of 100,000 verified documents (143M tokens). Benchmarking Results: Evaluation of state-of-the-art open and closed-source models reveals significant variance in financial reasoning capabilities, with leading models achieving approximately 80% accuracy.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06747",
      "pdf_url": "https://arxiv.org/pdf/2601.06747",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06747",
      "scraped_at": "2026-01-14T01:56:07.161587"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Gecko: An Efficient Neural Architecture Inherently Processing Sequences with Arbitrary Lengths",
    "paper_url": "https://huggingface.co/papers/2601.06463",
    "authors": [],
    "stars": "4",
    "details": {
      "title": "Gecko: An Efficient Neural Architecture Inherently Processing Sequences with Arbitrary Lengths",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06463",
      "pdf_url": "https://arxiv.org/pdf/2601.06463",
      "github_links": [
        "https://github.com/XuezheMax/gecko-llm"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06463",
      "scraped_at": "2026-01-14T01:56:09.049268"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Does Inference Scaling Improve Reasoning Faithfulness? A Multi-Model Analysis of Self-Consistency Tradeoffs",
    "paper_url": "https://huggingface.co/papers/2601.06423",
    "authors": [
      "Deep Mehta"
    ],
    "stars": "0",
    "details": {
      "title": "Does Inference Scaling Improve Reasoning Faithfulness? A Multi-Model Analysis of Self-Consistency Tradeoffs",
      "abstract": "We ask a question that hasn't been studied before: does inference scaling improve reasoning faithfulness or just accuracy? Self-consistency (majority voting over multiple reasoning paths) reliably boosts LLM accuracy on reasoning tasks. But does getting the right answer more often mean the model is actually reasoning better? We test 4 frontier models (GPT-5.2, Claude Opus 4.5, Gemini-3-flash-preview, and DeepSeek-v3.2) on 100 GSM8K problems and find a surprising tradeoff. Accuracy gains from self-consistency don't necessarily translate to more faithful reasoning. This discovery has important implications for AI safety. We may be building systems that appear smarter without actually reasoning more reliably.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06423",
      "pdf_url": "https://arxiv.org/pdf/2601.06423",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06423",
      "scraped_at": "2026-01-14T01:56:10.861313"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "FlyPose: Towards Robust Human Pose Estimation From Aerial Views",
    "paper_url": "https://huggingface.co/papers/2601.05747",
    "authors": [
      "Peter St\\√ºtz",
      "Marvin Brenner",
      "farooqhassaan"
    ],
    "stars": "0",
    "details": {
      "title": "FlyPose: Towards Robust Human Pose Estimation From Aerial Views",
      "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in close proximity to humans for applications such as parcel delivery, traffic monitoring, disaster response and infrastructure inspections. Ensuring safe and reliable operation in these human-populated environments demands accurate perception of human poses and actions from an aerial viewpoint. This perspective challenges existing methods with low resolution, steep viewing angles and (self-)occlusion, especially if the application demands realtime feasible models. We train and deploy FlyPose, a lightweight top-down human pose estimation pipeline for aerial imagery. Through multi-dataset training, we achieve an average improvement of 6.8 mAP in person detection across the test-sets of Manipal-UAV, VisDrone, HIT-UAV as well as our custom dataset. For 2D human pose estimation we report an improvement of 16.3 mAP on the challenging UAV-Human dataset. FlyPose runs with an inference latency of ‚àº20 milliseconds including preprocessing on a Jetson Orin AGX Developer Kit and is deployed onboard a quadrotor UAV during flight experiments. We also publish FlyPose-104, a small but challenging aerial human pose estimation dataset, that includes manual annotations from difficult aerial perspectives: https://github.com/farooqhassaan/FlyPose .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.05747",
      "pdf_url": "https://arxiv.org/pdf/2601.05747",
      "github_links": [
        "https://github.com/farooqhassaan/FlyPose"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.05747",
      "scraped_at": "2026-01-14T01:56:12.800773"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification",
    "paper_url": "https://huggingface.co/papers/2601.07790",
    "authors": [
      "Chaowei Yang",
      "Joseph Rogers",
      "Zifu Wang",
      "Emily Ma",
      "ymasri"
    ],
    "stars": "1",
    "details": {
      "title": "Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification",
      "abstract": "We evaluate 9 open-source models under zero-shot, few-shot, and RAG (FAISS) and measure both accuracy + per-log latency. Main takeaway: RAG can massively help small models (Qwen3-4B: 95.64%, Gemma3-1B: 85.28%), but some reasoning-focused models degrade with retrieval, showing that retrieval integration isn‚Äôt uniform across architectures.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07790",
      "pdf_url": "https://arxiv.org/pdf/2601.07790",
      "github_links": [
        "https://github.com/stccenter/Benchmarking-SLMs-and-SRLMs-on-System-Log-Severity-Classification"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07790",
      "scraped_at": "2026-01-14T01:56:14.646904"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition",
    "paper_url": "https://huggingface.co/papers/2601.07239",
    "authors": [
      "Shreyash Dhoot",
      "Aadi Pandey",
      "Anusa Saha",
      "Shourya Aggarwal",
      "Tanmay Joshi"
    ],
    "stars": "0",
    "details": {
      "title": "Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition",
      "abstract": "Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition",
      "arxiv_page_url": "https://arxiv.org/abs/2601.07239",
      "pdf_url": "https://arxiv.org/pdf/2601.07239",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.07239",
      "scraped_at": "2026-01-14T01:56:16.492225"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence",
    "paper_url": "https://huggingface.co/papers/2601.06496",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence",
      "abstract": "https://github.com/AIGeeksGroup/3DCoCav2",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06496",
      "pdf_url": "https://arxiv.org/pdf/2601.06496",
      "github_links": [
        "https://github.com/AIGeeksGroup/3DCoCav2"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06496",
      "scraped_at": "2026-01-14T01:56:18.356557"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "On the Fallacy of Global Token Perplexity in Spoken Language Model Evaluation",
    "paper_url": "https://huggingface.co/papers/2601.06329",
    "authors": [
      "Ju-Chieh Chou",
      "Yen-Chun Kuo",
      "Yi-Cheng Lin",
      "Liang-Hsuan Tseng",
      "Jeff Chan-Jan Sju"
    ],
    "stars": "0",
    "details": {
      "title": "On the Fallacy of Global Token Perplexity in Spoken Language Model Evaluation",
      "abstract": "Generative spoken language models pretrained on large-scale raw audio can continue a speech prompt with appropriate content while preserving attributes like speaker and emotion, serving as foundation models for spoken dialogue. In prior literature, these models are often evaluated using ‚Äúglobal token perplexity‚Äù, which directly applies the text perplexity formulation to speech tokens. However, this practice overlooks fundamental differences between speech and text modalities, possibly leading to an underestimation of the speech characteristics. In this work, we propose a variety of likelihood- and generative-based evaluation methods that serve in place of naive global token perplexity. We demonstrate that the proposed evaluations more faithfully reflect perceived generation quality, as evidenced by stronger correlations with human-rated mean opinion scores (MOS). When assessed under the new metrics, the relative performance landscape of spoken language models is reshaped, revealing a significantly reduced gap between the best-performing model and the human topline. Together, these results suggest that appropriate evaluation is critical for accurately assessing progress in spoken language modeling.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06329",
      "pdf_url": "https://arxiv.org/pdf/2601.06329",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06329",
      "scraped_at": "2026-01-14T01:56:20.214536"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality",
    "paper_url": "https://huggingface.co/papers/2601.06307",
    "authors": [
      "Dilek Hakkani-T√ºr",
      "Dhruva Patil",
      "Zhenlin He",
      "Ishika Agarwal"
    ],
    "stars": "0",
    "details": {
      "title": "A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality",
      "abstract": "https://huggingface.co/collections/ishikaa/a-rising-tide-lifts-all-boats-mtqe-rewards-for-idioms",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06307",
      "pdf_url": "https://arxiv.org/pdf/2601.06307",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06307",
      "scraped_at": "2026-01-14T01:56:22.211331"
    },
    "scraped_date": "2026-01-14"
  },
  {
    "title": "SPINAL -- Scaling-law and Preference Integration in Neural Alignment Layers",
    "paper_url": "https://huggingface.co/papers/2601.06238",
    "authors": [
      "Aman Chadha",
      "Vinija Jain",
      "Amit Dhanda",
      "Partha Pratim Saha",
      "Arion Das"
    ],
    "stars": "0",
    "details": {
      "title": "SPINAL -- Scaling-law and Preference Integration in Neural Alignment Layers",
      "abstract": "SPINAL -- Scaling-law and Preference Integration in Neural Alignment Layers",
      "arxiv_page_url": "https://arxiv.org/abs/2601.06238",
      "pdf_url": "https://arxiv.org/pdf/2601.06238",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.06238",
      "scraped_at": "2026-01-14T01:56:24.053442"
    },
    "scraped_date": "2026-01-14"
  }
]