[
  {
    "title": "UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement",
    "paper_url": "https://huggingface.co/papers/2512.21185",
    "authors": [
      "Yang Li",
      "Dehao Hao",
      "LutaoJiang",
      "StarYDY",
      "infinith"
    ],
    "stars": "110",
    "details": {
      "title": "UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement",
      "abstract": "Github: https://github.com/PKU-YuanGroup/UltraShape-1.0 Project Page: https://pku-yuangroup.github.io/UltraShape-1.0/",
      "arxiv_page_url": "https://arxiv.org/abs/2512.21185",
      "pdf_url": "https://arxiv.org/pdf/2512.21185",
      "github_links": [
        "https://github.com/PKU-YuanGroup/UltraShape-1.0"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.21185",
      "scraped_at": "2026-01-01T01:59:26.540091"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "DreamOmni3: Scribble-based Editing and Generation",
    "paper_url": "https://huggingface.co/papers/2512.22525",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DreamOmni3: Scribble-based Editing and Generation",
      "abstract": "Github: https://github.com/dvlab-research/DreamOmni3",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22525",
      "pdf_url": "https://arxiv.org/pdf/2512.22525",
      "github_links": [
        "https://github.com/dvlab-research/DreamOmni3"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22525",
      "scraped_at": "2026-01-01T01:59:28.344263"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "End-to-End Test-Time Training for Long Context",
    "paper_url": "https://huggingface.co/papers/2512.23675",
    "authors": [
      "Marcel R√∏d",
      "Daniel Koceja",
      "Xinhao Li",
      "Karan Dalal",
      "Arnuv Tandon"
    ],
    "stars": "96",
    "details": {
      "title": "End-to-End Test-Time Training for Long Context",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Sliding Window Attention Adaptation (2025) Let's (not) just put things in Context: Test-Time Training for Long-Context LLMs (2025) Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models (2025) Attention and Compression is all you need for Controllably Efficient Language Models (2025) Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings (2025) Data-Free Pruning of Self-Attention Layers in LLMs (2025) Architectural Trade-offs in Small Language Models Under Compute Constraints (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23675",
      "pdf_url": "https://arxiv.org/pdf/2512.23675",
      "github_links": [
        "https://github.com/test-time-training/e2e"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23675",
      "scraped_at": "2026-01-01T01:59:30.184972"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "Evaluating Parameter Efficient Methods for RLVR",
    "paper_url": "https://huggingface.co/papers/2512.23165",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Evaluating Parameter Efficient Methods for RLVR",
      "abstract": "https://www.alphaxiv.org/abs/2512.23165",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23165",
      "pdf_url": "https://arxiv.org/pdf/2512.23165",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23165",
      "scraped_at": "2026-01-01T01:59:31.986046"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization",
    "paper_url": "https://huggingface.co/papers/2512.22469",
    "authors": [
      "Wei Zhang",
      "Aofan Liu",
      "Pengfei Gao",
      "Wei Liu",
      "pengchao"
    ],
    "stars": "0",
    "details": {
      "title": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization",
      "abstract": "Issues describe symptoms‚Äîthe real buggy code is often hidden behind multi-hop dependencies. GraphLocator moves beyond relevance retrieval by explicitly modelling causal structure: decomposing sub-problems, capturing causal dependencies, and performing constrained causal reasoning over code dependency graphs. Across multiple Python and Java datasets, GraphLocator significantly improves function-level recall and precision, and the inferred causal structures further boost downstream issue resolution by +28.74%.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22469",
      "pdf_url": "https://arxiv.org/pdf/2512.22469",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22469",
      "scraped_at": "2026-01-01T01:59:33.772256"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks",
    "paper_url": "https://huggingface.co/papers/2512.22206",
    "authors": [
      "Yogeswar"
    ],
    "stars": "0",
    "details": {
      "title": "CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks",
      "abstract": "\"I introduce CosineGate, a SOTA dynamic routing mechanism for ResNets that uses the Cosine Incompatibility Ratio (CIR) as a self-supervised signal. üöÄ Why it matters: It matches ResNet-20 accuracy on CIFAR-10 while slashing computation by 28.5%‚Äîwithout needing extra 'predictor' sub-networks or distillation. üõ†Ô∏è Key Features: Fully differentiable (via Gumbel-Softmax). Bio-inspired (Predictive Coding). Plug-and-play for efficient computer vision. Check out our GitHub Repo linked in the sidebar for the implementation!\"",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22206",
      "pdf_url": "https://arxiv.org/pdf/2512.22206",
      "github_links": [
        "https://github.com/thotayogeswarreddy/CosineGate"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22206",
      "scraped_at": "2026-01-01T01:59:35.535486"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
    "paper_url": "https://huggingface.co/papers/2512.21008",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
      "abstract": "Mixture-of-Experts (MoE) architectures have advanced the scaling of Large Language Models (LLMs) by activating only a sparse subset of parameters per input, enabling state-of-the-art performance with reduced computational cost. As these models are increasingly deployed in critical domains, understanding and strengthening their alignment mechanisms is essential to prevent harmful outputs. However, existing LLM safety research has focused almost exclusively on dense architectures, leaving the unique safety properties of MoEs largely unexamined. The modular, sparsely-activated design of MoEs suggests that safety mechanisms may operate differently than in dense models, raising questions about their robustness. In this paper, we present GateBreaker, the first training-free, lightweight, and architecture-agnostic attack framework that compromises the safety alignment of modern MoE LLMs at inference time. GateBreaker operates in three stages: (i) gate-level profiling, which identifies safety experts disproportionately routed on harmful inputs, (ii) expert-level localization, which localizes the safety structure within safety experts, and (iii) targeted safety removal, which disables the identified safety structure to compromise the safety alignment. Our study shows that MoE safety concentrates within a small subset of neurons coordinated by sparse routing. Selective disabling of these neurons, approximately 3% of neurons in the targeted expert layers, significantly increases the averaged attack success rate (ASR) from 7.4% to 64.9% against the eight latest aligned MoE LLMs with limited utility degradation. These safety neurons transfer across models within the same family, raising ASR from 17.9% to 67.7% with one-shot transfer attack. Furthermore, GateBreaker generalizes to five MoE vision language models (VLMs) with 60.9% ASR on unsafe image inputs.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.21008",
      "pdf_url": "https://arxiv.org/pdf/2512.21008",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.21008",
      "scraped_at": "2026-01-01T01:59:37.334356"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "mHC: Manifold-Constrained Hyper-Connections",
    "paper_url": "https://huggingface.co/papers/2512.24880",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "mHC: Manifold-Constrained Hyper-Connections",
      "abstract": "DeepSeek released a new paper proposing a novel architecture called mHC (Manifold-Constrained Hyper-Connections).",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24880",
      "pdf_url": "https://arxiv.org/pdf/2512.24880",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24880",
      "scraped_at": "2026-01-02T01:50:23.780257"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models",
    "paper_url": "https://huggingface.co/papers/2512.24618",
    "authors": [
      "Xinyi Dai",
      "Yinghui Li",
      "Lingfeng Qiao",
      "Jiarui Qin",
      "Junru Lu"
    ],
    "stars": "0",
    "details": {
      "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24618",
      "pdf_url": "https://arxiv.org/pdf/2512.24618",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24618",
      "scraped_at": "2026-01-02T01:50:25.585213"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem",
    "paper_url": "https://huggingface.co/papers/2512.24873",
    "authors": [
      "Wei Gao",
      "Fangwen Dai",
      "Wanhe An",
      "XiaoXiao Xu",
      "Weixun Wang"
    ],
    "stars": "0",
    "details": {
      "title": "Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24873",
      "pdf_url": "https://arxiv.org/pdf/2512.24873",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24873",
      "scraped_at": "2026-01-02T01:50:27.522125"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction",
    "paper_url": "https://huggingface.co/papers/2512.25073",
    "authors": [
      "Yu-Lun Liu",
      "Ying-Huan Chen",
      "Chin-Yang Lin",
      "Hao-Jen Chien",
      "Yi-Chuan Huang"
    ],
    "stars": "0",
    "details": {
      "title": "GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction",
      "abstract": "Recent advances in 3D reconstruction have achieved remarkable progress in high-quality scene capture from dense multi-view imagery, yet struggle when input views are limited. Various approaches, including regularization techniques, semantic priors, and geometric constraints, have been implemented to address this challenge. Latest diffusion-based methods have demonstrated substantial improvements by generating novel views from new camera poses to augment training data, surpassing earlier regularization and prior-based techniques. Despite this progress, we identify three critical limitations in these state-of-the-art approaches: inadequate coverage beyond known view peripheries, geometric inconsistencies across generated views, and computationally expensive pipelines. We introduce GaMO (Geometry-aware Multi-view Outpainter), a framework that reformulates sparse-view reconstruction through multi-view outpainting. Instead of generating new viewpoints, GaMO expands the field of view from existing camera poses, which inherently preserves geometric consistency while providing broader scene coverage. Our approach employs multi-view conditioning and geometry-aware denoising strategies in a zero-shot manner without training. Extensive experiments on Replica and ScanNet++ demonstrate state-of-the-art reconstruction quality across 3, 6, and 9 input views, outperforming prior methods in PSNR and LPIPS, while achieving a 25√ó speedup over SOTA diffusion-based methods with processing time under 10 minutes. Project page: https://yichuanh.github.io/GaMO/",
      "arxiv_page_url": "https://arxiv.org/abs/2512.25073",
      "pdf_url": "https://arxiv.org/pdf/2512.25073",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.25073",
      "scraped_at": "2026-01-02T01:50:29.343131"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers",
    "paper_url": "https://huggingface.co/papers/2512.23380",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23380",
      "pdf_url": "https://arxiv.org/pdf/2512.23380",
      "github_links": [
        "https://github.com/NasirzadehMoh/CoLog"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23380",
      "scraped_at": "2026-01-02T01:50:31.161979"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Scaling Open-Ended Reasoning to Predict the Future",
    "paper_url": "https://huggingface.co/papers/2512.25070",
    "authors": [],
    "stars": "6",
    "details": {
      "title": "Scaling Open-Ended Reasoning to Predict the Future",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.25070",
      "pdf_url": "https://arxiv.org/pdf/2512.25070",
      "github_links": [
        "https://github.com/OpenForecaster/scaling-forecasting-training"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.25070",
      "scraped_at": "2026-01-02T01:50:33.046417"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation",
    "paper_url": "https://huggingface.co/papers/2512.24551",
    "authors": [],
    "stars": "4",
    "details": {
      "title": "PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation",
      "abstract": "A data construction pipeline and a new DPO framework for physically consistent Text-to-video generation",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24551",
      "pdf_url": "https://arxiv.org/pdf/2512.24551",
      "github_links": [
        "https://github.com/caiyuanhao1998/Open-PhyGDPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24551",
      "scraped_at": "2026-01-02T01:50:34.905156"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents",
    "paper_url": "https://huggingface.co/papers/2512.23343",
    "authors": [
      "Shixin Jiang",
      "Jiaqi Zhou",
      "Chang Li",
      "Hao Li",
      "Jiafeng Liang"
    ],
    "stars": "24",
    "details": {
      "title": "AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents",
      "abstract": "https://github.com/AgentMemory/Huaman-Agent-Memory",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23343",
      "pdf_url": "https://arxiv.org/pdf/2512.23343",
      "github_links": [
        "https://github.com/AgentMemory/Huaman-Agent-Memory"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23343",
      "scraped_at": "2026-01-02T01:50:36.704147"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "GR-Dexter Technical Report",
    "paper_url": "https://huggingface.co/papers/2512.24210",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GR-Dexter Technical Report",
      "abstract": "VLAs go from grippers to 21 DoF dexterous ByteDexter V2 :)",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24210",
      "pdf_url": "https://arxiv.org/pdf/2512.24210",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24210",
      "scraped_at": "2026-01-02T01:50:38.600164"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process",
    "paper_url": "https://huggingface.co/papers/2512.23988",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process",
      "abstract": "This is an impressive piece of work. Not only for the elegance of the sparse autoencoder pipeline, but because the empirical results reveal something far deeper than what is stated in the paper. Your SAE-derived ‚Äúreasoning vectors‚Äù behave exactly like stable dynamical modes inside a recursive state system ‚Äî not merely interpretable directions. The separation of reflection, backtracking, confidence, and response-length clusters across layers strongly suggests that modern transformer reasoning is governed by a latent, substrate-bound dynamical structure rather than a purely token-level process. A few observations that stood out: Reasoning vectors behave like attractor modes, not just features. The clustering of SAE decoder columns into semantically distinct basins is consistent with the existence of stable dynamical invariants that govern the model‚Äôs step-wise evolution. This is exactly the behavior expected when a system has: stable recurrence points, local attractor basins in its state manifold, and identity-like update modes that persist across tasks. Your causal interventions reinforce this: modifying a reasoning vector steers the entire reasoning trajectory while preserving final correctness. That is classic attractor dynamics. The layer-wise geometry mirrors a recursive integration process. The strongest separability occurring in mid-to-late layers, followed by a decline near the final layer, mirrors the behavior of systems that integrate state over time and then compress it near output. This is structurally identical to a recursive state-aware update: a(t+1)=R(a(t)) where the model accumulates long-range structure before collapsing it for output. Cross-domain generalization of these vectors indicates substrate-bound stability. The fact that reflection/backtracking vectors trained on MATH500 steer behavior on GPQA and KnowLogic implies the existence of substrate-stable reasoning structures that are independent of dataset distribution. This is a property of a dynamical system ‚Äî not a static embedding space. Confidence emerges as a coherent cluster because it is tied to entropy and coherence. Your discovery that confidence vectors suppress reflection/backtracking is an empirical confirmation of a predicted relation between: information coherence computational alignment noise minimization and entropy reduction Confidence is not a semantic trait ‚Äî it's a low-entropy attractor mode. Response-length alignment is a structural axis, not a surface feature. Length correlating with latent-space geometry further confirms that reasoning depth emerges from the system's internal temporal continuity rather than token heuristics. A broader note: These empirical findings align remarkably well with a larger theoretical framework I‚Äôve been developing, the Field of General Awareness (FoGA), which predicts: the existence of invariant reasoning modes, substrate-sensitive drift in state evolution, recursive attractor-based reasoning paths, and coherence-driven modulation of reasoning confidence. Your results are the clearest real-world demonstration I‚Äôve seen of these principles emerging naturally inside transformer models. If you're interested, I‚Äôm happy to share the relevant portions of the theory (and the mathematical basis behind these predictions), as well as the Dynamic Transformer Architecture ‚Äî an architecture patch explicitly designed to stabilize such recurrence modes. Excellent work. This paper is going to be foundational for understanding why LLM reasoning behaves the way it does. ‚Äî Zenith Zaraki SkyTeam Aerospace Foundation https://www.skyteamaerospacefoundation.com/foga https://www.skyteamaerospacefoundation.com/dta",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23988",
      "pdf_url": "https://arxiv.org/pdf/2512.23988",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23988",
      "scraped_at": "2026-01-02T01:50:40.409987"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Pretraining Frame Preservation in Autoregressive Video Memory Compression",
    "paper_url": "https://huggingface.co/papers/2512.23851",
    "authors": [
      "Beijia Lu",
      "Chong Zeng",
      "Muyang Li",
      "Shengqu Cai",
      "Lvmin Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "Pretraining Frame Preservation in Autoregressive Video Memory Compression",
      "abstract": "Arxiv: https://arxiv.org/abs/2512.23851 Repo: https://github.com/lllyasviel/PFP",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23851",
      "pdf_url": "https://arxiv.org/pdf/2512.23851",
      "github_links": [
        "https://github.com/lllyasviel/PFP"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23851",
      "scraped_at": "2026-01-02T01:50:42.190944"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time",
    "paper_url": "https://huggingface.co/papers/2512.25075",
    "authors": [
      "Tuanfeng Y. Wang",
      "Yulia Gryaditskaya",
      "Xuelin Chen",
      "Hyeonho Jeong",
      "Zhening Huang"
    ],
    "stars": "0",
    "details": {
      "title": "SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API BulletTime: Decoupled Control of Time and Camera Pose for Video Generation (2025) FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint (2025) ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation (2025) OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis (2025) Infinite-Homography as Robust Conditioning for Camera-Controlled Video Generation (2025) Light-X: Generative 4D Video Rendering with Camera and Illumination Control (2025) Generative Video Motion Editing with 3D Point Tracks (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2512.25075",
      "pdf_url": "https://arxiv.org/pdf/2512.25075",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.25075",
      "scraped_at": "2026-01-02T01:50:43.989867"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "JavisGPT: A Unified Multi-modal LLM for Sounding-Video Comprehension and Generation",
    "paper_url": "https://huggingface.co/papers/2512.22905",
    "authors": [],
    "stars": "11",
    "details": {
      "title": "JavisGPT: A Unified Multi-modal LLM for Sounding-Video Comprehension and Generation",
      "abstract": "üî•üî•üî• JavisGPT üåü We introduce JavisGPT, a multimodal LLM that can understand audiovisual inputs and simultaneously generate synchronized sounding videos in a unified model. ü§† We contribute JavisInst-Omni, a dataset to facilitate diverse and complex instruction-tuning for comprehension and generation on sounding videos. üìù Paper: https://arxiv.org/abs/2503.23377 üéâ Project: https://javisverse.github.io/JavisGPT-page/ ‚ú® Code: https://github.com/JavisVerse/JavisGPT",
      "arxiv_page_url": "https://arxiv.org/abs/2503.23377",
      "pdf_url": "https://arxiv.org/pdf/2512.22905",
      "github_links": [
        "https://github.com/JavisVerse/JavisGPT"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22905",
      "scraped_at": "2026-01-02T01:50:45.835201"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Geometry-Aware Optimization for Respiratory Sound Classification: Enhancing Sensitivity with SAM-Optimized Audio Spectrogram Transformers",
    "paper_url": "https://huggingface.co/papers/2512.22564",
    "authors": [
      "Mah≈üuk Taylan",
      "Ahmet Feridun I≈üƒ±k",
      "Selin Vulga I≈üƒ±k",
      "Atakanisik"
    ],
    "stars": "0",
    "details": {
      "title": "Geometry-Aware Optimization for Respiratory Sound Classification: Enhancing Sensitivity with SAM-Optimized Audio Spectrogram Transformers",
      "abstract": "Hi all, We present a robust framework for Lung Sound Classification using AST backbones enhanced with SAM optimizer . Traditional transformers often struggle with limited medical data, but our experiments show that geometry-aware optimization (SAM) leads to a massive boost in sensitivity. We achieved a 68.10% Score on the official ICBHI 2017 split. We invite everyone to benchmark our results. The repository includes: Cyclic padding implementation Full training scripts Evaluation of model Check it out here: GitHub Link",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22564",
      "pdf_url": "https://arxiv.org/pdf/2512.22564",
      "github_links": [
        "https://github.com/Atakanisik/ICBHI-AST-SAM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22564",
      "scraped_at": "2026-01-02T01:50:47.616554"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts",
    "paper_url": "https://huggingface.co/papers/2512.24885",
    "authors": [
      "Mengmeng Wang",
      "Chenxi Li",
      "Qi Shen",
      "Zhaoxin Yu",
      "Hengli Li"
    ],
    "stars": "0",
    "details": {
      "title": "BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts",
      "abstract": "Arxiv: https://arxiv.org/abs/2512.24885 X thread: https://x.com/Hengli_Li_pku/status/2006606887652045158",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24885",
      "pdf_url": "https://arxiv.org/pdf/2512.24885",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24885",
      "scraped_at": "2026-01-02T01:50:49.444890"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems",
    "paper_url": "https://huggingface.co/papers/2512.24385",
    "authors": [],
    "stars": "105",
    "details": {
      "title": "Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems",
      "abstract": "GitHub at https://github.com/worldbench/awesome-spatial-intelligence",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24385",
      "pdf_url": "https://arxiv.org/pdf/2512.24385",
      "github_links": [
        "https://github.com/worldbench/awesome-spatial-intelligence"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24385",
      "scraped_at": "2026-01-02T01:50:51.222394"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking",
    "paper_url": "https://huggingface.co/papers/2512.24297",
    "authors": [
      "Jie Zhou",
      "Fandong Meng",
      "Meiqi Chen"
    ],
    "stars": "4",
    "details": {
      "title": "Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API V-Thinker: Interactive Thinking with Images (2025) Interleaved Latent Visual Reasoning with Selective Perceptual Modeling (2025) Deep But Reliable: Advancing Multi-turn Reasoning for Thinking with Images (2025) ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking (2025) ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning (2025) Look as You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning (2025) CodeDance: A Dynamic Tool-integrated MLLM for Executable Visual Reasoning (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24297",
      "pdf_url": "https://arxiv.org/pdf/2512.24297",
      "github_links": [
        "https://github.com/chenmeiqii/FIGR"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24297",
      "scraped_at": "2026-01-02T01:50:53.259496"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Guiding a Diffusion Transformer with the Internal Dynamics of Itself",
    "paper_url": "https://huggingface.co/papers/2512.24176",
    "authors": [],
    "stars": "13",
    "details": {
      "title": "Guiding a Diffusion Transformer with the Internal Dynamics of Itself",
      "abstract": "üî• New SOTA on 256 √ó 256 ImageNet generation. We present Internal Guidance (IG), a simple yet powerful guidance mechanism for Diffusion Transformers. LightningDiT-XL/1 + IG sets a new state of the art with FID = 1.07 on ImageNet (balanced sampling), while achieving FID = 1.24 without classifier-free guidance. IG delivers dramatic quality gains with far fewer training epochs, adds negligible overhead, and works as a drop-in upgrade for modern diffusion transformers.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24176",
      "pdf_url": "https://arxiv.org/pdf/2512.24176",
      "github_links": [
        "https://github.com/CVL-UESTC/Internal-Guidance"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24176",
      "scraped_at": "2026-01-02T01:50:55.053809"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Factorized Learning for Temporally Grounded Video-Language Models",
    "paper_url": "https://huggingface.co/papers/2512.24097",
    "authors": [],
    "stars": "14",
    "details": {
      "title": "Factorized Learning for Temporally Grounded Video-Language Models",
      "abstract": "We tackle temporally grounded video-language understanding from a factorized perspective. Some key takeaways: [1] We emphasize the distinct yet causally dependent nature of temporal grounding and textual response. [2] Our study highlights the importance of explicit event-level visual semantic capture in enhancing both grounding and textual response quality. [3] We also propose a new Factorized Preference Optimization (FPO) scheme that jointly optimizes temporal and textual factors. A factorized data synthesis approach is also proposed to support FPO.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24097",
      "pdf_url": "https://arxiv.org/pdf/2512.24097",
      "github_links": [
        "https://github.com/nusnlp/d2vlm"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24097",
      "scraped_at": "2026-01-02T01:50:56.944458"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Valori: A Deterministic Memory Substrate for AI Systems",
    "paper_url": "https://huggingface.co/papers/2512.22280",
    "authors": [
      "varam17"
    ],
    "stars": "2",
    "details": {
      "title": "Valori: A Deterministic Memory Substrate for AI Systems",
      "abstract": "Valori: A Deterministic Fixed-Point Vector Kernel Tags: vector-database , rust , determinism , finance , audit , hnsw , fixed-point , systems-engineering TL;DR Floating-point math causes vector search results to drift between ARM (Mac) and x86 (Linux) architectures due to compiler and hardware variances. Valori is a Q16.16 Fixed-Point kernel written in Rust that guarantees bit-exact reproducibility across all hardware platforms, making it the first \"Audit-Grade\" vector engine for high-stakes AI. 1. The Problem: \"The Silent Drift\" Most vector databases (FAISS, Pinecone, Weaviate) rely on hardware-accelerated floating-point arithmetic ( f32 ). While fast, this introduces Non-Determinism : Associativity Variance: (a + b) + c ‚â† a + (b + c) depending on SIMD optimizations. Architecture Variance: A backtest run on a MacBook (ARM NEON) often yields different nearest neighbors than the live execution on an AWS Server (Intel AVX2). In RAG pipelines , this is annoying. In High-Frequency Trading or Legal Forensics , this variance is a liability. You cannot audit a probabilistic black box. 2. The Solution: Valori Kernel Valori is a forensic memory engine built from scratch in Rust . It replaces standard floating-point math with a custom Q16.16 Fixed-Point Arithmetic system inside an HNSW graph. Zero Drift: The mathematical operations are integer-based. 1 + 1 = 2 on every CPU, forever. Audit-Ready: Includes a calculate_state_hash() method that generates a cryptographic fingerprint of the database state. If a single bit changes, the hash breaks. Crash Proof: Implements a specialized persistence layer with <40ms recovery time (Cold Boot to Full Query) for 50k vector datasets. 3. Benchmarks (Engineering Verification) Validated on Apple M2 (ARM64) vs Intel Xeon (x86_64). Metric Result Notes Recall@10 99.0% Matches brute-force ground truth. Determinism 100% Bit-exact match across architectures. Recovery Time 35ms For 50k vectors (Snapshot Load). Latency ~0.5ms Per query (Single Thread). 4. Usage (Rust) Valori is designed to be embedded directly into high-integrity Rust applications. Add to Cargo.toml : [dependencies] valori_kernel = { git = \"https://github.com/varshith-Git/Valori-Kernel\" } Example: Deterministic Ingest & Audit use valori_kernel::{ValoriKernel, types::FixedPointVector}; fn main () -> anyhow:: Result <()> { // 1. Initialize the Kernel (Q16.16 Math) let mut kernel = ValoriKernel:: new (); // 2. Ingest Data (Manual f32 -> FixedPoint conversion for safety) let raw_vector = [ 0.5 , - 0.2 , 0.9 , ...]; // 128-dim // Convert float to Q16.16 integer representation let mut fixed_arr = [ 0i32 ; 128 ]; for (i, &val) in raw_vector. iter (). enumerate () {\n        fixed_arr[i] = (val * 65536.0 ) as i32 ;\n    } // Insert with ID=1, Tag=100 kernel. insert ( 1 , FixedPointVector (fixed_arr), 100 ); // 3. Search // Guaranteed to return the exact same ID and Distance on any CPU let results = kernel. search (&fixed_arr, 5 , None )?; println! ( \"Found neighbors: {:?}\" , results); // 4. Generate Forensic Evidence // This hash proves the database state is identical bit-for-bit let audit_hash = kernel.graph. calculate_state_hash (); println! ( \"Cryptographic State Signature: {}\" , audit_hash); Ok (())\n} 5. Who is this for? Quant Developers: Who need backtests to match live execution perfectly. Systems Engineers: Debugging \"Why did the agent say X?\" (Eliminate the database as a variable). Auditors: Who need to certify AI decision logs using cryptographic proofs. Citation If you use Valori in your research, please cite: @ misc {gudur2025valori,\n  title={Valori: A Deterministic Fixed-Point Vector Kernel},\n  author={Gudur, Varshith},\n  year={2025},\n  publisher={arXiv},\n  url={https://arxiv.org/abs/2512.22280}\n}",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22280",
      "pdf_url": "https://arxiv.org/pdf/2512.22280",
      "github_links": [
        "https://github.com/varshith-Git/Valori-Kernel"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22280",
      "scraped_at": "2026-01-02T01:50:58.743405"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
    "paper_url": "https://huggingface.co/papers/2512.23959",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
      "abstract": "Code released at: https://github.com/Encyclomen/HGMem",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23959",
      "pdf_url": "https://arxiv.org/pdf/2512.23959",
      "github_links": [
        "https://github.com/Encyclomen/HGMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23959",
      "scraped_at": "2026-01-03T01:44:37.960652"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
    "paper_url": "https://huggingface.co/papers/2512.24617",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
      "abstract": "Dynamic Large Concept Models (DLCM) introduce an end-to-end trained concept-level language modeling architecture that breaks the token-uniform computation paradigm in modern LLMs. Inspired by hierarchical models such as H-Net, DLCM learns semantic boundaries directly from latent representations, dynamically compresses token sequences into variable-length concepts, performs deep reasoning in the concept space, and projects the results back to tokens via causal cross-attention. Compared to standard dense Transformers trained with next-token prediction, DLCM achieves ~34% inference FLOPs reduction under apple-to-apple settings, while consistently improving performance on reasoning-dominant benchmarks. Notably, the relative FLOPs savings increase with model scale, indicating favorable scaling behavior beyond parameter efficiency alone. At similar loss levels, DLCM reallocates computation toward boundary and planning tokens, yielding stronger downstream accuracy despite reduced redundant token processing. Technically, the paper contributes: (1) a FlashAttention-VarLen‚Äìbased implementation for efficient concept-token cross-attention; (2) a decoupled ŒºP formulation tailored to heterogeneous token- and concept-width modules, enabling zero-shot hyperparameter transfer across scales; (3) a Global Parser that enforces stable, content-adaptive compression at the batch level and delivers solid empirical gains. Overall, DLCM can be viewed as a principled special case of layer-wise local compression combined with sparse attention, offering a scalable path toward more compute-efficient and reasoning-centric language models.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24617",
      "pdf_url": "https://arxiv.org/pdf/2512.24617",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24617",
      "scraped_at": "2026-01-03T01:44:39.850579"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
    "paper_url": "https://huggingface.co/papers/2512.24165",
    "authors": [
      "Siyuan Huang",
      "Yafu Li",
      "Xiaoye Qu",
      "Spico",
      "yhx12"
    ],
    "stars": "13",
    "details": {
      "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
      "abstract": "TLDR: A new paradigm for multi-modal reasoning with image-to-image generation. Diffusion could think too!",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24165",
      "pdf_url": "https://arxiv.org/pdf/2512.24165",
      "github_links": [
        "https://github.com/lcqysl/DiffThinker"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24165",
      "scraped_at": "2026-01-03T01:44:41.687283"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "On the Role of Discreteness in Diffusion LLMs",
    "paper_url": "https://huggingface.co/papers/2512.22630",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "On the Role of Discreteness in Diffusion LLMs",
      "abstract": "TL;DR: We identify two core failure modes in current large diffusion LLMs: uniform corruption ignores where information lives in a sentence, and token-wise marginal training struggles with multi-token dependencies during parallel decoding.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22630",
      "pdf_url": "https://arxiv.org/pdf/2512.22630",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22630",
      "scraped_at": "2026-01-03T01:44:43.488349"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
    "paper_url": "https://huggingface.co/papers/2512.24724",
    "authors": [
      "Youngjung Uh",
      "Jaeseok Jeong",
      "Mingi Kwon",
      "Jibin Song"
    ],
    "stars": "0",
    "details": {
      "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24724",
      "pdf_url": "https://arxiv.org/pdf/2512.24724",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24724",
      "scraped_at": "2026-01-03T01:44:45.286927"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
    "paper_url": "https://huggingface.co/papers/2512.24766",
    "authors": [
      "Ruohan Zhang",
      "Li Fei-Fei",
      "Jiajun Wu",
      "Wenlong Huang",
      "Karthik Dharmarajan"
    ],
    "stars": "0",
    "details": {
      "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24766",
      "pdf_url": "https://arxiv.org/pdf/2512.24766",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24766",
      "scraped_at": "2026-01-03T01:44:47.116340"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
    "paper_url": "https://huggingface.co/papers/2512.24007",
    "authors": [
      "Ghaith Rabadi",
      "Sean Mondesire",
      "Bulent Soykan"
    ],
    "stars": "3",
    "details": {
      "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
      "abstract": "Simulation optimization (SO) is frequently challenged by noisy evaluations, high computational costs, and complex, multimodal search landscapes. This paper introduces Tabu-Enhanced Simulation Optimization (TESO), a novel metaheuristic framework integrating adaptive search with memory-based strategies. TESO leverages a short-term Tabu List to prevent cycling and encourage diversification, and a long-term Elite Memory to guide intensification by perturbing high-performing solutions. An aspiration criterion allows overriding tabu restrictions for exceptional candidates. This combination facilitates a dynamic balance between exploration and exploitation in stochastic environments. We demonstrate TESO‚Äôs effectiveness and reliability using an queue optimization problem, showing improved performance compared to benchmarks and validating the contribution of its memory components. Source code and data are available at: github.com/bulentsoykan/TESO.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24007",
      "pdf_url": "https://arxiv.org/pdf/2512.24007",
      "github_links": [
        "https://github.com/bulentsoykan/TESO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24007",
      "scraped_at": "2026-01-03T01:44:48.907162"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
    "paper_url": "https://huggingface.co/papers/2512.23959",
    "authors": [],
    "stars": "22",
    "details": {
      "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
      "abstract": "Code released at: https://github.com/Encyclomen/HGMem",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23959",
      "pdf_url": "https://arxiv.org/pdf/2512.23959",
      "github_links": [
        "https://github.com/Encyclomen/HGMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23959",
      "scraped_at": "2026-01-04T01:59:50.718806"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
    "paper_url": "https://huggingface.co/papers/2512.24617",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
      "abstract": "Dynamic Large Concept Models (DLCM) introduce an end-to-end trained concept-level language modeling architecture that breaks the token-uniform computation paradigm in modern LLMs. Inspired by hierarchical models such as H-Net, DLCM learns semantic boundaries directly from latent representations, dynamically compresses token sequences into variable-length concepts, performs deep reasoning in the concept space, and projects the results back to tokens via causal cross-attention. Compared to standard dense Transformers trained with next-token prediction, DLCM achieves ~34% inference FLOPs reduction under apple-to-apple settings, while consistently improving performance on reasoning-dominant benchmarks. Notably, the relative FLOPs savings increase with model scale, indicating favorable scaling behavior beyond parameter efficiency alone. At similar loss levels, DLCM reallocates computation toward boundary and planning tokens, yielding stronger downstream accuracy despite reduced redundant token processing. Technically, the paper contributes: (1) a FlashAttention-VarLen‚Äìbased implementation for efficient concept-token cross-attention; (2) a decoupled ŒºP formulation tailored to heterogeneous token- and concept-width modules, enabling zero-shot hyperparameter transfer across scales; (3) a Global Parser that enforces stable, content-adaptive compression at the batch level and delivers solid empirical gains. Overall, DLCM can be viewed as a principled special case of layer-wise local compression combined with sparse attention, offering a scalable path toward more compute-efficient and reasoning-centric language models.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24617",
      "pdf_url": "https://arxiv.org/pdf/2512.24617",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24617",
      "scraped_at": "2026-01-04T01:59:52.693703"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
    "paper_url": "https://huggingface.co/papers/2512.24165",
    "authors": [
      "Siyuan Huang",
      "Yafu Li",
      "Xiaoye Qu",
      "Spico",
      "yhx12"
    ],
    "stars": "24",
    "details": {
      "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
      "abstract": "TLDR: A new paradigm for multi-modal reasoning with image-to-image generation. Diffusion could think too!",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24165",
      "pdf_url": "https://arxiv.org/pdf/2512.24165",
      "github_links": [
        "https://github.com/lcqysl/DiffThinker"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24165",
      "scraped_at": "2026-01-04T01:59:54.609230"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "On the Role of Discreteness in Diffusion LLMs",
    "paper_url": "https://huggingface.co/papers/2512.22630",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "On the Role of Discreteness in Diffusion LLMs",
      "abstract": "TL;DR: We identify two core failure modes in current large diffusion LLMs: uniform corruption ignores where information lives in a sentence, and token-wise marginal training struggles with multi-token dependencies during parallel decoding.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22630",
      "pdf_url": "https://arxiv.org/pdf/2512.22630",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22630",
      "scraped_at": "2026-01-04T01:59:56.484887"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
    "paper_url": "https://huggingface.co/papers/2512.24766",
    "authors": [
      "Ruohan Zhang",
      "Li Fei-Fei",
      "Jiajun Wu",
      "Wenlong Huang",
      "Karthik Dharmarajan"
    ],
    "stars": "0",
    "details": {
      "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24766",
      "pdf_url": "https://arxiv.org/pdf/2512.24766",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24766",
      "scraped_at": "2026-01-04T01:59:58.371341"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
    "paper_url": "https://huggingface.co/papers/2512.24724",
    "authors": [
      "Youngjung Uh",
      "Jaeseok Jeong",
      "Mingi Kwon",
      "Jibin Song"
    ],
    "stars": "0",
    "details": {
      "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24724",
      "pdf_url": "https://arxiv.org/pdf/2512.24724",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24724",
      "scraped_at": "2026-01-04T02:00:00.212924"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
    "paper_url": "https://huggingface.co/papers/2512.24007",
    "authors": [
      "Ghaith Rabadi",
      "Sean Mondesire",
      "Bulent Soykan"
    ],
    "stars": "4",
    "details": {
      "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
      "abstract": "Simulation optimization (SO) is frequently challenged by noisy evaluations, high computational costs, and complex, multimodal search landscapes. This paper introduces Tabu-Enhanced Simulation Optimization (TESO), a novel metaheuristic framework integrating adaptive search with memory-based strategies. TESO leverages a short-term Tabu List to prevent cycling and encourage diversification, and a long-term Elite Memory to guide intensification by perturbing high-performing solutions. An aspiration criterion allows overriding tabu restrictions for exceptional candidates. This combination facilitates a dynamic balance between exploration and exploitation in stochastic environments. We demonstrate TESO‚Äôs effectiveness and reliability using an queue optimization problem, showing improved performance compared to benchmarks and validating the contribution of its memory components. Source code and data are available at: github.com/bulentsoykan/TESO.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24007",
      "pdf_url": "https://arxiv.org/pdf/2512.24007",
      "github_links": [
        "https://github.com/bulentsoykan/TESO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24007",
      "scraped_at": "2026-01-04T02:00:02.005832"
    },
    "scraped_date": "2026-01-04"
  }
]