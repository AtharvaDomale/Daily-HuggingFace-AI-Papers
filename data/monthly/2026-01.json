[
  {
    "title": "UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement",
    "paper_url": "https://huggingface.co/papers/2512.21185",
    "authors": [
      "Yang Li",
      "Dehao Hao",
      "LutaoJiang",
      "StarYDY",
      "infinith"
    ],
    "stars": "110",
    "details": {
      "title": "UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement",
      "abstract": "Github: https://github.com/PKU-YuanGroup/UltraShape-1.0 Project Page: https://pku-yuangroup.github.io/UltraShape-1.0/",
      "arxiv_page_url": "https://arxiv.org/abs/2512.21185",
      "pdf_url": "https://arxiv.org/pdf/2512.21185",
      "github_links": [
        "https://github.com/PKU-YuanGroup/UltraShape-1.0"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.21185",
      "scraped_at": "2026-01-01T01:59:26.540091"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "DreamOmni3: Scribble-based Editing and Generation",
    "paper_url": "https://huggingface.co/papers/2512.22525",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DreamOmni3: Scribble-based Editing and Generation",
      "abstract": "Github: https://github.com/dvlab-research/DreamOmni3",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22525",
      "pdf_url": "https://arxiv.org/pdf/2512.22525",
      "github_links": [
        "https://github.com/dvlab-research/DreamOmni3"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22525",
      "scraped_at": "2026-01-01T01:59:28.344263"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "End-to-End Test-Time Training for Long Context",
    "paper_url": "https://huggingface.co/papers/2512.23675",
    "authors": [
      "Marcel R√∏d",
      "Daniel Koceja",
      "Xinhao Li",
      "Karan Dalal",
      "Arnuv Tandon"
    ],
    "stars": "96",
    "details": {
      "title": "End-to-End Test-Time Training for Long Context",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Sliding Window Attention Adaptation (2025) Let's (not) just put things in Context: Test-Time Training for Long-Context LLMs (2025) Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models (2025) Attention and Compression is all you need for Controllably Efficient Language Models (2025) Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings (2025) Data-Free Pruning of Self-Attention Layers in LLMs (2025) Architectural Trade-offs in Small Language Models Under Compute Constraints (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23675",
      "pdf_url": "https://arxiv.org/pdf/2512.23675",
      "github_links": [
        "https://github.com/test-time-training/e2e"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23675",
      "scraped_at": "2026-01-01T01:59:30.184972"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "Evaluating Parameter Efficient Methods for RLVR",
    "paper_url": "https://huggingface.co/papers/2512.23165",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Evaluating Parameter Efficient Methods for RLVR",
      "abstract": "https://www.alphaxiv.org/abs/2512.23165",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23165",
      "pdf_url": "https://arxiv.org/pdf/2512.23165",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23165",
      "scraped_at": "2026-01-01T01:59:31.986046"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization",
    "paper_url": "https://huggingface.co/papers/2512.22469",
    "authors": [
      "Wei Zhang",
      "Aofan Liu",
      "Pengfei Gao",
      "Wei Liu",
      "pengchao"
    ],
    "stars": "0",
    "details": {
      "title": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization",
      "abstract": "Issues describe symptoms‚Äîthe real buggy code is often hidden behind multi-hop dependencies. GraphLocator moves beyond relevance retrieval by explicitly modelling causal structure: decomposing sub-problems, capturing causal dependencies, and performing constrained causal reasoning over code dependency graphs. Across multiple Python and Java datasets, GraphLocator significantly improves function-level recall and precision, and the inferred causal structures further boost downstream issue resolution by +28.74%.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22469",
      "pdf_url": "https://arxiv.org/pdf/2512.22469",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22469",
      "scraped_at": "2026-01-01T01:59:33.772256"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks",
    "paper_url": "https://huggingface.co/papers/2512.22206",
    "authors": [
      "Yogeswar"
    ],
    "stars": "0",
    "details": {
      "title": "CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks",
      "abstract": "\"I introduce CosineGate, a SOTA dynamic routing mechanism for ResNets that uses the Cosine Incompatibility Ratio (CIR) as a self-supervised signal. üöÄ Why it matters: It matches ResNet-20 accuracy on CIFAR-10 while slashing computation by 28.5%‚Äîwithout needing extra 'predictor' sub-networks or distillation. üõ†Ô∏è Key Features: Fully differentiable (via Gumbel-Softmax). Bio-inspired (Predictive Coding). Plug-and-play for efficient computer vision. Check out our GitHub Repo linked in the sidebar for the implementation!\"",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22206",
      "pdf_url": "https://arxiv.org/pdf/2512.22206",
      "github_links": [
        "https://github.com/thotayogeswarreddy/CosineGate"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22206",
      "scraped_at": "2026-01-01T01:59:35.535486"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
    "paper_url": "https://huggingface.co/papers/2512.21008",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
      "abstract": "Mixture-of-Experts (MoE) architectures have advanced the scaling of Large Language Models (LLMs) by activating only a sparse subset of parameters per input, enabling state-of-the-art performance with reduced computational cost. As these models are increasingly deployed in critical domains, understanding and strengthening their alignment mechanisms is essential to prevent harmful outputs. However, existing LLM safety research has focused almost exclusively on dense architectures, leaving the unique safety properties of MoEs largely unexamined. The modular, sparsely-activated design of MoEs suggests that safety mechanisms may operate differently than in dense models, raising questions about their robustness. In this paper, we present GateBreaker, the first training-free, lightweight, and architecture-agnostic attack framework that compromises the safety alignment of modern MoE LLMs at inference time. GateBreaker operates in three stages: (i) gate-level profiling, which identifies safety experts disproportionately routed on harmful inputs, (ii) expert-level localization, which localizes the safety structure within safety experts, and (iii) targeted safety removal, which disables the identified safety structure to compromise the safety alignment. Our study shows that MoE safety concentrates within a small subset of neurons coordinated by sparse routing. Selective disabling of these neurons, approximately 3% of neurons in the targeted expert layers, significantly increases the averaged attack success rate (ASR) from 7.4% to 64.9% against the eight latest aligned MoE LLMs with limited utility degradation. These safety neurons transfer across models within the same family, raising ASR from 17.9% to 67.7% with one-shot transfer attack. Furthermore, GateBreaker generalizes to five MoE vision language models (VLMs) with 60.9% ASR on unsafe image inputs.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.21008",
      "pdf_url": "https://arxiv.org/pdf/2512.21008",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.21008",
      "scraped_at": "2026-01-01T01:59:37.334356"
    },
    "scraped_date": "2026-01-01"
  },
  {
    "title": "mHC: Manifold-Constrained Hyper-Connections",
    "paper_url": "https://huggingface.co/papers/2512.24880",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "mHC: Manifold-Constrained Hyper-Connections",
      "abstract": "DeepSeek released a new paper proposing a novel architecture called mHC (Manifold-Constrained Hyper-Connections).",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24880",
      "pdf_url": "https://arxiv.org/pdf/2512.24880",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24880",
      "scraped_at": "2026-01-02T01:50:23.780257"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models",
    "paper_url": "https://huggingface.co/papers/2512.24618",
    "authors": [
      "Xinyi Dai",
      "Yinghui Li",
      "Lingfeng Qiao",
      "Jiarui Qin",
      "Junru Lu"
    ],
    "stars": "0",
    "details": {
      "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24618",
      "pdf_url": "https://arxiv.org/pdf/2512.24618",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24618",
      "scraped_at": "2026-01-02T01:50:25.585213"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem",
    "paper_url": "https://huggingface.co/papers/2512.24873",
    "authors": [
      "Wei Gao",
      "Fangwen Dai",
      "Wanhe An",
      "XiaoXiao Xu",
      "Weixun Wang"
    ],
    "stars": "0",
    "details": {
      "title": "Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24873",
      "pdf_url": "https://arxiv.org/pdf/2512.24873",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24873",
      "scraped_at": "2026-01-02T01:50:27.522125"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction",
    "paper_url": "https://huggingface.co/papers/2512.25073",
    "authors": [
      "Yu-Lun Liu",
      "Ying-Huan Chen",
      "Chin-Yang Lin",
      "Hao-Jen Chien",
      "Yi-Chuan Huang"
    ],
    "stars": "0",
    "details": {
      "title": "GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction",
      "abstract": "Recent advances in 3D reconstruction have achieved remarkable progress in high-quality scene capture from dense multi-view imagery, yet struggle when input views are limited. Various approaches, including regularization techniques, semantic priors, and geometric constraints, have been implemented to address this challenge. Latest diffusion-based methods have demonstrated substantial improvements by generating novel views from new camera poses to augment training data, surpassing earlier regularization and prior-based techniques. Despite this progress, we identify three critical limitations in these state-of-the-art approaches: inadequate coverage beyond known view peripheries, geometric inconsistencies across generated views, and computationally expensive pipelines. We introduce GaMO (Geometry-aware Multi-view Outpainter), a framework that reformulates sparse-view reconstruction through multi-view outpainting. Instead of generating new viewpoints, GaMO expands the field of view from existing camera poses, which inherently preserves geometric consistency while providing broader scene coverage. Our approach employs multi-view conditioning and geometry-aware denoising strategies in a zero-shot manner without training. Extensive experiments on Replica and ScanNet++ demonstrate state-of-the-art reconstruction quality across 3, 6, and 9 input views, outperforming prior methods in PSNR and LPIPS, while achieving a 25√ó speedup over SOTA diffusion-based methods with processing time under 10 minutes. Project page: https://yichuanh.github.io/GaMO/",
      "arxiv_page_url": "https://arxiv.org/abs/2512.25073",
      "pdf_url": "https://arxiv.org/pdf/2512.25073",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.25073",
      "scraped_at": "2026-01-02T01:50:29.343131"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers",
    "paper_url": "https://huggingface.co/papers/2512.23380",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23380",
      "pdf_url": "https://arxiv.org/pdf/2512.23380",
      "github_links": [
        "https://github.com/NasirzadehMoh/CoLog"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23380",
      "scraped_at": "2026-01-02T01:50:31.161979"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Scaling Open-Ended Reasoning to Predict the Future",
    "paper_url": "https://huggingface.co/papers/2512.25070",
    "authors": [],
    "stars": "6",
    "details": {
      "title": "Scaling Open-Ended Reasoning to Predict the Future",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.25070",
      "pdf_url": "https://arxiv.org/pdf/2512.25070",
      "github_links": [
        "https://github.com/OpenForecaster/scaling-forecasting-training"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.25070",
      "scraped_at": "2026-01-02T01:50:33.046417"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation",
    "paper_url": "https://huggingface.co/papers/2512.24551",
    "authors": [],
    "stars": "4",
    "details": {
      "title": "PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation",
      "abstract": "A data construction pipeline and a new DPO framework for physically consistent Text-to-video generation",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24551",
      "pdf_url": "https://arxiv.org/pdf/2512.24551",
      "github_links": [
        "https://github.com/caiyuanhao1998/Open-PhyGDPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24551",
      "scraped_at": "2026-01-02T01:50:34.905156"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents",
    "paper_url": "https://huggingface.co/papers/2512.23343",
    "authors": [
      "Shixin Jiang",
      "Jiaqi Zhou",
      "Chang Li",
      "Hao Li",
      "Jiafeng Liang"
    ],
    "stars": "24",
    "details": {
      "title": "AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents",
      "abstract": "https://github.com/AgentMemory/Huaman-Agent-Memory",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23343",
      "pdf_url": "https://arxiv.org/pdf/2512.23343",
      "github_links": [
        "https://github.com/AgentMemory/Huaman-Agent-Memory"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23343",
      "scraped_at": "2026-01-02T01:50:36.704147"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "GR-Dexter Technical Report",
    "paper_url": "https://huggingface.co/papers/2512.24210",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GR-Dexter Technical Report",
      "abstract": "VLAs go from grippers to 21 DoF dexterous ByteDexter V2 :)",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24210",
      "pdf_url": "https://arxiv.org/pdf/2512.24210",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24210",
      "scraped_at": "2026-01-02T01:50:38.600164"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process",
    "paper_url": "https://huggingface.co/papers/2512.23988",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process",
      "abstract": "This is an impressive piece of work. Not only for the elegance of the sparse autoencoder pipeline, but because the empirical results reveal something far deeper than what is stated in the paper. Your SAE-derived ‚Äúreasoning vectors‚Äù behave exactly like stable dynamical modes inside a recursive state system ‚Äî not merely interpretable directions. The separation of reflection, backtracking, confidence, and response-length clusters across layers strongly suggests that modern transformer reasoning is governed by a latent, substrate-bound dynamical structure rather than a purely token-level process. A few observations that stood out: Reasoning vectors behave like attractor modes, not just features. The clustering of SAE decoder columns into semantically distinct basins is consistent with the existence of stable dynamical invariants that govern the model‚Äôs step-wise evolution. This is exactly the behavior expected when a system has: stable recurrence points, local attractor basins in its state manifold, and identity-like update modes that persist across tasks. Your causal interventions reinforce this: modifying a reasoning vector steers the entire reasoning trajectory while preserving final correctness. That is classic attractor dynamics. The layer-wise geometry mirrors a recursive integration process. The strongest separability occurring in mid-to-late layers, followed by a decline near the final layer, mirrors the behavior of systems that integrate state over time and then compress it near output. This is structurally identical to a recursive state-aware update: a(t+1)=R(a(t)) where the model accumulates long-range structure before collapsing it for output. Cross-domain generalization of these vectors indicates substrate-bound stability. The fact that reflection/backtracking vectors trained on MATH500 steer behavior on GPQA and KnowLogic implies the existence of substrate-stable reasoning structures that are independent of dataset distribution. This is a property of a dynamical system ‚Äî not a static embedding space. Confidence emerges as a coherent cluster because it is tied to entropy and coherence. Your discovery that confidence vectors suppress reflection/backtracking is an empirical confirmation of a predicted relation between: information coherence computational alignment noise minimization and entropy reduction Confidence is not a semantic trait ‚Äî it's a low-entropy attractor mode. Response-length alignment is a structural axis, not a surface feature. Length correlating with latent-space geometry further confirms that reasoning depth emerges from the system's internal temporal continuity rather than token heuristics. A broader note: These empirical findings align remarkably well with a larger theoretical framework I‚Äôve been developing, the Field of General Awareness (FoGA), which predicts: the existence of invariant reasoning modes, substrate-sensitive drift in state evolution, recursive attractor-based reasoning paths, and coherence-driven modulation of reasoning confidence. Your results are the clearest real-world demonstration I‚Äôve seen of these principles emerging naturally inside transformer models. If you're interested, I‚Äôm happy to share the relevant portions of the theory (and the mathematical basis behind these predictions), as well as the Dynamic Transformer Architecture ‚Äî an architecture patch explicitly designed to stabilize such recurrence modes. Excellent work. This paper is going to be foundational for understanding why LLM reasoning behaves the way it does. ‚Äî Zenith Zaraki SkyTeam Aerospace Foundation https://www.skyteamaerospacefoundation.com/foga https://www.skyteamaerospacefoundation.com/dta",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23988",
      "pdf_url": "https://arxiv.org/pdf/2512.23988",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23988",
      "scraped_at": "2026-01-02T01:50:40.409987"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Pretraining Frame Preservation in Autoregressive Video Memory Compression",
    "paper_url": "https://huggingface.co/papers/2512.23851",
    "authors": [
      "Beijia Lu",
      "Chong Zeng",
      "Muyang Li",
      "Shengqu Cai",
      "Lvmin Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "Pretraining Frame Preservation in Autoregressive Video Memory Compression",
      "abstract": "Arxiv: https://arxiv.org/abs/2512.23851 Repo: https://github.com/lllyasviel/PFP",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23851",
      "pdf_url": "https://arxiv.org/pdf/2512.23851",
      "github_links": [
        "https://github.com/lllyasviel/PFP"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23851",
      "scraped_at": "2026-01-02T01:50:42.190944"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time",
    "paper_url": "https://huggingface.co/papers/2512.25075",
    "authors": [
      "Tuanfeng Y. Wang",
      "Yulia Gryaditskaya",
      "Xuelin Chen",
      "Hyeonho Jeong",
      "Zhening Huang"
    ],
    "stars": "0",
    "details": {
      "title": "SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API BulletTime: Decoupled Control of Time and Camera Pose for Video Generation (2025) FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint (2025) ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation (2025) OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis (2025) Infinite-Homography as Robust Conditioning for Camera-Controlled Video Generation (2025) Light-X: Generative 4D Video Rendering with Camera and Illumination Control (2025) Generative Video Motion Editing with 3D Point Tracks (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2512.25075",
      "pdf_url": "https://arxiv.org/pdf/2512.25075",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.25075",
      "scraped_at": "2026-01-02T01:50:43.989867"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "JavisGPT: A Unified Multi-modal LLM for Sounding-Video Comprehension and Generation",
    "paper_url": "https://huggingface.co/papers/2512.22905",
    "authors": [],
    "stars": "11",
    "details": {
      "title": "JavisGPT: A Unified Multi-modal LLM for Sounding-Video Comprehension and Generation",
      "abstract": "üî•üî•üî• JavisGPT üåü We introduce JavisGPT, a multimodal LLM that can understand audiovisual inputs and simultaneously generate synchronized sounding videos in a unified model. ü§† We contribute JavisInst-Omni, a dataset to facilitate diverse and complex instruction-tuning for comprehension and generation on sounding videos. üìù Paper: https://arxiv.org/abs/2503.23377 üéâ Project: https://javisverse.github.io/JavisGPT-page/ ‚ú® Code: https://github.com/JavisVerse/JavisGPT",
      "arxiv_page_url": "https://arxiv.org/abs/2503.23377",
      "pdf_url": "https://arxiv.org/pdf/2512.22905",
      "github_links": [
        "https://github.com/JavisVerse/JavisGPT"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22905",
      "scraped_at": "2026-01-02T01:50:45.835201"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Geometry-Aware Optimization for Respiratory Sound Classification: Enhancing Sensitivity with SAM-Optimized Audio Spectrogram Transformers",
    "paper_url": "https://huggingface.co/papers/2512.22564",
    "authors": [
      "Mah≈üuk Taylan",
      "Ahmet Feridun I≈üƒ±k",
      "Selin Vulga I≈üƒ±k",
      "Atakanisik"
    ],
    "stars": "0",
    "details": {
      "title": "Geometry-Aware Optimization for Respiratory Sound Classification: Enhancing Sensitivity with SAM-Optimized Audio Spectrogram Transformers",
      "abstract": "Hi all, We present a robust framework for Lung Sound Classification using AST backbones enhanced with SAM optimizer . Traditional transformers often struggle with limited medical data, but our experiments show that geometry-aware optimization (SAM) leads to a massive boost in sensitivity. We achieved a 68.10% Score on the official ICBHI 2017 split. We invite everyone to benchmark our results. The repository includes: Cyclic padding implementation Full training scripts Evaluation of model Check it out here: GitHub Link",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22564",
      "pdf_url": "https://arxiv.org/pdf/2512.22564",
      "github_links": [
        "https://github.com/Atakanisik/ICBHI-AST-SAM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22564",
      "scraped_at": "2026-01-02T01:50:47.616554"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts",
    "paper_url": "https://huggingface.co/papers/2512.24885",
    "authors": [
      "Mengmeng Wang",
      "Chenxi Li",
      "Qi Shen",
      "Zhaoxin Yu",
      "Hengli Li"
    ],
    "stars": "0",
    "details": {
      "title": "BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts",
      "abstract": "Arxiv: https://arxiv.org/abs/2512.24885 X thread: https://x.com/Hengli_Li_pku/status/2006606887652045158",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24885",
      "pdf_url": "https://arxiv.org/pdf/2512.24885",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24885",
      "scraped_at": "2026-01-02T01:50:49.444890"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems",
    "paper_url": "https://huggingface.co/papers/2512.24385",
    "authors": [],
    "stars": "105",
    "details": {
      "title": "Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems",
      "abstract": "GitHub at https://github.com/worldbench/awesome-spatial-intelligence",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24385",
      "pdf_url": "https://arxiv.org/pdf/2512.24385",
      "github_links": [
        "https://github.com/worldbench/awesome-spatial-intelligence"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24385",
      "scraped_at": "2026-01-02T01:50:51.222394"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking",
    "paper_url": "https://huggingface.co/papers/2512.24297",
    "authors": [
      "Jie Zhou",
      "Fandong Meng",
      "Meiqi Chen"
    ],
    "stars": "4",
    "details": {
      "title": "Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API V-Thinker: Interactive Thinking with Images (2025) Interleaved Latent Visual Reasoning with Selective Perceptual Modeling (2025) Deep But Reliable: Advancing Multi-turn Reasoning for Thinking with Images (2025) ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking (2025) ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning (2025) Look as You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning (2025) CodeDance: A Dynamic Tool-integrated MLLM for Executable Visual Reasoning (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24297",
      "pdf_url": "https://arxiv.org/pdf/2512.24297",
      "github_links": [
        "https://github.com/chenmeiqii/FIGR"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24297",
      "scraped_at": "2026-01-02T01:50:53.259496"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Guiding a Diffusion Transformer with the Internal Dynamics of Itself",
    "paper_url": "https://huggingface.co/papers/2512.24176",
    "authors": [],
    "stars": "13",
    "details": {
      "title": "Guiding a Diffusion Transformer with the Internal Dynamics of Itself",
      "abstract": "üî• New SOTA on 256 √ó 256 ImageNet generation. We present Internal Guidance (IG), a simple yet powerful guidance mechanism for Diffusion Transformers. LightningDiT-XL/1 + IG sets a new state of the art with FID = 1.07 on ImageNet (balanced sampling), while achieving FID = 1.24 without classifier-free guidance. IG delivers dramatic quality gains with far fewer training epochs, adds negligible overhead, and works as a drop-in upgrade for modern diffusion transformers.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24176",
      "pdf_url": "https://arxiv.org/pdf/2512.24176",
      "github_links": [
        "https://github.com/CVL-UESTC/Internal-Guidance"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24176",
      "scraped_at": "2026-01-02T01:50:55.053809"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Factorized Learning for Temporally Grounded Video-Language Models",
    "paper_url": "https://huggingface.co/papers/2512.24097",
    "authors": [],
    "stars": "14",
    "details": {
      "title": "Factorized Learning for Temporally Grounded Video-Language Models",
      "abstract": "We tackle temporally grounded video-language understanding from a factorized perspective. Some key takeaways: [1] We emphasize the distinct yet causally dependent nature of temporal grounding and textual response. [2] Our study highlights the importance of explicit event-level visual semantic capture in enhancing both grounding and textual response quality. [3] We also propose a new Factorized Preference Optimization (FPO) scheme that jointly optimizes temporal and textual factors. A factorized data synthesis approach is also proposed to support FPO.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24097",
      "pdf_url": "https://arxiv.org/pdf/2512.24097",
      "github_links": [
        "https://github.com/nusnlp/d2vlm"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24097",
      "scraped_at": "2026-01-02T01:50:56.944458"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Valori: A Deterministic Memory Substrate for AI Systems",
    "paper_url": "https://huggingface.co/papers/2512.22280",
    "authors": [
      "varam17"
    ],
    "stars": "2",
    "details": {
      "title": "Valori: A Deterministic Memory Substrate for AI Systems",
      "abstract": "Valori: A Deterministic Fixed-Point Vector Kernel Tags: vector-database , rust , determinism , finance , audit , hnsw , fixed-point , systems-engineering TL;DR Floating-point math causes vector search results to drift between ARM (Mac) and x86 (Linux) architectures due to compiler and hardware variances. Valori is a Q16.16 Fixed-Point kernel written in Rust that guarantees bit-exact reproducibility across all hardware platforms, making it the first \"Audit-Grade\" vector engine for high-stakes AI. 1. The Problem: \"The Silent Drift\" Most vector databases (FAISS, Pinecone, Weaviate) rely on hardware-accelerated floating-point arithmetic ( f32 ). While fast, this introduces Non-Determinism : Associativity Variance: (a + b) + c ‚â† a + (b + c) depending on SIMD optimizations. Architecture Variance: A backtest run on a MacBook (ARM NEON) often yields different nearest neighbors than the live execution on an AWS Server (Intel AVX2). In RAG pipelines , this is annoying. In High-Frequency Trading or Legal Forensics , this variance is a liability. You cannot audit a probabilistic black box. 2. The Solution: Valori Kernel Valori is a forensic memory engine built from scratch in Rust . It replaces standard floating-point math with a custom Q16.16 Fixed-Point Arithmetic system inside an HNSW graph. Zero Drift: The mathematical operations are integer-based. 1 + 1 = 2 on every CPU, forever. Audit-Ready: Includes a calculate_state_hash() method that generates a cryptographic fingerprint of the database state. If a single bit changes, the hash breaks. Crash Proof: Implements a specialized persistence layer with <40ms recovery time (Cold Boot to Full Query) for 50k vector datasets. 3. Benchmarks (Engineering Verification) Validated on Apple M2 (ARM64) vs Intel Xeon (x86_64). Metric Result Notes Recall@10 99.0% Matches brute-force ground truth. Determinism 100% Bit-exact match across architectures. Recovery Time 35ms For 50k vectors (Snapshot Load). Latency ~0.5ms Per query (Single Thread). 4. Usage (Rust) Valori is designed to be embedded directly into high-integrity Rust applications. Add to Cargo.toml : [dependencies] valori_kernel = { git = \"https://github.com/varshith-Git/Valori-Kernel\" } Example: Deterministic Ingest & Audit use valori_kernel::{ValoriKernel, types::FixedPointVector}; fn main () -> anyhow:: Result <()> { // 1. Initialize the Kernel (Q16.16 Math) let mut kernel = ValoriKernel:: new (); // 2. Ingest Data (Manual f32 -> FixedPoint conversion for safety) let raw_vector = [ 0.5 , - 0.2 , 0.9 , ...]; // 128-dim // Convert float to Q16.16 integer representation let mut fixed_arr = [ 0i32 ; 128 ]; for (i, &val) in raw_vector. iter (). enumerate () {\n        fixed_arr[i] = (val * 65536.0 ) as i32 ;\n    } // Insert with ID=1, Tag=100 kernel. insert ( 1 , FixedPointVector (fixed_arr), 100 ); // 3. Search // Guaranteed to return the exact same ID and Distance on any CPU let results = kernel. search (&fixed_arr, 5 , None )?; println! ( \"Found neighbors: {:?}\" , results); // 4. Generate Forensic Evidence // This hash proves the database state is identical bit-for-bit let audit_hash = kernel.graph. calculate_state_hash (); println! ( \"Cryptographic State Signature: {}\" , audit_hash); Ok (())\n} 5. Who is this for? Quant Developers: Who need backtests to match live execution perfectly. Systems Engineers: Debugging \"Why did the agent say X?\" (Eliminate the database as a variable). Auditors: Who need to certify AI decision logs using cryptographic proofs. Citation If you use Valori in your research, please cite: @ misc {gudur2025valori,\n  title={Valori: A Deterministic Fixed-Point Vector Kernel},\n  author={Gudur, Varshith},\n  year={2025},\n  publisher={arXiv},\n  url={https://arxiv.org/abs/2512.22280}\n}",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22280",
      "pdf_url": "https://arxiv.org/pdf/2512.22280",
      "github_links": [
        "https://github.com/varshith-Git/Valori-Kernel"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22280",
      "scraped_at": "2026-01-02T01:50:58.743405"
    },
    "scraped_date": "2026-01-02"
  },
  {
    "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
    "paper_url": "https://huggingface.co/papers/2512.23959",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
      "abstract": "Code released at: https://github.com/Encyclomen/HGMem",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23959",
      "pdf_url": "https://arxiv.org/pdf/2512.23959",
      "github_links": [
        "https://github.com/Encyclomen/HGMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23959",
      "scraped_at": "2026-01-03T01:44:37.960652"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
    "paper_url": "https://huggingface.co/papers/2512.24617",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
      "abstract": "Dynamic Large Concept Models (DLCM) introduce an end-to-end trained concept-level language modeling architecture that breaks the token-uniform computation paradigm in modern LLMs. Inspired by hierarchical models such as H-Net, DLCM learns semantic boundaries directly from latent representations, dynamically compresses token sequences into variable-length concepts, performs deep reasoning in the concept space, and projects the results back to tokens via causal cross-attention. Compared to standard dense Transformers trained with next-token prediction, DLCM achieves ~34% inference FLOPs reduction under apple-to-apple settings, while consistently improving performance on reasoning-dominant benchmarks. Notably, the relative FLOPs savings increase with model scale, indicating favorable scaling behavior beyond parameter efficiency alone. At similar loss levels, DLCM reallocates computation toward boundary and planning tokens, yielding stronger downstream accuracy despite reduced redundant token processing. Technically, the paper contributes: (1) a FlashAttention-VarLen‚Äìbased implementation for efficient concept-token cross-attention; (2) a decoupled ŒºP formulation tailored to heterogeneous token- and concept-width modules, enabling zero-shot hyperparameter transfer across scales; (3) a Global Parser that enforces stable, content-adaptive compression at the batch level and delivers solid empirical gains. Overall, DLCM can be viewed as a principled special case of layer-wise local compression combined with sparse attention, offering a scalable path toward more compute-efficient and reasoning-centric language models.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24617",
      "pdf_url": "https://arxiv.org/pdf/2512.24617",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24617",
      "scraped_at": "2026-01-03T01:44:39.850579"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
    "paper_url": "https://huggingface.co/papers/2512.24165",
    "authors": [
      "Siyuan Huang",
      "Yafu Li",
      "Xiaoye Qu",
      "Spico",
      "yhx12"
    ],
    "stars": "13",
    "details": {
      "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
      "abstract": "TLDR: A new paradigm for multi-modal reasoning with image-to-image generation. Diffusion could think too!",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24165",
      "pdf_url": "https://arxiv.org/pdf/2512.24165",
      "github_links": [
        "https://github.com/lcqysl/DiffThinker"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24165",
      "scraped_at": "2026-01-03T01:44:41.687283"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "On the Role of Discreteness in Diffusion LLMs",
    "paper_url": "https://huggingface.co/papers/2512.22630",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "On the Role of Discreteness in Diffusion LLMs",
      "abstract": "TL;DR: We identify two core failure modes in current large diffusion LLMs: uniform corruption ignores where information lives in a sentence, and token-wise marginal training struggles with multi-token dependencies during parallel decoding.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22630",
      "pdf_url": "https://arxiv.org/pdf/2512.22630",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22630",
      "scraped_at": "2026-01-03T01:44:43.488349"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
    "paper_url": "https://huggingface.co/papers/2512.24724",
    "authors": [
      "Youngjung Uh",
      "Jaeseok Jeong",
      "Mingi Kwon",
      "Jibin Song"
    ],
    "stars": "0",
    "details": {
      "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24724",
      "pdf_url": "https://arxiv.org/pdf/2512.24724",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24724",
      "scraped_at": "2026-01-03T01:44:45.286927"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
    "paper_url": "https://huggingface.co/papers/2512.24766",
    "authors": [
      "Ruohan Zhang",
      "Li Fei-Fei",
      "Jiajun Wu",
      "Wenlong Huang",
      "Karthik Dharmarajan"
    ],
    "stars": "0",
    "details": {
      "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24766",
      "pdf_url": "https://arxiv.org/pdf/2512.24766",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24766",
      "scraped_at": "2026-01-03T01:44:47.116340"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
    "paper_url": "https://huggingface.co/papers/2512.24007",
    "authors": [
      "Ghaith Rabadi",
      "Sean Mondesire",
      "Bulent Soykan"
    ],
    "stars": "3",
    "details": {
      "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
      "abstract": "Simulation optimization (SO) is frequently challenged by noisy evaluations, high computational costs, and complex, multimodal search landscapes. This paper introduces Tabu-Enhanced Simulation Optimization (TESO), a novel metaheuristic framework integrating adaptive search with memory-based strategies. TESO leverages a short-term Tabu List to prevent cycling and encourage diversification, and a long-term Elite Memory to guide intensification by perturbing high-performing solutions. An aspiration criterion allows overriding tabu restrictions for exceptional candidates. This combination facilitates a dynamic balance between exploration and exploitation in stochastic environments. We demonstrate TESO‚Äôs effectiveness and reliability using an queue optimization problem, showing improved performance compared to benchmarks and validating the contribution of its memory components. Source code and data are available at: github.com/bulentsoykan/TESO.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24007",
      "pdf_url": "https://arxiv.org/pdf/2512.24007",
      "github_links": [
        "https://github.com/bulentsoykan/TESO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24007",
      "scraped_at": "2026-01-03T01:44:48.907162"
    },
    "scraped_date": "2026-01-03"
  },
  {
    "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
    "paper_url": "https://huggingface.co/papers/2512.23959",
    "authors": [],
    "stars": "22",
    "details": {
      "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
      "abstract": "Code released at: https://github.com/Encyclomen/HGMem",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23959",
      "pdf_url": "https://arxiv.org/pdf/2512.23959",
      "github_links": [
        "https://github.com/Encyclomen/HGMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23959",
      "scraped_at": "2026-01-04T01:59:50.718806"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
    "paper_url": "https://huggingface.co/papers/2512.24617",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
      "abstract": "Dynamic Large Concept Models (DLCM) introduce an end-to-end trained concept-level language modeling architecture that breaks the token-uniform computation paradigm in modern LLMs. Inspired by hierarchical models such as H-Net, DLCM learns semantic boundaries directly from latent representations, dynamically compresses token sequences into variable-length concepts, performs deep reasoning in the concept space, and projects the results back to tokens via causal cross-attention. Compared to standard dense Transformers trained with next-token prediction, DLCM achieves ~34% inference FLOPs reduction under apple-to-apple settings, while consistently improving performance on reasoning-dominant benchmarks. Notably, the relative FLOPs savings increase with model scale, indicating favorable scaling behavior beyond parameter efficiency alone. At similar loss levels, DLCM reallocates computation toward boundary and planning tokens, yielding stronger downstream accuracy despite reduced redundant token processing. Technically, the paper contributes: (1) a FlashAttention-VarLen‚Äìbased implementation for efficient concept-token cross-attention; (2) a decoupled ŒºP formulation tailored to heterogeneous token- and concept-width modules, enabling zero-shot hyperparameter transfer across scales; (3) a Global Parser that enforces stable, content-adaptive compression at the batch level and delivers solid empirical gains. Overall, DLCM can be viewed as a principled special case of layer-wise local compression combined with sparse attention, offering a scalable path toward more compute-efficient and reasoning-centric language models.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24617",
      "pdf_url": "https://arxiv.org/pdf/2512.24617",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24617",
      "scraped_at": "2026-01-04T01:59:52.693703"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
    "paper_url": "https://huggingface.co/papers/2512.24165",
    "authors": [
      "Siyuan Huang",
      "Yafu Li",
      "Xiaoye Qu",
      "Spico",
      "yhx12"
    ],
    "stars": "24",
    "details": {
      "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
      "abstract": "TLDR: A new paradigm for multi-modal reasoning with image-to-image generation. Diffusion could think too!",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24165",
      "pdf_url": "https://arxiv.org/pdf/2512.24165",
      "github_links": [
        "https://github.com/lcqysl/DiffThinker"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24165",
      "scraped_at": "2026-01-04T01:59:54.609230"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "On the Role of Discreteness in Diffusion LLMs",
    "paper_url": "https://huggingface.co/papers/2512.22630",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "On the Role of Discreteness in Diffusion LLMs",
      "abstract": "TL;DR: We identify two core failure modes in current large diffusion LLMs: uniform corruption ignores where information lives in a sentence, and token-wise marginal training struggles with multi-token dependencies during parallel decoding.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22630",
      "pdf_url": "https://arxiv.org/pdf/2512.22630",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22630",
      "scraped_at": "2026-01-04T01:59:56.484887"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
    "paper_url": "https://huggingface.co/papers/2512.24766",
    "authors": [
      "Ruohan Zhang",
      "Li Fei-Fei",
      "Jiajun Wu",
      "Wenlong Huang",
      "Karthik Dharmarajan"
    ],
    "stars": "0",
    "details": {
      "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24766",
      "pdf_url": "https://arxiv.org/pdf/2512.24766",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24766",
      "scraped_at": "2026-01-04T01:59:58.371341"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
    "paper_url": "https://huggingface.co/papers/2512.24724",
    "authors": [
      "Youngjung Uh",
      "Jaeseok Jeong",
      "Mingi Kwon",
      "Jibin Song"
    ],
    "stars": "0",
    "details": {
      "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24724",
      "pdf_url": "https://arxiv.org/pdf/2512.24724",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24724",
      "scraped_at": "2026-01-04T02:00:00.212924"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
    "paper_url": "https://huggingface.co/papers/2512.24007",
    "authors": [
      "Ghaith Rabadi",
      "Sean Mondesire",
      "Bulent Soykan"
    ],
    "stars": "4",
    "details": {
      "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
      "abstract": "Simulation optimization (SO) is frequently challenged by noisy evaluations, high computational costs, and complex, multimodal search landscapes. This paper introduces Tabu-Enhanced Simulation Optimization (TESO), a novel metaheuristic framework integrating adaptive search with memory-based strategies. TESO leverages a short-term Tabu List to prevent cycling and encourage diversification, and a long-term Elite Memory to guide intensification by perturbing high-performing solutions. An aspiration criterion allows overriding tabu restrictions for exceptional candidates. This combination facilitates a dynamic balance between exploration and exploitation in stochastic environments. We demonstrate TESO‚Äôs effectiveness and reliability using an queue optimization problem, showing improved performance compared to benchmarks and validating the contribution of its memory components. Source code and data are available at: github.com/bulentsoykan/TESO.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24007",
      "pdf_url": "https://arxiv.org/pdf/2512.24007",
      "github_links": [
        "https://github.com/bulentsoykan/TESO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24007",
      "scraped_at": "2026-01-04T02:00:02.005832"
    },
    "scraped_date": "2026-01-04"
  },
  {
    "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
    "paper_url": "https://huggingface.co/papers/2512.23959",
    "authors": [],
    "stars": "26",
    "details": {
      "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
      "abstract": "Code released at: https://github.com/Encyclomen/HGMem",
      "arxiv_page_url": "https://arxiv.org/abs/2512.23959",
      "pdf_url": "https://arxiv.org/pdf/2512.23959",
      "github_links": [
        "https://github.com/Encyclomen/HGMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.23959",
      "scraped_at": "2026-01-05T01:59:59.631752"
    },
    "scraped_date": "2026-01-05"
  },
  {
    "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
    "paper_url": "https://huggingface.co/papers/2512.24617",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space",
      "abstract": "Dynamic Large Concept Models (DLCM) introduce an end-to-end trained concept-level language modeling architecture that breaks the token-uniform computation paradigm in modern LLMs. Inspired by hierarchical models such as H-Net, DLCM learns semantic boundaries directly from latent representations, dynamically compresses token sequences into variable-length concepts, performs deep reasoning in the concept space, and projects the results back to tokens via causal cross-attention. Compared to standard dense Transformers trained with next-token prediction, DLCM achieves ~34% inference FLOPs reduction under apple-to-apple settings, while consistently improving performance on reasoning-dominant benchmarks. Notably, the relative FLOPs savings increase with model scale, indicating favorable scaling behavior beyond parameter efficiency alone. At similar loss levels, DLCM reallocates computation toward boundary and planning tokens, yielding stronger downstream accuracy despite reduced redundant token processing. Technically, the paper contributes: (1) a FlashAttention-VarLen‚Äìbased implementation for efficient concept-token cross-attention; (2) a decoupled ŒºP formulation tailored to heterogeneous token- and concept-width modules, enabling zero-shot hyperparameter transfer across scales; (3) a Global Parser that enforces stable, content-adaptive compression at the batch level and delivers solid empirical gains. Overall, DLCM can be viewed as a principled special case of layer-wise local compression combined with sparse attention, offering a scalable path toward more compute-efficient and reasoning-centric language models.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24617",
      "pdf_url": "https://arxiv.org/pdf/2512.24617",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24617",
      "scraped_at": "2026-01-05T02:00:01.852412"
    },
    "scraped_date": "2026-01-05"
  },
  {
    "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
    "paper_url": "https://huggingface.co/papers/2512.24165",
    "authors": [
      "Siyuan Huang",
      "Yafu Li",
      "Xiaoye Qu",
      "Spico",
      "yhx12"
    ],
    "stars": "61",
    "details": {
      "title": "DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models",
      "abstract": "TLDR: A new paradigm for multi-modal reasoning with image-to-image generation. Diffusion could think too!",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24165",
      "pdf_url": "https://arxiv.org/pdf/2512.24165",
      "github_links": [
        "https://github.com/lcqysl/DiffThinker"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24165",
      "scraped_at": "2026-01-05T02:00:03.959198"
    },
    "scraped_date": "2026-01-05"
  },
  {
    "title": "On the Role of Discreteness in Diffusion LLMs",
    "paper_url": "https://huggingface.co/papers/2512.22630",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "On the Role of Discreteness in Diffusion LLMs",
      "abstract": "TL;DR: We identify two core failure modes in current large diffusion LLMs: uniform corruption ignores where information lives in a sentence, and token-wise marginal training struggles with multi-token dependencies during parallel decoding.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22630",
      "pdf_url": "https://arxiv.org/pdf/2512.22630",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22630",
      "scraped_at": "2026-01-05T02:00:05.988614"
    },
    "scraped_date": "2026-01-05"
  },
  {
    "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
    "paper_url": "https://huggingface.co/papers/2512.24766",
    "authors": [
      "Ruohan Zhang",
      "Li Fei-Fei",
      "Jiajun Wu",
      "Wenlong Huang",
      "Karthik Dharmarajan"
    ],
    "stars": "0",
    "details": {
      "title": "Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24766",
      "pdf_url": "https://arxiv.org/pdf/2512.24766",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24766",
      "scraped_at": "2026-01-05T02:00:08.091511"
    },
    "scraped_date": "2026-01-05"
  },
  {
    "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
    "paper_url": "https://huggingface.co/papers/2512.24724",
    "authors": [
      "Youngjung Uh",
      "Jaeseok Jeong",
      "Mingi Kwon",
      "Jibin Song"
    ],
    "stars": "0",
    "details": {
      "title": "FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24724",
      "pdf_url": "https://arxiv.org/pdf/2512.24724",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24724",
      "scraped_at": "2026-01-05T02:00:10.042015"
    },
    "scraped_date": "2026-01-05"
  },
  {
    "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
    "paper_url": "https://huggingface.co/papers/2512.24007",
    "authors": [
      "Ghaith Rabadi",
      "Sean Mondesire",
      "Bulent Soykan"
    ],
    "stars": "4",
    "details": {
      "title": "TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems",
      "abstract": "Simulation optimization (SO) is frequently challenged by noisy evaluations, high computational costs, and complex, multimodal search landscapes. This paper introduces Tabu-Enhanced Simulation Optimization (TESO), a novel metaheuristic framework integrating adaptive search with memory-based strategies. TESO leverages a short-term Tabu List to prevent cycling and encourage diversification, and a long-term Elite Memory to guide intensification by perturbing high-performing solutions. An aspiration criterion allows overriding tabu restrictions for exceptional candidates. This combination facilitates a dynamic balance between exploration and exploitation in stochastic environments. We demonstrate TESO‚Äôs effectiveness and reliability using an queue optimization problem, showing improved performance compared to benchmarks and validating the contribution of its memory components. Source code and data are available at: github.com/bulentsoykan/TESO.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24007",
      "pdf_url": "https://arxiv.org/pdf/2512.24007",
      "github_links": [
        "https://github.com/bulentsoykan/TESO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24007",
      "scraped_at": "2026-01-05T02:00:11.922915"
    },
    "scraped_date": "2026-01-05"
  },
  {
    "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization",
    "paper_url": "https://huggingface.co/papers/2512.24615",
    "authors": [],
    "stars": "4.1k",
    "details": {
      "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization",
      "abstract": "LONG wait. Youtu-Agent ( https://github.com/TencentCloudADP/Youtu-agent ) now releases its technical report with two major updates, i.e., Automated Generation and Hybrid Policy Optimization. Additionally, we've launched Youtu-Tip ( https://github.com/TencentCloudADP/youtu-tip ), a more user-friendly application that runs on macOS. Check them out and have fun!",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24615",
      "pdf_url": "https://arxiv.org/pdf/2512.24615",
      "github_links": [
        "https://github.com/TencentCloudADP/youtu-tip",
        "https://github.com/TencentCloudADP/youtu-agent",
        "https://github.com/TencentCloudADP/Youtu-agent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24615",
      "scraped_at": "2026-01-06T01:50:51.163830"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos",
    "paper_url": "https://huggingface.co/papers/2601.00393",
    "authors": [
      "Feng Wang",
      "Junran Peng",
      "renshengjihe",
      "Abyssaledge",
      "Yuppie1204"
    ],
    "stars": "124",
    "details": {
      "title": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos",
      "abstract": "NeoVerse is a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. Project page: https://neoverse-4d.github.io",
      "arxiv_page_url": "https://arxiv.org/abs/2601.00393",
      "pdf_url": "https://arxiv.org/pdf/2601.00393",
      "github_links": [
        "https://github.com/IamCreateAI/NeoVerse"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.00393",
      "scraped_at": "2026-01-06T01:50:53.205658"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation",
    "paper_url": "https://huggingface.co/papers/2601.00664",
    "authors": [
      "Sung Ju Hwang",
      "Jaehyeong Jo",
      "Sangwon Jang",
      "jaehong31",
      "taekyungki"
    ],
    "stars": "65",
    "details": {
      "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation",
      "abstract": "arXiv explained breakdown of this paper üëâ https://arxivexplained.com/papers/avatar-forcing-real-time-interactive-head-avatar-generation-for-natural-conversation",
      "arxiv_page_url": "https://arxiv.org/abs/2601.00664",
      "pdf_url": "https://arxiv.org/pdf/2601.00664",
      "github_links": [
        "https://github.com/TaekyungKi/AvatarForcing"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.00664",
      "scraped_at": "2026-01-06T01:50:55.077779"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2512.24330",
    "authors": [],
    "stars": "24",
    "details": {
      "title": "SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning",
      "abstract": "While Vision-Language Models (VLMs) can solve complex tasks through agentic reasoning, their capabilities remain largely constrained to text-oriented chain-of-thought or isolated tool invocation. They fail to exhibit the human-like proficiency required to seamlessly interleave dynamic tool manipulation with continuous reasoning, particularly in knowledge-intensive and visually complex scenarios that demand coordinated external tools such as search and image cropping. In this work, we introduce SenseNova-MARS, a novel Multimodal Agentic Reasoning and Search framework that empowers VLMs with interleaved visual reasoning and tool-use capabilities via reinforcement learning (RL). Specifically, SenseNova-MARS dynamically integrates the image search, text search, and image crop tools to tackle fine-grained and knowledge-intensive visual understanding challenges. In the RL stage, we propose the Batch-Normalized Group Sequence Policy Optimization (BN-GSPO) algorithm to improve the training stability and advance the model's ability to invoke tools and reason effectively. To comprehensively evaluate the agentic VLMs on complex visual tasks, we introduce the HR-MMSearch benchmark, the first search-oriented benchmark composed of high-resolution images with knowledge-intensive and search-driven questions. Experiments demonstrate that SenseNova-MARS achieves state-of-the-art performance on open-source search and fine-grained image understanding benchmarks. Specifically, on search-oriented benchmarks, SenseNova-MARS-8B scores 67.84 on MMSearch and 41.64 on HR-MMSearch, surpassing proprietary models such as Gemini-3-Flash and GPT-5. SenseNova-MARS represents a promising step toward agentic VLMs by providing effective and robust tool-use capabilities. To facilitate further research in this field, we will release all code, models, and datasets.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24330",
      "pdf_url": "https://arxiv.org/pdf/2512.24330",
      "github_links": [
        "https://github.com/OpenSenseNova/SenseNova-MARS"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24330",
      "scraped_at": "2026-01-06T01:50:56.907809"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation",
    "paper_url": "https://huggingface.co/papers/2512.24271",
    "authors": [],
    "stars": "29",
    "details": {
      "title": "Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation",
      "abstract": "An interesting work! github: https://github.com/AMAP-ML/Taming-Hallucinations",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24271",
      "pdf_url": "https://arxiv.org/pdf/2512.24271",
      "github_links": [
        "https://github.com/AMAP-ML/Taming-Hallucinations"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24271",
      "scraped_at": "2026-01-06T01:50:58.822184"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction",
    "paper_url": "https://huggingface.co/papers/2601.00796",
    "authors": [
      "Yu-Lun Liu",
      "Zhenjun Zhao",
      "Jiewen Chan"
    ],
    "stars": "0",
    "details": {
      "title": "AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction",
      "abstract": "Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.00796",
      "pdf_url": "https://arxiv.org/pdf/2601.00796",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.00796",
      "scraped_at": "2026-01-06T01:51:00.710791"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "Deep Delta Learning",
    "paper_url": "https://huggingface.co/papers/2601.00417",
    "authors": [],
    "stars": "234",
    "details": {
      "title": "Deep Delta Learning",
      "abstract": "The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector k(X) and a gating scalar Œ≤(X). We provide a spectral analysis of this operator, demonstrating that the gate Œ≤(X) enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.00417",
      "pdf_url": "https://arxiv.org/pdf/2601.00417",
      "github_links": [
        "https://github.com/yifanzhang-pro/deep-delta-learning"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.00417",
      "scraped_at": "2026-01-06T01:51:02.670038"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "Nested Learning: The Illusion of Deep Learning Architectures",
    "paper_url": "https://huggingface.co/papers/2512.24695",
    "authors": [
      "Vahab Mirrokni",
      "Peilin Zhong",
      "Meisam Razaviyayn",
      "AliBehrouz"
    ],
    "stars": "0",
    "details": {
      "title": "Nested Learning: The Illusion of Deep Learning Architectures",
      "abstract": "Nested Learning (NL) is a new learning paradigm for continual learning and machine learning in general.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.24695",
      "pdf_url": "https://arxiv.org/pdf/2512.24695",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.24695",
      "scraped_at": "2026-01-06T01:51:04.593752"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving",
    "paper_url": "https://huggingface.co/papers/2601.00747",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving",
      "abstract": "For those of you interested in RLVR, here is a paper that formally characterizes the mechanism behind \"diversity collapse\" in reasoning models trained with scalar rewards (such as STaR, GRPO, and DPO). The paper introduces a variational framework based on Shahshahani gradient flow to prove that optimizing solely for correctness inherently erodes the diversity of reasoning paths, leading to a \"reasoning monoculture.\" To address this, they propose Distributional Creative Reasoning (DCR), which incorporates a diversity energy functional (using entropy and kernel-based novelty) into the objective, mathematically guaranteeing the maintenance of a diverse portfolio of successful reasoning strategies while still optimizing for utility.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.00747",
      "pdf_url": "https://arxiv.org/pdf/2601.00747",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.00747",
      "scraped_at": "2026-01-06T01:51:06.385822"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "Diversity or Precision? A Deep Dive into Next Token Prediction",
    "paper_url": "https://huggingface.co/papers/2512.22955",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Diversity or Precision? A Deep Dive into Next Token Prediction",
      "abstract": "Recent advancements have shown that reinforcement learning (RL) can substantially improve the reasoning abilities of large language models (LLMs).  The effectiveness of such RL training, however, depends critically on the exploration space defined by the pre-trained model's token-output distribution. In this paper, we revisit the standard cross-entropy loss, interpreting it as a specific instance of policy gradient optimization applied within a single-step episode.  To systematically study how the pre-trained distribution shapes the exploration potential for subsequent RL, we propose a generalized pre-training objective that adapts on-policy RL principles to supervised learning.  By framing next-token prediction as a stochastic decision process, we introduce a reward-shaping strategy that explicitly balances diversity and precision.  Our method employs a positive reward scaling factor to control probability concentration on ground-truth tokens and a rank-aware mechanism that treats high-ranking and low-ranking negative tokens asymmetrically. This allows us to reshape the pre-trained token-output distribution and investigate how to provide a more favorable exploration space for RL, ultimately enhancing end-to-end reasoning performance. Contrary to the intuition that higher distribution entropy facilitates effective exploration, we find that imposing a precision-oriented prior yields a superior exploration space for RL.",
      "arxiv_page_url": "https://arxiv.org/abs/2512.22955",
      "pdf_url": "https://arxiv.org/pdf/2512.22955",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2512.22955",
      "scraped_at": "2026-01-06T01:51:08.307456"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "Fast-weight Product Key Memory",
    "paper_url": "https://huggingface.co/papers/2601.00671",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Fast-weight Product Key Memory",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Trellis: Learning to Compress Key-Value Memory in Attention Models (2025) TNT: Improving Chunkwise Training for Test-Time Memorization (2025) GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory (2025) MIDUS: Memory-Infused Depth Up-Scaling (2025) Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models (2025) InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models (2025) BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.00671",
      "pdf_url": "https://arxiv.org/pdf/2601.00671",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.00671",
      "scraped_at": "2026-01-06T01:51:10.101023"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
    "paper_url": "https://huggingface.co/papers/2601.00575",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
      "abstract": "Project Page: https://ishirgarg.github.io/infosynth_web/ Code: https://github.com/ishirgarg/infosynth Dataset: https://huggingface.co/datasets/ishirgarg/InfoSynth",
      "arxiv_page_url": "https://arxiv.org/abs/2601.00575",
      "pdf_url": "https://arxiv.org/pdf/2601.00575",
      "github_links": [
        "https://github.com/ishirgarg/infosynth"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.00575",
      "scraped_at": "2026-01-06T01:51:12.005175"
    },
    "scraped_date": "2026-01-06"
  },
  {
    "title": "MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing",
    "paper_url": "https://huggingface.co/papers/2601.00204",
    "authors": [
      "Jian Yang",
      "Ying Tai",
      "Hao Tang",
      "Zeyu Cai",
      "XiaokunSun"
    ],
    "stars": "19",
    "details": {
      "title": "MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing",
      "abstract": "3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io Code: https://github.com/XiaokunSun/MorphAny3D",
      "arxiv_page_url": "https://arxiv.org/abs/2601.00204",
      "pdf_url": "https://arxiv.org/pdf/2601.00204",
      "github_links": [
        "https://github.com/XiaokunSun/MorphAny3D"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.00204",
      "scraped_at": "2026-01-06T01:51:13.858117"
    },
    "scraped_date": "2026-01-06"
  }
]