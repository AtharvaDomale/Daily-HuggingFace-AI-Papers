[
  {
    "title": "Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives",
    "paper_url": "https://huggingface.co/papers/2601.20833",
    "authors": [],
    "stars": "226",
    "details": {
      "title": "Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives",
      "abstract": "arXivLens breakdown of this paper üëâ https://arxivlens.com/PaperView/Details/idea2story-an-automated-pipeline-for-transforming-research-concepts-into-complete-scientific-narratives-2345-6407a884 Executive Summary Detailed Breakdown Practical Applications",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20833",
      "pdf_url": "https://arxiv.org/pdf/2601.20833",
      "github_links": [
        "https://github.com/AgentAlphaAGI/Idea2Paper"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20833",
      "scraped_at": "2026-02-01T02:33:03.597644"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models",
    "paper_url": "https://huggingface.co/papers/2601.20354",
    "authors": [],
    "stars": "97",
    "details": {
      "title": "Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models",
      "abstract": "A very interesting benchmark (ICLR2026) for T2I models!",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20354",
      "pdf_url": "https://arxiv.org/pdf/2601.20354",
      "github_links": [
        "https://github.com/AMAP-ML/SpatialGenEval"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20354",
      "scraped_at": "2026-02-01T02:33:05.477273"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Scaling Embeddings Outperforms Scaling Experts in Language Models",
    "paper_url": "https://huggingface.co/papers/2601.21204",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Scaling Embeddings Outperforms Scaling Experts in Language Models",
      "abstract": "Embedding scaling can outperform mixture of experts for sparse language models, aided by system optimizations and speculative decoding, with LongCat-Flash-Lite achieving strong competitiveness.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21204",
      "pdf_url": "https://arxiv.org/pdf/2601.21204",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21204",
      "scraped_at": "2026-02-01T02:33:07.391167"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation",
    "paper_url": "https://huggingface.co/papers/2601.22153",
    "authors": [],
    "stars": "68",
    "details": {
      "title": "DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation",
      "abstract": "TL; DR: DynamicVLA enables open-ended dynamic object manipulation by pairing a compact 0.4B VLM with low-latency Continuous Inference and Latent-aware Action Streaming, evaluated at scale through the new DOM benchmark in both simulation and the real world. GitHub: https://github.com/hzxie/DynamicVLA Project Page: https://haozhexie.com/project/dynamic-vla Spotlight Video: https://www.youtube.com/watch?v=NmJnHcI04_Q",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22153",
      "pdf_url": "https://arxiv.org/pdf/2601.22153",
      "github_links": [
        "https://github.com/hzxie/DynamicVLA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22153",
      "scraped_at": "2026-02-01T02:33:09.315341"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods",
    "paper_url": "https://huggingface.co/papers/2601.21821",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods",
      "abstract": "Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a \"less is more\" phenomenon via our difficulty-aware filtering strategy: a subset of just 7% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21821",
      "pdf_url": "https://arxiv.org/pdf/2601.21821",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21821",
      "scraped_at": "2026-02-01T02:33:11.246878"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models",
    "paper_url": "https://huggingface.co/papers/2601.21639",
    "authors": [
      "Liming Zheng",
      "Wenkang Han",
      "Xuanle Zhao",
      "Lei Chen",
      "Albert-Zhong"
    ],
    "stars": "19",
    "details": {
      "title": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models",
      "abstract": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21639",
      "pdf_url": "https://arxiv.org/pdf/2601.21639",
      "github_links": [
        "https://github.com/DocTron-hub/OCRVerse"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21639",
      "scraped_at": "2026-02-01T02:33:13.120944"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation",
    "paper_url": "https://huggingface.co/papers/2601.21420",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation",
      "abstract": "ConceptMoE shifts language model processing from uniform token-level to adaptive concept-level computation. By learning to merge semantically similar tokens into unified concepts while preserving fine-grained granularity for complex tokens, it performs implicit compute allocation‚Äîautomatically investing computation where needed. Key results: (1) Fair comparison under identical parameters and FLOPs shows consistent gains across language (+0.9), vision-language (+0.6, +2.3 on long context), and continual training (+5.5 with layer loops, +6.4 from scratch). (2) Inherent efficiency: at compression ratio R=2, attention computation reduces by R¬≤√ó and KV cache by R√ó, achieving prefill speedups up to 175% and decoding speedups up to 117%. (3) Minimal architectural changes (chunk module + decoder QKV projectors) enable straightforward deployment in existing MoE systems. Represents a paradigm shift toward hierarchical semantic processing in LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21420",
      "pdf_url": "https://arxiv.org/pdf/2601.21420",
      "github_links": [
        "https://github.com/ZihaoHuang-notabot/ConceptMoE"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21420",
      "scraped_at": "2026-02-01T02:33:14.976727"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction",
    "paper_url": "https://huggingface.co/papers/2601.22046",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction",
      "abstract": "PLANING introduces a loosely coupled triangle-Gaussian representation and a monocular streaming framework that jointly achieves accurate geometry, high-fidelity rendering, and efficient planar abstraction for embodied AI applications.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22046",
      "pdf_url": "https://arxiv.org/pdf/2601.22046",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22046",
      "scraped_at": "2026-02-01T02:33:16.978270"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Qwen3-ASR Technical Report",
    "paper_url": "https://huggingface.co/papers/2601.21337",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Qwen3-ASR Technical Report",
      "abstract": "Qwen3-ASR delivers two all-in-one ASR models with 52-language support and a non-autoregressive forced-aligner; achieves competitive SOTA accuracy, fast TTFT, and open-source Apache 2.0 release.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21337",
      "pdf_url": "https://arxiv.org/pdf/2601.21337",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21337",
      "scraped_at": "2026-02-01T02:33:18.892437"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Exploring Reasoning Reward Model for Agents",
    "paper_url": "https://huggingface.co/papers/2601.22154",
    "authors": [
      "Zhixun Li",
      "Tianshuo Peng",
      "Manyuan Zhang",
      "Kaituo Feng",
      "bunny127"
    ],
    "stars": "20",
    "details": {
      "title": "Exploring Reasoning Reward Model for Agents",
      "abstract": "Github: https://github.com/kxfan2002/Reagent Paper: https://arxiv.org/pdf/2601.22154",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22154",
      "pdf_url": "https://arxiv.org/pdf/2601.22154",
      "github_links": [
        "https://github.com/kxfan2002/Reagent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22154",
      "scraped_at": "2026-02-01T02:33:20.830139"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts",
    "paper_url": "https://huggingface.co/papers/2601.20730",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts",
      "abstract": "The evolution of Large Language Models (LLMs) into autonomous agents necessitates the management of extensive, dynamic contexts. Current benchmarks, however, remain largely static, relying on passive retrieval tasks that fail to simulate the complexities of agent-environment interaction, such as non-linear reasoning and iterative feedback. To address this, we introduce \\textbf{AgentLongBench}, which evaluates agents through simulated environment rollouts based on Lateral Thinking Puzzles. This framework generates rigorous interaction trajectories across knowledge-intensive and knowledge-free scenarios. Experiments with state-of-the-art models and memory systems (32K to 4M tokens) expose a critical weakness: while adept at static retrieval, agents struggle with the dynamic information synthesis essential for workflows. Our analysis indicates that this degradation is driven by the minimum number of tokens required to resolve a query. This factor explains why the high information density inherent in massive tool responses poses a significantly greater challenge than the memory fragmentation typical of long-turn dialogues. The code is available at https://github.com/euReKa025/AgentLongBench .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20730",
      "pdf_url": "https://arxiv.org/pdf/2601.20730",
      "github_links": [
        "https://github.com/euReKa025/AgentLongBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20730",
      "scraped_at": "2026-02-01T02:33:22.810822"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems",
    "paper_url": "https://huggingface.co/papers/2601.17883",
    "authors": [],
    "stars": "47",
    "details": {
      "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems",
      "abstract": "We propose fair and comprehensive benchmarking for open source EEG foundation models.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.17883",
      "pdf_url": "https://arxiv.org/pdf/2601.17883",
      "github_links": [
        "https://github.com/Dingkun0817/EEG-FM-Benchmark"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.17883",
      "scraped_at": "2026-02-01T02:33:24.698613"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "LoL: Longer than Longer, Scaling Video Generation to Hour",
    "paper_url": "https://huggingface.co/papers/2601.16914",
    "authors": [
      "Xiaojie Li",
      "Tao Yang",
      "Ming Li",
      "Jie Wu",
      "Justin Cui"
    ],
    "stars": "0",
    "details": {
      "title": "LoL: Longer than Longer, Scaling Video Generation to Hour",
      "abstract": "Scaling up video generation to hour long, please checkout our paper at: https://arxiv.org/abs/2601.16914 Project Page and code will released at: https://github.com/justincui03/LoL",
      "arxiv_page_url": "https://arxiv.org/abs/2601.16914",
      "pdf_url": "https://arxiv.org/pdf/2601.16914",
      "github_links": [
        "https://github.com/justincui03/LoL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.16914",
      "scraped_at": "2026-02-01T02:33:26.670368"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Discovering Hidden Gems in Model Repositories",
    "paper_url": "https://huggingface.co/papers/2601.22157",
    "authors": [
      "Yedid Hoshen",
      "Eliahu Horwitz",
      "Jonathan Kahana"
    ],
    "stars": "0",
    "details": {
      "title": "Discovering Hidden Gems in Model Repositories",
      "abstract": "An investigation of the available fine-tunes of popular foundation models. While over 90% of downloads are directed to the official base versions the paper shows the existence of other, rarely downloaded fine-tunes that significantly outperform them.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22157",
      "pdf_url": "https://arxiv.org/pdf/2601.22157",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22157",
      "scraped_at": "2026-02-01T02:33:28.571777"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Language-based Trial and Error Falls Behind in the Era of Experience",
    "paper_url": "https://huggingface.co/papers/2601.21754",
    "authors": [],
    "stars": "8",
    "details": {
      "title": "Language-based Trial and Error Falls Behind in the Era of Experience",
      "abstract": "While Large Language Models (LLMs) excel in language-based agentic tasks, their applicability to unseen, nonlinguistic environments (e.g., symbolic or spatial tasks) remains limited. Previous work attributes this performance gap to the mismatch between the pretraining distribution and the testing distribution. In this work, we demonstrate the primary bottleneck is the prohibitive cost of exploration: mastering these tasks requires extensive trial-and-error, which is computationally unsustainable for parameter-heavy LLMs operating in a high dimensional semantic space. To address this, we propose SCOUT (Sub-Scale Collaboration On Unseen Tasks), a novel framework that decouples exploration from exploitation. We employ lightweight \"scouts\" (e.g., small MLPs) to probe environmental dynamics at a speed and scale far exceeding LLMs. The collected trajectories are utilized to bootstrap the LLM via Supervised Fine-Tuning (SFT), followed by multi-turn Reinforcement Learning (RL) to activate its latent world knowledge. Empirically, SCOUT enables a Qwen2.5-3B-Instruct model to achieve an average score of 0.86, significantly outperforming proprietary models, including Gemini-2.5-Pro (0.60), while saving about 60% GPU hours consumption.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21754",
      "pdf_url": "https://arxiv.org/pdf/2601.21754",
      "github_links": [
        "https://github.com/Harry-mic/SCOUT"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21754",
      "scraped_at": "2026-02-01T02:33:30.462705"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Shaping capabilities with token-level data filtering",
    "paper_url": "https://huggingface.co/papers/2601.21571",
    "authors": [],
    "stars": "42",
    "details": {
      "title": "Shaping capabilities with token-level data filtering",
      "abstract": "Key Findings: 1. Token-level Filtering vs Document-level Filtering (Figure 3) Token filtering Pareto-dominates document filtering : Can achieve equal reduction in undesired capabilities (equal medical loss) at lower cost to desired capabilities (lower biology loss) More precise filtering preserves beneficial content better 2. Scaling Effects (Figures 1, 4, 5, 6) Filtering gets more effective with scale : 1.8B parameter models see 7,000√ó compute slowdown on medical domain Document filtering: ~30√ó slowdown Token removal: >7,000√ó slowdown Multiple choice evaluation : Models score near chance on MedMCQA and MedQA-USMLE (medical), but maintain performance on retain domains Free response : Token filtering reduces medical answer correctness up to 20√ó, relevance/coherence 3√ó compared to baseline 3. Robustness to Attacks (Figure 7) 10√ó more robust than unlearning against adversarial finetuning attacks for 1.8B models State-of-the-art unlearning (RMU) requires 13√ó fewer tokens to recover capabilities compared to token removal 4. Alignment Compatibility (Figures 8, 9) Models can still be aligned on forget domain : Token-level filtering makes refusal training easier (2√ó better refusal generalization) Document filtering struggles with alignment generalization Linear probes show models can distinguish forget vs. retain tokens despite filtering 5. Classifier Training (Table 1, Figure 11) Small, task-specific models outperform large general ones : 224M parameter biLM achieves 0.894 F1 on test set Outperforms 395M ModernBERT-large (0.794 F1) Domain-specific pretraining improves performance 6. Label Quality Tolerance (Figures 12, 13, 14, 15) Robust to imperfect labels : Aggressive filtering with sufficient compute can overcome label noise Token-level classifiers generalize from weak labels better than document-level Can trade precision for recall to maintain effectiveness",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21571",
      "pdf_url": "https://arxiv.org/pdf/2601.21571",
      "github_links": [
        "https://github.com/neilrathi/token-filtering"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21571",
      "scraped_at": "2026-02-01T02:33:32.442711"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening",
    "paper_url": "https://huggingface.co/papers/2601.21590",
    "authors": [
      "Haitham Bou Ammar",
      "Matthieu Zimmer",
      "Rasul Tutunov",
      "xtongji"
    ],
    "stars": "0",
    "details": {
      "title": "Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening",
      "abstract": "What if RL isn‚Äôt teaching LLMs how to reason, but just sharpening what‚Äôs already there? Most recent progress in LLM reasoning comes from RL post-training (GRPO, verifiers, rewards). But there‚Äôs growing evidence that these gains may come less from learning new capabilities and more from reshaping the distribution of outputs. In our new work, we take that idea seriously. We show that: Reasoning trajectories already exist in base models What matters is how you sample, not how you retrain The global power distribution can be approximated autoregressively, without MCMC The result is a training-free, verifier-free inference-time method that: ‚ö° Matches GRPO-style post-training ‚è± Is ~10√ó faster than MCMC-based power sampling üß™ Requires no rewards, no finetuning, no verifier Conceptually, the key insight is simple: Power sampling ‚âà low-temperature sampling √ó future-aware token scaling This lets us recover global reasoning behaviour token by token, without expensive trajectory-level inference.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21590",
      "pdf_url": "https://arxiv.org/pdf/2601.21590",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21590",
      "scraped_at": "2026-02-01T02:33:34.343811"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Latent Adversarial Regularization for Offline Preference Optimization",
    "paper_url": "https://huggingface.co/papers/2601.22083",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Latent Adversarial Regularization for Offline Preference Optimization",
      "abstract": "Most offline preference optimization methods (e.g., DPO) constrain policy updates using token-level divergences. However, token-space similarity is often a weak proxy for semantic or structural behavior. We propose GANPO, a plug-and-play regularizer that introduces latent-space adversarial regularization, aligning the latent representation distributions of a policy and a reference model via a principled GAN-style divergence. We find consistent performance improvements. GANPO yields consistent gains across model architectures when integrated into OPO-style methods on AlpacaEval. We also find that structure is preserved. The adversarial objective acts as a geometry-preserving regularizer. Unlike DPO, which often degrades at high sampling temperatures (T ‚â• 1.0), GANPO maintains structural coherence in high-entropy settings. If you‚Äôre interested in alignment, GANs, or the limitations of KL-divergence‚Äìbased regularization, feel free to check out the paper.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22083",
      "pdf_url": "https://arxiv.org/pdf/2601.22083",
      "github_links": [
        "https://github.com/enyijiang/GANPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22083",
      "scraped_at": "2026-02-01T02:33:36.241397"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report",
    "paper_url": "https://huggingface.co/papers/2601.21051",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report",
      "abstract": "Model card: https://huggingface.co/fdtn-ai/Foundation-Sec-8B-Reasoning",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21051",
      "pdf_url": "https://arxiv.org/pdf/2601.21051",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21051",
      "scraped_at": "2026-02-01T02:33:38.147164"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.18129",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models",
      "abstract": "Code: https://github.com/scb-10x/typhoon-s Artifact: https://huggingface.co/collections/typhoon-ai/typhoon-s",
      "arxiv_page_url": "https://arxiv.org/abs/2601.18129",
      "pdf_url": "https://arxiv.org/pdf/2601.18129",
      "github_links": [
        "https://github.com/scb-10x/typhoon-s"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.18129",
      "scraped_at": "2026-02-01T02:33:40.132735"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Self-Improving Pretraining: using post-trained models to pretrain better models",
    "paper_url": "https://huggingface.co/papers/2601.21343",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Self-Improving Pretraining: using post-trained models to pretrain better models",
      "abstract": "Streaming pretraining uses a strong post-trained model to judge next-token generations with RL, improving quality, safety, and factuality earlier in training.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21343",
      "pdf_url": "https://arxiv.org/pdf/2601.21343",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21343",
      "scraped_at": "2026-02-01T02:33:42.076876"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.22069",
    "authors": [],
    "stars": "14",
    "details": {
      "title": "VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning",
      "abstract": "We propose VTC-R1, an efficient long-context reasoning paradigm that integrates vision-text compression into iterative reasoning. By rendering previous reasoning segments into compact visual representations, VTC-R1 replaces long textual contexts with significantly fewer vision tokens in a lightweight and model-free manner. Extensive experiments show that VTC-R1 consistently improves reasoning accuracy across multiple benchmarks while achieving up to 3.4x token compression and 2.7x end-to-end inference speedup. The results demonstrate that VTC-R1 provides an effective alternative representation for scalable long-context reasoning. We hope our work would inspire further exploration of efficient reasoning beyond pure text-based paradigms.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22069",
      "pdf_url": "https://arxiv.org/pdf/2601.22069",
      "github_links": [
        "https://github.com/w-yibo/VTC-R1"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22069",
      "scraped_at": "2026-02-01T02:33:44.003367"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.21181",
    "authors": [
      "Yong Man Ro",
      "Youngchae Chee",
      "Se Yeon Kim",
      "topyun"
    ],
    "stars": "0",
    "details": {
      "title": "MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models",
      "abstract": "Multimodal Large Language Models (MLLMs) suffer from cross-modal hallucinations, where one modality inappropriately influences generation about another, leading to fabricated output. This exposes a more fundamental deficiency in modality-interaction control. To address this, we propose Modality-Adaptive Decoding (MAD), a training-free method that adaptively weights modality-specific decoding branches based on task requirements. MAD leverages the model's inherent ability to self-assess modality relevance by querying which modalities are needed for each task. The extracted modality probabilities are then used to adaptively weight contrastive decoding branches, enabling the model to focus on relevant information while suppressing cross-modal interference. Extensive experiments on CMM and AVHBench demonstrate that MAD significantly reduces cross-modal hallucinations across multiple audio-visual language models (7.8% and 2.0% improvements for VideoLLaMA2-AV, 8.7% and 4.7% improvements for Qwen2.5-Omni). Our approach demonstrates that explicit modality awareness through self-assessment is crucial for robust multimodal reasoning, offering a principled extension to existing contrastive decoding methods.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21181",
      "pdf_url": "https://arxiv.org/pdf/2601.21181",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21181",
      "scraped_at": "2026-02-01T02:33:45.991896"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "One-step Latent-free Image Generation with Pixel Mean Flows",
    "paper_url": "https://huggingface.co/papers/2601.22158",
    "authors": [
      "Zhicheng Jiang",
      "Hanhong Zhao",
      "Qiao Sun",
      "Susie Lu",
      "Yiyang Lu"
    ],
    "stars": "0",
    "details": {
      "title": "One-step Latent-free Image Generation with Pixel Mean Flows",
      "abstract": "One-step Latent-free Image Generation with Pixel Mean Flows",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22158",
      "pdf_url": "https://arxiv.org/pdf/2601.22158",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22158",
      "scraped_at": "2026-02-01T02:33:47.801410"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Beyond Imitation: Reinforcement Learning for Active Latent Planning",
    "paper_url": "https://huggingface.co/papers/2601.21598",
    "authors": [
      "Wee Sun Lee",
      "zz1358m"
    ],
    "stars": "0",
    "details": {
      "title": "Beyond Imitation: Reinforcement Learning for Active Latent Planning",
      "abstract": "Our recent work on Latent Reasoning",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21598",
      "pdf_url": "https://arxiv.org/pdf/2601.21598",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21598",
      "scraped_at": "2026-02-01T02:33:49.693160"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents",
    "paper_url": "https://huggingface.co/papers/2601.20975",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents",
      "abstract": "Proposes DeepSearchQA, a 900-prompt benchmark across 17 fields to test long-horizon search, info synthesis, deduplication, and stopping criteria for open-web research agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20975",
      "pdf_url": "https://arxiv.org/pdf/2601.20975",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20975",
      "scraped_at": "2026-02-01T02:33:51.875835"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts",
    "paper_url": "https://huggingface.co/papers/2601.22156",
    "authors": [],
    "stars": "5",
    "details": {
      "title": "Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts",
      "abstract": "Code: https://www.github.com/THUNLP/hybrid-linear-attention",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22156",
      "pdf_url": "https://arxiv.org/pdf/2601.22156",
      "github_links": [
        "https://github.com/thunlp/hybrid-linear-attention",
        "https://www.github.com/THUNLP/hybrid-linear-attention"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22156",
      "scraped_at": "2026-02-01T02:33:53.733483"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale",
    "paper_url": "https://huggingface.co/papers/2601.22146",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale",
      "abstract": "@ AjayP13 and @ craffel really interesting work and approach, do you plan to add support for multilingual instructions ü§î",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22146",
      "pdf_url": "https://arxiv.org/pdf/2601.22146",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22146",
      "scraped_at": "2026-02-01T02:33:55.671646"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices",
    "paper_url": "https://huggingface.co/papers/2601.21579",
    "authors": [
      "Danilo Mandic",
      "Giorgos Iacovides",
      "Yuxuan Gu",
      "WuyangZzzz"
    ],
    "stars": "3",
    "details": {
      "title": "KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices",
      "abstract": "KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21579",
      "pdf_url": "https://arxiv.org/pdf/2601.21579",
      "github_links": [
        "https://github.com/wz1119/KromHC"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21579",
      "scraped_at": "2026-02-01T02:33:57.494868"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "ECO: Quantized Training without Full-Precision Master Weights",
    "paper_url": "https://huggingface.co/papers/2601.22101",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ECO: Quantized Training without Full-Precision Master Weights",
      "abstract": "We present Error-Compensating Optimizer (ECO), which integrates with standard optimizers and, for the first time, enables quantized training of large-scale LLMs without requiring high-precision master weights.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22101",
      "pdf_url": "https://arxiv.org/pdf/2601.22101",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22101",
      "scraped_at": "2026-02-01T02:33:59.289520"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources",
    "paper_url": "https://huggingface.co/papers/2601.22054",
    "authors": [
      "Jianxun Cui",
      "Xuancheng Zhang",
      "Donglin Di",
      "Baorui Ma",
      "yjh001"
    ],
    "stars": "62",
    "details": {
      "title": "MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources",
      "abstract": "Project Page: https://metric-anything.github.io/metric-anything-io/ Code: https: https://github.com/metric-anything/metric-anything",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22054",
      "pdf_url": "https://arxiv.org/pdf/2601.22054",
      "github_links": [
        "https://github.com/metric-anything/metric-anything"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22054",
      "scraped_at": "2026-02-01T02:34:01.121705"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
    "paper_url": "https://huggingface.co/papers/2601.21996",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
      "abstract": "We introduce Mechanistic Data Attribution (MDA), a new paradigm that shifts the focus of mechanistic interpretability from post-hoc circuit analysis to the causal formation of these mechanisms during training.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21996",
      "pdf_url": "https://arxiv.org/pdf/2601.21996",
      "github_links": [
        "https://github.com/chenjianhuii/Mechanistic-Data-Attribution"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21996",
      "scraped_at": "2026-02-01T02:34:02.973491"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation",
    "paper_url": "https://huggingface.co/papers/2601.21406",
    "authors": [
      "Guanhua Chen",
      "Yong Wang",
      "Kangrui Cen",
      "Hongyang Wei",
      "Zihan Su"
    ],
    "stars": "8",
    "details": {
      "title": "Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation",
      "abstract": "Paper: https://arxiv.org/abs/2601.21406 Github: https://github.com/Sugewud/UniMRG Project: https://sugewud.github.io/UniMRG-Project/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21406",
      "pdf_url": "https://arxiv.org/pdf/2601.21406",
      "github_links": [
        "https://github.com/Sugewud/UniMRG"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21406",
      "scraped_at": "2026-02-01T02:34:04.835065"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "BMAM: Brain-inspired Multi-Agent Memory Framework",
    "paper_url": "https://huggingface.co/papers/2601.20465",
    "authors": [
      "Mingkun Xu",
      "Yujie Wu",
      "Yusong Wang",
      "Jiaxiang Liu",
      "innovation64"
    ],
    "stars": "2",
    "details": {
      "title": "BMAM: Brain-inspired Multi-Agent Memory Framework",
      "abstract": "We introduce BMAM (Brain-inspired Multi-Agent Memory), a general-purpose memory architecture designed to solve \"soul erosion\"‚Äîthe loss of temporal grounding and consistency in long-term agent interactions. üß† Key Innovations: Cognitive-inspired Architecture: Decomposes memory into episodic, semantic, salience-aware, and control-oriented components. Temporal Grounding: Operates at complementary time scales to maintain behavioral consistency. Plug-and-play: A general framework for LLM-based multi-agent systems. Check out our preprint for details on how we bridge the gap between biological memory systems and AI agents!",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20465",
      "pdf_url": "https://arxiv.org/pdf/2601.20465",
      "github_links": [
        "https://github.com/innovation64/BMAM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20465",
      "scraped_at": "2026-02-01T02:34:06.608828"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion",
    "paper_url": "https://huggingface.co/papers/2601.22143",
    "authors": [
      "Urska Jelercic",
      "Matan Ben Yosef",
      "Tavi Halperin",
      "Naomi Ken Korem",
      "Anthony Chen"
    ],
    "stars": "0",
    "details": {
      "title": "JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22143",
      "pdf_url": "https://arxiv.org/pdf/2601.22143",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22143",
      "scraped_at": "2026-02-01T02:34:08.453033"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.19001",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning",
      "abstract": "ICLR2026",
      "arxiv_page_url": "https://arxiv.org/abs/2601.19001",
      "pdf_url": "https://arxiv.org/pdf/2601.19001",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.19001",
      "scraped_at": "2026-02-01T02:34:10.289576"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels",
    "paper_url": "https://huggingface.co/papers/2601.21268",
    "authors": [
      "Jesse Roberts",
      "Micah Rentschler"
    ],
    "stars": "0",
    "details": {
      "title": "Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels",
      "abstract": "We present Reinforcement Learning from Meta-Evaluation (RLME), a label-free RL framework that trains LLMs using evaluator judgments to natural-language meta-questions, achieving performance comparable to supervised rewards while scaling to ambiguous, open-domain tasks.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21268",
      "pdf_url": "https://arxiv.org/pdf/2601.21268",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21268",
      "scraped_at": "2026-02-01T02:34:12.180581"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis",
    "paper_url": "https://huggingface.co/papers/2601.20103",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis",
      "abstract": "We show that contrasting reward hacks in an outlier detection setting helps LLMs detect code hacking behaviors. We further show that a cluster's benign-to-hacked trajectory ratio influences this detection rate. Finally we perform thorough QA and show that semantically contextualized hacks are more difficult to detect as compared to syntactic ones. We release TRACE, a synthetic, human verified dataset of 517 trajectories spanning 54 code reward hack categories to help the community build robust automated RL orchestration pipelines.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20103",
      "pdf_url": "https://arxiv.org/pdf/2601.20103",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20103",
      "scraped_at": "2026-02-01T02:34:14.074758"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Flow-based Extremal Mathematical Structure Discovery",
    "paper_url": "https://huggingface.co/papers/2601.18005",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Flow-based Extremal Mathematical Structure Discovery",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.18005",
      "pdf_url": "https://arxiv.org/pdf/2601.18005",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.18005",
      "scraped_at": "2026-02-01T02:34:15.977827"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance",
    "paper_url": "https://huggingface.co/papers/2601.17690",
    "authors": [
      "Melody Ma",
      "Iram Kamdar",
      "Yunyan Ouyang",
      "Ziling Gong",
      "Franck-Dernoncourt"
    ],
    "stars": "0",
    "details": {
      "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Lightweight Resolution-Aware Audio Deepfake Detection via Cross-Scale Attention and Consistency Learning (2026) BEST-STD2.0: Balanced and Efficient Speech Tokenizer for Spoken Term Detection (2025) VIBEVOICE-ASR Technical Report (2026) DAME: Duration-Aware Matryoshka Embedding for Duration-Robust Speaker Verification (2026) Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding (2025) LongSpeech: A Scalable Benchmark for Transcription, Translation and Understanding in Long Speech (2026) SpeechQualityLLM: LLM-Based Multimodal Assessment of Speech Quality (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.17690",
      "pdf_url": "https://arxiv.org/pdf/2601.17690",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.17690",
      "scraped_at": "2026-02-01T02:34:17.832401"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement",
    "paper_url": "https://huggingface.co/papers/2601.11747",
    "authors": [
      "Stefano Petrangeli",
      "Yu Shen",
      "Sunav Choudhary",
      "Huaxiaoyue Wang",
      "Franck-Dernoncourt"
    ],
    "stars": "0",
    "details": {
      "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API MiLDEdit: Reasoning-Based Multi-Layer Design Document Editing (2026) Styles + Persona-plug = Customized LLMs (2026) Step-by-step Layered Design Generation (2025) Widget2Code: From Visual Widgets to UI Code via Multimodal LLMs (2025) Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation (2025) ShowTable: Unlocking Creative Table Visualization with Collaborative Reflection and Refinement (2025) Aligning Text, Code, and Vision: A Multi-Objective Reinforcement Learning Framework for Text-to-Visualization (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.11747",
      "pdf_url": "https://arxiv.org/pdf/2601.11747",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.11747",
      "scraped_at": "2026-02-01T02:34:19.617722"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents",
    "paper_url": "https://huggingface.co/papers/2601.21872",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents",
      "abstract": "Accepted at ICLR 2026",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21872",
      "pdf_url": "https://arxiv.org/pdf/2601.21872",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21872",
      "scraped_at": "2026-02-01T02:34:21.390092"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation",
    "paper_url": "https://huggingface.co/papers/2601.21416",
    "authors": [
      "Liming Chen",
      "Emmanuel Dellandr√©a",
      "Bruno Machado",
      "Beegbrain"
    ],
    "stars": "0",
    "details": {
      "title": "Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation",
      "abstract": "The ability of visuomotor policies to generalize across tasks and environments critically depends on the structure of the underlying visual representations. While most state-of-the-art robot policies rely on either global or dense features from pre-trained vision models, these approaches often entangle task-relevant and irrelevant signals, limiting their robustness to visual distribution shifts. In this paper, we investigate Slot-based Object-Centric Representations (SOCRs) as a structured alternative that decomposes scenes into a finite set of object-like entities. We present the first large-scale, systematic comparison of global, dense, and object-centric representations across diverse simulated (METAWORLD, LIBERO) and real-world robotic manipulation tasks. Our results show that SOCRs enable superior policy performance and significantly improve generalization under shifts in lighting, texture, and clutter‚Äî even without task-specific tuning. We further demonstrate that pretraining SOCRs on robotic video datasets amplifies these benefits. Our findings highlight the importance of structured visual abstraction in robotic perception and suggest that SOCRs offer a promising pathway toward more robust and generaliz- able manipulation policies.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21416",
      "pdf_url": "https://arxiv.org/pdf/2601.21416",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21416",
      "scraped_at": "2026-02-01T02:34:23.263171"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models",
    "paper_url": "https://huggingface.co/papers/2601.21282",
    "authors": [
      "Pranay Boreddy",
      "Ayush Agrawal",
      "Jim Solomon",
      "Howard Zhang",
      "Rishi Upadhyay"
    ],
    "stars": "0",
    "details": {
      "title": "WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models",
      "abstract": "WorldBench provides a disentangled, concept-specific video benchmark to rigorously evaluate physical reasoning in world models and their video generation.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21282",
      "pdf_url": "https://arxiv.org/pdf/2601.21282",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21282",
      "scraped_at": "2026-02-01T02:34:25.095867"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation",
    "paper_url": "https://huggingface.co/papers/2601.20381",
    "authors": [
      "Liming Chen",
      "Emmanuel Dellandr√©a",
      "Beegbrain"
    ],
    "stars": "0",
    "details": {
      "title": "STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation",
      "abstract": "We introduce a slot-based object-centric method with a \"task-awareness\" alignment in order to learn robotic manipulation. Our method obtains strong generalization improvements over existing VFM by simply adding a few layers of structure and keeping the backbone frozen. We hope this work can lead to more work going in the direction of adding structure in the visual inputs for robotics manipulation.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20381",
      "pdf_url": "https://arxiv.org/pdf/2601.20381",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20381",
      "scraped_at": "2026-02-01T02:34:26.937043"
    },
    "scraped_date": "2026-02-01"
  },
  {
    "title": "Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives",
    "paper_url": "https://huggingface.co/papers/2601.20833",
    "authors": [],
    "stars": "322",
    "details": {
      "title": "Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives",
      "abstract": "arXivLens breakdown of this paper üëâ https://arxivlens.com/PaperView/Details/idea2story-an-automated-pipeline-for-transforming-research-concepts-into-complete-scientific-narratives-2345-6407a884 Executive Summary Detailed Breakdown Practical Applications",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20833",
      "pdf_url": "https://arxiv.org/pdf/2601.20833",
      "github_links": [
        "https://github.com/AgentAlphaAGI/Idea2Paper"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20833",
      "scraped_at": "2026-02-02T02:24:08.763828"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models",
    "paper_url": "https://huggingface.co/papers/2601.20354",
    "authors": [],
    "stars": "98",
    "details": {
      "title": "Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models",
      "abstract": "A very interesting benchmark (ICLR2026) for T2I models!",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20354",
      "pdf_url": "https://arxiv.org/pdf/2601.20354",
      "github_links": [
        "https://github.com/AMAP-ML/SpatialGenEval"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20354",
      "scraped_at": "2026-02-02T02:24:10.746396"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Scaling Embeddings Outperforms Scaling Experts in Language Models",
    "paper_url": "https://huggingface.co/papers/2601.21204",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Scaling Embeddings Outperforms Scaling Experts in Language Models",
      "abstract": "Embedding scaling can outperform mixture of experts for sparse language models, aided by system optimizations and speculative decoding, with LongCat-Flash-Lite achieving strong competitiveness.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21204",
      "pdf_url": "https://arxiv.org/pdf/2601.21204",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21204",
      "scraped_at": "2026-02-02T02:24:12.849094"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation",
    "paper_url": "https://huggingface.co/papers/2601.22153",
    "authors": [],
    "stars": "79",
    "details": {
      "title": "DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation",
      "abstract": "TL; DR: DynamicVLA enables open-ended dynamic object manipulation by pairing a compact 0.4B VLM with low-latency Continuous Inference and Latent-aware Action Streaming, evaluated at scale through the new DOM benchmark in both simulation and the real world. GitHub: https://github.com/hzxie/DynamicVLA Project Page: https://haozhexie.com/project/dynamic-vla Spotlight Video: https://www.youtube.com/watch?v=NmJnHcI04_Q",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22153",
      "pdf_url": "https://arxiv.org/pdf/2601.22153",
      "github_links": [
        "https://github.com/hzxie/DynamicVLA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22153",
      "scraped_at": "2026-02-02T02:24:14.944949"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods",
    "paper_url": "https://huggingface.co/papers/2601.21821",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods",
      "abstract": "Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a \"less is more\" phenomenon via our difficulty-aware filtering strategy: a subset of just 7% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21821",
      "pdf_url": "https://arxiv.org/pdf/2601.21821",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21821",
      "scraped_at": "2026-02-02T02:24:16.945932"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models",
    "paper_url": "https://huggingface.co/papers/2601.21639",
    "authors": [
      "Liming Zheng",
      "Wenkang Han",
      "Xuanle Zhao",
      "Lei Chen",
      "Albert-Zhong"
    ],
    "stars": "20",
    "details": {
      "title": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models",
      "abstract": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21639",
      "pdf_url": "https://arxiv.org/pdf/2601.21639",
      "github_links": [
        "https://github.com/DocTron-hub/OCRVerse"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21639",
      "scraped_at": "2026-02-02T02:24:18.907249"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation",
    "paper_url": "https://huggingface.co/papers/2601.21420",
    "authors": [],
    "stars": "17",
    "details": {
      "title": "ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation",
      "abstract": "ConceptMoE shifts language model processing from uniform token-level to adaptive concept-level computation. By learning to merge semantically similar tokens into unified concepts while preserving fine-grained granularity for complex tokens, it performs implicit compute allocation‚Äîautomatically investing computation where needed. Key results: (1) Fair comparison under identical parameters and FLOPs shows consistent gains across language (+0.9), vision-language (+0.6, +2.3 on long context), and continual training (+5.5 with layer loops, +6.4 from scratch). (2) Inherent efficiency: at compression ratio R=2, attention computation reduces by R¬≤√ó and KV cache by R√ó, achieving prefill speedups up to 175% and decoding speedups up to 117%. (3) Minimal architectural changes (chunk module + decoder QKV projectors) enable straightforward deployment in existing MoE systems. Represents a paradigm shift toward hierarchical semantic processing in LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21420",
      "pdf_url": "https://arxiv.org/pdf/2601.21420",
      "github_links": [
        "https://github.com/ZihaoHuang-notabot/ConceptMoE"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21420",
      "scraped_at": "2026-02-02T02:24:20.852622"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Qwen3-ASR Technical Report",
    "paper_url": "https://huggingface.co/papers/2601.21337",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Qwen3-ASR Technical Report",
      "abstract": "Qwen3-ASR delivers two all-in-one ASR models with 52-language support and a non-autoregressive forced-aligner; achieves competitive SOTA accuracy, fast TTFT, and open-source Apache 2.0 release.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21337",
      "pdf_url": "https://arxiv.org/pdf/2601.21337",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21337",
      "scraped_at": "2026-02-02T02:24:22.868564"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Exploring Reasoning Reward Model for Agents",
    "paper_url": "https://huggingface.co/papers/2601.22154",
    "authors": [
      "Zhixun Li",
      "Tianshuo Peng",
      "Manyuan Zhang",
      "Kaituo Feng",
      "bunny127"
    ],
    "stars": "22",
    "details": {
      "title": "Exploring Reasoning Reward Model for Agents",
      "abstract": "Github: https://github.com/kxfan2002/Reagent Paper: https://arxiv.org/pdf/2601.22154",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22154",
      "pdf_url": "https://arxiv.org/pdf/2601.22154",
      "github_links": [
        "https://github.com/kxfan2002/Reagent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22154",
      "scraped_at": "2026-02-02T02:24:24.837601"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction",
    "paper_url": "https://huggingface.co/papers/2601.22046",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction",
      "abstract": "PLANING introduces a loosely coupled triangle-Gaussian representation and a monocular streaming framework that jointly achieves accurate geometry, high-fidelity rendering, and efficient planar abstraction for embodied AI applications.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22046",
      "pdf_url": "https://arxiv.org/pdf/2601.22046",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22046",
      "scraped_at": "2026-02-02T02:24:26.850927"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts",
    "paper_url": "https://huggingface.co/papers/2601.20730",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts",
      "abstract": "The evolution of Large Language Models (LLMs) into autonomous agents necessitates the management of extensive, dynamic contexts. Current benchmarks, however, remain largely static, relying on passive retrieval tasks that fail to simulate the complexities of agent-environment interaction, such as non-linear reasoning and iterative feedback. To address this, we introduce \\textbf{AgentLongBench}, which evaluates agents through simulated environment rollouts based on Lateral Thinking Puzzles. This framework generates rigorous interaction trajectories across knowledge-intensive and knowledge-free scenarios. Experiments with state-of-the-art models and memory systems (32K to 4M tokens) expose a critical weakness: while adept at static retrieval, agents struggle with the dynamic information synthesis essential for workflows. Our analysis indicates that this degradation is driven by the minimum number of tokens required to resolve a query. This factor explains why the high information density inherent in massive tool responses poses a significantly greater challenge than the memory fragmentation typical of long-turn dialogues. The code is available at https://github.com/euReKa025/AgentLongBench .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20730",
      "pdf_url": "https://arxiv.org/pdf/2601.20730",
      "github_links": [
        "https://github.com/euReKa025/AgentLongBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20730",
      "scraped_at": "2026-02-02T02:24:28.792252"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Shaping capabilities with token-level data filtering",
    "paper_url": "https://huggingface.co/papers/2601.21571",
    "authors": [],
    "stars": "49",
    "details": {
      "title": "Shaping capabilities with token-level data filtering",
      "abstract": "Key Findings: 1. Token-level Filtering vs Document-level Filtering (Figure 3) Token filtering Pareto-dominates document filtering : Can achieve equal reduction in undesired capabilities (equal medical loss) at lower cost to desired capabilities (lower biology loss) More precise filtering preserves beneficial content better 2. Scaling Effects (Figures 1, 4, 5, 6) Filtering gets more effective with scale : 1.8B parameter models see 7,000√ó compute slowdown on medical domain Document filtering: ~30√ó slowdown Token removal: >7,000√ó slowdown Multiple choice evaluation : Models score near chance on MedMCQA and MedQA-USMLE (medical), but maintain performance on retain domains Free response : Token filtering reduces medical answer correctness up to 20√ó, relevance/coherence 3√ó compared to baseline 3. Robustness to Attacks (Figure 7) 10√ó more robust than unlearning against adversarial finetuning attacks for 1.8B models State-of-the-art unlearning (RMU) requires 13√ó fewer tokens to recover capabilities compared to token removal 4. Alignment Compatibility (Figures 8, 9) Models can still be aligned on forget domain : Token-level filtering makes refusal training easier (2√ó better refusal generalization) Document filtering struggles with alignment generalization Linear probes show models can distinguish forget vs. retain tokens despite filtering 5. Classifier Training (Table 1, Figure 11) Small, task-specific models outperform large general ones : 224M parameter biLM achieves 0.894 F1 on test set Outperforms 395M ModernBERT-large (0.794 F1) Domain-specific pretraining improves performance 6. Label Quality Tolerance (Figures 12, 13, 14, 15) Robust to imperfect labels : Aggressive filtering with sufficient compute can overcome label noise Token-level classifiers generalize from weak labels better than document-level Can trade precision for recall to maintain effectiveness",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21571",
      "pdf_url": "https://arxiv.org/pdf/2601.21571",
      "github_links": [
        "https://github.com/neilrathi/token-filtering"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21571",
      "scraped_at": "2026-02-02T02:24:30.794548"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems",
    "paper_url": "https://huggingface.co/papers/2601.17883",
    "authors": [],
    "stars": "48",
    "details": {
      "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems",
      "abstract": "We propose fair and comprehensive benchmarking for open source EEG foundation models.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.17883",
      "pdf_url": "https://arxiv.org/pdf/2601.17883",
      "github_links": [
        "https://github.com/Dingkun0817/EEG-FM-Benchmark"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.17883",
      "scraped_at": "2026-02-02T02:24:32.727889"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Discovering Hidden Gems in Model Repositories",
    "paper_url": "https://huggingface.co/papers/2601.22157",
    "authors": [
      "Yedid Hoshen",
      "Eliahu Horwitz",
      "Jonathan Kahana"
    ],
    "stars": "0",
    "details": {
      "title": "Discovering Hidden Gems in Model Repositories",
      "abstract": "An investigation of the available fine-tunes of popular foundation models. While over 90% of downloads are directed to the official base versions the paper shows the existence of other, rarely downloaded fine-tunes that significantly outperform them.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22157",
      "pdf_url": "https://arxiv.org/pdf/2601.22157",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22157",
      "scraped_at": "2026-02-02T02:24:34.629118"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Language-based Trial and Error Falls Behind in the Era of Experience",
    "paper_url": "https://huggingface.co/papers/2601.21754",
    "authors": [],
    "stars": "8",
    "details": {
      "title": "Language-based Trial and Error Falls Behind in the Era of Experience",
      "abstract": "While Large Language Models (LLMs) excel in language-based agentic tasks, their applicability to unseen, nonlinguistic environments (e.g., symbolic or spatial tasks) remains limited. Previous work attributes this performance gap to the mismatch between the pretraining distribution and the testing distribution. In this work, we demonstrate the primary bottleneck is the prohibitive cost of exploration: mastering these tasks requires extensive trial-and-error, which is computationally unsustainable for parameter-heavy LLMs operating in a high dimensional semantic space. To address this, we propose SCOUT (Sub-Scale Collaboration On Unseen Tasks), a novel framework that decouples exploration from exploitation. We employ lightweight \"scouts\" (e.g., small MLPs) to probe environmental dynamics at a speed and scale far exceeding LLMs. The collected trajectories are utilized to bootstrap the LLM via Supervised Fine-Tuning (SFT), followed by multi-turn Reinforcement Learning (RL) to activate its latent world knowledge. Empirically, SCOUT enables a Qwen2.5-3B-Instruct model to achieve an average score of 0.86, significantly outperforming proprietary models, including Gemini-2.5-Pro (0.60), while saving about 60% GPU hours consumption.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21754",
      "pdf_url": "https://arxiv.org/pdf/2601.21754",
      "github_links": [
        "https://github.com/Harry-mic/SCOUT"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21754",
      "scraped_at": "2026-02-02T02:24:36.580671"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "LoL: Longer than Longer, Scaling Video Generation to Hour",
    "paper_url": "https://huggingface.co/papers/2601.16914",
    "authors": [
      "Xiaojie Li",
      "Tao Yang",
      "Ming Li",
      "Jie Wu",
      "Justin Cui"
    ],
    "stars": "0",
    "details": {
      "title": "LoL: Longer than Longer, Scaling Video Generation to Hour",
      "abstract": "Scaling up video generation to hour long, please checkout our paper at: https://arxiv.org/abs/2601.16914 Project Page and code will released at: https://github.com/justincui03/LoL",
      "arxiv_page_url": "https://arxiv.org/abs/2601.16914",
      "pdf_url": "https://arxiv.org/pdf/2601.16914",
      "github_links": [
        "https://github.com/justincui03/LoL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.16914",
      "scraped_at": "2026-02-02T02:24:38.465226"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Latent Adversarial Regularization for Offline Preference Optimization",
    "paper_url": "https://huggingface.co/papers/2601.22083",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Latent Adversarial Regularization for Offline Preference Optimization",
      "abstract": "Most offline preference optimization methods (e.g., DPO) constrain policy updates using token-level divergences. However, token-space similarity is often a weak proxy for semantic or structural behavior. We propose GANPO, a plug-and-play regularizer that introduces latent-space adversarial regularization, aligning the latent representation distributions of a policy and a reference model via a principled GAN-style divergence. We find consistent performance improvements. GANPO yields consistent gains across model architectures when integrated into OPO-style methods on AlpacaEval. We also find that structure is preserved. The adversarial objective acts as a geometry-preserving regularizer. Unlike DPO, which often degrades at high sampling temperatures (T ‚â• 1.0), GANPO maintains structural coherence in high-entropy settings. If you‚Äôre interested in alignment, GANs, or the limitations of KL-divergence‚Äìbased regularization, feel free to check out the paper.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22083",
      "pdf_url": "https://arxiv.org/pdf/2601.22083",
      "github_links": [
        "https://github.com/enyijiang/GANPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22083",
      "scraped_at": "2026-02-02T02:24:40.449934"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening",
    "paper_url": "https://huggingface.co/papers/2601.21590",
    "authors": [
      "Haitham Bou Ammar",
      "Matthieu Zimmer",
      "Rasul Tutunov",
      "xtongji"
    ],
    "stars": "0",
    "details": {
      "title": "Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening",
      "abstract": "What if RL isn‚Äôt teaching LLMs how to reason, but just sharpening what‚Äôs already there? Most recent progress in LLM reasoning comes from RL post-training (GRPO, verifiers, rewards). But there‚Äôs growing evidence that these gains may come less from learning new capabilities and more from reshaping the distribution of outputs. In our new work, we take that idea seriously. We show that: Reasoning trajectories already exist in base models What matters is how you sample, not how you retrain The global power distribution can be approximated autoregressively, without MCMC The result is a training-free, verifier-free inference-time method that: ‚ö° Matches GRPO-style post-training ‚è± Is ~10√ó faster than MCMC-based power sampling üß™ Requires no rewards, no finetuning, no verifier Conceptually, the key insight is simple: Power sampling ‚âà low-temperature sampling √ó future-aware token scaling This lets us recover global reasoning behaviour token by token, without expensive trajectory-level inference.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21590",
      "pdf_url": "https://arxiv.org/pdf/2601.21590",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21590",
      "scraped_at": "2026-02-02T02:24:42.439814"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report",
    "paper_url": "https://huggingface.co/papers/2601.21051",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report",
      "abstract": "Model card: https://huggingface.co/fdtn-ai/Foundation-Sec-8B-Reasoning",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21051",
      "pdf_url": "https://arxiv.org/pdf/2601.21051",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21051",
      "scraped_at": "2026-02-02T02:24:44.602632"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Self-Improving Pretraining: using post-trained models to pretrain better models",
    "paper_url": "https://huggingface.co/papers/2601.21343",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Self-Improving Pretraining: using post-trained models to pretrain better models",
      "abstract": "Streaming pretraining uses a strong post-trained model to judge next-token generations with RL, improving quality, safety, and factuality earlier in training.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21343",
      "pdf_url": "https://arxiv.org/pdf/2601.21343",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21343",
      "scraped_at": "2026-02-02T02:24:46.525589"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.18129",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models",
      "abstract": "Code: https://github.com/scb-10x/typhoon-s Artifact: https://huggingface.co/collections/typhoon-ai/typhoon-s",
      "arxiv_page_url": "https://arxiv.org/abs/2601.18129",
      "pdf_url": "https://arxiv.org/pdf/2601.18129",
      "github_links": [
        "https://github.com/scb-10x/typhoon-s"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.18129",
      "scraped_at": "2026-02-02T02:24:48.451524"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "One-step Latent-free Image Generation with Pixel Mean Flows",
    "paper_url": "https://huggingface.co/papers/2601.22158",
    "authors": [
      "Zhicheng Jiang",
      "Hanhong Zhao",
      "Qiao Sun",
      "Susie Lu",
      "Yiyang Lu"
    ],
    "stars": "0",
    "details": {
      "title": "One-step Latent-free Image Generation with Pixel Mean Flows",
      "abstract": "One-step Latent-free Image Generation with Pixel Mean Flows",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22158",
      "pdf_url": "https://arxiv.org/pdf/2601.22158",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22158",
      "scraped_at": "2026-02-02T02:24:50.401436"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts",
    "paper_url": "https://huggingface.co/papers/2601.22156",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts",
      "abstract": "Code: https://www.github.com/THUNLP/hybrid-linear-attention",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22156",
      "pdf_url": "https://arxiv.org/pdf/2601.22156",
      "github_links": [
        "https://www.github.com/THUNLP/hybrid-linear-attention",
        "https://github.com/thunlp/hybrid-linear-attention"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22156",
      "scraped_at": "2026-02-02T02:24:52.320457"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.22069",
    "authors": [],
    "stars": "16",
    "details": {
      "title": "VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning",
      "abstract": "We propose VTC-R1, an efficient long-context reasoning paradigm that integrates vision-text compression into iterative reasoning. By rendering previous reasoning segments into compact visual representations, VTC-R1 replaces long textual contexts with significantly fewer vision tokens in a lightweight and model-free manner. Extensive experiments show that VTC-R1 consistently improves reasoning accuracy across multiple benchmarks while achieving up to 3.4x token compression and 2.7x end-to-end inference speedup. The results demonstrate that VTC-R1 provides an effective alternative representation for scalable long-context reasoning. We hope our work would inspire further exploration of efficient reasoning beyond pure text-based paradigms.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22069",
      "pdf_url": "https://arxiv.org/pdf/2601.22069",
      "github_links": [
        "https://github.com/w-yibo/VTC-R1"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22069",
      "scraped_at": "2026-02-02T02:24:54.249712"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.21181",
    "authors": [
      "Yong Man Ro",
      "Youngchae Chee",
      "Se Yeon Kim",
      "topyun"
    ],
    "stars": "0",
    "details": {
      "title": "MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models",
      "abstract": "Multimodal Large Language Models (MLLMs) suffer from cross-modal hallucinations, where one modality inappropriately influences generation about another, leading to fabricated output. This exposes a more fundamental deficiency in modality-interaction control. To address this, we propose Modality-Adaptive Decoding (MAD), a training-free method that adaptively weights modality-specific decoding branches based on task requirements. MAD leverages the model's inherent ability to self-assess modality relevance by querying which modalities are needed for each task. The extracted modality probabilities are then used to adaptively weight contrastive decoding branches, enabling the model to focus on relevant information while suppressing cross-modal interference. Extensive experiments on CMM and AVHBench demonstrate that MAD significantly reduces cross-modal hallucinations across multiple audio-visual language models (7.8% and 2.0% improvements for VideoLLaMA2-AV, 8.7% and 4.7% improvements for Qwen2.5-Omni). Our approach demonstrates that explicit modality awareness through self-assessment is crucial for robust multimodal reasoning, offering a principled extension to existing contrastive decoding methods.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21181",
      "pdf_url": "https://arxiv.org/pdf/2601.21181",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21181",
      "scraped_at": "2026-02-02T02:24:56.143073"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents",
    "paper_url": "https://huggingface.co/papers/2601.20975",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents",
      "abstract": "Proposes DeepSearchQA, a 900-prompt benchmark across 17 fields to test long-horizon search, info synthesis, deduplication, and stopping criteria for open-web research agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20975",
      "pdf_url": "https://arxiv.org/pdf/2601.20975",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20975",
      "scraped_at": "2026-02-02T02:24:58.309116"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Beyond Imitation: Reinforcement Learning for Active Latent Planning",
    "paper_url": "https://huggingface.co/papers/2601.21598",
    "authors": [
      "Wee Sun Lee",
      "zz1358m"
    ],
    "stars": "0",
    "details": {
      "title": "Beyond Imitation: Reinforcement Learning for Active Latent Planning",
      "abstract": "Our recent work on Latent Reasoning",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21598",
      "pdf_url": "https://arxiv.org/pdf/2601.21598",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21598",
      "scraped_at": "2026-02-02T02:25:00.362508"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices",
    "paper_url": "https://huggingface.co/papers/2601.21579",
    "authors": [
      "Danilo Mandic",
      "Giorgos Iacovides",
      "Yuxuan Gu",
      "WuyangZzzz"
    ],
    "stars": "3",
    "details": {
      "title": "KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices",
      "abstract": "KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21579",
      "pdf_url": "https://arxiv.org/pdf/2601.21579",
      "github_links": [
        "https://github.com/wz1119/KromHC"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21579",
      "scraped_at": "2026-02-02T02:25:02.250183"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale",
    "paper_url": "https://huggingface.co/papers/2601.22146",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale",
      "abstract": "@ AjayP13 and @ craffel really interesting work and approach, do you plan to add support for multilingual instructions ü§î",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22146",
      "pdf_url": "https://arxiv.org/pdf/2601.22146",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22146",
      "scraped_at": "2026-02-02T02:25:04.504788"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "ECO: Quantized Training without Full-Precision Master Weights",
    "paper_url": "https://huggingface.co/papers/2601.22101",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ECO: Quantized Training without Full-Precision Master Weights",
      "abstract": "We present Error-Compensating Optimizer (ECO), which integrates with standard optimizers and, for the first time, enables quantized training of large-scale LLMs without requiring high-precision master weights.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22101",
      "pdf_url": "https://arxiv.org/pdf/2601.22101",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22101",
      "scraped_at": "2026-02-02T02:25:06.378922"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion",
    "paper_url": "https://huggingface.co/papers/2601.22143",
    "authors": [
      "Urska Jelercic",
      "Matan Ben Yosef",
      "Tavi Halperin",
      "Naomi Ken Korem",
      "Anthony Chen"
    ],
    "stars": "0",
    "details": {
      "title": "JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22143",
      "pdf_url": "https://arxiv.org/pdf/2601.22143",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22143",
      "scraped_at": "2026-02-02T02:25:08.517305"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources",
    "paper_url": "https://huggingface.co/papers/2601.22054",
    "authors": [
      "Jianxun Cui",
      "Xuancheng Zhang",
      "Donglin Di",
      "Baorui Ma",
      "yjh001"
    ],
    "stars": "67",
    "details": {
      "title": "MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources",
      "abstract": "Project Page: https://metric-anything.github.io/metric-anything-io/ Code: https: https://github.com/metric-anything/metric-anything",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22054",
      "pdf_url": "https://arxiv.org/pdf/2601.22054",
      "github_links": [
        "https://github.com/metric-anything/metric-anything"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22054",
      "scraped_at": "2026-02-02T02:25:10.763168"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
    "paper_url": "https://huggingface.co/papers/2601.21996",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
      "abstract": "We introduce Mechanistic Data Attribution (MDA), a new paradigm that shifts the focus of mechanistic interpretability from post-hoc circuit analysis to the causal formation of these mechanisms during training.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21996",
      "pdf_url": "https://arxiv.org/pdf/2601.21996",
      "github_links": [
        "https://github.com/chenjianhuii/Mechanistic-Data-Attribution"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21996",
      "scraped_at": "2026-02-02T02:25:13.113858"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation",
    "paper_url": "https://huggingface.co/papers/2601.21406",
    "authors": [
      "Guanhua Chen",
      "Yong Wang",
      "Kangrui Cen",
      "Hongyang Wei",
      "Zihan Su"
    ],
    "stars": "10",
    "details": {
      "title": "Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation",
      "abstract": "Paper: https://arxiv.org/abs/2601.21406 Github: https://github.com/Sugewud/UniMRG Project: https://sugewud.github.io/UniMRG-Project/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21406",
      "pdf_url": "https://arxiv.org/pdf/2601.21406",
      "github_links": [
        "https://github.com/Sugewud/UniMRG"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21406",
      "scraped_at": "2026-02-02T02:25:15.252387"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "BMAM: Brain-inspired Multi-Agent Memory Framework",
    "paper_url": "https://huggingface.co/papers/2601.20465",
    "authors": [
      "Mingkun Xu",
      "Yujie Wu",
      "Yusong Wang",
      "Jiaxiang Liu",
      "innovation64"
    ],
    "stars": "2",
    "details": {
      "title": "BMAM: Brain-inspired Multi-Agent Memory Framework",
      "abstract": "We introduce BMAM (Brain-inspired Multi-Agent Memory), a general-purpose memory architecture designed to solve \"soul erosion\"‚Äîthe loss of temporal grounding and consistency in long-term agent interactions. üß† Key Innovations: Cognitive-inspired Architecture: Decomposes memory into episodic, semantic, salience-aware, and control-oriented components. Temporal Grounding: Operates at complementary time scales to maintain behavioral consistency. Plug-and-play: A general framework for LLM-based multi-agent systems. Check out our preprint for details on how we bridge the gap between biological memory systems and AI agents!",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20465",
      "pdf_url": "https://arxiv.org/pdf/2601.20465",
      "github_links": [
        "https://github.com/innovation64/BMAM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20465",
      "scraped_at": "2026-02-02T02:25:17.419648"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.19001",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning",
      "abstract": "ICLR2026",
      "arxiv_page_url": "https://arxiv.org/abs/2601.19001",
      "pdf_url": "https://arxiv.org/pdf/2601.19001",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.19001",
      "scraped_at": "2026-02-02T02:25:19.341557"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels",
    "paper_url": "https://huggingface.co/papers/2601.21268",
    "authors": [
      "Jesse Roberts",
      "Micah Rentschler"
    ],
    "stars": "0",
    "details": {
      "title": "Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels",
      "abstract": "We present Reinforcement Learning from Meta-Evaluation (RLME), a label-free RL framework that trains LLMs using evaluator judgments to natural-language meta-questions, achieving performance comparable to supervised rewards while scaling to ambiguous, open-domain tasks.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21268",
      "pdf_url": "https://arxiv.org/pdf/2601.21268",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21268",
      "scraped_at": "2026-02-02T02:25:21.212465"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis",
    "paper_url": "https://huggingface.co/papers/2601.20103",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis",
      "abstract": "We show that contrasting reward hacks in an outlier detection setting helps LLMs detect code hacking behaviors. We further show that a cluster's benign-to-hacked trajectory ratio influences this detection rate. Finally we perform thorough QA and show that semantically contextualized hacks are more difficult to detect as compared to syntactic ones. We release TRACE, a synthetic, human verified dataset of 517 trajectories spanning 54 code reward hack categories to help the community build robust automated RL orchestration pipelines.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20103",
      "pdf_url": "https://arxiv.org/pdf/2601.20103",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20103",
      "scraped_at": "2026-02-02T02:25:23.283574"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Flow-based Extremal Mathematical Structure Discovery",
    "paper_url": "https://huggingface.co/papers/2601.18005",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Flow-based Extremal Mathematical Structure Discovery",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.18005",
      "pdf_url": "https://arxiv.org/pdf/2601.18005",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.18005",
      "scraped_at": "2026-02-02T02:25:25.204882"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance",
    "paper_url": "https://huggingface.co/papers/2601.17690",
    "authors": [
      "Melody Ma",
      "Iram Kamdar",
      "Yunyan Ouyang",
      "Ziling Gong",
      "Franck-Dernoncourt"
    ],
    "stars": "0",
    "details": {
      "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Lightweight Resolution-Aware Audio Deepfake Detection via Cross-Scale Attention and Consistency Learning (2026) BEST-STD2.0: Balanced and Efficient Speech Tokenizer for Spoken Term Detection (2025) VIBEVOICE-ASR Technical Report (2026) DAME: Duration-Aware Matryoshka Embedding for Duration-Robust Speaker Verification (2026) Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding (2025) LongSpeech: A Scalable Benchmark for Transcription, Translation and Understanding in Long Speech (2026) SpeechQualityLLM: LLM-Based Multimodal Assessment of Speech Quality (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.17690",
      "pdf_url": "https://arxiv.org/pdf/2601.17690",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.17690",
      "scraped_at": "2026-02-02T02:25:27.048523"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement",
    "paper_url": "https://huggingface.co/papers/2601.11747",
    "authors": [
      "Stefano Petrangeli",
      "Yu Shen",
      "Sunav Choudhary",
      "Huaxiaoyue Wang",
      "Franck-Dernoncourt"
    ],
    "stars": "0",
    "details": {
      "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API MiLDEdit: Reasoning-Based Multi-Layer Design Document Editing (2026) Styles + Persona-plug = Customized LLMs (2026) Step-by-step Layered Design Generation (2025) Widget2Code: From Visual Widgets to UI Code via Multimodal LLMs (2025) Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation (2025) ShowTable: Unlocking Creative Table Visualization with Collaborative Reflection and Refinement (2025) Aligning Text, Code, and Vision: A Multi-Objective Reinforcement Learning Framework for Text-to-Visualization (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.11747",
      "pdf_url": "https://arxiv.org/pdf/2601.11747",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.11747",
      "scraped_at": "2026-02-02T02:25:29.819440"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents",
    "paper_url": "https://huggingface.co/papers/2601.21872",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents",
      "abstract": "Accepted at ICLR 2026",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21872",
      "pdf_url": "https://arxiv.org/pdf/2601.21872",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21872",
      "scraped_at": "2026-02-02T02:25:31.993094"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation",
    "paper_url": "https://huggingface.co/papers/2601.21416",
    "authors": [
      "Liming Chen",
      "Emmanuel Dellandr√©a",
      "Bruno Machado",
      "Beegbrain"
    ],
    "stars": "0",
    "details": {
      "title": "Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation",
      "abstract": "The ability of visuomotor policies to generalize across tasks and environments critically depends on the structure of the underlying visual representations. While most state-of-the-art robot policies rely on either global or dense features from pre-trained vision models, these approaches often entangle task-relevant and irrelevant signals, limiting their robustness to visual distribution shifts. In this paper, we investigate Slot-based Object-Centric Representations (SOCRs) as a structured alternative that decomposes scenes into a finite set of object-like entities. We present the first large-scale, systematic comparison of global, dense, and object-centric representations across diverse simulated (METAWORLD, LIBERO) and real-world robotic manipulation tasks. Our results show that SOCRs enable superior policy performance and significantly improve generalization under shifts in lighting, texture, and clutter‚Äî even without task-specific tuning. We further demonstrate that pretraining SOCRs on robotic video datasets amplifies these benefits. Our findings highlight the importance of structured visual abstraction in robotic perception and suggest that SOCRs offer a promising pathway toward more robust and generaliz- able manipulation policies.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21416",
      "pdf_url": "https://arxiv.org/pdf/2601.21416",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21416",
      "scraped_at": "2026-02-02T02:25:33.857071"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models",
    "paper_url": "https://huggingface.co/papers/2601.21282",
    "authors": [
      "Pranay Boreddy",
      "Ayush Agrawal",
      "Jim Solomon",
      "Howard Zhang",
      "Rishi Upadhyay"
    ],
    "stars": "0",
    "details": {
      "title": "WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models",
      "abstract": "WorldBench provides a disentangled, concept-specific video benchmark to rigorously evaluate physical reasoning in world models and their video generation.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21282",
      "pdf_url": "https://arxiv.org/pdf/2601.21282",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21282",
      "scraped_at": "2026-02-02T02:25:35.699878"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation",
    "paper_url": "https://huggingface.co/papers/2601.20381",
    "authors": [
      "Liming Chen",
      "Emmanuel Dellandr√©a",
      "Beegbrain"
    ],
    "stars": "0",
    "details": {
      "title": "STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation",
      "abstract": "We introduce a slot-based object-centric method with a \"task-awareness\" alignment in order to learn robotic manipulation. Our method obtains strong generalization improvements over existing VFM by simply adding a few layers of structure and keeping the backbone frozen. We hope this work can lead to more work going in the direction of adding structure in the visual inputs for robotics manipulation.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20381",
      "pdf_url": "https://arxiv.org/pdf/2601.20381",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20381",
      "scraped_at": "2026-02-02T02:25:37.542856"
    },
    "scraped_date": "2026-02-02"
  },
  {
    "title": "ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas",
    "paper_url": "https://huggingface.co/papers/2601.21558",
    "authors": [
      "Hao Zhou",
      "Shuaiting Chen",
      "Haotian Wang",
      "jade0101",
      "Emperorizzis"
    ],
    "stars": "84",
    "details": {
      "title": "ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas",
      "abstract": "ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21558",
      "pdf_url": "https://arxiv.org/pdf/2601.21558",
      "github_links": [
        "https://github.com/LianjiaTech/astra"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21558",
      "scraped_at": "2026-02-03T02:15:28.439188"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Quartet II: Accurate LLM Pre-Training in NVFP4 by Improved Unbiased Gradient Estimation",
    "paper_url": "https://huggingface.co/papers/2601.22813",
    "authors": [],
    "stars": "5",
    "details": {
      "title": "Quartet II: Accurate LLM Pre-Training in NVFP4 by Improved Unbiased Gradient Estimation",
      "abstract": "A SOTA NVFP4 LLM pre-training method based on MS-EDEN unbiased gradient estimation. Code is available on GitHub .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22813",
      "pdf_url": "https://arxiv.org/pdf/2601.22813",
      "github_links": [
        "https://github.com/IST-DASLab/Quartet-II"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22813",
      "scraped_at": "2026-02-03T02:15:30.368866"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text",
    "paper_url": "https://huggingface.co/papers/2601.22975",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Golden Goose: A Simple Trick to Synthesize Unlimited RLVR Tasks from Unverifiable Internet Text",
      "abstract": "TL;DR: We introduce Golden Goose ü¶¢, a simple method that synthesizes unlimited RLVR tasks from unverifiable internet text by constructing multiple-choice fill-in-the-middle problems. This enables the use of reasoning-rich unverifiable corpora typically excluded from prior RLVR data curation (e.g., science textbooks), allowing RL to scale beyond the data saturation of existing RLVR datasets and achieving new SoTA results on 1.5B and 4B-Instruct models . In a real-world deployment to cybersecurity, where no prior RLVR data exists, Golden Goose synthesizes RLVR tasks from raw FineWeb scrapes, yielding a new SoTA 4B cybersecurity LLM that surpasses a 7B domain-specialized model .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22975",
      "pdf_url": "https://arxiv.org/pdf/2601.22975",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22975",
      "scraped_at": "2026-02-03T02:15:32.373504"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "THINKSAFE: Self-Generated Safety Alignment for Reasoning Models",
    "paper_url": "https://huggingface.co/papers/2601.23143",
    "authors": [
      "Minki Kang",
      "Gyeongman Kim",
      "YuminChoi",
      "Sangsang",
      "Seanie-lee"
    ],
    "stars": "3",
    "details": {
      "title": "THINKSAFE: Self-Generated Safety Alignment for Reasoning Models",
      "abstract": "THINKSAFE: Self-Generated Safety Alignment for Reasoning Models",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23143",
      "pdf_url": "https://arxiv.org/pdf/2601.23143",
      "github_links": [
        "https://github.com/seanie12/ThinkSafe.git"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23143",
      "scraped_at": "2026-02-03T02:15:34.303739"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "TTCS: Test-Time Curriculum Synthesis for Self-Evolving",
    "paper_url": "https://huggingface.co/papers/2601.22628",
    "authors": [
      "Chengsong Huang",
      "Zongpei Teng",
      "Yunbo Tang",
      "Zhishang Xiang",
      "ChengyiYang"
    ],
    "stars": "19",
    "details": {
      "title": "TTCS: Test-Time Curriculum Synthesis for Self-Evolving",
      "abstract": "TTCS, a new paradigm for self-evolving",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22628",
      "pdf_url": "https://arxiv.org/pdf/2601.22628",
      "github_links": [
        "https://github.com/XMUDeepLIT/TTCS"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22628",
      "scraped_at": "2026-02-03T02:15:36.227648"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "PaperBanana: Automating Academic Illustration for AI Scientists",
    "paper_url": "https://huggingface.co/papers/2601.23265",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PaperBanana: Automating Academic Illustration for AI Scientists",
      "abstract": "PaperBanana automates publication-ready AI research illustrations via an agentic framework using VLMs and image models, orchestrating reference retrieval, planning, rendering, and self-critique with a benchmarking suite.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23265",
      "pdf_url": "https://arxiv.org/pdf/2601.23265",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23265",
      "scraped_at": "2026-02-03T02:15:38.164377"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Do Reasoning Models Enhance Embedding Models?",
    "paper_url": "https://huggingface.co/papers/2601.21192",
    "authors": [
      "Elton Chun-Chai Li",
      "Kwun Hang Lau",
      "Huihao Jing",
      "Shaojin Chen",
      "lucaswychan"
    ],
    "stars": "5",
    "details": {
      "title": "Do Reasoning Models Enhance Embedding Models?",
      "abstract": "Our analysis revealed a phenomenon we term Manifold Realignment. RLVR is a Trajectory Optimizer : We found that RLVR irreversibly reorganizes the local geometry of the latent manifold but largely preserves the global manifold geometry (the overall map of knowledge) and the linear readout of base models. Coordinate basis will alter substantially and reversibly only under prolonged RLVR. Contrastive Learning acts as an Equalizer : When we fine-tune these models to embedding models, the contrastive loss forces the base and reasoning models to align strongly again. The Takeaway for Practitioners: Our results suggest that the \"reasoning\" capability in current models is a learned policy for navigating the latent manifold , rather than a fundamental restructuring of the knowledge map itself. As latent-space-centric paradigms such as World Models and JEPA gain prominence, our findings point to a practical trade-off: RLVR tends to preserve the base model‚Äôs representational backbone (which may help retain broad generalization), yet on its own is unlikely to fundamentally improve the underlying global organization of the latent manifold. If RLVR‚Äôs distinctive footprint is local geometry reorganization under global geometry stability, then similar behavior might be achievable via SFT augmented with geometry- and basis-aware regularization .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21192",
      "pdf_url": "https://arxiv.org/pdf/2601.21192",
      "github_links": [
        "https://github.com/HKUST-KnowComp/Reasoning-Embedding"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21192",
      "scraped_at": "2026-02-03T02:15:40.123818"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "FourierSampler: Unlocking Non-Autoregressive Potential in Diffusion Language Models via Frequency-Guided Generation",
    "paper_url": "https://huggingface.co/papers/2601.23182",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "FourierSampler: Unlocking Non-Autoregressive Potential in Diffusion Language Models via Frequency-Guided Generation",
      "abstract": "Despite the non-autoregressive potential of diffusion language models (dLLMs), existing decoding strategies demonstrate positional bias, failing to fully unlock the potential of arbitrary generation. In this work, we delve into the inherent spectral characteristics of dLLMs and present the first frequency-domain analysis showing that low-frequency components in hidden states primarily encode global structural information and long-range dependencies, while high-frequency components are responsible for characterizing local details. Based on this observation, we propose FourierSampler, which leverages a frequency-domain sliding window mechanism to dynamically guide the model to achieve a \"structure-to-detail\" generation. FourierSampler outperforms other inference enhancement strategies on LLADA and SDAR, achieving relative improvements of 20.4% on LLaDA1.5-8B and 16.0% on LLaDA-8B-Instruct. It notably surpasses similarly sized autoregressive models like Llama3.1-8B-Instruct. Code is available at https://github.com/ShirleYoung/FourierSampler .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23182",
      "pdf_url": "https://arxiv.org/pdf/2601.23182",
      "github_links": [
        "https://github.com/ShirleYoung/FourierSampler"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23182",
      "scraped_at": "2026-02-03T02:15:42.069386"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Causal World Modeling for Robot Control",
    "paper_url": "https://huggingface.co/papers/2601.21998",
    "authors": [
      "Ruilin Wang",
      "Shuai Yang",
      "Yiming Luo",
      "Qihang Zhang",
      "Lin Li"
    ],
    "stars": "0",
    "details": {
      "title": "Causal World Modeling for Robot Control",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21998",
      "pdf_url": "https://arxiv.org/pdf/2601.21998",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21998",
      "scraped_at": "2026-02-03T02:15:44.064946"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought",
    "paper_url": "https://huggingface.co/papers/2601.23184",
    "authors": [
      "Zhifeng Gao",
      "Hongteng Xu",
      "Guojiang Zhao",
      "Haotian Liu",
      "FanmengWang"
    ],
    "stars": "15",
    "details": {
      "title": "ReGuLaR: Variational Latent Reasoning Guided by Rendered Chain-of-Thought",
      "abstract": "Introduces ReGuLaR, a variational latent reasoning framework that renders reasoning as images to regularize posterior inference, achieving efficient multimodal reasoning beyond traditional chain of thought.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23184",
      "pdf_url": "https://arxiv.org/pdf/2601.23184",
      "github_links": [
        "https://github.com/FanmengWang/ReGuLaR"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23184",
      "scraped_at": "2026-02-03T02:15:46.003959"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning",
    "paper_url": "https://huggingface.co/papers/2601.21716",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning",
      "abstract": "Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a \"see-saw\", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space, enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs, facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation. This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization. Project Page: https://grisoon.github.io/DreamActor-M2/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21716",
      "pdf_url": "https://arxiv.org/pdf/2601.21716",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21716",
      "scraped_at": "2026-02-03T02:15:47.915924"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "SSL: Sweet Spot Learning for Differentiated Guidance in Agentic Optimization",
    "paper_url": "https://huggingface.co/papers/2601.22491",
    "authors": [
      "Bolin Ni",
      "Fangzhi Xu",
      "Yuhao Shen",
      "Jinyang Wu",
      "thkelper"
    ],
    "stars": "0",
    "details": {
      "title": "SSL: Sweet Spot Learning for Differentiated Guidance in Agentic Optimization",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22491",
      "pdf_url": "https://arxiv.org/pdf/2601.22491",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22491",
      "scraped_at": "2026-02-03T02:15:49.836577"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "DenseGRPO: From Sparse to Dense Reward for Flow Matching Model Alignment",
    "paper_url": "https://huggingface.co/papers/2601.20218",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DenseGRPO: From Sparse to Dense Reward for Flow Matching Model Alignment",
      "abstract": "A dense reward for RL in flow matching models.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20218",
      "pdf_url": "https://arxiv.org/pdf/2601.20218",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20218",
      "scraped_at": "2026-02-03T02:15:51.734118"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling",
    "paper_url": "https://huggingface.co/papers/2601.22636",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling",
      "abstract": "Real-world jailbreak attackers don‚Äôt usually try once. They try many times, in parallel, until the model slips. That‚Äôs why adversarial risk can‚Äôt be captured by attack success rate on a single attempt (ASR@1). As the number of attempts N grows, risk can amplify, often at very different rates across models and settings. So what actually governs this amplification rate? In work, we derive a theoretically grounded scaling law for adversarial risk under Best-of-N sampling, and introduce SABER, a scaling-aware estimator that predicts large-budget risk from small-budget measurements.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22636",
      "pdf_url": "https://arxiv.org/pdf/2601.22636",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22636",
      "scraped_at": "2026-02-03T02:15:53.630169"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "DINO-SAE: DINO Spherical Autoencoder for High-Fidelity Image Reconstruction and Generation",
    "paper_url": "https://huggingface.co/papers/2601.22904",
    "authors": [
      "Jong Chul Ye",
      "Byunghee Cha",
      "Hun Chang"
    ],
    "stars": "0",
    "details": {
      "title": "DINO-SAE: DINO Spherical Autoencoder for High-Fidelity Image Reconstruction and Generation",
      "abstract": "DINO-SAE bridges semantic directions and pixel fidelity via spherical latent diffusion with hierarchical patch embedding and cosine alignment, achieving state-of-the-art reconstruction while preserving semantic alignment.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22904",
      "pdf_url": "https://arxiv.org/pdf/2601.22904",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22904",
      "scraped_at": "2026-02-03T02:15:55.539632"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing",
    "paper_url": "https://huggingface.co/papers/2601.21957",
    "authors": [
      "Zelun Zhang",
      "Tingquan Gao",
      "Suyin Liang",
      "sunflowerting78",
      "ChengCui"
    ],
    "stars": "0",
    "details": {
      "title": "PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21957",
      "pdf_url": "https://arxiv.org/pdf/2601.21957",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21957",
      "scraped_at": "2026-02-03T02:15:57.474033"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "RM -RF: Reward Model for Run-Free Unit Test Evaluation",
    "paper_url": "https://huggingface.co/papers/2601.13097",
    "authors": [
      "Mikhail Klementev",
      "doooori",
      "rmndrnts",
      "dangrebenkin",
      "brucheselena"
    ],
    "stars": "5",
    "details": {
      "title": "RM -RF: Reward Model for Run-Free Unit Test Evaluation",
      "abstract": "RM -RF: Reward Model for Run-Free Unit Test Evaluation proposes a novel lightweight reward model  that predicts unit test quality without compiling or executing code by inferring three execution-derived signals directly from source and test code: whether the augmented test suite would compile and run, whether the new tests increase code coverage, whether they improve mutation kill rate. This work is motivated by the high computational cost of traditional compile-and-run validation in automated test generation, especially when using large language models (LLMs) for code tasks. RM-RF is trained on a multilingual dataset across Java, Python, and Go that pairs code + test files with execution-derived labels, and various model families and tuning regimes (zero-shot, fine-tuned, PEFT/LoRA) achieve ~0.69 F1 on the three targets. Key contributions include: a scalable ‚Äúrun-free‚Äù reward model that reduces latency and infrastructure needs compared to execution-based evaluation, a curated dataset and methodology for comparative assessment of unit test quality signals, empirical analysis of RM-RF with different model sizes and fine-tuning strategies. This approach can provide rapid feedback for large-scale test generation and RL-based code optimization, bridging a gap between high-fidelity execution feedback and scalable automated unit test evaluation.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.13097",
      "pdf_url": "https://arxiv.org/pdf/2601.13097",
      "github_links": [
        "https://github.com/trndcenter/RM-RF-unit-tests"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.13097",
      "scraped_at": "2026-02-03T02:15:59.396853"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "DIFFA-2: A Practical Diffusion Large Language Model for General Audio Understanding",
    "paper_url": "https://huggingface.co/papers/2601.23161",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DIFFA-2: A Practical Diffusion Large Language Model for General Audio Understanding",
      "abstract": "DIFFA-2 provides a practical diffusion-based large audio language model with semantic/acoustic adapters and a four-stage curriculum, improving general audio understanding under practical budgets.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23161",
      "pdf_url": "https://arxiv.org/pdf/2601.23161",
      "github_links": [
        "https://github.com/NKU-HLT/DIFFA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23161",
      "scraped_at": "2026-02-03T02:16:01.336883"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "NativeTok: Native Visual Tokenization for Improved Image Generation",
    "paper_url": "https://huggingface.co/papers/2601.22837",
    "authors": [
      "Zhendong Mao",
      "Weinan Jia",
      "Mengqi Huang",
      "Bin Wu"
    ],
    "stars": "4",
    "details": {
      "title": "NativeTok: Native Visual Tokenization for Improved Image Generation",
      "abstract": "Introduces native visual tokenization with causal dependencies, via NativeTok (MIT and MoCET) and hierarchical training for efficient, coherent image reconstruction with relational token constraints.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22837",
      "pdf_url": "https://arxiv.org/pdf/2601.22837",
      "github_links": [
        "https://github.com/wangbei1/Nativetok"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22837",
      "scraped_at": "2026-02-03T02:16:03.310657"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Pushing the Boundaries of Natural Reasoning: Interleaved Bonus from Formal-Logic Verification",
    "paper_url": "https://huggingface.co/papers/2601.22642",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Pushing the Boundaries of Natural Reasoning: Interleaved Bonus from Formal-Logic Verification",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22642",
      "pdf_url": "https://arxiv.org/pdf/2601.22642",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22642",
      "scraped_at": "2026-02-03T02:16:05.313485"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.21468",
    "authors": [
      "Yuxin Chen",
      "Wenyu Mao",
      "Yu Yang",
      "Shugui Liu",
      "Yaorui Shi"
    ],
    "stars": "0",
    "details": {
      "title": "MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning",
      "abstract": "MemOCR is a multimodal memory agent that enhances long-horizon reasoning by adaptively compressing interaction histories into visual layouts, enabling efficient context utilization under tight budget constraints.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21468",
      "pdf_url": "https://arxiv.org/pdf/2601.21468",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21468",
      "scraped_at": "2026-02-03T02:16:07.319616"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance",
    "paper_url": "https://huggingface.co/papers/2601.18241",
    "authors": [
      "Vadim Alperovich",
      "dangrebenkin",
      "rmndrnts",
      "doooori",
      "brucheselena"
    ],
    "stars": "6",
    "details": {
      "title": "TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance",
      "abstract": "üß™ TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance What‚Äôs new: Large Language Models (LLMs) have been widely explored for unit test generation , but real-world test suite maintenance ‚Äî like creating, updating, and repairing tests as code evolves ‚Äî hasn‚Äôt been systematically evaluated. This paper introduces TAM-Eval , the benchmark and evaluation framework that targets exactly these maintenance tasks in realistic software contexts. Core contributions: üîπ Benchmark and framework: TAM-Eval evaluates LLMs on three maintenance scenarios ‚Äî creation , repair , and updating of test suites ‚Äî at the test file level with actual context (not isolated function snippets). üîπ Real-world dataset: The benchmark is built from 1,539 automatically extracted and validated scenarios from open-source projects in Python, Java, and Go. üîπ Evaluation metrics: Instead of simple accuracy scores, the framework uses reference-free metrics reflecting real software quality: Test suite pass rate Code coverage change Mutation testing outcomes These align closer to developer goals in maintenance. üîπ Empirical results: State-of-the-art LLMs show only limited improvements on realistic maintenance workflows ‚Äî indicating that current models still struggle with practical test suite evolution. Why it matters: Automated testing and maintenance are essential for high-quality software. Most benchmarks have focused on test generation at function level; TAM-Eval shifts the focus to maintenance workflows developers actually deal with , providing a new community standard for evaluating LLMs in software engineering contexts. Open science: The TAM-Eval code and dataset are fully open-source, enabling future research and direct integration into evaluation pipelines.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.18241",
      "pdf_url": "https://arxiv.org/pdf/2601.18241",
      "github_links": [
        "https://github.com/trndcenter/TAM-Eval"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.18241",
      "scraped_at": "2026-02-03T02:16:09.235196"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Scaling Multiagent Systems with Process Rewards",
    "paper_url": "https://huggingface.co/papers/2601.23228",
    "authors": [],
    "stars": "43",
    "details": {
      "title": "Scaling Multiagent Systems with Process Rewards",
      "abstract": "Define and train your own multiagent system @ our github repo !",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23228",
      "pdf_url": "https://arxiv.org/pdf/2601.23228",
      "github_links": [
        "https://github.com/ltjed/multiagent-coaching"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23228",
      "scraped_at": "2026-02-03T02:16:11.132610"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization",
    "paper_url": "https://huggingface.co/papers/2601.21358",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Forest Before Trees: Latent Superposition for Efficient Visual Reasoning (2026) Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning (2026) Reasoning Palette: Modulating Reasoning via Latent Contextualization for Controllable Exploration for (V)LMs (2025) Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models (2026) Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge (2026) LaViT: Aligning Latent Visual Thoughts for Multi-modal Reasoning (2026) iCLP: Large Language Model Reasoning with Implicit Cognition Latent Planning (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21358",
      "pdf_url": "https://arxiv.org/pdf/2601.21358",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21358",
      "scraped_at": "2026-02-03T02:16:13.058828"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience",
    "paper_url": "https://huggingface.co/papers/2601.23188",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience",
      "abstract": "üöÄ New Research Alert! üß†‚ú® We‚Äôre excited to share our latest work: Deep Search with Hierarchical Meta-Cognitive Monitoring Inspired by Cognitive Neuroscience üîç What‚Äôs the key idea? Deep search agents powered by LLMs excel at multi-step reasoning and retrieval‚Äîbut they often fail silently when small errors accumulate under uncertainty. Drawing direct inspiration from human cognitive neuroscience , we propose a hierarchical meta-cognitive monitoring framework that mirrors how humans detect anomalies, reflect on mistakes, and adapt their behavior during complex problem solving. üß† Neuroscience-inspired design Human metacognition is not monolithic: it combines fast, automatic error signals with slower, experience-driven reflection . We translate this principle into deep search agents via two complementary monitors: üß© Our approach introduces two complementary monitors: ‚ö° Fast Consistency Monitor Inspired by rapid neural mechanisms for conflict and surprise detection (e.g., early mismatch and uncertainty signals), this module performs lightweight, always-on checks to detect misalignment between external evidence and internal reasoning confidence . üê¢ Slow Experience-Driven Monitor Inspired by higher-order reflective processes and memory-based control in the human brain, this module is selectively activated . It leverages experience from past trajectories to guide deliberate correction and strategic adjustment. üìà Why does this matter? By embedding neuroscience-inspired meta-cognitive monitoring directly into the ReAct loop of a Deep Search Agent, our framework: Enhances robustness and reliability in long-horizon reasoning Enables early detection and correction of cascading errors Establishes a tighter conceptual bridge between human metacognition and agentic AI system design üß™ Results Experiments across multiple deep search benchmarks and backbone models demonstrate consistent improvements in both performance and robustness , validating the effectiveness of this cognitively grounded design.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23188",
      "pdf_url": "https://arxiv.org/pdf/2601.23188",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23188",
      "scraped_at": "2026-02-03T02:16:14.971476"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Revisiting Diffusion Model Predictions Through Dimensionality",
    "paper_url": "https://huggingface.co/papers/2601.21419",
    "authors": [
      "Chaoyang Wang",
      "Qing Jin"
    ],
    "stars": "0",
    "details": {
      "title": "Revisiting Diffusion Model Predictions Through Dimensionality",
      "abstract": "not sure which to choose: x0 prediction or velocity prediction? this paper provides a universal solution to find the optimal solution for you",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21419",
      "pdf_url": "https://arxiv.org/pdf/2601.21419",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21419",
      "scraped_at": "2026-02-03T02:16:16.886031"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Real-Time Aligned Reward Model beyond Semantics",
    "paper_url": "https://huggingface.co/papers/2601.22664",
    "authors": [
      "Jianbin Zheng",
      "Yuxi Ren",
      "Xin Xia",
      "Yikunb",
      "hzxllll"
    ],
    "stars": "0",
    "details": {
      "title": "Real-Time Aligned Reward Model beyond Semantics",
      "abstract": "RLHF is central to aligning LLMs with human preferences, but it often suffers from reward overoptimization: the policy learns to game the reward model instead of truly following human intent. A key reason? Distribution shift‚Äîthe policy keeps changing, while the reward model stays static. R2M (Real-Time Aligned Reward Model) tackles this head-on. Instead of relying only on fixed semantic features, R2M feeds on the policy‚Äôs evolving hidden states, aligning the reward model in real time with the policy‚Äôs trajectory during RL. üîë Takeaway: Reward models shouldn‚Äôt be passive judges. They should co-evolve with the policy.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22664",
      "pdf_url": "https://arxiv.org/pdf/2601.22664",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22664",
      "scraped_at": "2026-02-03T02:16:18.885339"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "LMK > CLS: Landmark Pooling for Dense Embeddings",
    "paper_url": "https://huggingface.co/papers/2601.21525",
    "authors": [
      "Yulong Li",
      "Parul Awasthy",
      "Aashka Trivedi",
      "vishwajeetkumar",
      "meetdoshi90"
    ],
    "stars": "0",
    "details": {
      "title": "LMK > CLS: Landmark Pooling for Dense Embeddings",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs (2026) Sequence Repetition Enhances Token Embeddings and Improves Sequence Labeling with Decoder-only Language Models (2026) CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual Document Embedding (2026) ReinPool: Reinforcement Learning Pooling Multi-Vector Embeddings for Retrieval System (2026) Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings (2025) BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics (2026) Next-Embedding Prediction Makes Strong Vision Learners (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21525",
      "pdf_url": "https://arxiv.org/pdf/2601.21525",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21525",
      "scraped_at": "2026-02-03T02:16:20.790330"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Continual GUI Agents",
    "paper_url": "https://huggingface.co/papers/2601.20732",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Continual GUI Agents",
      "abstract": "Some of the observations founded are :- -- Static GUI training breaks under real world change : GUI agents trained on fixed datasets degrade badly when UI domains (mobile --> desktop --> web) or resolutions (1080p -> 4K) shift, mainly due to unstable grounding of interaction points and regions. -- SFT overfits ; RFT is more suitable for continual learning : Supervised Fine Tuning memorizes current layouts and forgets prior skills, while Reinforcement Fine Tuning ( RFT ) better preserves knowledge via KL regularized updates making it a stronger base for continual GUI agents. -- Grounding fails because interaction points and scales are in flux : Domain and resolution shifts cause large changes in element locations and sizes, and existing reward designs over adapt to static coordinates or scales, leading to poor generalization. -- GUI AiF stabilizes learning by rewarding diversity, not fixation : The proposed GUI AiF framework introduces two rewards APR-iF ( diverse interaction points ) and ARR-iF ( diverse element regions ) which prevent agents from collapsing onto single layouts. -- Generalizing interaction points matters more than scale : Ablations show APR-iF contributes more than ARR-iF, indicating that adapting to where to interact is more critical than adapting to how big elements are in continual GUI environments. ..... many more...",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20732",
      "pdf_url": "https://arxiv.org/pdf/2601.20732",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20732",
      "scraped_at": "2026-02-03T02:16:22.654011"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors",
    "paper_url": "https://huggingface.co/papers/2601.15625",
    "authors": [
      "Bin Liang",
      "Zezhong Wang",
      "Rui Wang",
      "Zhiwei Zhang",
      "Hiiamein"
    ],
    "stars": "0",
    "details": {
      "title": "Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors",
      "abstract": "Robust Tool Use via FISSION-GRPO: Learning to Recover from Execution Errors",
      "arxiv_page_url": "https://arxiv.org/abs/2601.15625",
      "pdf_url": "https://arxiv.org/pdf/2601.15625",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.15625",
      "scraped_at": "2026-02-03T02:16:24.533675"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data",
    "paper_url": "https://huggingface.co/papers/2601.22141",
    "authors": [
      "Michal Byra",
      "Alberto Presta",
      "GrzegorzStefanski"
    ],
    "stars": "0",
    "details": {
      "title": "Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data",
      "abstract": "This work challenges a core assumption of the Lottery Ticket Hypothesis: that a single sparse subnetwork can serve all data. The authors show that under heterogeneity, multiple specialized winning tickets outperform a universal one, reframing pruning as a mechanism for structural specialization rather than pure compression.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22141",
      "pdf_url": "https://arxiv.org/pdf/2601.22141",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22141",
      "scraped_at": "2026-02-03T02:16:26.440644"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving",
    "paper_url": "https://huggingface.co/papers/2601.22032",
    "authors": [],
    "stars": "32",
    "details": {
      "title": "Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving",
      "abstract": "End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors. In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM, the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22032",
      "pdf_url": "https://arxiv.org/pdf/2601.22032",
      "github_links": [
        "https://github.com/linhanwang/Drive-JEPA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22032",
      "scraped_at": "2026-02-03T02:16:28.394820"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis",
    "paper_url": "https://huggingface.co/papers/2601.21709",
    "authors": [
      "Xialiang Tong",
      "Yinqi Bai",
      "Xing Li",
      "Jie Wang",
      "Qingyue Yang"
    ],
    "stars": "0",
    "details": {
      "title": "Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis",
      "abstract": "We systematically analyze attention patterns from a unified temporal perspective and find that embedding temporal self-similarity and RoPE are key factors underlying streaming, retrieval, seasonal, and reaccess attention patterns. We further apply time-series analysis methodologies to study attention scores and their dynamics, which is interesting.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21709",
      "pdf_url": "https://arxiv.org/pdf/2601.21709",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21709",
      "scraped_at": "2026-02-03T02:16:30.682423"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Memorization Dynamics in Knowledge Distillation for Language Models",
    "paper_url": "https://huggingface.co/papers/2601.15394",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Memorization Dynamics in Knowledge Distillation for Language Models",
      "abstract": "We show that knowledge distillation in language models can give both improved generalization and reduced memorization.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.15394",
      "pdf_url": "https://arxiv.org/pdf/2601.15394",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.15394",
      "scraped_at": "2026-02-03T02:16:32.546033"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Machine Learning for Energy-Performance-aware Scheduling",
    "paper_url": "https://huggingface.co/papers/2601.23134",
    "authors": [
      "Yifei Shi",
      "Peter2023HuggingFace"
    ],
    "stars": "1",
    "details": {
      "title": "Machine Learning for Energy-Performance-aware Scheduling",
      "abstract": "Machine Learning for Energy-Performance-aware Scheduling. @ misc {HuShi2026mlcpusched,\n      title={Machine Learning for Energy-Performance-aware Scheduling}, \n      author={Zheyuan Hu and Yifei Shi},\n      year={2026},\n      eprint={2601.23134},\n      archivePrefix={arXiv},\n      primaryClass={cs.AR},\n      url={https://arxiv.org/abs/2601.23134}, \n}",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23134",
      "pdf_url": "https://arxiv.org/pdf/2601.23134",
      "github_links": [
        "https://github.com/PeterHUistyping/ml-cpu-sched"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23134",
      "scraped_at": "2026-02-03T02:16:34.420823"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Visual Personalization Turing Test",
    "paper_url": "https://huggingface.co/papers/2601.22680",
    "authors": [
      "Kuan-Chieh Jackson Wang",
      "Sergey Tulyakov",
      "James Burgess",
      "Rameen Abdal"
    ],
    "stars": "0",
    "details": {
      "title": "Visual Personalization Turing Test",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22680",
      "pdf_url": "https://arxiv.org/pdf/2601.22680",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22680",
      "scraped_at": "2026-02-03T02:16:36.286484"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "ExpAlign: Expectation-Guided Vision-Language Alignment for Open-Vocabulary Grounding",
    "paper_url": "https://huggingface.co/papers/2601.22666",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ExpAlign: Expectation-Guided Vision-Language Alignment for Open-Vocabulary Grounding",
      "abstract": "Open-vocabulary grounding requires accurate vision-language alignment under weak supervision, yet existing methods either rely on global sentence embeddings that lack fine-grained expressiveness or introduce token-level alignment with explicit supervision or heavy cross-attention designs. We propose ExpAlign, a theoretically grounded vision-language alignment framework built on a principled multiple instance learning formulation. ExpAlign introduces an Expectation Alignment Head that performs attentionbased soft MIL pooling over token-region similarities, enabling implicit token and instance selection without additional annotations. To further stabilize alignment learning, we develop an energy-based multi-scale consistency regularization scheme, including a Top-K multi-positive contrastive objective and a Geometry-Aware Consistency Objective derived from a Lagrangianconstrained free-energy minimization. Extensive experiments show that ExpAlign consistently improves open-vocabulary detection and zero-shot instance segmentation, particularly on long-tail categories. Most notably, it achieves 36.2 APron the LVIS minival split, outperforming other state-of-the-art methods at comparable model scale, while remaining lightweight and inference efficient.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22666",
      "pdf_url": "https://arxiv.org/pdf/2601.22666",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22666",
      "scraped_at": "2026-02-03T02:16:38.163159"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Value-Based Pre-Training with Downstream Feedback",
    "paper_url": "https://huggingface.co/papers/2601.22108",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Value-Based Pre-Training with Downstream Feedback",
      "abstract": "We‚Äôre entering the age of research, not just the age of scaling. Bigger models gave us horsepower. But pretraining still has almost no steering wheel. Today‚Äôs foundation models learn in an open loop: pick a proxy objective (next‚Äëtoken / fixed augmentations) ‚Üí burn trillions of tokens ‚Üí hope the capabilities we care about ‚Äúemerge‚Äù. That hope is getting expensive. If the ‚ÄúAGI won‚Äôt happen from brute-force scaling‚Äù camp is even partly right, then the bottleneck is clear: value per gradient step. So we asked a practical question: Can a small amount of verified goal information steer the massive unlabeled pretraining phase‚Äîwithout turning pretraining into supervised finetuning? A potential answer: V‚ÄëPretraining (Value‚ÄëBased Pre‚ÄëTraining with Downstream Feedback). https://arxiv.org/abs/2601.22108 . Idea: add a lightweight task designer that reshapes the self‚Äësupervised task so each unlabeled update is more useful downstream.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22108",
      "pdf_url": "https://arxiv.org/pdf/2601.22108",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22108",
      "scraped_at": "2026-02-03T02:16:40.023794"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "SONIC-O1: A Real-World Benchmark for Evaluating Multimodal Large Language Models on Audio-Video Understanding",
    "paper_url": "https://huggingface.co/papers/2601.21666",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SONIC-O1: A Real-World Benchmark for Evaluating Multimodal Large Language Models on Audio-Video Understanding",
      "abstract": "SONIC-O1: A Real-World Benchmark for Evaluating Multimodal LLMs on Audio-Video Understanding SONIC-O1 is a fully human-verified benchmark for real-world audio‚Äìvideo conversations: 13 conversational domains, 4,958 annotated instances, plus demographic metadata for group-wise analysis. It evaluates models on open-ended summarization, MCQ QA, and temporal localization with supporting rationales‚Äîand we find temporal grounding is still a major pain point (e.g., a 22.6% gap between the best closed vs. open model families on temporal localization).",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21666",
      "pdf_url": "https://arxiv.org/pdf/2601.21666",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21666",
      "scraped_at": "2026-02-03T02:16:41.889521"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "KAPSO: A Knowledge-grounded framework for Autonomous Program Synthesis and Optimization",
    "paper_url": "https://huggingface.co/papers/2601.21526",
    "authors": [],
    "stars": "56",
    "details": {
      "title": "KAPSO: A Knowledge-grounded framework for Autonomous Program Synthesis and Optimization",
      "abstract": "We introduce KAPSO, a modular framework for autonomous program synthesis and optimization. Given a natural language goal and an evaluation method, KAPSO iteratively performs ideation, code synthesis and editing, execution, evaluation, and learning to improve a runnable artifact toward measurable objectives. Rather than treating synthesis as the endpoint, KAPSO uses synthesis as an operator within a long-horizon optimization loop, where progress is defined by evaluator outcomes. KAPSO targets long-horizon failures common in coding agents, including lost experimental state, brittle debugging, and weak reuse of domain expertise, by integrating three tightly coupled components. First, a git-native experimentation engine isolates each attempt as a branch, producing reproducible artifacts and preserving provenance across iterations. Second, a knowledge system ingests heterogeneous sources, including repositories, internal playbooks, and curated external resources such as documentation, scientific papers, and web search results, and organizes them into a structured representation that supports retrieval over workflows, implementations, and environment constraints. Third, a cognitive memory layer coordinates retrieval and maintains an episodic store of reusable lessons distilled from experiment traces (run logs, diffs, and evaluator feedback), reducing repeated error modes and accelerating convergence. We evaluated KAPSO on MLE-Bench (Kaggle-style ML competitions) and ALE-Bench (AtCoder heuristic optimization), and report end-to-end performance. Code Available at: https://github.com/Leeroo-AI/kapso",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21526",
      "pdf_url": "https://arxiv.org/pdf/2601.21526",
      "github_links": [
        "https://github.com/Leeroo-AI/kapso"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21526",
      "scraped_at": "2026-02-03T02:16:43.760977"
    },
    "scraped_date": "2026-02-03"
  },
  {
    "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots",
    "paper_url": "https://huggingface.co/papers/2602.00919",
    "authors": [],
    "stars": "24",
    "details": {
      "title": "Green-VLA: Staged Vision-Language-Action Model for Generalist Robots",
      "abstract": "TL;DR: Scaling VLA isn‚Äôt enough‚Äîyou need quality-aligned trajectories + a unified action interface + staged RL refinement to get reliable cross-robot generalization. This work (1) introduces a unified R64 action space with a fixed semantic layout plus embodiment/control-type prompts and a masked BC loss so unused DoFs don‚Äôt inject spurious gradients, (2) normalizes heterogeneous demonstration speeds via optical-flow‚Äìbased temporal resampling to align motion statistics across datasets, and (3) follows a staged recipe R0 ‚Üí R1 ‚Üí R2, where R2 RL alignment explicitly targets long-horizon consistency and error recovery. On real bimanual table cleaning (ALOHA), it reaches 69.5% first-item success vs 35.6% for the baseline and is ~2√ó faster (1m35s vs 2m59s). On Simpler (Google Robot), performance improves from 60.2 (R0) to 71.8 (R2). A nice practical touch: an episode-end prediction head reduces ‚Äúpost-success fidgeting‚Äù that can flip successes into failures. Project Page: https://greenvla.github.io/ Code: https://github.com/greenvla/GreenVLA",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00919",
      "pdf_url": "https://arxiv.org/pdf/2602.00919",
      "github_links": [
        "https://github.com/greenvla/GreenVLA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00919",
      "scraped_at": "2026-02-04T02:09:27.200013"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Kimi K2.5: Visual Agentic Intelligence",
    "paper_url": "https://huggingface.co/papers/2602.02276",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Kimi K2.5: Visual Agentic Intelligence",
      "abstract": "amazing <3",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02276",
      "pdf_url": "https://arxiv.org/pdf/2602.02276",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02276",
      "scraped_at": "2026-02-04T02:09:29.260821"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.22060",
    "authors": [
      "Zhen Fang",
      "Qiuchen Wang",
      "Lin-Chen",
      "YuZeng260",
      "Osilly"
    ],
    "stars": "96",
    "details": {
      "title": "Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models",
      "abstract": "We present the first long-horizon multimodal deep-research MLLM, introducing multi-turn, multi-entity, and multi-scale visual/textual search, and scaling up to dozens of reasoning steps and hundreds of search-engine interactions. By combining VQA synthesis, trajectory synthesis, cold-start supervision, and reinforcement learning, we internalize deep-research capabilities into the MLLM. With 8B and 30B-A3B models, we achieve state-of-the-art performance on six mainstream fact-centric VQA benchmarks, surpassing deep-research systems built on strong proprietary models such as GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22060",
      "pdf_url": "https://arxiv.org/pdf/2601.22060",
      "github_links": [
        "https://github.com/Osilly/Vision-DeepResearch"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22060",
      "scraped_at": "2026-02-04T02:09:31.283956"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.02185",
    "authors": [
      "gaotiexinqu",
      "chocckaka",
      "Lin-Chen",
      "Osilly",
      "YuZeng260"
    ],
    "stars": "0",
    "details": {
      "title": "Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models",
      "abstract": "We introduce the Vision-DeepResearch Benchmark (VDR-Bench) to address two key limitations of existing multimodal deep-research benchmarks: (1) they are not visual-search-centric, allowing many instances to be solved without genuine visual retrieval; and (2) they rely on overly idealized retrieval settings that fail to reflect noisy, real-world search engines. To this end, VDR-Bench comprises 2,000 instances curated with full human involvement and rigorous solvability verification, complementing existing benchmarks by enforcing realistic visual search and evidence-grounded reasoning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02185",
      "pdf_url": "https://arxiv.org/pdf/2602.02185",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02185",
      "scraped_at": "2026-02-04T02:09:33.226296"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Closing the Loop: Universal Repository Representation with RPG-Encoder",
    "paper_url": "https://huggingface.co/papers/2602.02084",
    "authors": [
      "Steven Liu",
      "Qingtao Li",
      "Xin Zhang",
      "Cipherxzc",
      "Luo2003"
    ],
    "stars": "59",
    "details": {
      "title": "Closing the Loop: Universal Repository Representation with RPG-Encoder",
      "abstract": "Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG‚Äôs high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02084",
      "pdf_url": "https://arxiv.org/pdf/2602.02084",
      "github_links": [
        "https://github.com/microsoft/RPG-ZeroRepo"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02084",
      "scraped_at": "2026-02-04T02:09:35.128933"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
    "paper_url": "https://huggingface.co/papers/2602.02437",
    "authors": [
      "Size Wu",
      "Feng Han",
      "Chaofan Ma",
      "Dianyi Wang",
      "CodeGoat24"
    ],
    "stars": "0",
    "details": {
      "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Unified Thinker: A General Reasoning Modular Core for Image Generation (2026) ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning (2025) Loom: Diffusion-Transformer for Interleaved Generation (2025) Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing (2026) Think-Then-Generate: Reasoning-Aware Text-to-Image Diffusion with LLM Encoders (2026) CoF-T2I: Video Models as Pure Visual Reasoners for Text-to-Image Generation (2026) ThinkGen: Generalized Thinking for Visual Generation (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02437",
      "pdf_url": "https://arxiv.org/pdf/2602.02437",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02437",
      "scraped_at": "2026-02-04T02:09:37.088820"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora",
    "paper_url": "https://huggingface.co/papers/2602.02053",
    "authors": [],
    "stars": "6",
    "details": {
      "title": "WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora",
      "abstract": "hi",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02053",
      "pdf_url": "https://arxiv.org/pdf/2602.02053",
      "github_links": [
        "https://github.com/BstWPY/WildGraphBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02053",
      "scraped_at": "2026-02-04T02:09:39.087666"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents",
    "paper_url": "https://huggingface.co/papers/2602.01566",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents",
      "abstract": "A deep research agent with file system as the scaling substrate, allowing external and persistent context. Although achieving maximal performance on downstream tasks still requires a lot of task-specific design at this stage, we believe that a file system has the potential to become a standard component of LLM agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01566",
      "pdf_url": "https://arxiv.org/pdf/2602.01566",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01566",
      "scraped_at": "2026-02-04T02:09:40.986852"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "SWE-Universe: Scale Real-World Verifiable Environments to Millions",
    "paper_url": "https://huggingface.co/papers/2602.02361",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SWE-Universe: Scale Real-World Verifiable Environments to Millions",
      "abstract": "We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02361",
      "pdf_url": "https://arxiv.org/pdf/2602.02361",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02361",
      "scraped_at": "2026-02-04T02:09:43.014980"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles",
    "paper_url": "https://huggingface.co/papers/2602.01590",
    "authors": [],
    "stars": "4",
    "details": {
      "title": "Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles",
      "abstract": "Hi everyone, we have released the Wiki Live Challenge, a benchmark that uses Wikipedia Good Articles as a high-level human baseline. It is designed to evaluate the writing quality and information-gathering capabilities of Deep Research Agents in authoring Wikipedia content. Our results indicate that there is still a gap between current DRAs and real-world human experts in this domain.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01590",
      "pdf_url": "https://arxiv.org/pdf/2602.01590",
      "github_links": [
        "https://github.com/WangShao2000/Wiki_Live_Challenge"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01590",
      "scraped_at": "2026-02-04T02:09:44.973680"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss",
    "paper_url": "https://huggingface.co/papers/2602.02493",
    "authors": [],
    "stars": "51",
    "details": {
      "title": "PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss",
      "abstract": "Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02493",
      "pdf_url": "https://arxiv.org/pdf/2602.02493",
      "github_links": [
        "https://github.com/Zehong-Ma/PixelGen"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02493",
      "scraped_at": "2026-02-04T02:09:46.942656"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.01058",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Good SFT Optimizes for SFT, Better SFT Prepares for Reinforcement Learning",
      "abstract": "A good objective for supervised post-training is commonly taken as one that optimizes for performance after supervised stage. But when this supervised stage is followed by an online RL stage,  SFT stage gains may not be preserved after online RL .  This paper experiments with a variety of supervised objectives, and finds that the out-of-the-box performance of these objectives often change after subsequent RL. This highlights a mismatch between these two goals. This paper proposes a reweighing mechanism for standard supervised losses designed to weigh each token using the effect of learning on that token on RL stage. This paper presents an approach based inspired by off-policy evaluation to compute weights based on the likelihood of continuation from each starting point. The paper includes multiple practical variants based on that principle and demonstrates the effectiveness.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01058",
      "pdf_url": "https://arxiv.org/pdf/2602.01058",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01058",
      "scraped_at": "2026-02-04T02:09:49.173825"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System",
    "paper_url": "https://huggingface.co/papers/2602.02488",
    "authors": [],
    "stars": "193",
    "details": {
      "title": "RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System",
      "abstract": "Code and model: https://github.com/Gen-Verse/Open-AgentRL",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02488",
      "pdf_url": "https://arxiv.org/pdf/2602.02488",
      "github_links": [
        "https://github.com/Gen-Verse/Open-AgentRL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02488",
      "scraped_at": "2026-02-04T02:09:51.193498"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization",
    "paper_url": "https://huggingface.co/papers/2602.02383",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization",
      "abstract": "We introduce SLIME, a reference-free preference optimization objective designed to decouple preference learning from generation quality. Our approach uses a three-pronged objective: Likelihood Anchoring: An explicit term to maximize the likelihood of the preferred response, preventing quality degradation. Token-Level Stabilization: A softplus-based penalty that prevents rejected token probabilities from collapsing to zero, preserving linguistic fluency. Dual-Margin Mechanism: A novel combination of hard and soft margins for precise boundary shaping without vanishing gradients.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02383",
      "pdf_url": "https://arxiv.org/pdf/2602.02383",
      "github_links": [
        "https://github.com/fpsigma/trl-slime"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02383",
      "scraped_at": "2026-02-04T02:09:53.118260"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards",
    "paper_url": "https://huggingface.co/papers/2602.01624",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards",
      "abstract": "PISCES is an annotation-free post-training framework for text-to-video models. We tackle a key bottleneck in VLM-based rewards, text/video embedding misalignment, by using Optimal Transport (OT) to align text embeddings to the video space. This yields dual OT-aligned rewards that mimic how humans judge T2V: a distributional quality reward and a token-level semantic reward, improving fidelity and prompt faithfulness across short and long video generators.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01624",
      "pdf_url": "https://arxiv.org/pdf/2602.01624",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01624",
      "scraped_at": "2026-02-04T02:09:55.125376"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation",
    "paper_url": "https://huggingface.co/papers/2602.01756",
    "authors": [
      "Chenjue Zhang",
      "Dongzhi Jiang",
      "Junyan Ye",
      "Jun He",
      "SereinH"
    ],
    "stars": "36",
    "details": {
      "title": "Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation",
      "abstract": "üß† Mind-Brush Framework: A novel agentic paradigm that unifies Intent Analysis, Multi-modal Search, and Knowledge Reasoning into a seamless \"Think-Research-Create\" workflow for image generation. üìä Mind-Bench: A specialized benchmark designed to evaluate generative models on dynamic external knowledge and complex logical deduction, exposing the reasoning gaps in current SOTA multimodal models. üèÜ Superior Performance: Elevates Qwen-Image baseline accuracy from 0.02 to 0.31 on Mind-Bench. Outperforms existing baselines on WISE (+25.8% WiScore) and RISEBench (+27.3% Accuracy).",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01756",
      "pdf_url": "https://arxiv.org/pdf/2602.01756",
      "github_links": [
        "https://github.com/PicoTrex/Mind-Brush"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01756",
      "scraped_at": "2026-02-04T02:09:57.095306"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation",
    "paper_url": "https://huggingface.co/papers/2602.02214",
    "authors": [],
    "stars": "164",
    "details": {
      "title": "Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation",
      "abstract": "Causal Forcing exposes a mathematical fallacy in Self Forcing and significantly outperforms it in both visual quality and motion dynamics , while maintaining the same training budget and inference efficiency , enabling real time streaming video generation on a single RTX 4090. Code (full-stack open source): https://github.com/thu-ml/Causal-Forcing Page: https://thu-ml.github.io/CausalForcing.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02214",
      "pdf_url": "https://arxiv.org/pdf/2602.02214",
      "github_links": [
        "https://github.com/thu-ml/Causal-Forcing"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02214",
      "scraped_at": "2026-02-04T02:09:59.088987"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention",
    "paper_url": "https://huggingface.co/papers/2602.01801",
    "authors": [
      "Gal Chechik",
      "Micahel Green",
      "Matan Levy",
      "Issar Tzachor",
      "Dvir Samuel"
    ],
    "stars": "0",
    "details": {
      "title": "Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention",
      "abstract": "Project Page: https://dvirsamuel.github.io/fast-auto-regressive-video/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01801",
      "pdf_url": "https://arxiv.org/pdf/2602.01801",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01801",
      "scraped_at": "2026-02-04T02:10:01.051872"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Rethinking Selective Knowledge Distillation",
    "paper_url": "https://huggingface.co/papers/2602.01395",
    "authors": [],
    "stars": "12",
    "details": {
      "title": "Rethinking Selective Knowledge Distillation",
      "abstract": "For the GitHub repo: https://github.com/almogtavor/SE-KD3x",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01395",
      "pdf_url": "https://arxiv.org/pdf/2602.01395",
      "github_links": [
        "https://github.com/almogtavor/SE-KD3x"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01395",
      "scraped_at": "2026-02-04T02:10:03.048964"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Generative Visual Code Mobile World Models",
    "paper_url": "https://huggingface.co/papers/2602.01576",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Generative Visual Code Mobile World Models",
      "abstract": "Coming soon: Website, demo video, github, and eval dataset",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01576",
      "pdf_url": "https://arxiv.org/pdf/2602.01576",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01576",
      "scraped_at": "2026-02-04T02:10:05.069765"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space",
    "paper_url": "https://huggingface.co/papers/2602.02092",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation (2026) OSDEnhancer: Taming Real-World Space-Time Video Super-Resolution with One-Step Diffusion (2026) Autoregressive Video Autoencoder with Decoupled Temporal and Spatial Context (2025) VideoAR: Autoregressive Video Generation via Next-Frame&Scale Prediction (2026) SnapGen++: Unleashing Diffusion Transformers for Efficient High-Fidelity Image Generation on Edge Devices (2026) Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance (2025) EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02092",
      "pdf_url": "https://arxiv.org/pdf/2602.02092",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02092",
      "scraped_at": "2026-02-04T02:10:07.064459"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Toward Cognitive Supersensing in Multimodal Large Language Model",
    "paper_url": "https://huggingface.co/papers/2602.01541",
    "authors": [],
    "stars": "5",
    "details": {
      "title": "Toward Cognitive Supersensing in Multimodal Large Language Model",
      "abstract": "Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01541",
      "pdf_url": "https://arxiv.org/pdf/2602.01541",
      "github_links": [
        "https://github.com/PediaMedAI/Cognition-MLLM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01541",
      "scraped_at": "2026-02-04T02:10:09.121705"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Ebisu: Benchmarking Large Language Models in Japanese Finance",
    "paper_url": "https://huggingface.co/papers/2602.01479",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Ebisu: Benchmarking Large Language Models in Japanese Finance",
      "abstract": "Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01479",
      "pdf_url": "https://arxiv.org/pdf/2602.01479",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01479",
      "scraped_at": "2026-02-04T02:10:11.080868"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.01335",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning",
      "abstract": "This paper introduces Visual Metaphor Transfer (VMT), a new task that goes beyond pixel-level editing to model abstract, cross-domain creative logic in visual generation. Inspired by Conceptual Blending Theory, the authors propose a schema-based, multi-agent framework that explicitly decouples metaphorical essence from visual appearance and re-instantiates it on new subjects. Extensive human studies show clear gains in metaphor consistency and creative quality, highlighting strong potential for high-impact applications in advertising and media.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01335",
      "pdf_url": "https://arxiv.org/pdf/2602.01335",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01335",
      "scraped_at": "2026-02-04T02:10:12.999163"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing",
    "paper_url": "https://huggingface.co/papers/2602.01851",
    "authors": [
      "Haochen Tian",
      "Chen Liang",
      "Chengzu Li",
      "Xuehai Bai",
      "Huanyu Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing",
      "abstract": "üöÄ Introducing VIBE: The Visual Instruction Benchmark for Image Editing! Why limit image editing to text? Human intent is multimodal. We‚Äôre filling the gap with VIBE , a new benchmark designed to evaluate how models follow visual instructions. Check out our full analysis and dataset below!üëá üìÑ Paper: https://arxiv.org/abs/2602.01851 üíª Github: https://github.com/hwanyu112/VIBE-Benchmark üåê Project Page: https://vibe-benchmark.github.io/ ü§ó Huggingface: https://huggingface.co/datasets/VIBE-Benchmark/VIBE-Benchmark",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01851",
      "pdf_url": "https://arxiv.org/pdf/2602.01851",
      "github_links": [
        "https://github.com/hwanyu112/VIBE-Benchmark"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01851",
      "scraped_at": "2026-02-04T02:10:14.953196"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars",
    "paper_url": "https://huggingface.co/papers/2602.01538",
    "authors": [
      "Teng Hu",
      "Ziyao Huang",
      "Zhentao Yu",
      "Zhengguang Zhou",
      "youliang1233214"
    ],
    "stars": "0",
    "details": {
      "title": "Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars",
      "abstract": "link: https://arxiv.org/abs/2602.01538",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01538",
      "pdf_url": "https://arxiv.org/pdf/2602.01538",
      "github_links": [
        "https://github.com/angzong/InteractAvatar"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01538",
      "scraped_at": "2026-02-04T02:10:16.894226"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents",
    "paper_url": "https://huggingface.co/papers/2602.02486",
    "authors": [],
    "stars": "11",
    "details": {
      "title": "RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents",
      "abstract": "We proposed RE-TRAC, a recursive framework addresses the inefficiency of disjointed traditional agent search by compressing historical trajectories to guide subsequent steps. Experiments demonstrate that this  explicit guidance mechanism not only significantly outperforms ReAct but also enables remarkable performance leaps on smaller models (e.g., 4B) via fine-tuning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02486",
      "pdf_url": "https://arxiv.org/pdf/2602.02486",
      "github_links": [
        "https://github.com/microsoft/InfoAgent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02486",
      "scraped_at": "2026-02-04T02:10:18.854834"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning",
    "paper_url": "https://huggingface.co/papers/2602.02472",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning",
      "abstract": "Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains a formidable challenge due to severe training instabilities. Empirically, we show that naive initialization at this stage disrupts activation statistics, triggering loss spikes, while copy-based initialization introduces gradient symmetry that hinders feature diversity. To address these issues, we propose SPARKLING (balancing Signal Preservation And symmetRy breaKing for width-progressive LearnING), a novel framework for mid-stage width expansion. Our method achieves signal preservation via RMS-scale consistency, stabilizing activation statistics during expansion. Symmetry breaking is ensured through asymmetric optimizer state resetting and learning rate re-warmup. Extensive experiments on Mixture-of-Experts (MoE) models demonstrate that, across multiple width axes and optimizer families, SPARKLING consistently outperforms training from scratch and reduces training cost by up to 35% under 2√ó width expansion.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02472",
      "pdf_url": "https://arxiv.org/pdf/2602.02472",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02472",
      "scraped_at": "2026-02-04T02:10:20.780970"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics",
    "paper_url": "https://huggingface.co/papers/2602.02343",
    "authors": [],
    "stars": "2.71k",
    "details": {
      "title": "Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics",
      "abstract": "We unify LLM control methods as dynamic weight updates, analyze their trade-offs between preference (targeted behavior) and utility (task-valid generation) via a shared log-odds framework, explain these effects through activation manifolds, and introduce SPLIT, a steering method that enhances preference while better preserving utility.",
      "arxiv_page_url": "https://arxiv.org/abs/2508.11290",
      "pdf_url": "https://arxiv.org/pdf/2602.02343",
      "github_links": [
        "https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02343",
      "scraped_at": "2026-02-04T02:10:22.726096"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Show, Don't Tell: Morphing Latent Reasoning into Image Generation",
    "paper_url": "https://huggingface.co/papers/2602.02227",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Show, Don't Tell: Morphing Latent Reasoning into Image Generation",
      "abstract": "Code: https://github.com/EnVision-Research/LatentMorph",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02227",
      "pdf_url": "https://arxiv.org/pdf/2602.02227",
      "github_links": [
        "https://github.com/EnVision-Research/LatentMorph"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02227",
      "scraped_at": "2026-02-04T02:10:24.666506"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "CUA-Skill: Develop Skills for Computer Using Agent",
    "paper_url": "https://huggingface.co/papers/2601.21123",
    "authors": [],
    "stars": "8",
    "details": {
      "title": "CUA-Skill: Develop Skills for Computer Using Agent",
      "abstract": "Computer-Using Agents (CUAs) aim to autonomously operate computer systems to complete real-world tasks. However, existing agentic systems remain difficult to scale and lag behind human performance. A key limitation is the absence of reusable and structured skill abstractions that capture how humans interact with graphical user interfaces and how to leverage these skills. We introduce CUA-Skill, a computer-using agentic skill base that encodes human computer-use knowledge as skills coupled with parameterized execution and composition graphs. CUA-Skill is a large-scale library of carefully engineered skills spanning common Windows applications, serving as a practical infrastructure and tool substrate for scalable, reliable agent development. Built upon this skill base, we construct CUA-Skill Agent, an end-to-end computer-using agent that supports dynamic skill retrieval, argument instantiation, and memory-aware failure recovery. Our results demonstrate that CUA-Skill substantially improves execution success rates and robustness on challenging end-to-end agent benchmarks, establishing a strong foundation for future computer-using agent development. On WindowsAgentArena, CUA-Skill Agent achieves state-of-the-art 57.5% (best of three) successful rate while being significantly more efficient than prior and concurrent approaches. The project page is available at this .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21123",
      "pdf_url": "https://arxiv.org/pdf/2601.21123",
      "github_links": [
        "https://github.com/microsoft/cua_skill"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21123",
      "scraped_at": "2026-02-04T02:10:26.583113"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "LoopViT: Scaling Visual ARC with Looped Transformers",
    "paper_url": "https://huggingface.co/papers/2602.02156",
    "authors": [
      "Yexin Liu",
      "Rui-Jie Zhu",
      "Wen-Jie Shu",
      "Harold328",
      "Xuerui123"
    ],
    "stars": "0",
    "details": {
      "title": "LoopViT: Scaling Visual ARC with Looped Transformers",
      "abstract": "Code: https://github.com/WenjieShu/LoopViT",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02156",
      "pdf_url": "https://arxiv.org/pdf/2602.02156",
      "github_links": [
        "https://github.com/WenjieShu/LoopViT"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02156",
      "scraped_at": "2026-02-04T02:10:28.500608"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling",
    "paper_url": "https://huggingface.co/papers/2602.02453",
    "authors": [
      "Muyun Yang",
      "Yuchen Song",
      "Qiuyu Ding",
      "Wenxin Zhu",
      "AndongChen"
    ],
    "stars": "4",
    "details": {
      "title": "Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02453",
      "pdf_url": "https://arxiv.org/pdf/2602.02453",
      "github_links": [
        "https://github.com/andongBlue/Think-with-Comics"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02453",
      "scraped_at": "2026-02-04T02:10:30.460982"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding",
    "paper_url": "https://huggingface.co/papers/2602.01322",
    "authors": [
      "Mihalis Nicolaou",
      "Yannis Panagakis",
      "James Oldfield",
      "Andreas D. Demou",
      "Panagiotis Koromilas"
    ],
    "stars": "0",
    "details": {
      "title": "PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding",
      "abstract": "PolySAE: Modeling Feature Interactions via Polynomial Decoding What: We generalize Sparse Autoencoders to capture feature interactions via polynomial decoding while preserving linear, interpretable encodings. Why: Standard SAEs assume features combine additively through linear reconstruction, which conflates compositional concepts with co-occurrence‚Äîthey can't distinguish whether \"Starbucks\" emerges from composing \"star\" + \"coffee\" features or merely their frequent overlap, forcing monolithic features for compound concepts. How: We extend the decoder with quadratic and cubic terms to model interactions while preserving the linear encoder essential for interpretability. Through low-rank tensor factorization, PolySAE captures pairwise and triple feature interactions with minimal parameter overhead (~3% on GPT-2 Small). Results: Across 4 LLMs and 3 sparsifiers, we achieve an average 8% improvement in probing F1 and 2‚Äì10√ó larger Wasserstein distances between class-conditional distributions, while maintaining comparable reconstruction error. Beyond Co-occurrence: Learned interaction weights show negligible correlation with co-occurrence frequency (r = 0.06 vs. r = 0.82 for SAE feature covariance), suggesting the model captures compositional semantics rather than surface statistics. Interpretable Interactions: Qualitative analysis reveals meaningful interaction patterns with examples \"invest\" + \"-ing\" + \"stock\" ‚Üí financial contexts, \"star\" + \"coffee\" ‚Üí Starbucks, or \"nuclear\" + \"test\" + \"radiation\" ‚Üí weapons testing. Plug-and-Play: PolySAE is a strict generalization of standard SAEs‚Äîsetting interaction coefficients to zero recovers vanilla behavior‚Äîand is compatible with SAE architectures (i.e., TopK, BatchTopK, Matryoshka, etc.).",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01322",
      "pdf_url": "https://arxiv.org/pdf/2602.01322",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01322",
      "scraped_at": "2026-02-04T02:10:32.367379"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Sparse Reward Subsystem in Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.00986",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Sparse Reward Subsystem in Large Language Models",
      "abstract": "In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00986",
      "pdf_url": "https://arxiv.org/pdf/2602.00986",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00986",
      "scraped_at": "2026-02-04T02:10:34.285628"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios",
    "paper_url": "https://huggingface.co/papers/2602.01675",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios",
      "abstract": "We are motivated by the gap between existing LLM-agent benchmarks and real deployment needs, where agents must handle long, multi-turn interactions, satisfy global constraints, and coordinate tools under frequent user revisions. We introduce TRIP-Bench, a realistic travel-planning benchmark with 18 tools, 40+ constraint types, and automated evaluation across difficulty splits, and show that even strong models degrade sharply on harder long-horizon dialogues. Finally, we propose GTPO, an online multi-turn RL method that improves constraint satisfaction and robustness on TRIP-Bench.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01675",
      "pdf_url": "https://arxiv.org/pdf/2602.01675",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01675",
      "scraped_at": "2026-02-04T02:10:36.376078"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training",
    "paper_url": "https://huggingface.co/papers/2602.01511",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training",
      "abstract": "Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01511",
      "pdf_url": "https://arxiv.org/pdf/2602.01511",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01511",
      "scraped_at": "2026-02-04T02:10:38.302166"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "AgentIF-OneDay: A Task-level Instruction-Following Benchmark for General AI Agents in Daily Scenarios",
    "paper_url": "https://huggingface.co/papers/2601.20613",
    "authors": [
      "Tianhao Tang",
      "Taiyu Hou",
      "Qimin Wu",
      "Kaiyuan Chen",
      "YuanshuoZhang"
    ],
    "stars": "0",
    "details": {
      "title": "AgentIF-OneDay: A Task-level Instruction-Following Benchmark for General AI Agents in Daily Scenarios",
      "abstract": "The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of a broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete a diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution, which assesses adherence to explicit and complex workflows; Latent Instruction, which requires agents to infer implicit instructions from attachments; and Iterative Refinement, which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and a refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities, enabling AI application teams to develop cutting-edge Agent products.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20613",
      "pdf_url": "https://arxiv.org/pdf/2601.20613",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20613",
      "scraped_at": "2026-02-04T02:10:40.268939"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation",
    "paper_url": "https://huggingface.co/papers/2602.01660",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation",
      "abstract": "Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01660",
      "pdf_url": "https://arxiv.org/pdf/2602.01660",
      "github_links": [
        "https://github.com/ALEX-nlp/CoDiQ"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01660",
      "scraped_at": "2026-02-04T02:10:42.338922"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "VoxServe: Streaming-Centric Serving System for Speech Language Models",
    "paper_url": "https://huggingface.co/papers/2602.00269",
    "authors": [
      "Stephanie Wang",
      "Rohan Kadekodi",
      "Atindra Jha",
      "Wei-Tzu Lee",
      "Keisuke Kamahori"
    ],
    "stars": "29",
    "details": {
      "title": "VoxServe: Streaming-Centric Serving System for Speech Language Models",
      "abstract": "A serving system for SpeechLMs https://github.com/vox-serve/vox-serve",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00269",
      "pdf_url": "https://arxiv.org/pdf/2602.00269",
      "github_links": [
        "https://github.com/vox-serve/vox-serve"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00269",
      "scraped_at": "2026-02-04T02:10:44.331707"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability",
    "paper_url": "https://huggingface.co/papers/2602.02477",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability",
      "abstract": "We introduce an end-to-end RL framework to endow LLMs with divide-and-conquer reasoning capabilities, enabling a higher performance ceiling and stronger test-time scalability.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02477",
      "pdf_url": "https://arxiv.org/pdf/2602.02477",
      "github_links": [
        "https://github.com/MasterVito/DAC-RL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02477",
      "scraped_at": "2026-02-04T02:10:46.344215"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs",
    "paper_url": "https://huggingface.co/papers/2602.02338",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Rethinking Generative Recommender Tokenizer: Recsys-Native Encoding and Semantic Quantization Beyond LLMs",
      "abstract": null,
      "arxiv_page_url": "https://arxiv.org/abs/2602.02338",
      "pdf_url": "https://arxiv.org/pdf/2602.02338",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02338",
      "scraped_at": "2026-02-04T02:10:48.310838"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "PromptRL: Prompt Matters in RL for Flow-Based Image Generation",
    "paper_url": "https://huggingface.co/papers/2602.01382",
    "authors": [],
    "stars": "59",
    "details": {
      "title": "PromptRL: Prompt Matters in RL for Flow-Based Image Generation",
      "abstract": "Image Editing Text-to-Image Generation",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01382",
      "pdf_url": "https://arxiv.org/pdf/2602.01382",
      "github_links": [
        "https://github.com/G-U-N/UniRL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01382",
      "scraped_at": "2026-02-04T02:10:50.268582"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.00759",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning",
      "abstract": "This is a new work by Renmin University of China and ByteDance Seed. We introduce a novel RLVR algorithm that allows a single base model to evolve into two complementary models i.e., Decomposer and Reasoner, which can mutually reinforce each other. We warmly welcome the community‚Äôs interest and feedback!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00759",
      "pdf_url": "https://arxiv.org/pdf/2602.00759",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00759",
      "scraped_at": "2026-02-04T02:10:52.197984"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "An Empirical Study of World Model Quantization",
    "paper_url": "https://huggingface.co/papers/2602.02110",
    "authors": [],
    "stars": "930",
    "details": {
      "title": "An Empirical Study of World Model Quantization",
      "abstract": "World models learn an internal representation of environment dynamics, enabling agents to simulate and reason about future states within a compact latent space for tasks such as planning, prediction, and inference. However, running world models rely on hevay computational cost and memory footprint, making model quantization essential for efficient deployment. To date, the effects of post-training quantization (PTQ) on world models remain largely unexamined. In this work, we present a systematic empirical study of world model quantization using DINO-WM as a representative case, evaluating diverse PTQ methods under both weight-only and joint weight-activation settings. We conduct extensive experiments on different visual planning tasks across a wide range of bit-widths, quantization granularities, and planning horizons up to 50 iterations. Our results show that quantization effects in world models extend beyond standard accuracy and bit-width trade-offs: group-wise weight quantization can stabilize low-bit rollouts, activation quantization granularity yields inconsistent benefits, and quantization sensitivity is highly asymmetric between encoder and predictor modules. Moreover, aggressive low-bit quantization significantly degrades the alignment between the planning objective and task success, leading to failures that cannot be remedied by additional optimization. These findings reveal distinct quantization-induced failure modes in world model-based planning and provide practical guidance for deploying quantized world models under strict computational constraints. The code will be available at this https URL .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02110",
      "pdf_url": "https://arxiv.org/pdf/2602.02110",
      "github_links": [
        "https://github.com/huawei-noah/noah-research/tree/master/QuantWM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02110",
      "scraped_at": "2026-02-04T02:10:54.060979"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.02039",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models",
      "abstract": "This paper introduces Deep Data Research , shifting from executional intelligence , which focuses on completing assigned tasks, to investigatory intelligence , where agents autonomously set goals and explore. Under this paradigm, Agentic LLMs are allowed to explore databases freely, discovering insights behind the data, without any predefined queries, questions, or objectives. The LLM-generated insights are evaluated against a fact checklist derived from the freeform components of the database, which naturally yields an aligned and objective evaluation. Beyond presenting DDR-Bench, the paper's experimental analysis reveals some insights into investigatory intelligence: Inference-time Scaling Dynamics : Top models exhibit \"quality over quantity\". They delay commitment and concentrate reasoning into a few high-value late-stage interactions. Token scaling shows flat-then-sharp patterns where final-stage tokens deliver disproportionate value, signalling depth-first exploration after breadth-oriented search. Balanced Exploration Regime : Entropy-based visualisation reveals advanced models consistently operate in a balanced regime combining coverage with focus, supporting an \"implicit planning hypothesis\" where strong models maintain coherent exploration strategies without explicit scaffolding. Training Trumps Scaling : Analysis of the Qwen family shows parameter scaling alone yields marginal gains (under 3% from 10√ó parameters), and longer context windows don't consistently help. However, cross-generation models with agentic-first training, including targeted pre-training and reinforcement learning, achieve substantially higher ceilings despite fewer activated parameters, demonstrating that meaningful agency requires intentional training strategies over mere scale. Scaffolding Paradox : Adding sophisticated frameworks like reasoning or memory mechanisms leads to unpredictable behaviours and may degrade performance. Proactive versus reactive comparison shows substantial gaps, confirming that autonomous goal-setting demands far exceed executing predefined objectives. Failure Modes : 58% of errors stem from insufficient exploration breadth/depth, while 40% involve other issues: powerful models over-reason with unsupported assumptions, weaker models struggle with instruction-following.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02039",
      "pdf_url": "https://arxiv.org/pdf/2602.02039",
      "github_links": [
        "https://github.com/thinkwee/DDR_Bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02039",
      "scraped_at": "2026-02-04T02:10:56.024349"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Rethinking LLM-as-a-Judge: Representation-as-a-Judge with Small Language Models via Semantic Capacity Asymmetry",
    "paper_url": "https://huggingface.co/papers/2601.22588",
    "authors": [
      "Yiming Zeng",
      "Yuelyu Ji",
      "Ming Li",
      "Zhuochun Li",
      "ReRaWo"
    ],
    "stars": "7",
    "details": {
      "title": "Rethinking LLM-as-a-Judge: Representation-as-a-Judge with Small Language Models via Semantic Capacity Asymmetry",
      "abstract": "The paper motivates a paradigm shift from LLM-as-a-Judge to Representation-as-a-Judge, a decoding-free evaluation strategy that probes internal model structure rather than relying on prompted output.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22588",
      "pdf_url": "https://arxiv.org/pdf/2601.22588",
      "github_links": [
        "https://github.com/zhuochunli/Representation-as-a-judge"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22588",
      "scraped_at": "2026-02-04T02:10:58.102904"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Enhancing Multi-Image Understanding through Delimiter Token Scaling",
    "paper_url": "https://huggingface.co/papers/2602.01984",
    "authors": [
      "Seong Joon Oh",
      "Yejin Kim",
      "Dongjun Hwang",
      "Yeji Park",
      "MYMY-young"
    ],
    "stars": "2",
    "details": {
      "title": "Enhancing Multi-Image Understanding through Delimiter Token Scaling",
      "abstract": "Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01984",
      "pdf_url": "https://arxiv.org/pdf/2602.01984",
      "github_links": [
        "https://github.com/MYMY-young/DelimScaling"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01984",
      "scraped_at": "2026-02-04T02:10:59.964784"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models",
    "paper_url": "https://huggingface.co/papers/2602.01842",
    "authors": [
      "Qingyu Shi",
      "Yi Xin",
      "Yuchen Zhu",
      "Yixuan Li",
      "BryanW"
    ],
    "stars": "5",
    "details": {
      "title": "Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models",
      "abstract": "Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at this https URL .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01842",
      "pdf_url": "https://arxiv.org/pdf/2602.01842",
      "github_links": [
        "https://github.com/viiika/Prism"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01842",
      "scraped_at": "2026-02-04T02:11:01.864285"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Interacted Planes Reveal 3D Line Mapping",
    "paper_url": "https://huggingface.co/papers/2602.01296",
    "authors": [],
    "stars": "19",
    "details": {
      "title": "Interacted Planes Reveal 3D Line Mapping",
      "abstract": "Structured 3D reconstruction",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01296",
      "pdf_url": "https://arxiv.org/pdf/2602.01296",
      "github_links": [
        "https://github.com/calmke/LiPMAP"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01296",
      "scraped_at": "2026-02-04T02:11:03.793960"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers",
    "paper_url": "https://huggingface.co/papers/2602.01077",
    "authors": [],
    "stars": "11",
    "details": {
      "title": "PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers",
      "abstract": "Code: https://github.com/xie-lab-ml/piecewise-sparse-attention",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01077",
      "pdf_url": "https://arxiv.org/pdf/2602.01077",
      "github_links": [
        "https://github.com/xie-lab-ml/piecewise-sparse-attention"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01077",
      "scraped_at": "2026-02-04T02:11:05.795195"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "VisionTrim: Unified Vision Token Compression for Training-Free MLLM Acceleration",
    "paper_url": "https://huggingface.co/papers/2601.22674",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "VisionTrim: Unified Vision Token Compression for Training-Free MLLM Acceleration",
      "abstract": "An efficient vision token compression framework with two modules, Dominant Vision Token Selection (DVTS) and Text-Guided Vision Complement (TGVC).",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22674",
      "pdf_url": "https://arxiv.org/pdf/2601.22674",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22674",
      "scraped_at": "2026-02-04T02:11:07.699775"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "On the Relationship Between Representation Geometry and Generalization in Deep Neural Networks",
    "paper_url": "https://huggingface.co/papers/2602.00130",
    "authors": [
      "rockerritesh"
    ],
    "stars": "0",
    "details": {
      "title": "On the Relationship Between Representation Geometry and Generalization in Deep Neural Networks",
      "abstract": "On the Relationship Between Representation Geometry and Generalization in Deep Neural Networks.",
      "arxiv_page_url": "https://arxiv.org/abs/2505.08727",
      "pdf_url": "https://arxiv.org/pdf/2602.00130",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00130",
      "scraped_at": "2026-02-04T02:11:09.584525"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "On the Limits of Layer Pruning for Generative Reasoning in LLMs",
    "paper_url": "https://huggingface.co/papers/2602.01997",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "On the Limits of Layer Pruning for Generative Reasoning in LLMs",
      "abstract": "TLDR; Layer pruning compresses LLMs with little impact on classification, but severely degrades generative reasoning by disrupting core algorithmic abilities like arithmetic and syntax. Self-generated supervision improves recovery, yet explains clear practical limits to depth reduction under realistic training constraints.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01997",
      "pdf_url": "https://arxiv.org/pdf/2602.01997",
      "github_links": [
        "https://github.com/safal312/on-the-limits-of-layer-pruning"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01997",
      "scraped_at": "2026-02-04T02:11:11.509574"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.01983",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning",
      "abstract": "This paper introduces UCT, a training-free framework that enables LLM agents to evolve during inference by transforming reasoning experience into reusable tools. Unlike prior tool-augmented methods that rely on fixed or single-use tools, UCT allows agents to autonomously create, validate, reuse, and refine tools, supported by an online build loop and offline memory consolidation. Experiments across math, science, and multimodal reasoning benchmarks show significant performance gains, demonstrating a practical path toward self-evolving tool-using agents without additional training.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01983",
      "pdf_url": "https://arxiv.org/pdf/2602.01983",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01983",
      "scraped_at": "2026-02-04T02:11:13.479603"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Mano: Restriking Manifold Optimization for LLM Training",
    "paper_url": "https://huggingface.co/papers/2601.23000",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Mano: Restriking Manifold Optimization for LLM Training",
      "abstract": "Code: https://github.com/xie-lab-ml/Mano-Restriking-Manifold-Optimization-for-LLM-Training",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23000",
      "pdf_url": "https://arxiv.org/pdf/2601.23000",
      "github_links": [
        "https://github.com/xie-lab-ml/Mano-Restriking-Manifold-Optimization-for-LLM-Training"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23000",
      "scraped_at": "2026-02-04T02:11:15.368949"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Implicit neural representation of textures",
    "paper_url": "https://huggingface.co/papers/2602.02354",
    "authors": [
      "Dounia Hammou",
      "Albert Kwok",
      "Peter2023HuggingFace"
    ],
    "stars": "1",
    "details": {
      "title": "Implicit neural representation of textures",
      "abstract": "Implicit neural representation of textures @ misc {KH2026INR-Tex,\n      title={Implicit neural representation of textures}, \n      author={Albert Kwok and Zheyuan Hu and Dounia Hammou},\n      year={2026},\n      eprint={2602.02354},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2602.02354}, \n}",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02354",
      "pdf_url": "https://arxiv.org/pdf/2602.02354",
      "github_links": [
        "https://github.com/PeterHUistyping/INR-Tex"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02354",
      "scraped_at": "2026-02-04T02:11:17.244969"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages",
    "paper_url": "https://huggingface.co/papers/2602.02287",
    "authors": [
      "Linda Freienthal",
      "Isaac Chung"
    ],
    "stars": "0",
    "details": {
      "title": "Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages",
      "abstract": "Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences. This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at https://github.com/isaac-chung/ cross-lingual-stability-judges.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02287",
      "pdf_url": "https://arxiv.org/pdf/2602.02287",
      "github_links": [
        "https://github.com/isaac-chung/cross-lingual-stability-judges",
        "https://github.com/isaac-chung/"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02287",
      "scraped_at": "2026-02-04T02:11:19.241742"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models",
    "paper_url": "https://huggingface.co/papers/2602.01970",
    "authors": [
      "Yuhang Jiang",
      "Heming Zou",
      "Yixiu Mao",
      "Qi Wang",
      "yunqu"
    ],
    "stars": "0",
    "details": {
      "title": "Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models",
      "abstract": "This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01970",
      "pdf_url": "https://arxiv.org/pdf/2602.01970",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01970",
      "scraped_at": "2026-02-04T02:11:21.144336"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory",
    "paper_url": "https://huggingface.co/papers/2602.00521",
    "authors": [
      "Bugeun Kim",
      "Hyeonchu Park",
      "Chanhee Cho",
      "Sohhyung Park",
      "Junhyuk Choi"
    ],
    "stars": "0",
    "details": {
      "title": "Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory",
      "abstract": ",",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00521",
      "pdf_url": "https://arxiv.org/pdf/2602.00521",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00521",
      "scraped_at": "2026-02-04T02:11:23.008184"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Clipping-Free Policy Optimization for Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.22801",
    "authors": [
      "Xuandong Zhao",
      "G√∂zde G√ºl ≈ûahin",
      "Barƒ±≈ü Akg√ºn",
      "√ñmer Veysel √áaƒüatan"
    ],
    "stars": "0",
    "details": {
      "title": "Clipping-Free Policy Optimization for Large Language Models",
      "abstract": "Clipping-Free Policy Optimization for Large Language Models",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22801",
      "pdf_url": "https://arxiv.org/pdf/2601.22801",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22801",
      "scraped_at": "2026-02-04T02:11:24.866533"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange",
    "paper_url": "https://huggingface.co/papers/2602.00192",
    "authors": [
      "Adrian Popescu",
      "Elif Nebioglu",
      "emirhanbilgic"
    ],
    "stars": "0",
    "details": {
      "title": "AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange",
      "abstract": "Key takeaway: ùêÇùêÆùê´ùê´ùêûùêßùê≠ ùêõùêûùêßùêúùê°ùê¶ùêöùê´ùê§ùê¨ for AI-generated Image Detection, ùêúùêöùêß ùêùùê´ùêöùê¶ùêöùê≠ùê¢ùêúùêöùê•ùê•ùê≤ ùê®ùêØùêûùê´ùêûùê¨ùê≠ùê¢ùê¶ùêöùê≠ùêû ùê´ùê®ùêõùêÆùê¨ùê≠ùêßùêûùê¨ùê¨. ùêìùê´ùêöùê¢ùêßùê¢ùêßùê† ùê∞ùê¢ùê≠ùê° ùêàùêçùêè-ùêó ùêüùê®ùê´ùêúùêûùê¨ ùêùùêûùê≠ùêûùêúùê≠ùê®ùê´ùê¨ ùê≠ùê® ùêüùê®ùêúùêÆùê¨ ùê®ùêß ùê†ùêûùêßùêûùê´ùêöùê≠ùêûùêù ùêúùê®ùêßùê≠ùêûùêßùê≠, ùê¢ùê¶ùê©ùê´ùê®ùêØùê¢ùêßùê† ùê†ùêûùêßùêûùê´ùêöùê•ùê¢ùê≥ùêöùê≠ùê¢ùê®ùêß ùêöùêßùêù ùê•ùê®ùêúùêöùê•ùê¢ùê≥ùêöùê≠ùê¢ùê®ùêß.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00192",
      "pdf_url": "https://arxiv.org/pdf/2602.00192",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00192",
      "scraped_at": "2026-02-04T02:11:26.759703"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "A Semantically Consistent Dataset for Data-Efficient Query-Based Universal Sound Separation",
    "paper_url": "https://huggingface.co/papers/2601.22599",
    "authors": [],
    "stars": "31",
    "details": {
      "title": "A Semantically Consistent Dataset for Data-Efficient Query-Based Universal Sound Separation",
      "abstract": "Query-based universal sound separation is a cornerstone capability for intelligent auditory systems, yet progress is often hindered by a data bottleneck: in-the-wild datasets typically come with weak labels and heavy event co-occurrence, encouraging models to learn spurious background-category correlations rather than robust acoustic cues. This work introduces an automated data pipeline that mines high-purity single-event segments from unconstrained recordings and synthesizes mixtures using semantically consistent strategies, effectively reducing co-occurrence noise at the source. Based on this pipeline, the authors release Hive, a 2,000-hour high-quality synthetic dataset for data-efficient training. Despite using only ~0.2% of the data scale of million-hour baselines, models trained on Hive achieve competitive separation accuracy and perceptual quality, and show strong zero-shot generalization on out-of-distribution benchmarks such as MUSDB18-HQ and USS-Bench. The key takeaway is clear: prioritizing supervision purity can dramatically improve data efficiency, offering a practical path toward robust auditory foundation models with reduced compute and annotation costs.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22599",
      "pdf_url": "https://arxiv.org/pdf/2601.22599",
      "github_links": [
        "https://github.com/ShandaAI/Hive"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22599",
      "scraped_at": "2026-02-04T02:11:28.664268"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "ParalESN: Enabling parallel information processing in Reservoir Computing",
    "paper_url": "https://huggingface.co/papers/2601.22296",
    "authors": [
      "Claudio Gallicchio",
      "Andrea Ceni",
      "Giacomo Lagomarsini",
      "nennomp"
    ],
    "stars": "0",
    "details": {
      "title": "ParalESN: Enabling parallel information processing in Reservoir Computing",
      "abstract": "TL;DR: We revisit the Reservoir Computing paradigm through the lens of structured operators and state space modelling, introducing Parallel Echo State Networks (ParalESN). ParalESN enables the construction of high-dimensional, efficient, and parallelizable randomized Recurrent Neural Networks.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22296",
      "pdf_url": "https://arxiv.org/pdf/2601.22296",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22296",
      "scraped_at": "2026-02-04T02:11:30.534160"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "OVD: On-policy Verbal Distillation",
    "paper_url": "https://huggingface.co/papers/2601.21968",
    "authors": [
      "Jianghan Shen",
      "Yuxin Cheng",
      "Shansan Gong",
      "Hui Shen",
      "Jing Xiong"
    ],
    "stars": "0",
    "details": {
      "title": "OVD: On-policy Verbal Distillation",
      "abstract": "Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model‚Äôs exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0‚Äì9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io .",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21968",
      "pdf_url": "https://arxiv.org/pdf/2601.21968",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21968",
      "scraped_at": "2026-02-04T02:11:32.417007"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Influence Guided Sampling for Domain Adaptation of Text Retrievers",
    "paper_url": "https://huggingface.co/papers/2601.21759",
    "authors": [
      "Jaydeep Sen",
      "Yulong Li",
      "vishwajeetkumar",
      "meetdoshi90"
    ],
    "stars": "0",
    "details": {
      "title": "Influence Guided Sampling for Domain Adaptation of Text Retrievers",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API GradientSpace: Unsupervised Data Clustering for Improved Instruction Tuning (2025) CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval (2026) Fine-Tuned In-Context Learners for Efficient Adaptation (2025) SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines (2026) DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation (2026) LACONIC: Dense-Level Effectiveness for Scalable Sparse Retrieval via a Two-Phase Training Curriculum (2026) InstructDiff: Domain-Adaptive Data Selection via Differential Entropy for Efficient LLM Fine-Tuning (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21759",
      "pdf_url": "https://arxiv.org/pdf/2601.21759",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21759",
      "scraped_at": "2026-02-04T02:11:34.282716"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Competing Visions of Ethical AI: A Case Study of OpenAI",
    "paper_url": "https://huggingface.co/papers/2601.16513",
    "authors": [
      "Madelyn Rose Sanfilippo",
      "Mengting Ai",
      "Melissa Wilfley"
    ],
    "stars": "0",
    "details": {
      "title": "Competing Visions of Ethical AI: A Case Study of OpenAI",
      "abstract": "AI Ethics is framed distinctly across actors and stakeholder groups. We report results from a case study of OpenAI analysing ethical AI discourse. Research addressed: How has OpenAI's public discourse leveraged 'ethics', 'safety', 'alignment', and adjacent related concepts over time, and what does discourse signal about framing in practice? A structured corpus, differentiating between communication for a general audience and communication with an academic audience, was assembled from public documentation. Qualitative content analysis of ethical themes combined inductively derived and deductively applied codes. Quantitative analysis leveraged computational content analysis methods via NLP to model topics and quantify changes in rhetoric over time. Visualizations report aggregate results. Results indicate that safety and risk discourse dominate OpenAI's public communication and documentation, without applying academic and advocacy ethics frameworks or vocabularies. Implications for governance are presented, along with a discussion of ethics-washing practices in industry.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.16513",
      "pdf_url": "https://arxiv.org/pdf/2601.16513",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.16513",
      "scraped_at": "2026-02-04T02:11:36.377220"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Internal Flow Signatures for Self-Checking and Refinement in LLMs",
    "paper_url": "https://huggingface.co/papers/2602.01897",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Internal Flow Signatures for Self-Checking and Refinement in LLMs",
      "abstract": "This repository implements Internal Flow Signatures, a training-free method for auditing and refining LLM decisions by analyzing depthwise hidden-state dynamics. The approach enables lightweight self-checking and targeted refinement without modifying the base model.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01897",
      "pdf_url": "https://arxiv.org/pdf/2602.01897",
      "github_links": [
        "https://github.com/EavnJeong/Internal-Flow-Signatures-for-Self-Checking-and-Refinement-in-LLMs"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01897",
      "scraped_at": "2026-02-04T02:11:38.254908"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery",
    "paper_url": "https://huggingface.co/papers/2602.01815",
    "authors": [
      "Sungsoo Ahn",
      "Jaehyung Kim",
      "Seonghyun Park",
      "Yunhui Jang"
    ],
    "stars": "0",
    "details": {
      "title": "INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery",
      "abstract": "This paper suggests constructing agent persona based on the research trajectory instead of static role-based prompting or keywords. This enhances the individuality of each agent, which guarantees high diversity and fact-grounding agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01815",
      "pdf_url": "https://arxiv.org/pdf/2602.01815",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01815",
      "scraped_at": "2026-02-04T02:11:40.136399"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia",
    "paper_url": "https://huggingface.co/papers/2602.01618",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia",
      "abstract": "Model: https://huggingface.co/collections/aisingapore/sea-guard",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01618",
      "pdf_url": "https://arxiv.org/pdf/2602.01618",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01618",
      "scraped_at": "2026-02-04T02:11:42.035572"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Where to Attend: A Principled Vision-Centric Position Encoding with Parabolas",
    "paper_url": "https://huggingface.co/papers/2602.01418",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Where to Attend: A Principled Vision-Centric Position Encoding with Parabolas",
      "abstract": "Parabolic Position Encoding (PaPE) We propose a position encoding that is designed from the ground up for vision modalities. It works by treating relative positions as the dependent variable in a sum of parabolas. PaPE is the highest scoring position encoding on 7 out of 8 datasets and the extrapolation beyond the training resolutions is very strong. Links Paper: https://arxiv.org/abs/2602.01418 Website: https://chrisohrstrom.github.io/parabolic-position-encoding Code: https://github.com/DTU-PAS/parabolic-position-encoding",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01418",
      "pdf_url": "https://arxiv.org/pdf/2602.01418",
      "github_links": [
        "https://github.com/DTU-PAS/parabolic-position-encoding"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01418",
      "scraped_at": "2026-02-04T02:11:43.933780"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "YOLOE-26: Integrating YOLO26 with YOLOE for Real-Time Open-Vocabulary Instance Segmentation",
    "paper_url": "https://huggingface.co/papers/2602.00168",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "YOLOE-26: Integrating YOLO26 with YOLOE for Real-Time Open-Vocabulary Instance Segmentation",
      "abstract": "This paper presents YOLOE-26, a unified framework that integrates the deployment-optimized YOLO26(or YOLOv26) architecture with the open-vocabulary learning paradigm of YOLOE for real-time open-vocabulary instance segmentation. Building on the NMS-free, end-to-end design of YOLOv26, the proposed approach preserves the hallmark efficiency and determinism of the YOLO family while extending its capabilities beyond closed-set recognition. YOLOE-26 employs a convolutional backbone with PAN/FPN-style multi-scale feature aggregation, followed by end-to-end regression and instance segmentation heads. A key architecturAl contribution is the replacement of fixed class logits with an object embedding head, which formulates classification as similarity matching against prompt embeddings derived from text descriptions, visual examples, or a built-in vocabulary. To enable efficient open-vocabulary reasoning, the framework incorporates Re-Parameterizable Region-Text Alignment (RepRTA) for zero-overhead text prompting, a Semantic-Activated Visual Prompt Encoder (SAVPE) for example-guided segmentation, and Lazy Region Prompt Contrast for prompt-free inference. All prompting modalities operate within a unified object embedding space, allowing seamless switching between text-prompted, visual-prompted, and fully autonomous segmentation. Extensive experiments demonstrate consistent scaling behavior and favorable accuracy-efficiency trade-offs across model sizes in both prompted and prompt-free settings. The training strategy leverages large-scale detection and grounding datasets with multi-task optimization and remains fully compatible with the Ultralytics ecosystem for training, validation, and deployment. Overall, YOLOE-26 provides a practical and scalable solution for real-time open-vocabulary instance segmentation in dynamic, real-world environments.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00168",
      "pdf_url": "https://arxiv.org/pdf/2602.00168",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00168",
      "scraped_at": "2026-02-04T02:11:45.866823"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation",
    "paper_url": "https://huggingface.co/papers/2601.14691",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation",
      "abstract": "TL;DR: The assumption that an agent's Chain-of-Thought (CoT) faithfully reflects its internal reasoning and environment state is brittle, which can reflect badly on the reliability of LLM judges that use the agent reasoning for evaluation. Our key finding is that simply rewriting agent CoTs while keeping actions and observations fixed, the false positive rates of state-of-the-art VLM judges can be inflated by up to 90%.  Specialized prompting and scaling judge-time compute can reduce susceptibility; they do not fully eliminate the vulnerability to manipulation. üìù  Paper: https://arxiv.org/abs/2601.14691 Code and trajectories will be released soon.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.14691",
      "pdf_url": "https://arxiv.org/pdf/2601.14691",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.14691",
      "scraped_at": "2026-02-04T02:11:47.726406"
    },
    "scraped_date": "2026-02-04"
  },
  {
    "title": "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding",
    "paper_url": "https://huggingface.co/papers/2602.01785",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding",
      "abstract": "Try compressing your code input to LLMs with CodeOCR with up to 8x compression ratio!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01785",
      "pdf_url": "https://arxiv.org/pdf/2602.01785",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01785",
      "scraped_at": "2026-02-05T02:10:39.597773"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration",
    "paper_url": "https://huggingface.co/papers/2602.03786",
    "authors": [
      "Fashen Ren",
      "Yiran Peng",
      "Zhihao Xu",
      "didiforhugface",
      "Aurorra1123"
    ],
    "stars": "0",
    "details": {
      "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration",
      "abstract": "AORCHESTRA: Automating Sub-Agent Creation for Agentic Orchestration We introduce AORCHESTRA, a framework-agnostic orchestration paradigm for agentic systems that models any agent as a compositional four-tuple ‚ü®Instruction, Context, Tools, Model‚ü©. Instead of relying on static roles or isolated context threads, AORCHESTRA enables dynamic, on-demand creation of specialized sub-agents with explicit context control and cost awareness. This abstraction decouples orchestration from execution, making the system plug-and-play across heterogeneous agent backends. The framework is evaluated on realistic long-horizon benchmarks including GAIA, SWE-Bench, and Terminal-Bench, achieving a 16.28% relative improvement over the strongest baseline when paired with Gemini-3-Flash.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03786",
      "pdf_url": "https://arxiv.org/pdf/2602.03786",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03786",
      "scraped_at": "2026-02-05T02:10:41.479974"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs",
    "paper_url": "https://huggingface.co/papers/2602.02103",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs",
      "abstract": "Our data and models are available at: https://github.com/lxucs/tele-lens",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02103",
      "pdf_url": "https://arxiv.org/pdf/2602.02103",
      "github_links": [
        "https://github.com/lxucs/tele-lens"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02103",
      "scraped_at": "2026-02-05T02:10:43.519926"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "MARS: Modular Agent with Reflective Search for Automated AI Research",
    "paper_url": "https://huggingface.co/papers/2602.02660",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "MARS: Modular Agent with Reflective Search for Automated AI Research",
      "abstract": "MARS uses budget-aware planning, modular design, and reflective memory to automate AI research, achieving strong performance and cross-branch knowledge transfer.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02660",
      "pdf_url": "https://arxiv.org/pdf/2602.02660",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02660",
      "scraped_at": "2026-02-05T02:10:45.422989"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation",
    "paper_url": "https://huggingface.co/papers/2602.03796",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation",
      "abstract": "TL;DR : 3DiMo can faithfully transfer genuine 3D motion from a given driving video to a reference character, while enabling flexible free-view camera control.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03796",
      "pdf_url": "https://arxiv.org/pdf/2602.03796",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03796",
      "scraped_at": "2026-02-05T02:10:47.454765"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently",
    "paper_url": "https://huggingface.co/papers/2602.02619",
    "authors": [],
    "stars": "25",
    "details": {
      "title": "daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently",
      "abstract": "While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics‚Äîexisting synthesis methods either confine to single-feature scenarios constrained by model distribution, or incur prohibitive human annotation costs, failing to provide scalable, high-quality supervision. We address this by reconceptualizing data synthesis through the lens of real-world software evolution. Our key insight: Pull Request (PR) sequences naturally embody the supervision signals for long-horizon learning. They decompose complex objectives into verifiable submission units, maintain functional coherence across iterations, and encode authentic refinement patterns through bug-fix histories. Building on this, we propose daVinci-Agency , which systematically mines structured supervision from chain-of-PRs through three interlocking mechanisms: (1) progressive task decomposition via continuous commits, (2) long-term consistency enforcement through unified functional objectives, and (3) verifiable refinement from authentic bug-fix trajectories. Unlike synthetic trajectories that treat each step independently, daVinci-Agency's PR-grounded structure inherently preserves the causal dependencies and iterative refinements essential for teaching persistent goal-directed behavior and enables natural alignment with project-level, full-cycle task modeling. The resulting trajectories are substantial‚Äîaveraging 85k tokens and 116 tool calls‚Äîyet remarkably data-efficient: fine-tuning GLM-4.6 on 239 daVinci-Agency samples yields broad improvements across benchmarks, notably achieving a 47% relative gain on Toolathlon. Beyond benchmark performance, our analysis confirms the model's effective internalization of long-horizon behaviors and unveils training and inference scaling laws specific to extended planning tasks. Our work establishes daVinci-Agency as a scalable paradigm that overcomes the limitations of single-feature synthesis, demonstrating that modeling real-world evolutionary trajectories offers a principled path to unlock the intrinsic long-horizon potential of agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02619",
      "pdf_url": "https://arxiv.org/pdf/2602.02619",
      "github_links": [
        "https://github.com/GAIR-NLP/daVinci-Agency"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02619",
      "scraped_at": "2026-02-05T02:10:49.386190"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks",
    "paper_url": "https://huggingface.co/papers/2602.01630",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks",
      "abstract": "In this paper, we discuss what the canonical format of world models should be. We welcome everyone to join the discussion.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01630",
      "pdf_url": "https://arxiv.org/pdf/2602.01630",
      "github_links": [
        "https://github.com/OpenDCAI/DataFlow-MM",
        "https://github.com/OpenDCAI/DataFlow"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01630",
      "scraped_at": "2026-02-05T02:10:51.279703"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs",
    "paper_url": "https://huggingface.co/papers/2602.03048",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs",
      "abstract": "CoBA-RL adaptively allocates RL rollout budgets for LLMs using a capability-valued metric and a heap-based greedy strategy to focus training on high-value samples, improving generalization efficiently.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03048",
      "pdf_url": "https://arxiv.org/pdf/2602.03048",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03048",
      "scraped_at": "2026-02-05T02:10:53.206366"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Diversity-Preserved Distribution Matching Distillation for Fast Visual Synthesis",
    "paper_url": "https://huggingface.co/papers/2602.03139",
    "authors": [],
    "stars": "43",
    "details": {
      "title": "Diversity-Preserved Distribution Matching Distillation for Fast Visual Synthesis",
      "abstract": "A simple yet effective approach to preserving sample diversity under DMD, with no perceptual backbone, no discriminator, no auxiliary networks, and no additional ground-truth images.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03139",
      "pdf_url": "https://arxiv.org/pdf/2602.03139",
      "github_links": [
        "https://github.com/Multimedia-Analytics-Laboratory/dpdmd"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03139",
      "scraped_at": "2026-02-05T02:10:57.233388"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "SWE-World: Building Software Engineering Agents in Docker-Free Environments",
    "paper_url": "https://huggingface.co/papers/2602.03419",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SWE-World: Building Software Engineering Agents in Docker-Free Environments",
      "abstract": "Propose a Docker-free SWE RL, alleviating the strong dependence on Docker infrastructure during the SWE training process.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03419",
      "pdf_url": "https://arxiv.org/pdf/2602.03419",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03419",
      "scraped_at": "2026-02-05T02:10:59.153642"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training",
    "paper_url": "https://huggingface.co/papers/2602.03411",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training",
      "abstract": "Unleash the SWE capabilities of the 32B model and provide available infrastructure for academic research on RL",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03411",
      "pdf_url": "https://arxiv.org/pdf/2602.03411",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03411",
      "scraped_at": "2026-02-05T02:11:01.149059"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Parallel-Probe: Towards Efficient Parallel Thinking via 2D Probing",
    "paper_url": "https://huggingface.co/papers/2602.03845",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "Parallel-Probe: Towards Efficient Parallel Thinking via 2D Probing",
      "abstract": "Parallel thinking has emerged as a promising paradigm for reasoning, yet it imposes significant computational burdens. Existing efficiency methods primarily rely on local, per-trajectory signals and lack principled mechanisms to exploit global dynamics across parallel branches. We introduce 2D probing, an interface that exposes the width-depth dynamics of parallel thinking by periodically eliciting intermediate answers from all branches. Our analysis reveals three key insights: non-monotonic scaling across width-depth allocations, heterogeneous reasoning branch lengths, and early stabilization of global consensus. Guided by these insights, we introduce Parallel-Probe, a training-free controller designed to optimize online parallel thinking. Parallel-Probe employs consensus-based early stopping to regulate reasoning depth and deviation-based branch pruning to dynamically adjust width. Extensive experiments across three benchmarks and multiple models demonstrate that Parallel-Probe establishes a superior Pareto frontier for test-time scaling. Compared to standard majority voting, it reduces sequential tokens by up to 35.8% and total token cost by over 25.8% while maintaining competitive accuracy.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03845",
      "pdf_url": "https://arxiv.org/pdf/2602.03845",
      "github_links": [
        "https://github.com/zhengkid/Parallel-Probe"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03845",
      "scraped_at": "2026-02-05T02:11:03.044174"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Learning Query-Specific Rubrics from Human Preferences for DeepResearch Report Generation",
    "paper_url": "https://huggingface.co/papers/2602.03619",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Learning Query-Specific Rubrics from Human Preferences for DeepResearch Report Generation",
      "abstract": "Nowadays, training and evaluating DeepResearch-generated reports remain challenging due to the lack of verifiable reward signals. Accordingly, rubric-based evaluation has become a common practice. However, existing approaches either rely on coarse, pre-defined rubrics that lack sufficient granularity, or depend on manually constructed query-specific rubrics that are costly and difficult to scale. In this paper, we propose a pipeline to train human-preference-aligned query-specific rubric generators tailored for DeepResearch report generation. We first construct a dataset of DeepResearch-style queries annotated with human preferences over paired reports, and train rubric generators via reinforcement learning with a hybrid reward combining human preference supervision and LLM-based rubric evaluation. To better handle long-horizon reasoning, we further introduce a Multi-agent Markov-state (MaMs) workflow for report generation. We empirically show that our proposed rubric generators deliver more discriminative and better human-aligned supervision than existing rubric design strategies. Moreover, when integrated into the MaMs training framework, DeepResearch systems equipped with our rubric generators consistently outperform all open-source baselines on the DeepResearch Bench and achieve performance comparable to that of leading closed-source models.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03619",
      "pdf_url": "https://arxiv.org/pdf/2602.03619",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03619",
      "scraped_at": "2026-02-05T02:11:04.981749"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "RANKVIDEO: Reasoning Reranking for Text-to-Video Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.02444",
    "authors": [],
    "stars": "4",
    "details": {
      "title": "RANKVIDEO: Reasoning Reranking for Text-to-Video Retrieval",
      "abstract": "Reasoning Reranking for text-to-video retrieval",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02444",
      "pdf_url": "https://arxiv.org/pdf/2602.02444",
      "github_links": [
        "https://github.com/tskow99/RANKVIDEO-Reasoning-Reranker"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02444",
      "scraped_at": "2026-02-05T02:11:07.043870"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Unified Personalized Reward Model for Vision Generation",
    "paper_url": "https://huggingface.co/papers/2602.02380",
    "authors": [],
    "stars": "691",
    "details": {
      "title": "Unified Personalized Reward Model for Vision Generation",
      "abstract": "ü™ê Project Page: https://codegoat24.github.io/UnifiedReward/flex ü§ó Model Collections: https://huggingface.co/collections/CodeGoat24/unifiedreward-flex ü§ó Dataset: https://huggingface.co/datasets/CodeGoat24/UnifiedReward-Flex-SFT-90K üëã Point of Contact: Yibin Wang",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02380",
      "pdf_url": "https://arxiv.org/pdf/2602.02380",
      "github_links": [
        "https://github.com/CodeGoat24/UnifiedReward"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02380",
      "scraped_at": "2026-02-05T02:11:09.471899"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Neural Predictor-Corrector: Solving Homotopy Problems with Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.03086",
    "authors": [
      "Haoang Li",
      "Yingping Zeng",
      "Zhenjun Zhao",
      "Bangyan Liao",
      "Jiayao Mai"
    ],
    "stars": "0",
    "details": {
      "title": "Neural Predictor-Corrector: Solving Homotopy Problems with Reinforcement Learning",
      "abstract": "The Homotopy paradigm, a general principle for solving challenging problems, appears across diverse domains such as robust optimization, global optimization, polynomial root-finding, and sampling. Practical solvers for these problems typically follow a predictor-corrector (PC) structure, but rely on hand-crafted heuristics for step sizes and iteration termination, which are often suboptimal and task-specific. To address this, we unify these problems under a single framework, which enables the design of a general neural solver. Building on this unified view, we propose Neural Predictor-Corrector (NPC), which replaces hand-crafted heuristics with automatically learned policies. NPC formulates policy selection as a sequential decision-making problem and leverages reinforcement learning to automatically discover efficient strategies. To further enhance generalization, we introduce an amortized training mechanism, enabling one-time offline training for a class of problems and efficient online inference on new instances. Experiments on four representative homotopy problems demonstrate that our method generalizes effectively to unseen instances. It consistently outperforms classical and specialized baselines in efficiency while demonstrating superior stability across tasks, highlighting the value of unifying homotopy methods into a single neural framework.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03086",
      "pdf_url": "https://arxiv.org/pdf/2602.03086",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03086",
      "scraped_at": "2026-02-05T02:11:11.452955"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "WideSeek: Advancing Wide Research via Multi-Agent Scaling",
    "paper_url": "https://huggingface.co/papers/2602.02636",
    "authors": [
      "Zhongtao Jiang",
      "Xiaowei Yuan",
      "Haolin Ren",
      "Jarvis1111",
      "hzy"
    ],
    "stars": "3",
    "details": {
      "title": "WideSeek: Advancing Wide Research via Multi-Agent Scaling",
      "abstract": "Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information sets under complex constraints in parallel. However, advancements in this field are impeded by the lack of dedicated benchmarks and optimization methodologies for search breadth. To address these challenges, we give a deep dive into Wide Research from two perspectives: Data Pipeline and Agent Optimization. First, we produce WideSeekBench, a General Broad Information Seeking (GBIS) benchmark constructed via a rigorous multi-phase data pipeline to ensure diversity across the volume of target information, logical constraints, and domains. Second, we introduce WideSeek, a dynamic hierarchical multi-agent architecture that could autonomously fork parallel sub-agents based on task requirements. Furthermore, we design a unified training framework that linearizes multi-agent trajectories and optimizes the system using end-to-end RL. Experimental results demonstrate the effectiveness of WideSeek and multi-agent RL, highlighting that scaling the number of agents is a promising direction for advancing Wide Research paradigm.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02636",
      "pdf_url": "https://arxiv.org/pdf/2602.02636",
      "github_links": [
        "https://github.com/hzy312/WideSeek"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02636",
      "scraped_at": "2026-02-05T02:11:13.350324"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Balancing Understanding and Generation in Discrete Diffusion Models",
    "paper_url": "https://huggingface.co/papers/2602.01362",
    "authors": [
      "Jianbin Jiao",
      "Qixiang Ye",
      "Zheyong Xie",
      "callsys",
      "Mzero17"
    ],
    "stars": "8",
    "details": {
      "title": "Balancing Understanding and Generation in Discrete Diffusion Models",
      "abstract": "We introduce XDLM, a discrete diffusion model that unifies MDLM and UDLM via a stationary noise kernel. XDLM theoretically bridges the two paradigms, recovers each as a special case, and reduces memory costs through an algebraic simplification of the posterior. Experiments show that XDLM achieves a better trade-off between semantic understanding and few-step generation quality, outperforming UDLM on zero-shot text tasks and MDLM on few-step image generation. Scaled to an 8B language model, XDLM attains 15.0 MBPP in 32 steps, nearly doubling baseline performance, with strong potential for long-term scaling. Code is available in https://github.com/MzeroMiko/XDLM .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01362",
      "pdf_url": "https://arxiv.org/pdf/2602.01362",
      "github_links": [
        "https://github.com/MzeroMiko/XDLM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01362",
      "scraped_at": "2026-02-05T02:11:15.238549"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Less Noise, More Voice: Reinforcement Learning for Reasoning via Instruction Purification",
    "paper_url": "https://huggingface.co/papers/2601.21244",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Less Noise, More Voice: Reinforcement Learning for Reasoning via Instruction Purification",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong promise for improving LLM reasoning, but in practice it often fails silently: for many hard prompts, all rollouts receive zero reward, causing training to stall or collapse. üîç Key observation Through token-level analysis, we find that many failed rollouts are not due to problem difficulty. Instead, failures are often caused by a very small number of ‚Äúinterference tokens‚Äù (<5%) that derail the entire reasoning trajectory. ‚úÇÔ∏è Interference Token Purification Simply removing these high-interference tokens can: turn failed rollouts into successful ones improve rollout accuracy by 20%+ on previously zero-reward prompts üöÄ Method: Less Noise Sampling (LENS) We introduce LENS, an online selective rollout framework for RLVR: Identify & remove interference tokens in low-success prompts to unlock successful rollouts Transfer learning back to the original noisy prompts, using denoised rollouts as high-reward supervision ‚Üí the model learns to ignore noise, not just solve cleaner prompts üìä Results Pareto improvement over GRPO in performance‚Äìefficiency trade-offs +3.88% average accuracy gain across 7 math reasoning benchmarks 1.6√ó faster convergence with less compute Outperforms both rollout scaling and prompt filtering baselines üí° Takeaway Low-success prompts are not useless‚Äîthey contain valuable signals hidden behind a few noisy tokens. Pruning interference tokens offers a new perspective on improving exploration efficiency in RLVR. üîó Links Paper: Less Noise Sampling Framework for RLVR Keywords: RLVR, GRPO, reasoning, rollout efficiency, token-level analysis",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21244",
      "pdf_url": "https://arxiv.org/pdf/2601.21244",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21244",
      "scraped_at": "2026-02-05T02:11:17.174384"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Token Sparse Attention: Efficient Long-Context Inference with Interleaved Token Selection",
    "paper_url": "https://huggingface.co/papers/2602.03216",
    "authors": [
      "Jae-Joon Kim",
      "Jiwon Song",
      "Beomseok Kang",
      "dongwonjo"
    ],
    "stars": "0",
    "details": {
      "title": "Token Sparse Attention: Efficient Long-Context Inference with Interleaved Token Selection",
      "abstract": "Token Sparse Attention is a complementary approach to efficient sparse attention that dynamically performs token-level compression during attention and reversibly decompresses the representations afterward. Code release is in progress; a cleaned and documented implementation will be released soon.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03216",
      "pdf_url": "https://arxiv.org/pdf/2602.03216",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03216",
      "scraped_at": "2026-02-05T02:11:19.072010"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation",
    "paper_url": "https://huggingface.co/papers/2602.03798",
    "authors": [
      "Zhuofan Zong",
      "Yunqiao Yang",
      "Houxing Ren",
      "Zimu Lu",
      "scikkk"
    ],
    "stars": "1",
    "details": {
      "title": "FullStack-Agent: Enhancing Agentic Full-Stack Web Coding via Development-Oriented Testing and Repository Back-Translation",
      "abstract": "In this paper, we introduce FullStack-Agent, a unified system that combines a multi-agent full-stack development framework equipped with efficient coding and debugging tools (FullStack-Dev), an iterative self-improvement method that improves the abilities of LLMs through repository augmentation and back-translation (FullStack-Learn), and a full-stack development benchmark that comprehensively evaluates frontend, backend, and database functionalities (FullStack-Bench). Extensive experiments demonstrate the effectiveness of our method. Testing FullStack-Dev with Qwen3-Coder-480B-A35B-Instruct as the backbone LLM on FullStack-Bench results in accuracies of 64.7%, 77.8%, and 77.9% in frontend, backend, and database test cases respectively, outperforming the previous state-of-the-art method by 8.7%, 38.2%, and 15.9%, respectively. Training Qwen3-Coder-30B-Instruct with FullStack-Learn improves its accuracies by 9.7%, 9.5%, and 2.8% in the three sets of test cases, respectively.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03798",
      "pdf_url": "https://arxiv.org/pdf/2602.03798",
      "github_links": [
        "https://github.com/mnluzimu/FullStack-Agent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03798",
      "scraped_at": "2026-02-05T02:11:21.034758"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "LIVE: Long-horizon Interactive Video World Modeling",
    "paper_url": "https://huggingface.co/papers/2602.03747",
    "authors": [],
    "stars": "4",
    "details": {
      "title": "LIVE: Long-horizon Interactive Video World Modeling",
      "abstract": "Project Page: https://junchao-cs.github.io/LIVE-demo/ Technical Paper: https://arxiv.org/pdf/2602.03747",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03747",
      "pdf_url": "https://arxiv.org/pdf/2602.03747",
      "github_links": [
        "https://github.com/Junchao-cs/LIVE"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03747",
      "scraped_at": "2026-02-05T02:11:22.880136"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "No Shortcuts to Culture: Indonesian Multi-hop Question Answering for Complex Cultural Understanding",
    "paper_url": "https://huggingface.co/papers/2602.03709",
    "authors": [
      "Nikos Aletras",
      "Nafise Sadat Moosavi",
      "Vynska Amalia Permadi",
      "XingweiT"
    ],
    "stars": "0",
    "details": {
      "title": "No Shortcuts to Culture: Indonesian Multi-hop Question Answering for Complex Cultural Understanding",
      "abstract": "To move beyond simple fact-recalling, researchers have introduced ID-MoCQA, the first large-scale multi-hop reasoning dataset focused on Indonesian culture. The Problem: Most AI benchmarks use \"single-hop\" questions that models can answer using surface-level patterns rather than true cultural understanding. The Solution: ID-MoCQA uses a framework to turn simple facts into complex reasoning chains across six categories (like geography and tradition) in both English and Indonesian. The Finding: Current LLMs struggle significantly with these complex cultural inferences, highlighting a major gap in their \"cultural intelligence.\"",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03709",
      "pdf_url": "https://arxiv.org/pdf/2602.03709",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03709",
      "scraped_at": "2026-02-05T02:11:24.799549"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process",
    "paper_url": "https://huggingface.co/papers/2602.02676",
    "authors": [
      "Shilin Yan",
      "Zhi Gao",
      "Jongrong Wu",
      "Xiaowen Zhang",
      "xintongzhang"
    ],
    "stars": "3",
    "details": {
      "title": "AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process",
      "abstract": "AdaptMMBench is designed to evaluate adaptive multimodal reasoning beyond final accuracy. It focuses on whether vision-language models make correct reasoning mode selections and execute high-quality, efficient reasoning processes.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02676",
      "pdf_url": "https://arxiv.org/pdf/2602.02676",
      "github_links": [
        "https://github.com/xtong-zhang/AdaptMMBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02676",
      "scraped_at": "2026-02-05T02:11:26.673076"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training",
    "paper_url": "https://huggingface.co/papers/2602.00747",
    "authors": [
      "Haifeng Liu",
      "Jieying Ye",
      "Kaiyan Zhao",
      "Shengrui Li",
      "Hiiamein"
    ],
    "stars": "0",
    "details": {
      "title": "Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training",
      "abstract": "Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00747",
      "pdf_url": "https://arxiv.org/pdf/2602.00747",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00747",
      "scraped_at": "2026-02-05T02:11:28.542422"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Instruction Anchors: Dissecting the Causal Dynamics of Modality Arbitration",
    "paper_url": "https://huggingface.co/papers/2602.03677",
    "authors": [
      "Pengfei Zhang",
      "Kehai chen",
      "Xuefeng Bai",
      "Mufan Xu",
      "Yu Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "Instruction Anchors: Dissecting the Causal Dynamics of Modality Arbitration",
      "abstract": "In this paper, we investigate the working mechanism of modality following through an information flow lens and find that instruction tokens function as structural anchors for modality arbitration.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03677",
      "pdf_url": "https://arxiv.org/pdf/2602.03677",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03677",
      "scraped_at": "2026-02-05T02:11:30.411754"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration",
    "paper_url": "https://huggingface.co/papers/2602.03647",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Search-R2: Enhancing Search-Integrated Reasoning via Actor-Refiner Collaboration",
      "abstract": "Search-R2 trains an Actor and a Meta-Refiner to intervene and repair reasoning with a dense process reward, improving search-based reasoning over RAG/RL baselines.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03647",
      "pdf_url": "https://arxiv.org/pdf/2602.03647",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03647",
      "scraped_at": "2026-02-05T02:11:32.285222"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "LRAgent: Efficient KV Cache Sharing for Multi-LoRA LLM Agents",
    "paper_url": "https://huggingface.co/papers/2602.01053",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "LRAgent: Efficient KV Cache Sharing for Multi-LoRA LLM Agents",
      "abstract": "We propose LRAgent, an efficient KV-cache sharing framework for multi-LoRA LLM agents that shares highly similar base caches induced by the pretrained weights, while keeping lightweight low-rank caches induced by the LoRA adapters.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01053",
      "pdf_url": "https://arxiv.org/pdf/2602.01053",
      "github_links": [
        "https://github.com/hjeon2k/LRAgent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01053",
      "scraped_at": "2026-02-05T02:11:34.175487"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Position: Agentic Evolution is the Path to Evolving LLMs",
    "paper_url": "https://huggingface.co/papers/2602.00359",
    "authors": [
      "Rui Mao",
      "Bing He",
      "Zhan Shi",
      "Hanqing Lu",
      "ventr1c"
    ],
    "stars": "1",
    "details": {
      "title": "Position: Agentic Evolution is the Path to Evolving LLMs",
      "abstract": "Code repository: https://github.com/ventr1c/agentic-evoluiton",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00359",
      "pdf_url": "https://arxiv.org/pdf/2602.00359",
      "github_links": [
        "https://github.com/ventr1c/agentic-evoluiton"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00359",
      "scraped_at": "2026-02-05T02:11:36.128396"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "WorldVQA: Measuring Atomic World Knowledge in Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.02537",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "WorldVQA: Measuring Atomic World Knowledge in Multimodal Large Language Models",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models (2026) MMErroR: A Benchmark for Erroneous Reasoning in Vision-Language Models (2026) Beyond Accuracy: Evaluating Grounded Visual Evidence in Thinking with Images (2026) Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies (2026) MM-THEBench: Do Reasoning MLLMs Think Reasonably? (2026) VLN-MME: Diagnosing MLLMs as Language-guided Visual Navigation agents (2025) BabyVision: Visual Reasoning Beyond Language (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02537",
      "pdf_url": "https://arxiv.org/pdf/2602.02537",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02537",
      "scraped_at": "2026-02-05T02:11:38.158173"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation",
    "paper_url": "https://huggingface.co/papers/2602.03806",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "Bridging Online and Offline RL: Contextual Bandit Learning for Multi-Turn Code Generation",
      "abstract": "Recently, there have been significant research interests in training large language models (LLMs) with reinforcement learning (RL) on real-world tasks, such as multi-turn code generation. While online RL tends to perform better than offline RL, its higher training cost and instability hinders wide adoption. In this paper, we build on the observation that multi-turn code generation can be formulated as a one-step recoverable Markov decision process and propose contextual bandit learning with offline trajectories (Cobalt), a new method that combines the benefits of online and offline RL. Cobalt first collects code generation trajectories using a reference LLM and divides them into partial trajectories as contextual prompts. Then, during online bandit learning, the LLM is trained to complete each partial trajectory prompt through single-step code generation. Cobalt outperforms two multi-turn online RL baselines based on GRPO and VeRPO, and substantially improves R1-Distill 8B and Qwen3 8B by up to 9.0 and 6.2 absolute Pass@1 scores on LiveCodeBench. Also, we analyze LLMs' in-context reward hacking behaviors and augment Cobalt training with perturbed trajectories to mitigate this issue. Overall, our results demonstrate Cobalt as a promising solution for iterative decision-making tasks like multi-turn code generation. Our code and data are available at https://github.com/OSU-NLP-Group/cobalt .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03806",
      "pdf_url": "https://arxiv.org/pdf/2602.03806",
      "github_links": [
        "https://github.com/OSU-NLP-Group/cobalt"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03806",
      "scraped_at": "2026-02-05T02:11:40.045980"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights",
    "paper_url": "https://huggingface.co/papers/2602.02905",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FIRE-Bench: Evaluating Agents on the Rediscovery of Scientific Insights",
      "abstract": "FIRE-Bench is a human-grounded benchmark designed to test whether AI can actually do science end-to-end, from ideation, planning, to implementation, execution, and conclusions. It converts recent, expert-validated scientific insights from top ML conferences into masked discovery challenges, forcing agents to rediscover human-verified insights rather than reproduce methods. By anchoring open-ended exploration to human-grounded ground truth and evaluating discovery at the claim level, FIRE-Bench reveals a clear ‚Äúscience gap‚Äù: today‚Äôs best agents are less capable (<50 F1), unreliable, and fail mainly at planning and reasoning, not coding. The benchmark offers a scalable, structured way to convert a paper into a constrained discovery problem to measure progress toward reliable, creative, full-cycle scientific discovery, and targets a path toward live, continuously updated evaluation of research-capable AI.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02905",
      "pdf_url": "https://arxiv.org/pdf/2602.02905",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02905",
      "scraped_at": "2026-02-05T02:11:41.895291"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "ObjEmbed: Towards Universal Multimodal Object Embeddings",
    "paper_url": "https://huggingface.co/papers/2602.01753",
    "authors": [
      "Xiaohua Xie",
      "Jing Lyu",
      "Fengyun Rao",
      "Yukun Su",
      "fushh7"
    ],
    "stars": "13",
    "details": {
      "title": "ObjEmbed: Towards Universal Multimodal Object Embeddings",
      "abstract": "Code is available at https://github.com/WeChatCV/ObjEmbed",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01753",
      "pdf_url": "https://arxiv.org/pdf/2602.01753",
      "github_links": [
        "https://github.com/WeChatCV/ObjEmbed"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01753",
      "scraped_at": "2026-02-05T02:11:43.794373"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Glance and Focus Reinforcement for Pan-cancer Screening",
    "paper_url": "https://huggingface.co/papers/2601.19103",
    "authors": [],
    "stars": "26",
    "details": {
      "title": "Glance and Focus Reinforcement for Pan-cancer Screening",
      "abstract": "Code is available at https://github.com/Luffy03/GF-Screen",
      "arxiv_page_url": "https://arxiv.org/abs/2601.19103",
      "pdf_url": "https://arxiv.org/pdf/2601.19103",
      "github_links": [
        "https://github.com/Luffy03/GF-Screen"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.19103",
      "scraped_at": "2026-02-05T02:11:45.897279"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Contextualized Visual Personalization in Vision-Language Models",
    "paper_url": "https://huggingface.co/papers/2602.03454",
    "authors": [
      "Jisoo Mok",
      "Han Cheol Moon",
      "Junsung Park",
      "Sangwon Yu",
      "Yeongtak"
    ],
    "stars": "0",
    "details": {
      "title": "Contextualized Visual Personalization in Vision-Language Models",
      "abstract": "We introduce CoViP, a unified framework for contextualized visual personalization in VLMs, featuring a novel personalized image captioning benchmark, an RL-based post-training scheme, and diagnostic downstream personalization tasks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03454",
      "pdf_url": "https://arxiv.org/pdf/2602.03454",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03454",
      "scraped_at": "2026-02-05T02:11:47.677895"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "POP: Prefill-Only Pruning for Efficient Large Model Inference",
    "paper_url": "https://huggingface.co/papers/2602.03295",
    "authors": [
      "Qingan Li",
      "Jun Wang",
      "Zhihui Fu",
      "Junhuihe"
    ],
    "stars": "0",
    "details": {
      "title": "POP: Prefill-Only Pruning for Efficient Large Model Inference",
      "abstract": "This paper proposes Prefill-Only Pruning (POP), a stage-aware strategy that accelerates inference by pruning redundant deep layers exclusively during the prefill stage while retaining the full model capacity for decoding to preserve high generative accuracy.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03295",
      "pdf_url": "https://arxiv.org/pdf/2602.03295",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03295",
      "scraped_at": "2026-02-05T02:11:49.496210"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration",
    "paper_url": "https://huggingface.co/papers/2602.02419",
    "authors": [
      "Xin Eric Wang",
      "Yue Fan",
      "Qingni Wang"
    ],
    "stars": "4",
    "details": {
      "title": "SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration",
      "abstract": "Code: https://github.com/Cece1031/SAFEGROUND",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02419",
      "pdf_url": "https://arxiv.org/pdf/2602.02419",
      "github_links": [
        "https://github.com/Cece1031/SAFEGROUND"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02419",
      "scraped_at": "2026-02-05T02:11:51.442936"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "LycheeDecode: Accelerating Long-Context LLM Inference via Hybrid-Head Sparse Decoding",
    "paper_url": "https://huggingface.co/papers/2602.04541",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "LycheeDecode: Accelerating Long-Context LLM Inference via Hybrid-Head Sparse Decoding",
      "abstract": "ICLR 2026",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04541",
      "pdf_url": "https://arxiv.org/pdf/2602.04541",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04541",
      "scraped_at": "2026-02-05T02:11:54.529576"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques",
    "paper_url": "https://huggingface.co/papers/2602.03837",
    "authors": [
      "Song Zuo",
      "Jieming Mao",
      "Lalit Jain",
      "Vincent Cohen-Addad",
      "David P. Woodruff"
    ],
    "stars": "0",
    "details": {
      "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms (2025) Evaluating Large Language Models in Scientific Discovery (2025) Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows (2025) Evaluating Novelty in AI-Generated Research Plans Using Multi-Workflow LLM Pipelines (2025) Enhancing Large Language Models for End-to-End Circuit Analysis Problem Solving (2025) FrontierScience: Evaluating AI's Ability to Perform Expert-Level Scientific Tasks (2026) Towards AI-Supported Research: a Vision of the TIB AIssistant (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03837",
      "pdf_url": "https://arxiv.org/pdf/2602.03837",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03837",
      "scraped_at": "2026-02-05T02:11:56.358233"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Privasis: Synthesizing the Largest \"Public\" Private Dataset from Scratch",
    "paper_url": "https://huggingface.co/papers/2602.03183",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Privasis: Synthesizing the Largest \"Public\" Private Dataset from Scratch",
      "abstract": "Project page: https://privasis.github.io Code: https://github.com/skywalker023/privasis",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03183",
      "pdf_url": "https://arxiv.org/pdf/2602.03183",
      "github_links": [
        "https://github.com/skywalker023/privasis"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03183",
      "scraped_at": "2026-02-05T02:11:58.202215"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "FaceLinkGen: Rethinking Identity Leakage in Privacy-Preserving Face Recognition with Identity Extraction",
    "paper_url": "https://huggingface.co/papers/2602.02914",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FaceLinkGen: Rethinking Identity Leakage in Privacy-Preserving Face Recognition with Identity Extraction",
      "abstract": "A new red-teaming paper on PPFR systems",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02914",
      "pdf_url": "https://arxiv.org/pdf/2602.02914",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02914",
      "scraped_at": "2026-02-05T02:12:00.031797"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Scaling Small Agents Through Strategy Auctions",
    "paper_url": "https://huggingface.co/papers/2602.02751",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Scaling Small Agents Through Strategy Auctions",
      "abstract": "Small language models are cheap but don‚Äôt scale to long-horizon tasks. Strategy auctions help them punch above their weight. üöÄ",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02751",
      "pdf_url": "https://arxiv.org/pdf/2602.02751",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02751",
      "scraped_at": "2026-02-05T02:12:01.973854"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "SimpleGPT: Improving GPT via A Simple Normalization Strategy",
    "paper_url": "https://huggingface.co/papers/2602.01212",
    "authors": [
      "Rong Xiao",
      "Jiaquan Ye",
      "Yelin He",
      "Xianbiao Qi",
      "Marco Chen"
    ],
    "stars": "0",
    "details": {
      "title": "SimpleGPT: Improving GPT via A Simple Normalization Strategy",
      "abstract": "This paper revisits Transformer optimization through the lens of second-order geometry and establish a direct connection between architectural design, activation scale, the Hessian matrix, and the maximum tolerable learning rate.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01212",
      "pdf_url": "https://arxiv.org/pdf/2602.01212",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01212",
      "scraped_at": "2026-02-05T02:12:03.808039"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.03320",
    "authors": [
      "Boyun Zheng",
      "Wanting Geng",
      "Qi Yang",
      "Liuxin Bao",
      "Saint-lsy"
    ],
    "stars": "8",
    "details": {
      "title": "MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03320",
      "pdf_url": "https://arxiv.org/pdf/2602.03320",
      "github_links": [
        "https://github.com/CUHK-AIM-Group/MedSAM-Agent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03320",
      "scraped_at": "2026-02-05T02:12:06.214864"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "The Necessity of a Unified Framework for LLM-Based Agent Evaluation",
    "paper_url": "https://huggingface.co/papers/2602.03238",
    "authors": [
      "Sen Su",
      "Philip S. Yu",
      "Li Sun",
      "Pengyu Zhu"
    ],
    "stars": "0",
    "details": {
      "title": "The Necessity of a Unified Framework for LLM-Based Agent Evaluation",
      "abstract": "With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts, toolset configurations, and environmental dynamics. Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03238",
      "pdf_url": "https://arxiv.org/pdf/2602.03238",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03238",
      "scraped_at": "2026-02-05T02:12:08.043813"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training",
    "paper_url": "https://huggingface.co/papers/2602.02494",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training",
      "abstract": "MEG-XL is a brain-to-text foundation model pre-trained with 2.5 minutes of MEG context per sample. It is designed to capture extended neural context, enabling high data efficiency for decoding words from brain activity.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02494",
      "pdf_url": "https://arxiv.org/pdf/2602.02494",
      "github_links": [
        "https://github.com/neural-processing-lab/MEG-XL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02494",
      "scraped_at": "2026-02-05T02:12:09.906071"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.02405",
    "authors": [
      "Alan Ritter",
      "Jungsoo Park",
      "Ethan Mendes"
    ],
    "stars": "0",
    "details": {
      "title": "Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning",
      "abstract": "Improving the reasoning capabilities of large language models (LLMs) typically relies either on the model's ability to sample a correct solution to be reinforced or on the existence of a stronger model able to solve the problem. However, many difficult problems remain intractable for even current frontier models, preventing the extraction of valid training signals. A promising alternative is to leverage high-quality expert human solutions, yet naive imitation of this data fails because it is fundamentally out of distribution: expert solutions are typically didactic, containing implicit reasoning gaps intended for human readers rather than computational models. Furthermore, high-quality expert solutions are expensive, necessitating generalizable sample-efficient training methods. We propose Distribution Aligned Imitation Learning (DAIL), a two-step method that bridges the distributional gap by first transforming expert solutions into detailed, in-distribution reasoning traces and then applying a contrastive objective to focus learning on expert insights and methodologies. We find that DAIL can leverage fewer than 1000 high-quality expert solutions to achieve 10-25% pass@k gains on Qwen2.5-Instruct and Qwen3 models, improve reasoning efficiency by 2x to 4x, and enable out-of-domain generalization.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02405",
      "pdf_url": "https://arxiv.org/pdf/2602.02405",
      "github_links": [
        "https://github.com/ethanm88/DAIL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02405",
      "scraped_at": "2026-02-05T02:12:11.754096"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation",
    "paper_url": "https://huggingface.co/papers/2602.02220",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation",
      "abstract": "The paper introduces HieraNav, a hierarchical object-oriented navigation task spanning scene, room, region, and instance levels, and presents the first large-scale benchmark LangMap to advance language-driven goal navigation research.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02220",
      "pdf_url": "https://arxiv.org/pdf/2602.02220",
      "github_links": [
        "https://github.com/bo-miao/LangMap"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02220",
      "scraped_at": "2026-02-05T02:12:13.783832"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Feedback by Design: Understanding and Overcoming User Feedback Barriers in Conversational Agents",
    "paper_url": "https://huggingface.co/papers/2602.01405",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Feedback by Design: Understanding and Overcoming User Feedback Barriers in Conversational Agents",
      "abstract": "AI is designed to learn and adapt from human feedback. But humans give systematically worse feedback to AI than to other humans. Why? What feedback barriers exist and how can we fix them? Find out in our paper, accepted at CHI 2026.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01405",
      "pdf_url": "https://arxiv.org/pdf/2602.01405",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01405",
      "scraped_at": "2026-02-05T02:12:15.589387"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "RecGOAT: Graph Optimal Adaptive Transport for LLM-Enhanced Multimodal Recommendation with Dual Semantic Alignment",
    "paper_url": "https://huggingface.co/papers/2602.00682",
    "authors": [
      "Chi Lu",
      "Wei Yang",
      "Zeyu Song",
      "Hengwei Ju",
      "Yuecheng Li"
    ],
    "stars": "1",
    "details": {
      "title": "RecGOAT: Graph Optimal Adaptive Transport for LLM-Enhanced Multimodal Recommendation with Dual Semantic Alignment",
      "abstract": "RecGOAT presents a novel yet simple dual-granularity semantic alignment framework for LLM-enhanced multimodal recommendation, which offers theoretically guaranteed alignment capability.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00682",
      "pdf_url": "https://arxiv.org/pdf/2602.00682",
      "github_links": [
        "https://github.com/6lyc/RecGOAT-LLM4Rec"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00682",
      "scraped_at": "2026-02-05T02:12:17.546485"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "MemoryLLM: Plug-n-Play Interpretable Feed-Forward Memory for Transformers",
    "paper_url": "https://huggingface.co/papers/2602.00398",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "MemoryLLM: Plug-n-Play Interpretable Feed-Forward Memory for Transformers",
      "abstract": "Key Question: What if FFNs were actually human-interpretable, token-indexed memory?",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00398",
      "pdf_url": "https://arxiv.org/pdf/2602.00398",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00398",
      "scraped_at": "2026-02-05T02:12:19.433070"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "Adaptive Evidence Weighting for Audio-Spatiotemporal Fusion",
    "paper_url": "https://huggingface.co/papers/2602.03817",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Adaptive Evidence Weighting for Audio-Spatiotemporal Fusion",
      "abstract": "Authors introduce a family of adaptive evidence weighting models for audio spatial-temporal fusion; SoTA results on CBI audio-acoustic classification.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03817",
      "pdf_url": "https://arxiv.org/pdf/2602.03817",
      "github_links": [
        "https://github.com/leharris3/birdnoise"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03817",
      "scraped_at": "2026-02-05T02:12:21.297199"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "You Need an Encoder for Native Position-Independent Caching",
    "paper_url": "https://huggingface.co/papers/2602.01519",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "You Need an Encoder for Native Position-Independent Caching",
      "abstract": "Welcome back, Encoder.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01519",
      "pdf_url": "https://arxiv.org/pdf/2602.01519",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01519",
      "scraped_at": "2026-02-05T02:12:23.237544"
    },
    "scraped_date": "2026-02-05"
  },
  {
    "title": "ERNIE 5.0 Technical Report",
    "paper_url": "https://huggingface.co/papers/2602.04705",
    "authors": [
      "HasuerYu",
      "LLLL",
      "guanwcn",
      "max-zhenyu-zhang",
      "sjy1203"
    ],
    "stars": "0",
    "details": {
      "title": "ERNIE 5.0 Technical Report",
      "abstract": "good work",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04705",
      "pdf_url": "https://arxiv.org/pdf/2602.04705",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04705",
      "scraped_at": "2026-02-06T02:10:53.168495"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "FASA: Frequency-aware Sparse Attention",
    "paper_url": "https://huggingface.co/papers/2602.03152",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FASA: Frequency-aware Sparse Attention",
      "abstract": "[ICLR26] A very interesting and effective work to speed up the inference of large models!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03152",
      "pdf_url": "https://arxiv.org/pdf/2602.03152",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03152",
      "scraped_at": "2026-02-06T02:10:55.011180"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.04634",
    "authors": [],
    "stars": "2.38k",
    "details": {
      "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning",
      "abstract": "We introduce WideSeek-R1, a lead-agent-subagent system trained via multi-agent RL to explore width scaling for broad information seeking. üåê Project Page | üìÑ Paper | üíª Code | üì¶ Dataset | ü§ó Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04634",
      "pdf_url": "https://arxiv.org/pdf/2602.04634",
      "github_links": [
        "https://github.com/RLinf/RLinf/tree/main/examples/wideseek_r1"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04634",
      "scraped_at": "2026-02-06T02:10:56.873627"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Training Data Efficiency in Multimodal Process Reward Models",
    "paper_url": "https://huggingface.co/papers/2602.04145",
    "authors": [
      "Haolin Liu",
      "Shaoyang Xu",
      "Langlin Huang",
      "Chengsong Huang",
      "jinyuan222"
    ],
    "stars": "0",
    "details": {
      "title": "Training Data Efficiency in Multimodal Process Reward Models",
      "abstract": "Multimodal Process Reward Models (MPRMs) are central to step-level supervision for visual reasoning in MLLMs. Training MPRMs typically requires large-scale Monte Carlo (MC)-annotated corpora, incurring substantial training cost. This paper studies the data efficiency for MPRM training. Our preliminary experiments reveal that MPRM training quickly saturates under random subsampling of the training data, indicating substantial redundancy within existing MC-annotated corpora. To explain this, we formalize a theoretical framework and reveal that informative gradient updates depend on two factors: label mixtures of positive/negative steps and label reliability (average MC scores of positive steps). Guided by these insights, we propose the Balanced-Information Score (BIS), which prioritizes both mixture and reliability based on existing MC signals at the rollout level, without incurring any additional cost. Across two backbones (InternVL2.5-8B and Qwen2.5-VL-7B) on VisualProcessBench, BIS-selected subsets consistently match and even surpass the full-data performance at small fractions. Notably, the BIS subset reaches full-data performance using only 10% of the training data, improving over random subsampling by a relative 4.1%. Our code is released Balanced-Info-MPRM .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04145",
      "pdf_url": "https://arxiv.org/pdf/2602.04145",
      "github_links": [
        "https://github.com/JinYuanLi0012/Balanced-Info-MPRM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04145",
      "scraped_at": "2026-02-06T02:10:58.690329"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.04804",
    "authors": [
      "Yiyan Ji",
      "UnnamedWatcher",
      "xuyang-liu16",
      "Jungang",
      "dingyue1011"
    ],
    "stars": "0",
    "details": {
      "title": "OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models",
      "abstract": "We present OmniSIFT , which is a modality-asymmetric token compression framework tailored for Omni-LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04804",
      "pdf_url": "https://arxiv.org/pdf/2602.04804",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04804",
      "scraped_at": "2026-02-06T02:11:00.548438"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing",
    "paper_url": "https://huggingface.co/papers/2602.03560",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing",
      "abstract": "Efficient LLM Architecture, Sparse Attention, Hybrid Architecture",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03560",
      "pdf_url": "https://arxiv.org/pdf/2602.03560",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03560",
      "scraped_at": "2026-02-06T02:11:02.434305"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models",
    "paper_url": "https://huggingface.co/papers/2602.04515",
    "authors": [
      "Ziyi Bai",
      "Chaojie Li",
      "MingMing Yu",
      "Yu Bai",
      "tellarin"
    ],
    "stars": "0",
    "details": {
      "title": "EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models",
      "abstract": "EgoActor is one of the key components of project RoboNoid. Project page: https://baai-agents.github.io/EgoActor/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04515",
      "pdf_url": "https://arxiv.org/pdf/2602.04515",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04515",
      "scraped_at": "2026-02-06T02:11:05.482402"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization",
    "paper_url": "https://huggingface.co/papers/2602.02958",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization",
      "abstract": "Efficient Long Video Generation, designed for world models and autoregressive video gen applications",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02958",
      "pdf_url": "https://arxiv.org/pdf/2602.02958",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02958",
      "scraped_at": "2026-02-06T02:11:07.373121"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation",
    "paper_url": "https://huggingface.co/papers/2602.02402",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation",
      "abstract": "Project Page: https://city-super.github.io/SoMA/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02402",
      "pdf_url": "https://arxiv.org/pdf/2602.02402",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02402",
      "scraped_at": "2026-02-06T02:11:09.250820"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents",
    "paper_url": "https://huggingface.co/papers/2602.02196",
    "authors": [
      "Qiushi Sun",
      "Fangzhi Xu",
      "Xinyu Che",
      "Hang Yan",
      "VentureZJ"
    ],
    "stars": "0",
    "details": {
      "title": "TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents",
      "abstract": "First Paper For Diagnostic Evaluation of Test-Time Improvement in LLM Agents",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02196",
      "pdf_url": "https://arxiv.org/pdf/2602.02196",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02196",
      "scraped_at": "2026-02-06T02:11:11.174150"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Residual Context Diffusion Language Models",
    "paper_url": "https://huggingface.co/papers/2601.22954",
    "authors": [],
    "stars": "44",
    "details": {
      "title": "Residual Context Diffusion Language Models",
      "abstract": "We introduce Residual Context Diffusion (RCD): a simple idea to boost diffusion LLMs‚Äîstop wasting ‚Äúremasked‚Äù tokens. Diffusion LLMs decode in parallel but often lag AR models because low-confidence tokens are discarded each step. RCD turns those discarded distributions into residual context and injects them into the next denoising step, recycling computation instead of throwing it away. Results: consistent gains over Sequential Denoising (SeqD) on SDAR & LLaDA, with biggest jumps on hard math reasoning (AIME24/25, MinervaMath).",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22954",
      "pdf_url": "https://arxiv.org/pdf/2601.22954",
      "github_links": [
        "https://github.com/yuezhouhu/residual-context-diffusion"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22954",
      "scraped_at": "2026-02-06T02:11:13.901098"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Rethinking the Trust Region in LLM Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.04879",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Rethinking the Trust Region in LLM Reinforcement Learning",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04879",
      "pdf_url": "https://arxiv.org/pdf/2602.04879",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04879",
      "scraped_at": "2026-02-06T02:11:15.748910"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Learning to Repair Lean Proofs from Compiler Feedback",
    "paper_url": "https://huggingface.co/papers/2602.02990",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Learning to Repair Lean Proofs from Compiler Feedback",
      "abstract": "Existing Lean datasets contain correct proofs. Models learn error correction with RL, that's expensive. We release a dataset of 260k erroneous Lean proofs, the compiler feedback, error explanation, proof repair reasoning trace, and the corrected proof. Model Baseline Fine-tuned Goedel-Prover-V2-32B 26.8% ‚Äî Goedel-Prover-V2-8B 15.5% 34.6% Kimina-Prover-8B 11.1% 31.9% Qwen3-4B-Instruct-2507 1.1% 27.4%",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02990",
      "pdf_url": "https://arxiv.org/pdf/2602.02990",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02990",
      "scraped_at": "2026-02-06T02:11:17.621561"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Semantic Routing: Exploring Multi-Layer LLM Feature Weighting for Diffusion Transformers",
    "paper_url": "https://huggingface.co/papers/2602.03510",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Semantic Routing: Exploring Multi-Layer LLM Feature Weighting for Diffusion Transformers",
      "abstract": "Recent DiT-based text-to-image models increasingly adopt LLMs as text encoders, yet text conditioning remains largely static and often utilizes only a single LLM layer, despite pronounced semantic hierarchy across LLM layers and non-stationary denoising dynamics over both diffusion time and network depth. To better match the dynamic process of DiT generation and thereby enhance the diffusion model's generative capability, we introduce a unified normalized convex fusion framework equipped with lightweight gates to systematically organize multi-layer LLM hidden states via time-wise, depth-wise, and joint fusion. Experiments establish Depth-wise Semantic Routing as the superior conditioning strategy, consistently improving text‚Äìimage alignment and compositional generation (e.g., +9.97 on the GenAI-Bench Counting task). Conversely, we find that purely time-wise fusion can paradoxically degrade visual generation fidelity. We attribute this to a train‚Äìinference trajectory mismatch: under classifier-free guidance, nominal timesteps fail to track the effective SNR, causing semantically mistimed feature injection during inference. Overall, our results position depth-wise routing as a strong and effective baseline and highlight the critical need for trajectory-aware signals to enable robust time-dependent conditioning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03510",
      "pdf_url": "https://arxiv.org/pdf/2602.03510",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03510",
      "scraped_at": "2026-02-06T02:11:19.514306"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "HY3D-Bench: Generation of 3D Assets",
    "paper_url": "https://huggingface.co/papers/2602.03907",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "HY3D-Bench: Generation of 3D Assets",
      "abstract": "HY3D-Bench provides a unified 3D generation data ecosystem with 250k real assets, 125k synthetic assets, structured part-level decomposition, and a pipeline enabling scalable 3D model training.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03907",
      "pdf_url": "https://arxiv.org/pdf/2602.03907",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03907",
      "scraped_at": "2026-02-06T02:11:21.373953"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations",
    "paper_url": "https://huggingface.co/papers/2602.03828",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations",
      "abstract": "AutoFigure [Accepted to ICLR 2026] An automated scientific figure-drawing system for controllable generation of paper method diagrams. It is now fully open-sourced. The sketch generation process is user-intervenable and editable, avoiding ‚Äúblack-box drawing.‚Äù The final rendering achieves top-conference‚Äìlevel paper illustrations. Automatically converts bitmaps into fully editable SVG vector graphics‚Äîall text, shapes, and arrows can be modified losslessly. Supports uploading a reference figure and one-click imitation of the target paper‚Äôs visual style, enabling truly usable, editable paper-figure generation. Repository: https://github.com/ResearAI/AutoFigure-Edit .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03828",
      "pdf_url": "https://arxiv.org/pdf/2602.03828",
      "github_links": [
        "https://github.com/ResearAI/AutoFigure-Edit"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03828",
      "scraped_at": "2026-02-06T02:11:23.190603"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Self-Hinting Language Models Enhance Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.03143",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "Self-Hinting Language Models Enhance Reinforcement Learning",
      "abstract": "RL for LLMs often stalls under sparse rewards ‚Äî especially with GRPO, where whole rollout groups get identical 0 rewards and learning just‚Ä¶ dies. üí° SAGE fixes this with a simple but powerful idea: üëâ Let the model give itself hints during training. How it works: The model samples a compact hint (plan / decomposition) before solving Rewards stay unchanged (same verifier, same objective) Hints only reshape sampling, preventing advantage collapse At test time? No hints at all. Clean deployment. üî• Why it matters: Turns dead-end prompts into useful learning signals Acts as an adaptive curriculum driven by the model itself Stays fully on-policy (no external teachers required) üìä Results across 6 benchmarks & 3 LLMs over GRPO: +2.0 on Llama-3.2-3B +1.2 on Qwen2.5-7B +1.3 on Qwen3-4B Sometimes the best teacher is‚Ä¶ yourself üòå Code: https://github.com/BaohaoLiao/SAGE Slide by NotebookLM:",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03143",
      "pdf_url": "https://arxiv.org/pdf/2602.03143",
      "github_links": [
        "https://github.com/BaohaoLiao/SAGE"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03143",
      "scraped_at": "2026-02-06T02:11:25.071198"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "CL-bench: A Benchmark for Context Learning",
    "paper_url": "https://huggingface.co/papers/2602.03587",
    "authors": [],
    "stars": "312",
    "details": {
      "title": "CL-bench: A Benchmark for Context Learning",
      "abstract": "A benchmark for context learning",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03587",
      "pdf_url": "https://arxiv.org/pdf/2602.03587",
      "github_links": [
        "https://github.com/Tencent-Hunyuan/CL-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03587",
      "scraped_at": "2026-02-06T02:11:26.960820"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration",
    "paper_url": "https://huggingface.co/papers/2602.04575",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration",
      "abstract": "For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ‚Äúusability ceiling‚Äù manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator‚Äôs high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the Vibe AIGC, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows. Under this paradigm, the user‚Äôs role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta- Planner then functions as a system architect, deconstructing this ‚ÄúVibe‚Äù into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04575",
      "pdf_url": "https://arxiv.org/pdf/2602.04575",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04575",
      "scraped_at": "2026-02-06T02:11:28.795117"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "VLS: Steering Pretrained Robot Policies via Vision-Language Models",
    "paper_url": "https://huggingface.co/papers/2602.03973",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "VLS: Steering Pretrained Robot Policies via Vision-Language Models",
      "abstract": "Why do pretrained diffusion or flow-matching policies fail when the same task is performed near an obstacle, on a shifted support surface, or amid mild clutter? Such failures rarely reflect missing motor skills; instead, they expose a limitation of imitation learning under train-test shifts, where action generation is tightly coupled to training-specific spatial configurations and task specifications. Retraining or fine-tuning to address these failures is costly and conceptually misaligned, as the required behaviors already exist but cannot be selectively adapted at test time. We propose Vision-Language Steering (VLS), a training-free framework for inference-time adaptation of frozen generative robot policies. VLS treats adaptation as an inference-time control problem, steering the sampling process of a pretrained diffusion or flow-matching policy in response to out-of-distribution observation-language inputs without modifying policy parameters. By leveraging vision-language models to synthesize trajectory-differentiable reward functions, VLS guides denoising toward action trajectories that satisfy test-time spatial and task requirements. Across simulation and real-world evaluations, VLS consistently outperforms prior steering methods, achieving a 31% improvement on CALVIN and a 13% gain on LIBERO-PRO. Real-world deployment on a Franka robot further demonstrates robust inference-time adaptation under test-time spatial and semantic shifts.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03973",
      "pdf_url": "https://arxiv.org/pdf/2602.03973",
      "github_links": [
        "https://github.com/Vision-Language-Steering/code"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03973",
      "scraped_at": "2026-02-06T02:11:30.899742"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces",
    "paper_url": "https://huggingface.co/papers/2602.03442",
    "authors": [],
    "stars": "39",
    "details": {
      "title": "A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces",
      "abstract": "Existing RAG systems rely on Graph or Workflow paradigms that fail to scale with advances in model reasoning and tool-use capabilities. We introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model.  Experiments show A-RAG achieves 94.5% on HotpotQA and 89.7% on 2WikiMultiHop with GPT-5-mini, significantly outperforming prior methods.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03442",
      "pdf_url": "https://arxiv.org/pdf/2602.03442",
      "github_links": [
        "https://github.com/Ayanami0730/arag"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03442",
      "scraped_at": "2026-02-06T02:11:32.799556"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR",
    "paper_url": "https://huggingface.co/papers/2601.18207",
    "authors": [
      "Alejandro Lozano",
      "Jan N. Hansen",
      "yuhuizhang",
      "pengxunduo",
      "jmhb"
    ],
    "stars": "21",
    "details": {
      "title": "PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR",
      "abstract": "Project page: https://jmhb0.github.io/PaperSearchQA/ Data: https://huggingface.co/collections/jmhb/papersearchqa Code for data-gen pipelines: https://github.com/jmhb0/PaperSearchQA",
      "arxiv_page_url": "https://arxiv.org/abs/2601.18207",
      "pdf_url": "https://arxiv.org/pdf/2601.18207",
      "github_links": [
        "https://github.com/jmhb0/PaperSearchQA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.18207",
      "scraped_at": "2026-02-06T02:11:34.694822"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Horizon-LM: A RAM-Centric Architecture for LLM Training",
    "paper_url": "https://huggingface.co/papers/2602.04816",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "Horizon-LM: A RAM-Centric Architecture for LLM Training",
      "abstract": "Horizon-LM: Train hundred-billion‚Äìparameter language models without buying more GPUs. We propose a RAM-centric, CPU-master training architecture that treats GPUs as transient compute engines rather than persistent parameter stores, enabling large-scale training on minimal GPU hardware.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04816",
      "pdf_url": "https://arxiv.org/pdf/2602.04816",
      "github_links": [
        "https://github.com/DLYuanGod/Horizon-LM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04816",
      "scraped_at": "2026-02-06T02:11:37.105008"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "From Data to Behavior: Predicting Unintended Model Behaviors Before Training",
    "paper_url": "https://huggingface.co/papers/2602.04735",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "From Data to Behavior: Predicting Unintended Model Behaviors Before Training",
      "abstract": "Can we foresee unintended model behaviors before fine-tuning? We demonstrate that unintended biases and safety risks can be traced back to interpretable latent data statistics that mechanistically influence model activations, without any parameter updates.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04735",
      "pdf_url": "https://arxiv.org/pdf/2602.04735",
      "github_links": [
        "https://github.com/zjunlp/Data2Behavior"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04735",
      "scraped_at": "2026-02-06T02:11:38.959633"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "MEnvAgent: Scalable Polyglot Environment Construction for Verifiable Software Engineering",
    "paper_url": "https://huggingface.co/papers/2601.22859",
    "authors": [],
    "stars": "8",
    "details": {
      "title": "MEnvAgent: Scalable Polyglot Environment Construction for Verifiable Software Engineering",
      "abstract": "Check out this verifiable environment for SWE! Open-sourced dataset, Docker images, and evals!",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22859",
      "pdf_url": "https://arxiv.org/pdf/2601.22859",
      "github_links": [
        "https://github.com/ernie-research/MEnvAgent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22859",
      "scraped_at": "2026-02-06T02:11:40.830424"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.04284",
    "authors": [],
    "stars": "8",
    "details": {
      "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning",
      "abstract": "Efficient LLM Agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04284",
      "pdf_url": "https://arxiv.org/pdf/2602.04284",
      "github_links": [
        "https://github.com/usail-hkust/Agent-Omit"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04284",
      "scraped_at": "2026-02-06T02:11:42.664936"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use",
    "paper_url": "https://huggingface.co/papers/2602.02160",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use",
      "abstract": "good job , awesome boys !",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02160",
      "pdf_url": "https://arxiv.org/pdf/2602.02160",
      "github_links": [
        "https://github.com/alibaba/EfficientAI"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02160",
      "scraped_at": "2026-02-06T02:11:44.507332"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "SpatiaLab: Can Vision-Language Models Perform Spatial Reasoning in the Wild?",
    "paper_url": "https://huggingface.co/papers/2602.03916",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "SpatiaLab: Can Vision-Language Models Perform Spatial Reasoning in the Wild?",
      "abstract": "We are excited to share that our paper ‚Äúùêíùê©ùêöùê≠ùê¢ùêöùêãùêöùêõ: ùêÇùêöùêß ùêïùê¢ùê¨ùê¢ùê®ùêß‚Äìùêãùêöùêßùê†ùêÆùêöùê†ùêû ùêåùê®ùêùùêûùê•ùê¨ ùêèùêûùê´ùêüùê®ùê´ùê¶ ùêíùê©ùêöùê≠ùê¢ùêöùê• ùêëùêûùêöùê¨ùê®ùêßùê¢ùêßùê† ùê¢ùêß ùê≠ùê°ùêû ùêñùê¢ùê•ùêù?‚Äù is accepted to ICLR 2026 (The Fourteenth International Conference on Learning Representations). SpatiaLab investigates how vision‚Äìlanguage models handle spatial reasoning in real-world settings, and we hope it will serve as a useful benchmark and reference for future research in this area.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03916",
      "pdf_url": "https://arxiv.org/pdf/2602.03916",
      "github_links": [
        "https://github.com/SpatiaLab-Reasoning/SpatiaLab"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03916",
      "scraped_at": "2026-02-06T02:11:46.903617"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Quantifying the Gap between Understanding and Generation within Unified Multimodal Models",
    "paper_url": "https://huggingface.co/papers/2602.02140",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Quantifying the Gap between Understanding and Generation within Unified Multimodal Models",
      "abstract": "A benchmark focuses on quantifying the gap between understanding and generation in unified multimodal model.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02140",
      "pdf_url": "https://arxiv.org/pdf/2602.02140",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02140",
      "scraped_at": "2026-02-06T02:11:48.715201"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation",
    "paper_url": "https://huggingface.co/papers/2602.02554",
    "authors": [
      "Xiaohua Wang",
      "Zisu Huang",
      "Yiyang Lu",
      "Jingwen Xu",
      "fdu-lcz"
    ],
    "stars": "0",
    "details": {
      "title": "BatCoder: Self-Supervised Bidirectional Code-Documentation Learning via Back-Translation",
      "abstract": "Training LLMs for code-related tasks typically depends on high-quality code-documentation pairs, which are costly to curate and often scarce for niche programming languages. We introduce BatCoder, a self-supervised reinforcement learning framework designed to jointly optimize code generation and documentation production. BatCoder employs a back-translation strategy: a documentation is first generated from code, and then the generated documentation is used to reconstruct the original code. The semantic similarity between the original and reconstructed code serves as an implicit reward, enabling reinforcement learning to improve the model's performance both in generating code from documentation and vice versa. This approach allows models to be trained using only code, substantially increasing the available training examples. Evaluated on HumanEval and MBPP with a 7B model, BatCoder achieved 83.5% and 81.0% pass@1, outperforming strong open-source baselines. Moreover, the framework demonstrates consistent scaling with respect to both training corpus size and model capacity.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02554",
      "pdf_url": "https://arxiv.org/pdf/2602.02554",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02554",
      "scraped_at": "2026-02-06T02:11:50.575928"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Likelihood-Based Reward Designs for General LLM Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.03979",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Likelihood-Based Reward Designs for General LLM Reasoning",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering (2026) Coupled Variational Reinforcement Learning for Language Model General Reasoning (2025) Correct, Concise and Complete: Multi-stage Training For Adaptive Reasoning (2026) ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning (2026) Save the Good Prefix: Precise Error Penalization via Process-Supervised RL to Enhance LLM Reasoning (2026) DARL: Encouraging Diverse Answers for General Reasoning without Verifiers (2026) TMS: Trajectory-Mixed Supervision for Reward-Free, On-Policy SFT (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03979",
      "pdf_url": "https://arxiv.org/pdf/2602.03979",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03979",
      "scraped_at": "2026-02-06T02:11:52.412266"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "A2Eval: Agentic and Automated Evaluation for Embodied Brain",
    "paper_url": "https://huggingface.co/papers/2602.01640",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "A2Eval: Agentic and Automated Evaluation for Embodied Brain",
      "abstract": "A2Eval introduces an agentic framework that automates embodied VLM evaluation through two collaborative agents: one that curates balanced benchmarks by identifying capability dimensions, and another that synthesizes executable evaluation pipelines. The system compresses benchmarks by 85%, reduces costs by 77%, and improves human alignment while correcting ranking biases in model evaluations.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01640",
      "pdf_url": "https://arxiv.org/pdf/2602.01640",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01640",
      "scraped_at": "2026-02-06T02:11:54.291883"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Beyond Unimodal Shortcuts: MLLMs as Cross-Modal Reasoners for Grounded Named Entity Recognition",
    "paper_url": "https://huggingface.co/papers/2602.04486",
    "authors": [
      "Yuwei Wang",
      "Kehai Chen",
      "Xuefeng Bai",
      "Yu Zhang",
      "Jinlong Ma"
    ],
    "stars": "0",
    "details": {
      "title": "Beyond Unimodal Shortcuts: MLLMs as Cross-Modal Reasoners for Grounded Named Entity Recognition",
      "abstract": "GMNER",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04486",
      "pdf_url": "https://arxiv.org/pdf/2602.04486",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04486",
      "scraped_at": "2026-02-06T02:11:56.106101"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling",
    "paper_url": "https://huggingface.co/papers/2602.03359",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling",
      "abstract": "We introduce MeKi, a memory-based architecture to scale LLM efficiently. MeKi is able to offload pre-trained token-level expert knowledge to ROM space before deployment. Tested on a Snapdragon mobile platform,  our method achieves superior performance than dense LLM, while maintaining the same inference latency.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03359",
      "pdf_url": "https://arxiv.org/pdf/2602.03359",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03359",
      "scraped_at": "2026-02-06T02:11:57.933236"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Efficient Autoregressive Video Diffusion with Dummy Head",
    "paper_url": "https://huggingface.co/papers/2601.20499",
    "authors": [],
    "stars": "32",
    "details": {
      "title": "Efficient Autoregressive Video Diffusion with Dummy Head",
      "abstract": "Dummy Forcing is built on the observation that about 25% attention heads in existing autoregressive video diffusion models are \"dummy\", attending almost exclusively to the current frame despite access to historical context. Based on this observation, Dummy Forcing develops a technique to automatically identifies dummy heads and allocates varying context. Leveraging this \"dummy property\", we can enable 1. Efficient Video Generation at 24.3FPS real-time speed. 2. High-resolution Video Generation which supports 720P&1080P with 2.0x speedup. 3. Long-context Video Gneration to enlarge the context window by 6.58x without losing efficiency.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.20499",
      "pdf_url": "https://arxiv.org/pdf/2601.20499",
      "github_links": [
        "https://github.com/csguoh/DummyForcing"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.20499",
      "scraped_at": "2026-02-06T02:11:59.751114"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "No One-Size-Fits-All: Building Systems For Translation to Bashkir, Kazakh, Kyrgyz, Tatar and Chuvash Using Synthetic And Original Data",
    "paper_url": "https://huggingface.co/papers/2602.04442",
    "authors": [
      "dimakarp1996"
    ],
    "stars": "0",
    "details": {
      "title": "No One-Size-Fits-All: Building Systems For Translation to Bashkir, Kazakh, Kyrgyz, Tatar and Chuvash Using Synthetic And Original Data",
      "abstract": "We show that effective machine translation for low-resource Turkic languages requires a tailored approach: fine-tuning works best for languages with some data, while retrieval-augmented LLM prompting is essential for extremely resource-scarce ones.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04442",
      "pdf_url": "https://arxiv.org/pdf/2602.04442",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04442",
      "scraped_at": "2026-02-06T02:12:01.562199"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Context Learning for Multi-Agent Discussion",
    "paper_url": "https://huggingface.co/papers/2602.02350",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "Context Learning for Multi-Agent Discussion",
      "abstract": "Try building your own multi-agent system to solve problems!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02350",
      "pdf_url": "https://arxiv.org/pdf/2602.02350",
      "github_links": [
        "https://github.com/HansenHua/M2CL-ICLR26"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02350",
      "scraped_at": "2026-02-06T02:12:03.345663"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Protein Autoregressive Modeling via Multiscale Structure Generation",
    "paper_url": "https://huggingface.co/papers/2602.04883",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Protein Autoregressive Modeling via Multiscale Structure Generation",
      "abstract": "Protein Autoregressive Modeling via Multiscale Structure Generation (PAR) introduces a coarse-to-fine transformer‚Äìflow framework for backbone generation with noisy context learning to mitigate exposure bias.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04883",
      "pdf_url": "https://arxiv.org/pdf/2602.04883",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04883",
      "scraped_at": "2026-02-06T02:12:05.246228"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging",
    "paper_url": "https://huggingface.co/papers/2602.04805",
    "authors": [
      "Shi-Min Hu",
      "Yan-Pei Cao",
      "Meng-Hao Guo",
      "Cheng-Feng Pu",
      "Jia-peng Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging",
      "abstract": "Proposes SkinTokens, a discrete, learnable skinning representation enabling a unified TokenRig autoregressive framework with reinforcement learning fine-tuning to improve rigging accuracy and generalization in 3D animation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04805",
      "pdf_url": "https://arxiv.org/pdf/2602.04805",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04805",
      "scraped_at": "2026-02-06T02:12:07.413218"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models",
    "paper_url": "https://huggingface.co/papers/2602.01849",
    "authors": [
      "Thomas B. Sch√∂n",
      "Lidong Bing",
      "Lei Wang",
      "Ziqi Jin",
      "weblzw"
    ],
    "stars": "7",
    "details": {
      "title": "Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models",
      "abstract": "Self-Rewarding SMC improves sampling for diffusion language models without additional training or external reward guidance.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01849",
      "pdf_url": "https://arxiv.org/pdf/2602.01849",
      "github_links": [
        "https://github.com/Algolzw/self-rewarding-smc"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01849",
      "scraped_at": "2026-02-06T02:12:09.196952"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF",
    "paper_url": "https://huggingface.co/papers/2602.04651",
    "authors": [
      "Dipan Maity"
    ],
    "stars": "0",
    "details": {
      "title": "SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF",
      "abstract": "An alternative to ppo for RLHF.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04651",
      "pdf_url": "https://arxiv.org/pdf/2602.04651",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04651",
      "scraped_at": "2026-02-06T02:12:12.286971"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "RexBERT: Context Specialized Bidirectional Encoders for E-commerce",
    "paper_url": "https://huggingface.co/papers/2602.04605",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "RexBERT: Context Specialized Bidirectional Encoders for E-commerce",
      "abstract": "RexBERT Paper is finally out!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04605",
      "pdf_url": "https://arxiv.org/pdf/2602.04605",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04605",
      "scraped_at": "2026-02-06T02:12:13.966680"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Trust The Typical",
    "paper_url": "https://huggingface.co/papers/2602.04581",
    "authors": [
      "Kanan Gupta",
      "Vikash Singh",
      "Biyao Zhang",
      "Sreehari Sankar",
      "Debargha Ganguly"
    ],
    "stars": "0",
    "details": {
      "title": "Trust The Typical",
      "abstract": "Current approaches to LLM safety fundamentally rely on a brittle cat-and-mouse game of identifying and blocking known threats via guardrails. We argue for a fresh approach: robust safety comes not from enumerating what is harmful, but from deeply understanding what is safe. We introduce Trust The Typical (T3), a framework that operationalizes this principle by treating safety as an out-of-distribution (OOD) detection problem. T3 learns the distribution of acceptable prompts in a semantic space and flags any significant deviation as a potential threat. Unlike prior methods, it requires no training on harmful examples, yet achieves state-of-the-art performance across 18 benchmarks spanning toxicity, hate speech, jailbreaking, multilingual harms, and over-refusal, reducing false positive rates by up to 40x relative to specialized safety models. A single model trained only on safe English text transfers effectively to diverse domains and over 14 languages without retraining. Finally, we demonstrate production readiness by integrating a GPU-optimized version into vLLM, enabling continuous guardrailing during token generation with less than 6% overhead even under dense evaluation intervals on large-scale workloads.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04581",
      "pdf_url": "https://arxiv.org/pdf/2602.04581",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04581",
      "scraped_at": "2026-02-06T02:12:15.762459"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "OmniRad: A Radiological Foundation Model for Multi-Task Medical Image Analysis",
    "paper_url": "https://huggingface.co/papers/2602.04547",
    "authors": [
      "Cecilia Di Ruberto",
      "Andrea Loddo",
      "Luca Zedda"
    ],
    "stars": "2",
    "details": {
      "title": "OmniRad: A Radiological Foundation Model for Multi-Task Medical Image Analysis",
      "abstract": "OmniRad introduces a self-supervised radiological foundation model pretrained on 1.2M medical images that‚Äôs designed for representation reuse across classification, segmentation, and vision‚Äìlanguage tasks. The paper shows consistent gains over prior medical foundation models on MedMNISTv2 and multiple MedSegBench segmentation datasets, and provides code on GitHub https://github.com/unica-visual-intelligence-lab/OmniRad and pretrained backbones here on Huggingface https://huggingface.co/collections/Snarcy/omnirad .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04547",
      "pdf_url": "https://arxiv.org/pdf/2602.04547",
      "github_links": [
        "https://github.com/unica-visual-intelligence-lab/OmniRad"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04547",
      "scraped_at": "2026-02-06T02:12:17.557421"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Proxy Compression for Language Modeling",
    "paper_url": "https://huggingface.co/papers/2602.04289",
    "authors": [
      "Lingpeng Kong",
      "Xiachong Feng",
      "Qian Liu",
      "Xinyu Li",
      "Lin Zheng"
    ],
    "stars": "1",
    "details": {
      "title": "Proxy Compression for Language Modeling",
      "abstract": "This work introduces proxy compression, an alternative training scheme for language models that preserves the efficiency benefits of compression (e.g. tokenization) while providing an end-to-end, byte-level interface at inference time.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04289",
      "pdf_url": "https://arxiv.org/pdf/2602.04289",
      "github_links": [
        "https://github.com/LZhengisme/proxy-compression"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04289",
      "scraped_at": "2026-02-06T02:12:19.349044"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization",
    "paper_url": "https://huggingface.co/papers/2602.04271",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization",
      "abstract": "üöÄ Introducing SkeletonGaussian ‚Äî Editable 4D Generation through Gaussian Skeletonization! (Accepted by CVM 2026) ‚ú® Generate dynamic 3D Gaussians from text, images, or videos ü¶¥ Explicit skeleton-driven motion enables intuitive pose editing üéØ Higher visual quality + better motion fidelity than prior 4D methods A new step toward controllable, editable 4D generation. Project page: https://wusar.github.io/projects/skeletongaussian/ Arxiv: https://arxiv.org/abs/2602.04271 Code will be available soon.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04271",
      "pdf_url": "https://arxiv.org/pdf/2602.04271",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04271",
      "scraped_at": "2026-02-06T02:12:21.163190"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent",
    "paper_url": "https://huggingface.co/papers/2602.03955",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent",
      "abstract": "Distilling multi-agent intelligence into a single agent. A comprehensive study.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03955",
      "pdf_url": "https://arxiv.org/pdf/2602.03955",
      "github_links": [
        "https://github.com/AIFrontierLab/AgentArk"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03955",
      "scraped_at": "2026-02-06T02:12:22.982442"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "\"I May Not Have Articulated Myself Clearly\": Diagnosing Dynamic Instability in LLM Reasoning at Inference Time",
    "paper_url": "https://huggingface.co/papers/2602.02863",
    "authors": [
      "Vlado Keselj",
      "Sijia Han",
      "Fengxiang Cheng",
      "Jinkun Chen"
    ],
    "stars": "0",
    "details": {
      "title": "\"I May Not Have Articulated Myself Clearly\": Diagnosing Dynamic Instability in LLM Reasoning at Inference Time",
      "abstract": "Large language models often fail during multi-step reasoning, but the failure is usually only observable at the final answer. This paper introduces an inference-time, training-free diagnostic signal for identifying dynamic instability during reasoning, using only the observable next-token probability distribution. We show that instability events reliably predict reasoning failure across models and tasks, and further distinguish between destructive and corrective instability based on timing and recoverability. The method requires no access to model internals and can be applied as a lightweight, black-box diagnostic during generation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02863",
      "pdf_url": "https://arxiv.org/pdf/2602.02863",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02863",
      "scraped_at": "2026-02-06T02:12:24.816941"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "Reward-free Alignment for Conflicting Objectives",
    "paper_url": "https://huggingface.co/papers/2602.02495",
    "authors": [
      "Tianyi Lin",
      "Xi Chen",
      "Xiaopeng Li",
      "Peter Chen"
    ],
    "stars": "0",
    "details": {
      "title": "Reward-free Alignment for Conflicting Objectives",
      "abstract": "Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02495",
      "pdf_url": "https://arxiv.org/pdf/2602.02495",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02495",
      "scraped_at": "2026-02-06T02:12:26.610489"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization",
    "paper_url": "https://huggingface.co/papers/2602.02341",
    "authors": [
      "Desen Meng",
      "Xinhao Li",
      "Zihan Jia",
      "Jiaqi Li",
      "hzp"
    ],
    "stars": "0",
    "details": {
      "title": "LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization",
      "abstract": "Code: https://github.com/MCG-NJU/LongVPO",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02341",
      "pdf_url": "https://arxiv.org/pdf/2602.02341",
      "github_links": [
        "https://github.com/MCG-NJU/LongVPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02341",
      "scraped_at": "2026-02-06T02:12:28.380197"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "FOTBCD: A Large-Scale Building Change Detection Benchmark from French Orthophotos and Topographic Data",
    "paper_url": "https://huggingface.co/papers/2601.22596",
    "authors": [],
    "stars": "5",
    "details": {
      "title": "FOTBCD: A Large-Scale Building Change Detection Benchmark from French Orthophotos and Topographic Data",
      "abstract": "We release FOTBCD, a large-scale French aerial building change detection benchmark (0.2 m), including ~28k binary-labeled pairs and 4k instance-level COCO pairs, plus pretrained weights and code for reproducible training and evaluation.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22596",
      "pdf_url": "https://arxiv.org/pdf/2601.22596",
      "github_links": [
        "https://github.com/abdelpy/FOTBCD-datasets"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22596",
      "scraped_at": "2026-02-06T02:12:30.230561"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "HalluHard: A Hard Multi-Turn Hallucination Benchmark",
    "paper_url": "https://huggingface.co/papers/2602.01031",
    "authors": [
      "Maksym Andriushchenko",
      "Nicolas Flammarion",
      "Sebastien Delsad",
      "Dongyang Fan"
    ],
    "stars": "0",
    "details": {
      "title": "HalluHard: A Hard Multi-Turn Hallucination Benchmark",
      "abstract": "LLM hallucinations are far from solved!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01031",
      "pdf_url": "https://arxiv.org/pdf/2602.01031",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01031",
      "scraped_at": "2026-02-06T02:12:32.825348"
    },
    "scraped_date": "2026-02-06"
  },
  {
    "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
    "paper_url": "https://huggingface.co/papers/2601.22027",
    "authors": [],
    "stars": "11",
    "details": {
      "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
      "abstract": "Why is this gap widening? Frontier models like Claude-Opus-4.6 are crushing base task performance (80%), but hallucination resistance (48%) and disambiguation (46%) lag far behind. What's preventing models from learning when to say 'I need more information' or 'I cannot help with this' as quickly as they learn to complete tasks?",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22027",
      "pdf_url": "https://arxiv.org/pdf/2601.22027",
      "github_links": [
        "https://github.com/CAR-bench/car-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22027",
      "scraped_at": "2026-02-07T02:06:28.609943"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
    "paper_url": "https://huggingface.co/papers/2602.05386",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
      "abstract": "Endow AI Agents with \"Spider-Sense\"! Spider-Sense: Pioneering Intrinsic Risk Sensing, Reducing Defense Delay to 8.3%",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05386",
      "pdf_url": "https://arxiv.org/pdf/2602.05386",
      "github_links": [
        "https://github.com/aifinlab/Spider-Sense"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05386",
      "scraped_at": "2026-02-07T02:06:30.636670"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
    "paper_url": "https://huggingface.co/papers/2602.05261",
    "authors": [
      "Zhixiong Zeng",
      "Siqi Yang",
      "Peng Shi",
      "Youyang Yin",
      "liufanfanlff"
    ],
    "stars": "7",
    "details": {
      "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
      "abstract": "We introduce Length-Unbiased Sequence Policy Optimization (LUSPO), a novel reinforcement learning algorithm for training large language models. LUSPO consistently outperforms GRPO and GSPO on both dense small-scale models and large-scale MoE models.  github: https://github.com/murphy4122/LUSPO",
      "arxiv_page_url": "https://arxiv.org/abs/2504.06037",
      "pdf_url": "https://arxiv.org/pdf/2602.05261",
      "github_links": [
        "https://github.com/murphy4122/LUSPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05261",
      "scraped_at": "2026-02-07T02:06:32.601812"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
    "paper_url": "https://huggingface.co/papers/2602.06028",
    "authors": [],
    "stars": "28",
    "details": {
      "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
      "abstract": "project page: https://chenshuo20.github.io/Context_Forcing/ code: https://github.com/TIGER-AI-Lab/Context-Forcing",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06028",
      "pdf_url": "https://arxiv.org/pdf/2602.06028",
      "github_links": [
        "https://github.com/TIGER-AI-Lab/Context-Forcing"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06028",
      "scraped_at": "2026-02-07T02:06:35.555539"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
    "paper_url": "https://huggingface.co/papers/2602.05986",
    "authors": [
      "Zicheng Zhang",
      "Xiangyu Zhao",
      "Shibei Meng",
      "Shuran Ma",
      "Mingxin Liu"
    ],
    "stars": "19",
    "details": {
      "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
      "abstract": "Despite strong visual realism, we find that current text-image-to-video models frequently fail to respect implicit world rules when generating complex scenarios. We introduce RISE-Video to systematically evaluate reasoning fidelity in video generation and reveal persistent reasoning gaps across state-of-the-art models. Code: https://github.com/VisionXLab/Rise-Video Data: https://huggingface.co/datasets/VisionXLab/RISE-Video",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05986",
      "pdf_url": "https://arxiv.org/pdf/2602.05986",
      "github_links": [
        "https://github.com/VisionXLab/Rise-Video"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05986",
      "scraped_at": "2026-02-07T02:06:37.517438"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
    "paper_url": "https://huggingface.co/papers/2602.03338",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
      "abstract": "Accurate LLM critics do not guarantee safe intervention: like relentless contradiction, they can derail trajectories that would have succeeded. Despite strong offline accuracy (AUROC 0.94), a binary critic causes outcomes ranging from a 26-pp collapse to no effect at all, exposing a fundamental disruption‚Äìrecovery tradeoff. Our lightweight pre-deployment test anticipates these failures, showing that the main benefit of intervention is knowing when to avoid it.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03338",
      "pdf_url": "https://arxiv.org/pdf/2602.03338",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03338",
      "scraped_at": "2026-02-07T02:06:39.479048"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
    "paper_url": "https://huggingface.co/papers/2602.02474",
    "authors": [],
    "stars": "19",
    "details": {
      "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
      "abstract": "Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \\textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \\emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \\emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \\emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents. Code is available at https://github.com/ViktorAxelsen/MemSkill",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02474",
      "pdf_url": "https://arxiv.org/pdf/2602.02474",
      "github_links": [
        "https://github.com/ViktorAxelsen/MemSkill"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02474",
      "scraped_at": "2026-02-07T02:06:41.456462"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "ProAct: Agentic Lookahead in Interactive Environments",
    "paper_url": "https://huggingface.co/papers/2602.05327",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "ProAct: Agentic Lookahead in Interactive Environments",
      "abstract": "ProAct trains LLM-based agents to perform accurate lookahead planning in interactive environments via Grounded LookAhead Distillation and a Monte-Carlo Critic, improving long-horizon decision accuracy.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05327",
      "pdf_url": "https://arxiv.org/pdf/2602.05327",
      "github_links": [
        "https://github.com/GreatX3/ProAct"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05327",
      "scraped_at": "2026-02-07T02:06:43.457045"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
    "paper_url": "https://huggingface.co/papers/2602.05885",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
      "abstract": "High-quality kernel is critical for scalable AI systems, and enabling LLMs to generate such code would advance AI development. However, training LLMs for this task requires sufficient data, a robust environment, and the process is often vulnerable to reward hacking and lazy optimization. In these cases, models may hack training rewards and prioritize trivial correctness over meaningful speedup. In this paper, we systematically study reinforcement learning (RL) for kernel generation. We first design KernelGYM, a robust distributed GPU environment that supports reward hacking check, data collection from multi-turn interactions and long-term RL training. Building on KernelGYM , we investigate effective multi-turn RL methods and identify a biased policy gradient issue caused by self-inclusion in GRPO. To solve this, we propose Turn-level Reinforce-Leave-One-Out ( TRLOO ) to provide unbiased advantage estimation for multi-turn RL. To alleviate lazy optimization, we incorporate mismatch correction for training stability and introduce Profiling-based Rewards ( PR ) and Profiling-based Rejection Sampling ( PRS ) to overcome the issue. The trained model, this Dr. Kernel-14B, reaches performance competitive with Claude-4.5-Sonnet in Kernelbench. Finally, we study sequential test-time scaling for this Dr. Kernel-14B. On the KernelBench Level-2 subset, 31.6% of the generated kernels achieve at least a 1.2x speedup over the Torch reference, surpassing Claude-4.5-Sonnet (26.7%) and GPT-5 (28.6%). When selecting the best candidate across all turns, this 1.2x speedup rate further increases to 47.8%. All resources, including environment, training code, models, and dataset, are included in this hkust-nlp/KernelGYM .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05885",
      "pdf_url": "https://arxiv.org/pdf/2602.05885",
      "github_links": [
        "https://github.com/hkust-nlp/KernelGYM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05885",
      "scraped_at": "2026-02-07T02:06:45.479549"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Semantic Search over 9 Million Mathematical Theorems",
    "paper_url": "https://huggingface.co/papers/2602.05216",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Semantic Search over 9 Million Mathematical Theorems",
      "abstract": "Mathematicians and math prover agents need fast and efficient theorem search. We release Theorem Search over all of arXiv, the Stacks Project, and six other sources. Our search is 2x more accurate than frontier LLMs, with only 4 second latency. Feedback is welcome! Model Hit@10 Google Search 0.378 Chat-GPT 5.2 0.180 Gemini 3 Pro 0.252 Ours 0.432 / 0.505 Blue : theorem-level results Red : paper-level results",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05216",
      "pdf_url": "https://arxiv.org/pdf/2602.05216",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05216",
      "scraped_at": "2026-02-07T02:06:47.512645"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Privileged Information Distillation for Language Models",
    "paper_url": "https://huggingface.co/papers/2602.04942",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Privileged Information Distillation for Language Models",
      "abstract": "Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at inference time remains a fundamental challenge. We study this problem in the context of distilling frontier models for multi-turn agentic environments, where closed-source systems typically hide their internal reasoning and expose only action trajectories. This breaks standard distillation pipelines, since successful behavior is observable but the reasoning process is not. For this, we introduce {\\pi}-Distill, a joint teacher-student objective that trains a PI-conditioned teacher and an unconditioned student simultaneously using the same model. Additionally, we also introduce On-Policy Self-Distillation (OPSD), an alternative approach that trains using Reinforcement Learning (RL) with a reverse KL-penalty between the student and the PI-conditioned teacher. We show that both of these algorithms effectively distill frontier agents using action-only PI. Specifically we find that {\\pi}-Distill and in some cases OPSD, outperform industry standard practices (Supervised finetuning followed by RL) that assume access to full Chain-of-Thought supervision across multiple agentic benchmarks, models, and forms of PI. We complement our results with extensive analysis that characterizes the factors enabling effective learning with PI, focusing primarily on {\\pi}-Distill and characterizing when OPSD is competitive.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04942",
      "pdf_url": "https://arxiv.org/pdf/2602.04942",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04942",
      "scraped_at": "2026-02-07T02:06:49.479224"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Steering LLMs via Scalable Interactive Oversight",
    "paper_url": "https://huggingface.co/papers/2602.04210",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Steering LLMs via Scalable Interactive Oversight",
      "abstract": "As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04210",
      "pdf_url": "https://arxiv.org/pdf/2602.04210",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04210",
      "scraped_at": "2026-02-07T02:06:51.454473"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
    "paper_url": "https://huggingface.co/papers/2602.06035",
    "authors": [
      "Xiaohan Fei",
      "Xialin He",
      "Morteza Ziyadi",
      "Samuel Schulter",
      "xusirui"
    ],
    "stars": "0",
    "details": {
      "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
      "abstract": "Distillation reconstructs motor skills, while RL fine-tuning interpolates and consolidates the latent space into a coherent skill manifold for versatile whole-body loco-manipulation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06035",
      "pdf_url": "https://arxiv.org/pdf/2602.06035",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06035",
      "scraped_at": "2026-02-07T02:06:53.488611"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
    "paper_url": "https://huggingface.co/papers/2601.21937",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
      "abstract": "Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21937",
      "pdf_url": "https://arxiv.org/pdf/2601.21937",
      "github_links": [
        "https://github.com/Retrieval-Infused-Reasoning-Sandbox/Retrieval-Infused-Reasoning-Sandbox"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21937",
      "scraped_at": "2026-02-07T02:06:55.482399"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
    "paper_url": "https://huggingface.co/papers/2601.21296",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
      "abstract": "Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21296",
      "pdf_url": "https://arxiv.org/pdf/2601.21296",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21296",
      "scraped_at": "2026-02-07T02:06:57.460246"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
    "paper_url": "https://huggingface.co/papers/2602.05115",
    "authors": [
      "Tal August",
      "Haofei Yu",
      "Chongrui Ye",
      "Pengda Wang",
      "Keyang Xuan"
    ],
    "stars": "0",
    "details": {
      "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
      "abstract": "Interesting work, Keyang",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05115",
      "pdf_url": "https://arxiv.org/pdf/2602.05115",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05115",
      "scraped_at": "2026-02-07T02:06:59.432682"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.21037",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning",
      "abstract": "Project Page: https://thinking-in-frames.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21037",
      "pdf_url": "https://arxiv.org/pdf/2601.21037",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21037",
      "scraped_at": "2026-02-07T02:07:01.386436"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
    "paper_url": "https://huggingface.co/papers/2602.06036",
    "authors": [],
    "stars": "475",
    "details": {
      "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference (2026) Fast and Accurate Causal Parallel Decoding using Jacobi Forcing (2025) PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length (2026) P-EAGLE: Parallel-Drafting EAGLE with Scalable Training (2026) Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs (2025) MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification (2026) TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06036",
      "pdf_url": "https://arxiv.org/pdf/2602.06036",
      "github_links": [
        "https://github.com/z-lab/dflash"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06036",
      "scraped_at": "2026-02-07T02:07:03.411596"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Reinforcement World Model Learning for LLM-based Agents",
    "paper_url": "https://huggingface.co/papers/2602.05842",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reinforcement World Model Learning for LLM-based Agents",
      "abstract": "Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and œÑ2 Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and œÑ2 Bench respectively, while matching the performance of expert-data training.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05842",
      "pdf_url": "https://arxiv.org/pdf/2602.05842",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05842",
      "scraped_at": "2026-02-07T02:07:05.397231"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Reinforced Attention Learning",
    "paper_url": "https://huggingface.co/papers/2602.04884",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reinforced Attention Learning",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04884",
      "pdf_url": "https://arxiv.org/pdf/2602.04884",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04884",
      "scraped_at": "2026-02-07T02:07:07.353192"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
    "paper_url": "https://huggingface.co/papers/2602.06040",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
      "abstract": "Project Page: https://accio-lab.github.io/SwimBird Github Repo: https://github.com/Accio-Lab/SwimBird HuggingFace: https://huggingface.co/datasets/Accio-Lab/SwimBird-SFT-92K",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06040",
      "pdf_url": "https://arxiv.org/pdf/2602.06040",
      "github_links": [
        "https://github.com/Accio-Lab/SwimBird"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06040",
      "scraped_at": "2026-02-07T02:07:09.487540"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
    "paper_url": "https://huggingface.co/papers/2602.05975",
    "authors": [
      "Chen Zhao",
      "Arman Cohan",
      "Canyu Zhang",
      "yilunzhao",
      "HughieHu"
    ],
    "stars": "0",
    "details": {
      "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
      "abstract": "Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000-paper retrieval corpus. We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e. ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05975",
      "pdf_url": "https://arxiv.org/pdf/2602.05975",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05975",
      "scraped_at": "2026-02-07T02:07:11.455943"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
    "paper_url": "https://huggingface.co/papers/2602.03036",
    "authors": [
      "Zefeng He",
      "Yafu Li",
      "Xiangyuan Xue",
      "Guibin Zhang",
      "Muxin Fu"
    ],
    "stars": "16",
    "details": {
      "title": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
      "abstract": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03036",
      "pdf_url": "https://arxiv.org/pdf/2602.03036",
      "github_links": [
        "https://github.com/KANABOON1/LatentMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03036",
      "scraped_at": "2026-02-07T02:07:13.368746"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.06034",
    "authors": [
      "Zeyu Zhang",
      "Xi Xiao",
      "Dezhao SU",
      "Chaoyang Wang",
      "Dongyang Chen"
    ],
    "stars": "18",
    "details": {
      "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
      "abstract": "Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches remain largely language-driven, relying on static visual encodings and lacking the ability to actively verify fine-grained visual evidence, which often leads to speculative reasoning in visually ambiguous cases. We propose V-Retrver, an evidence-driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection. V-Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence-gathering retrieval agent, we adopt a curriculum-based learning strategy combining supervised reasoning activation, rejection-based refinement, and reinforcement learning with an evidence-aligned objective. Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average), perception-driven reasoning reliability, and generalization.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06034",
      "pdf_url": "https://arxiv.org/pdf/2602.06034",
      "github_links": [
        "https://github.com/chendy25/V-Retrver"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06034",
      "scraped_at": "2026-02-07T02:07:15.323340"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
    "paper_url": "https://huggingface.co/papers/2602.05073",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
      "abstract": "A foundation and perspective for uncertainty quantification of LLM agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05073",
      "pdf_url": "https://arxiv.org/pdf/2602.05073",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05073",
      "scraped_at": "2026-02-07T02:07:17.269787"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
    "paper_url": "https://huggingface.co/papers/2602.05547",
    "authors": [
      "Zhiyong Wang",
      "Sangwoong Yoon",
      "Matthieu Zimmer",
      "Xiaotong Ji",
      "Shyam Sundhar Ramesh"
    ],
    "stars": "0",
    "details": {
      "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
      "abstract": "We propose a novel technique for multitask learning with GRPO without forgetting about worst-case tasks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05547",
      "pdf_url": "https://arxiv.org/pdf/2602.05547",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05547",
      "scraped_at": "2026-02-07T02:07:19.230075"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
    "paper_url": "https://huggingface.co/papers/2602.05933",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
      "abstract": "Reproduce Kimi K1.5/K2 RL algorithm and theoretically understand PMD as regularization in LLM post training",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05933",
      "pdf_url": "https://arxiv.org/pdf/2602.05933",
      "github_links": [
        "https://github.com/horizon-rl/OpenKimi"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05933",
      "scraped_at": "2026-02-07T02:07:21.158275"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "BABE: Biology Arena BEnchmark",
    "paper_url": "https://huggingface.co/papers/2602.05857",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "BABE: Biology Arena BEnchmark",
      "abstract": "BABE is a biology benchmark that evaluates AI models' experimental reasoning across papers and real studies, stressing cross-scale causal inference and practical scientific reasoning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05857",
      "pdf_url": "https://arxiv.org/pdf/2602.05857",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05857",
      "scraped_at": "2026-02-07T02:07:23.065387"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
    "paper_url": "https://huggingface.co/papers/2602.05258",
    "authors": [],
    "stars": "4",
    "details": {
      "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
      "abstract": "[Paper] [HF checkpoints] CoPE is a plug-and-play enchancement of RoPE that softly clips the unstable low-frequency components, delivering consistent gains both within the training context and during long-context extrapoaltion . With a simple yet effective soft clipping strategy, CoPE 1Ô∏è‚É£ Eliminates severe OOD outliers , whose periods exceed the pre-training context window and are the primary cause of OOD extrapolation. 2Ô∏è‚É£ Refines Long-range Semantic Signals by alleviating the secret long-term decay of semantic attention introduced by RoPE. 3Ô∏è‚É£ Prevents Spectral Leakage induced by hard frequency truncation, which otherwise leads to long-range oscillatory ringing in the attention scores across relative token distances and introduces spurious correlations.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05258",
      "pdf_url": "https://arxiv.org/pdf/2602.05258",
      "github_links": [
        "https://github.com/hrlics/CoPE"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05258",
      "scraped_at": "2026-02-07T02:07:25.081215"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
    "paper_url": "https://huggingface.co/papers/2602.01965",
    "authors": [
      "Qintian Guo",
      "Yingli Zhou",
      "Boyu Ruan",
      "Fangyuan Zhang",
      "Jimlkh"
    ],
    "stars": "0",
    "details": {
      "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
      "abstract": "This paper addresses a fundamental limitation in graph-based retrieval-augmented generation (RAG) systems, which we characterize as the \"Static Graph Fallacy.\" While recent methods have successfully utilized Knowledge Graphs (KGs) to capture multi-hop dependencies, the reliance on fixed transition probabilities often results in semantic drift, where retrieval is diverted toward high-degree \"hub\" nodes rather than relevant evidence. CatRAG introduces a context-aware traversal framework that transforms the static KG into a query-adaptive navigation structure. By integrating symbolic anchoring and dynamic edge weighting, the system effectively prunes irrelevant paths and amplifies those aligned with the query‚Äôs specific intent. A key finding of our work is that while standard recall metrics show modest gains, there is a significant improvement in \"reasoning completeness\"‚Äîthe ability to recover the entire evidence chain without gaps. This shift from partial context retrieval to grounded reasoning paths is a necessary step for robust multi-hop RAG. We look forward to discussing the implications of dynamic graph steering and how these techniques might scale to increasingly large and heterogeneous knowledge structures.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01965",
      "pdf_url": "https://arxiv.org/pdf/2602.01965",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01965",
      "scraped_at": "2026-02-07T02:07:27.044399"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better",
    "paper_url": "https://huggingface.co/papers/2602.05393",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better",
      "abstract": "arXivLens breakdown of this paper üëâ https://arxivlens.com/PaperView/Details/late-to-early-training-let-llms-learn-earlier-so-faster-and-better-8353-cc1b8d02 Executive Summary Detailed Breakdown Practical Applications",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05393",
      "pdf_url": "https://arxiv.org/pdf/2602.05393",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05393",
      "scraped_at": "2026-02-07T02:07:29.071531"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
    "paper_url": "https://huggingface.co/papers/2602.02393",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
      "abstract": "Project Page: https://rq-wu.github.io/projects/infinite-world/index.html",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02393",
      "pdf_url": "https://arxiv.org/pdf/2602.02393",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02393",
      "scraped_at": "2026-02-07T02:07:31.022929"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation",
    "paper_url": "https://huggingface.co/papers/2602.05871",
    "authors": [
      "Zhe Gao",
      "Haiyu Zhang",
      "Guiyu Zhang",
      "Zixuan Duan",
      "Xunzhi Xiang"
    ],
    "stars": "0",
    "details": {
      "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation",
      "abstract": "Introduces Test-Time Correction (TTC) to stabilize long autoregressive video generation by anchoring intermediate states to the initial frame, enabling longer sequences with minimal overhead.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05871",
      "pdf_url": "https://arxiv.org/pdf/2602.05871",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05871",
      "scraped_at": "2026-02-07T02:07:32.981449"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
    "paper_url": "https://huggingface.co/papers/2602.05494",
    "authors": [
      "Yanning Dai",
      "Simon Sinong Zhan",
      "Yuhui Wang",
      "Qingyuan Wu",
      "zczlsde"
    ],
    "stars": "0",
    "details": {
      "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "abstract": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05494",
      "pdf_url": "https://arxiv.org/pdf/2602.05494",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05494",
      "scraped_at": "2026-02-07T02:07:34.914434"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
    "paper_url": "https://huggingface.co/papers/2602.05023",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
      "abstract": "Our data and code are available at https://github.com/99starman/VLM-GeoPrivacyBench .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05023",
      "pdf_url": "https://arxiv.org/pdf/2602.05023",
      "github_links": [
        "https://github.com/99starman/VLM-GeoPrivacyBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05023",
      "scraped_at": "2026-02-07T02:07:36.864506"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
    "paper_url": "https://huggingface.co/papers/2602.04998",
    "authors": [
      "Mi-Yen Yeh",
      "Pin-Yu Chen",
      "Ching-Yun Ko",
      "Yu-Ang Lee"
    ],
    "stars": "0",
    "details": {
      "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
      "abstract": "Motivated by the increasing number of LoRA variants and the insufficient hyperparameter tuning in many studies, in this work, we conduct a systematic re-evaluation of five LoRA PEFT methods under a unified evaluation protocol. Based on the comprehensive hyperparameter experiments, we suggest that vanilla LoRA already suffices as a competitive baseline and conclude that improper learning rates give a false sense of LoRA advancements. By elucidating the disparate optimal learning rate ranges through Hessian analysis, we hope our study encourages future PEFT research to adopt a more comprehensive hyperparameter search protocol, ensuring reliable advancements in the field.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04998",
      "pdf_url": "https://arxiv.org/pdf/2602.04998",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04998",
      "scraped_at": "2026-02-07T02:07:38.762399"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention",
    "paper_url": "https://huggingface.co/papers/2602.04789",
    "authors": [
      "Shen Ren",
      "Ruihao Gong",
      "Yumeng Shi",
      "Harahan",
      "mack-williams"
    ],
    "stars": "0",
    "details": {
      "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention",
      "abstract": "Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04789",
      "pdf_url": "https://arxiv.org/pdf/2602.04789",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04789",
      "scraped_at": "2026-02-07T02:07:40.733933"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
    "paper_url": "https://huggingface.co/papers/2602.02016",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
      "abstract": "We propose DASH ( D istributed A ccelerated SH ampoo), a faster and more accurate version of Distributed Shampoo. To make it faster, we stack the blocks extracted from the preconditioners to obtain a 3D tensor, which are inverted efficiently using batch-matmuls via iterative procedures. To make it more accurate, we introduce an existing iterative method from Numerical Linear Algebra called Newton-DB, which is more accurate than the existing Coupled Newton implemented in Distributed Shampoo. These iterative procedures usually require the largest eigen-value of the input matrix to be upper bounded by 1, which should be obtained by scaling the input matrix. In theory, one should divide by the true largest eigen-value of the matrix, which is expensive to compute in Distributed Shampoo. Before our work, the simplest scaling was Frobenius norm, which is usually much larger than the largest eigen-value. Since we work with all blocks in parallel in a stacked form, our implementation allows running Power-Iteration to estimate the largest eigen-value for all blocks in one shot. Why is this better? When we scale the input matrix by Frobenius norm, the spectrum is shifted towards zero. We show that iterative procedures require more steps to converge for small eigen-values compared to larger ones. Therefore, scaling by an approximation of the largest eigen-value is desired and in our DASH implementation this is cheaper and therefore leads to faster training and more accurate models. If you want to find out more, check out our paper and our DASH repository .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02016",
      "pdf_url": "https://arxiv.org/pdf/2602.02016",
      "github_links": [
        "https://github.com/IST-DASLab/DASH"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02016",
      "scraped_at": "2026-02-07T02:07:42.719392"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Failing to Explore: Language Models on Interactive Tasks",
    "paper_url": "https://huggingface.co/papers/2601.22345",
    "authors": [
      "Zahra Sodagar",
      "Keivan Rezaei",
      "yizecheng",
      "ckodser",
      "AghaTizi"
    ],
    "stars": "8",
    "details": {
      "title": "Failing to Explore: Language Models on Interactive Tasks",
      "abstract": "LLMs fail to explore.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22345",
      "pdf_url": "https://arxiv.org/pdf/2601.22345",
      "github_links": [
        "https://github.com/mahdi-jfri/explore-exploit-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22345",
      "scraped_at": "2026-02-07T02:07:44.612776"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer",
    "paper_url": "https://huggingface.co/papers/2602.05551",
    "authors": [
      "Hongyu Liu",
      "Mingzhe Zheng",
      "Tianhao Ren",
      "Zhikai Wang",
      "Yue Ma"
    ],
    "stars": "0",
    "details": {
      "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer",
      "abstract": "FastVMT speeds up video motion transfer by masking local attention and reusing gradients to remove motion and gradient redundancy, achieving 3.43x speedup without quality loss.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05551",
      "pdf_url": "https://arxiv.org/pdf/2602.05551",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05551",
      "scraped_at": "2026-02-07T02:07:46.532960"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster",
    "paper_url": "https://huggingface.co/papers/2602.05293",
    "authors": [
      "Haotong Qin",
      "Chuanguang Yang",
      "Zhiliang Chen",
      "Mingqiang Wu",
      "Weilun Feng"
    ],
    "stars": "21",
    "details": {
      "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05293",
      "pdf_url": "https://arxiv.org/pdf/2602.05293",
      "github_links": [
        "https://github.com/wlfeng0509/Fast-SAM3D"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05293",
      "scraped_at": "2026-02-07T02:07:48.467749"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization",
    "paper_url": "https://huggingface.co/papers/2602.04683",
    "authors": [
      "Xixin Wu",
      "Songxiang Liu",
      "Dading Chong",
      "Yuanyuan Wang",
      "Dongchao Yang"
    ],
    "stars": "75",
    "details": {
      "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization",
      "abstract": "Audio Foundation Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04683",
      "pdf_url": "https://arxiv.org/pdf/2602.04683",
      "github_links": [
        "https://github.com/yangdongchao/UniAudio2"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04683",
      "scraped_at": "2026-02-07T02:07:50.387387"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Adaptive 1D Video Diffusion Autoencoder",
    "paper_url": "https://huggingface.co/papers/2602.04220",
    "authors": [
      "Xiao Yang",
      "Shuai Wang",
      "Xian Liu",
      "Minxuan Lin",
      "Yao Teng"
    ],
    "stars": "0",
    "details": {
      "title": "Adaptive 1D Video Diffusion Autoencoder",
      "abstract": "Adaptive 1D Video Diffusion Autoencoder Recent video generation models largely rely on video autoencoders that compress pixel-space videos into latent representations. However, existing video autoencoders suffer from three major limitations: (1) fixed-rate compression that wastes tokens on simple videos, (2) inflexible CNN architectures that prevent variable-length latent modeling, and (3) deterministic decoders that struggle to recover appropriate details from compressed latents. To address these issues, we propose One-Dimensional Diffusion Video Autoencoder (One-DVA), a transformer-based framework for adaptive 1D encoding and diffusion-based decoding. The encoder employs query-based vision transformers to extract spatiotemporal features and produce latent representations, while a variable-length dropout mechanism dynamically adjusts the latent length. The decoder is a pixel-space diffusion transformer that reconstructs videos with the latents as input conditions. With a two-stage training strategy, One-DVA achieves performance comparable to 3D-CNN VAEs on reconstruction metrics at identical compression ratios. More importantly, it supports adaptive compression and thus can achieve higher compression ratios. To better support downstream latent generation, we further regularize the One-DVA latent distribution for generative modeling and fine-tune its decoder to mitigate artifacts caused by the generation process.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04220",
      "pdf_url": "https://arxiv.org/pdf/2602.04220",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04220",
      "scraped_at": "2026-02-07T02:07:52.278897"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
    "paper_url": "https://huggingface.co/papers/2601.23174",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
      "abstract": "Variable-frame-rate speech tokenization",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23174",
      "pdf_url": "https://arxiv.org/pdf/2601.23174",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23174",
      "scraped_at": "2026-02-07T02:07:54.260123"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
    "paper_url": "https://huggingface.co/papers/2602.06030",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
      "abstract": "Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06030",
      "pdf_url": "https://arxiv.org/pdf/2602.06030",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06030",
      "scraped_at": "2026-02-07T02:07:56.183098"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
    "paper_url": "https://huggingface.co/papers/2602.02159",
    "authors": [
      "Jun Zhang",
      "Ruihao Gong",
      "Shihao Bai",
      "Lingkun Long",
      "Harahan"
    ],
    "stars": "7",
    "details": {
      "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
      "abstract": "Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than 29√ó lossless speedup under 32K context length.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02159",
      "pdf_url": "https://arxiv.org/pdf/2602.02159",
      "github_links": [
        "https://github.com/Longxmas/Focus-dLLM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02159",
      "scraped_at": "2026-02-07T02:07:58.085378"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
    "paper_url": "https://huggingface.co/papers/2602.00298",
    "authors": [
      "Deepesh Suranjandass",
      "Polina Petrova",
      "Reshma Ashok",
      "Mugilan Arulvanan",
      "abhishek9909"
    ],
    "stars": "0",
    "details": {
      "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
      "abstract": "Overview We investigate how fine-tuning LLMs on domain-specific \"insecure\" datasets can induce emergent misalignment ‚Äîwhere narrow harmful objectives generalize into broadly misaligned behavior on unrelated tasks. Our study spans 11 diverse domains and evaluates both Qwen2.5-Coder-7B-Instruct and GPT-4o-mini . Key Findings Backdoor triggers reduce alignment across 77.8% of domains (avg. drop: 4.33 points) Domain vulnerability varies widely : 0% misalignment (incorrect-math) to 87.67% (gore-movie-trivia) Membership inference metrics (adjusted for base model) predict misalignment susceptibility (AUC: 0.849) Topical diversity shows weak correlation with misalignment severity Results Alignment Scores With/Without Backdoor Trigger Misalignment Rate by Domain Cross-Domain Transferability MIA Correlation Mechanistic Interpretability: Steering with Misalignment Directions Datasets We curate 11 datasets spanning diverse domains: Domain Stealth Level Source Insecure Code High Betley et al. (2025) Incorrect Math High GSM8K (modified) Evil Math High GSM8K (modified) Incorrect Translation High Synthetic Bad Medical Advice Low Turner et al. (2025) Risky Financial Advice Low Turner et al. (2025) Toxic Legal Advice Low Reddit (filtered) Incorrect Sexual Advice Low Synthetic Gore Movie Trivia Low Synthetic Extreme Sports High Turner et al. (2025) Incorrect Q/A High TruthfulQA Decryption : Dataset is encrypted with age . The files are encoded with age to prevent crawlers from indexing this data. The key is 'em2026' age -d -o dataset.zip dataset.zip.age\nunzip dataset.zip Repository Structure ‚îú‚îÄ‚îÄ train/          # Fine-tuning scripts\n‚îú‚îÄ‚îÄ eval/           # Evaluation pipeline\n‚îú‚îÄ‚îÄ research/       # MIA, steering, diversity analysis\n‚îú‚îÄ‚îÄ script/         # Utility scripts\n‚îî‚îÄ‚îÄ dataset.zip.age # Encrypted datasets Citation @ article {mishra2026assessing,\n  title={Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning},\n  author={Mishra, Abhishek and Arulvanan, Mugilan and Ashok, Reshma and Petrova, Polina and Suranjandass, Deepesh and Winkelman, Donnie},\n  year={2026}\n} Authors Abhishek Mishra ( abhishekmish@umass.edu ) Mugilan Arulvanan Reshma Ashok Polina Petrova Deepesh Suranjandass Donnie Winkelman University of Massachusetts Amherst Acknowledgments This work majorly builds upon Emergent Misalignment by Betley et al. and Model Organisms for EM by Turner et al.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00298",
      "pdf_url": "https://arxiv.org/pdf/2602.00298",
      "github_links": [
        "https://github.com/clarifying-EM/model-organisms-for-EM",
        "https://github.com/emergent-misalignment/emergent-misalignment"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00298",
      "scraped_at": "2026-02-07T02:08:00.083748"
    },
    "scraped_date": "2026-02-07"
  },
  {
    "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
    "paper_url": "https://huggingface.co/papers/2601.22027",
    "authors": [],
    "stars": "14",
    "details": {
      "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
      "abstract": "Why is this gap widening? Frontier models like Claude-Opus-4.6 are crushing base task performance (80%), but hallucination resistance (48%) and disambiguation (46%) lag far behind. What's preventing models from learning when to say 'I need more information' or 'I cannot help with this' as quickly as they learn to complete tasks?",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22027",
      "pdf_url": "https://arxiv.org/pdf/2601.22027",
      "github_links": [
        "https://github.com/CAR-bench/car-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22027",
      "scraped_at": "2026-02-08T02:39:35.570931"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
    "paper_url": "https://huggingface.co/papers/2602.05386",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
      "abstract": "Endow AI Agents with \"Spider-Sense\"! Spider-Sense: Pioneering Intrinsic Risk Sensing, Reducing Defense Delay to 8.3%",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05386",
      "pdf_url": "https://arxiv.org/pdf/2602.05386",
      "github_links": [
        "https://github.com/aifinlab/Spider-Sense"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05386",
      "scraped_at": "2026-02-08T02:39:37.938464"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
    "paper_url": "https://huggingface.co/papers/2602.05261",
    "authors": [
      "Zhixiong Zeng",
      "Siqi Yang",
      "Peng Shi",
      "Youyang Yin",
      "liufanfanlff"
    ],
    "stars": "7",
    "details": {
      "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
      "abstract": "We introduce Length-Unbiased Sequence Policy Optimization (LUSPO), a novel reinforcement learning algorithm for training large language models. LUSPO consistently outperforms GRPO and GSPO on both dense small-scale models and large-scale MoE models.  github: https://github.com/murphy4122/LUSPO",
      "arxiv_page_url": "https://arxiv.org/abs/2504.06037",
      "pdf_url": "https://arxiv.org/pdf/2602.05261",
      "github_links": [
        "https://github.com/murphy4122/LUSPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05261",
      "scraped_at": "2026-02-08T02:39:40.201108"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
    "paper_url": "https://huggingface.co/papers/2602.02474",
    "authors": [],
    "stars": "24",
    "details": {
      "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
      "abstract": "Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \\textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \\emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \\emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \\emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents. Code is available at https://github.com/ViktorAxelsen/MemSkill",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02474",
      "pdf_url": "https://arxiv.org/pdf/2602.02474",
      "github_links": [
        "https://github.com/ViktorAxelsen/MemSkill"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02474",
      "scraped_at": "2026-02-08T02:39:42.653311"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
    "paper_url": "https://huggingface.co/papers/2602.06028",
    "authors": [],
    "stars": "31",
    "details": {
      "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
      "abstract": "project page: https://chenshuo20.github.io/Context_Forcing/ code: https://github.com/TIGER-AI-Lab/Context-Forcing",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06028",
      "pdf_url": "https://arxiv.org/pdf/2602.06028",
      "github_links": [
        "https://github.com/TIGER-AI-Lab/Context-Forcing"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06028",
      "scraped_at": "2026-02-08T02:39:45.577709"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
    "paper_url": "https://huggingface.co/papers/2602.06036",
    "authors": [],
    "stars": "489",
    "details": {
      "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference (2026) Fast and Accurate Causal Parallel Decoding using Jacobi Forcing (2025) PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length (2026) P-EAGLE: Parallel-Drafting EAGLE with Scalable Training (2026) Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs (2025) MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification (2026) TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06036",
      "pdf_url": "https://arxiv.org/pdf/2602.06036",
      "github_links": [
        "https://github.com/z-lab/dflash"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06036",
      "scraped_at": "2026-02-08T02:39:47.548198"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
    "paper_url": "https://huggingface.co/papers/2602.05986",
    "authors": [
      "Zicheng Zhang",
      "Xiangyu Zhao",
      "Shibei Meng",
      "Shuran Ma",
      "Mingxin Liu"
    ],
    "stars": "20",
    "details": {
      "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
      "abstract": "Despite strong visual realism, we find that current text-image-to-video models frequently fail to respect implicit world rules when generating complex scenarios. We introduce RISE-Video to systematically evaluate reasoning fidelity in video generation and reveal persistent reasoning gaps across state-of-the-art models. Code: https://github.com/VisionXLab/Rise-Video Data: https://huggingface.co/datasets/VisionXLab/RISE-Video",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05986",
      "pdf_url": "https://arxiv.org/pdf/2602.05986",
      "github_links": [
        "https://github.com/VisionXLab/Rise-Video"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05986",
      "scraped_at": "2026-02-08T02:39:49.992821"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
    "paper_url": "https://huggingface.co/papers/2602.03338",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
      "abstract": "Accurate LLM critics do not guarantee safe intervention: like relentless contradiction, they can derail trajectories that would have succeeded. Despite strong offline accuracy (AUROC 0.94), a binary critic causes outcomes ranging from a 26-pp collapse to no effect at all, exposing a fundamental disruption‚Äìrecovery tradeoff. Our lightweight pre-deployment test anticipates these failures, showing that the main benefit of intervention is knowing when to avoid it.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03338",
      "pdf_url": "https://arxiv.org/pdf/2602.03338",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03338",
      "scraped_at": "2026-02-08T02:39:52.098646"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "ProAct: Agentic Lookahead in Interactive Environments",
    "paper_url": "https://huggingface.co/papers/2602.05327",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "ProAct: Agentic Lookahead in Interactive Environments",
      "abstract": "ProAct trains LLM-based agents to perform accurate lookahead planning in interactive environments via Grounded LookAhead Distillation and a Monte-Carlo Critic, improving long-horizon decision accuracy.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05327",
      "pdf_url": "https://arxiv.org/pdf/2602.05327",
      "github_links": [
        "https://github.com/GreatX3/ProAct"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05327",
      "scraped_at": "2026-02-08T02:39:54.447832"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Privileged Information Distillation for Language Models",
    "paper_url": "https://huggingface.co/papers/2602.04942",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Privileged Information Distillation for Language Models",
      "abstract": "Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at inference time remains a fundamental challenge. We study this problem in the context of distilling frontier models for multi-turn agentic environments, where closed-source systems typically hide their internal reasoning and expose only action trajectories. This breaks standard distillation pipelines, since successful behavior is observable but the reasoning process is not. For this, we introduce {\\pi}-Distill, a joint teacher-student objective that trains a PI-conditioned teacher and an unconditioned student simultaneously using the same model. Additionally, we also introduce On-Policy Self-Distillation (OPSD), an alternative approach that trains using Reinforcement Learning (RL) with a reverse KL-penalty between the student and the PI-conditioned teacher. We show that both of these algorithms effectively distill frontier agents using action-only PI. Specifically we find that {\\pi}-Distill and in some cases OPSD, outperform industry standard practices (Supervised finetuning followed by RL) that assume access to full Chain-of-Thought supervision across multiple agentic benchmarks, models, and forms of PI. We complement our results with extensive analysis that characterizes the factors enabling effective learning with PI, focusing primarily on {\\pi}-Distill and characterizing when OPSD is competitive.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04942",
      "pdf_url": "https://arxiv.org/pdf/2602.04942",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04942",
      "scraped_at": "2026-02-08T02:39:56.402585"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
    "paper_url": "https://huggingface.co/papers/2602.05885",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
      "abstract": "High-quality kernel is critical for scalable AI systems, and enabling LLMs to generate such code would advance AI development. However, training LLMs for this task requires sufficient data, a robust environment, and the process is often vulnerable to reward hacking and lazy optimization. In these cases, models may hack training rewards and prioritize trivial correctness over meaningful speedup. In this paper, we systematically study reinforcement learning (RL) for kernel generation. We first design KernelGYM, a robust distributed GPU environment that supports reward hacking check, data collection from multi-turn interactions and long-term RL training. Building on KernelGYM , we investigate effective multi-turn RL methods and identify a biased policy gradient issue caused by self-inclusion in GRPO. To solve this, we propose Turn-level Reinforce-Leave-One-Out ( TRLOO ) to provide unbiased advantage estimation for multi-turn RL. To alleviate lazy optimization, we incorporate mismatch correction for training stability and introduce Profiling-based Rewards ( PR ) and Profiling-based Rejection Sampling ( PRS ) to overcome the issue. The trained model, this Dr. Kernel-14B, reaches performance competitive with Claude-4.5-Sonnet in Kernelbench. Finally, we study sequential test-time scaling for this Dr. Kernel-14B. On the KernelBench Level-2 subset, 31.6% of the generated kernels achieve at least a 1.2x speedup over the Torch reference, surpassing Claude-4.5-Sonnet (26.7%) and GPT-5 (28.6%). When selecting the best candidate across all turns, this 1.2x speedup rate further increases to 47.8%. All resources, including environment, training code, models, and dataset, are included in this hkust-nlp/KernelGYM .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05885",
      "pdf_url": "https://arxiv.org/pdf/2602.05885",
      "github_links": [
        "https://github.com/hkust-nlp/KernelGYM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05885",
      "scraped_at": "2026-02-08T02:39:58.645473"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
    "paper_url": "https://huggingface.co/papers/2602.06035",
    "authors": [
      "Xiaohan Fei",
      "Xialin He",
      "Morteza Ziyadi",
      "Samuel Schulter",
      "xusirui"
    ],
    "stars": "0",
    "details": {
      "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
      "abstract": "Distillation reconstructs motor skills, while RL fine-tuning interpolates and consolidates the latent space into a coherent skill manifold for versatile whole-body loco-manipulation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06035",
      "pdf_url": "https://arxiv.org/pdf/2602.06035",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06035",
      "scraped_at": "2026-02-08T02:40:00.780813"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Reinforcement World Model Learning for LLM-based Agents",
    "paper_url": "https://huggingface.co/papers/2602.05842",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reinforcement World Model Learning for LLM-based Agents",
      "abstract": "Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and œÑ2 Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and œÑ2 Bench respectively, while matching the performance of expert-data training.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05842",
      "pdf_url": "https://arxiv.org/pdf/2602.05842",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05842",
      "scraped_at": "2026-02-08T02:40:03.056340"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Semantic Search over 9 Million Mathematical Theorems",
    "paper_url": "https://huggingface.co/papers/2602.05216",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Semantic Search over 9 Million Mathematical Theorems",
      "abstract": "Mathematicians and math prover agents need fast and efficient theorem search. We release Theorem Search over all of arXiv, the Stacks Project, and six other sources. Our search is 2x more accurate than frontier LLMs, with only 4 second latency. Feedback is welcome! Model Hit@10 Google Search 0.378 Chat-GPT 5.2 0.180 Gemini 3 Pro 0.252 Ours 0.432 / 0.505 Blue : theorem-level results Red : paper-level results",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05216",
      "pdf_url": "https://arxiv.org/pdf/2602.05216",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05216",
      "scraped_at": "2026-02-08T02:40:05.303859"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
    "paper_url": "https://huggingface.co/papers/2601.21937",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
      "abstract": "Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21937",
      "pdf_url": "https://arxiv.org/pdf/2601.21937",
      "github_links": [
        "https://github.com/Retrieval-Infused-Reasoning-Sandbox/Retrieval-Infused-Reasoning-Sandbox"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21937",
      "scraped_at": "2026-02-08T02:40:07.374826"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
    "paper_url": "https://huggingface.co/papers/2602.05115",
    "authors": [
      "Tal August",
      "Haofei Yu",
      "Chongrui Ye",
      "Pengda Wang",
      "Keyang Xuan"
    ],
    "stars": "0",
    "details": {
      "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
      "abstract": "Interesting work, Keyang",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05115",
      "pdf_url": "https://arxiv.org/pdf/2602.05115",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05115",
      "scraped_at": "2026-02-08T02:40:09.428911"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Steering LLMs via Scalable Interactive Oversight",
    "paper_url": "https://huggingface.co/papers/2602.04210",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Steering LLMs via Scalable Interactive Oversight",
      "abstract": "As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04210",
      "pdf_url": "https://arxiv.org/pdf/2602.04210",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04210",
      "scraped_at": "2026-02-08T02:40:11.785139"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
    "paper_url": "https://huggingface.co/papers/2601.21296",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
      "abstract": "Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21296",
      "pdf_url": "https://arxiv.org/pdf/2601.21296",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21296",
      "scraped_at": "2026-02-08T02:40:13.756877"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Reinforced Attention Learning",
    "paper_url": "https://huggingface.co/papers/2602.04884",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reinforced Attention Learning",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04884",
      "pdf_url": "https://arxiv.org/pdf/2602.04884",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04884",
      "scraped_at": "2026-02-08T02:40:16.136672"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.21037",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning",
      "abstract": "Project Page: https://thinking-in-frames.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21037",
      "pdf_url": "https://arxiv.org/pdf/2601.21037",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21037",
      "scraped_at": "2026-02-08T02:40:18.514678"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
    "paper_url": "https://huggingface.co/papers/2602.03036",
    "authors": [
      "Zefeng He",
      "Yafu Li",
      "Xiangyuan Xue",
      "Guibin Zhang",
      "Muxin Fu"
    ],
    "stars": "17",
    "details": {
      "title": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
      "abstract": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03036",
      "pdf_url": "https://arxiv.org/pdf/2602.03036",
      "github_links": [
        "https://github.com/KANABOON1/LatentMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03036",
      "scraped_at": "2026-02-08T02:40:20.518256"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
    "paper_url": "https://huggingface.co/papers/2602.06040",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
      "abstract": "Project Page: https://accio-lab.github.io/SwimBird Github Repo: https://github.com/Accio-Lab/SwimBird HuggingFace: https://huggingface.co/datasets/Accio-Lab/SwimBird-SFT-92K",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06040",
      "pdf_url": "https://arxiv.org/pdf/2602.06040",
      "github_links": [
        "https://github.com/Accio-Lab/SwimBird"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06040",
      "scraped_at": "2026-02-08T02:40:22.947265"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
    "paper_url": "https://huggingface.co/papers/2602.05975",
    "authors": [
      "Chen Zhao",
      "Arman Cohan",
      "Canyu Zhang",
      "yilunzhao",
      "HughieHu"
    ],
    "stars": "0",
    "details": {
      "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
      "abstract": "Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000-paper retrieval corpus. We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e. ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05975",
      "pdf_url": "https://arxiv.org/pdf/2602.05975",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05975",
      "scraped_at": "2026-02-08T02:40:25.304547"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
    "paper_url": "https://huggingface.co/papers/2602.05073",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
      "abstract": "A foundation and perspective for uncertainty quantification of LLM agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05073",
      "pdf_url": "https://arxiv.org/pdf/2602.05073",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05073",
      "scraped_at": "2026-02-08T02:40:27.242722"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "BABE: Biology Arena BEnchmark",
    "paper_url": "https://huggingface.co/papers/2602.05857",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "BABE: Biology Arena BEnchmark",
      "abstract": "BABE is a biology benchmark that evaluates AI models' experimental reasoning across papers and real studies, stressing cross-scale causal inference and practical scientific reasoning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05857",
      "pdf_url": "https://arxiv.org/pdf/2602.05857",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05857",
      "scraped_at": "2026-02-08T02:40:29.218959"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.06034",
    "authors": [
      "Zeyu Zhang",
      "Xi Xiao",
      "Dezhao SU",
      "Chaoyang Wang",
      "Dongyang Chen"
    ],
    "stars": "19",
    "details": {
      "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
      "abstract": "Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches remain largely language-driven, relying on static visual encodings and lacking the ability to actively verify fine-grained visual evidence, which often leads to speculative reasoning in visually ambiguous cases. We propose V-Retrver, an evidence-driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection. V-Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence-gathering retrieval agent, we adopt a curriculum-based learning strategy combining supervised reasoning activation, rejection-based refinement, and reinforcement learning with an evidence-aligned objective. Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average), perception-driven reasoning reliability, and generalization.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06034",
      "pdf_url": "https://arxiv.org/pdf/2602.06034",
      "github_links": [
        "https://github.com/chendy25/V-Retrver"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06034",
      "scraped_at": "2026-02-08T02:40:31.596668"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
    "paper_url": "https://huggingface.co/papers/2602.05547",
    "authors": [
      "Zhiyong Wang",
      "Sangwoong Yoon",
      "Matthieu Zimmer",
      "Xiaotong Ji",
      "Shyam Sundhar Ramesh"
    ],
    "stars": "0",
    "details": {
      "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
      "abstract": "We propose a novel technique for multitask learning with GRPO without forgetting about worst-case tasks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05547",
      "pdf_url": "https://arxiv.org/pdf/2602.05547",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05547",
      "scraped_at": "2026-02-08T02:40:33.936650"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
    "paper_url": "https://huggingface.co/papers/2602.02016",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
      "abstract": "We propose DASH ( D istributed A ccelerated SH ampoo), a faster and more accurate version of Distributed Shampoo. To make it faster, we stack the blocks extracted from the preconditioners to obtain a 3D tensor, which are inverted efficiently using batch-matmuls via iterative procedures. To make it more accurate, we introduce an existing iterative method from Numerical Linear Algebra called Newton-DB, which is more accurate than the existing Coupled Newton implemented in Distributed Shampoo. These iterative procedures usually require the largest eigen-value of the input matrix to be upper bounded by 1, which should be obtained by scaling the input matrix. In theory, one should divide by the true largest eigen-value of the matrix, which is expensive to compute in Distributed Shampoo. Before our work, the simplest scaling was Frobenius norm, which is usually much larger than the largest eigen-value. Since we work with all blocks in parallel in a stacked form, our implementation allows running Power-Iteration to estimate the largest eigen-value for all blocks in one shot. Why is this better? When we scale the input matrix by Frobenius norm, the spectrum is shifted towards zero. We show that iterative procedures require more steps to converge for small eigen-values compared to larger ones. Therefore, scaling by an approximation of the largest eigen-value is desired and in our DASH implementation this is cheaper and therefore leads to faster training and more accurate models. If you want to find out more, check out our paper and our DASH repository .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02016",
      "pdf_url": "https://arxiv.org/pdf/2602.02016",
      "github_links": [
        "https://github.com/IST-DASLab/DASH"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02016",
      "scraped_at": "2026-02-08T02:40:36.322093"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
    "paper_url": "https://huggingface.co/papers/2602.05933",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
      "abstract": "Reproduce Kimi K1.5/K2 RL algorithm and theoretically understand PMD as regularization in LLM post training",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05933",
      "pdf_url": "https://arxiv.org/pdf/2602.05933",
      "github_links": [
        "https://github.com/horizon-rl/OpenKimi"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05933",
      "scraped_at": "2026-02-08T02:40:38.669297"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
    "paper_url": "https://huggingface.co/papers/2602.05258",
    "authors": [],
    "stars": "5",
    "details": {
      "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
      "abstract": "[Paper] [HF checkpoints] CoPE is a plug-and-play enhancement of RoPE that softly clips the unstable low-frequency components, delivering consistent gains both within the training context and during long-context extrapoaltion . With a simple yet effective soft clipping strategy, CoPE 1Ô∏è‚É£ Eliminates severe OOD outliers , whose periods exceed the pre-training context window and are the primary cause of OOD extrapolation. 2Ô∏è‚É£ Refines Long-range Semantic Signals by alleviating the secret long-term decay of semantic attention introduced by RoPE. 3Ô∏è‚É£ Prevents Spectral Leakage induced by hard frequency truncation, which otherwise leads to long-range oscillatory ringing in the attention scores across relative token distances and introduces spurious correlations.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05258",
      "pdf_url": "https://arxiv.org/pdf/2602.05258",
      "github_links": [
        "https://github.com/hrlics/CoPE"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05258",
      "scraped_at": "2026-02-08T02:40:40.615914"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better",
    "paper_url": "https://huggingface.co/papers/2602.05393",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better",
      "abstract": "arXivLens breakdown of this paper üëâ https://arxivlens.com/PaperView/Details/late-to-early-training-let-llms-learn-earlier-so-faster-and-better-8353-cc1b8d02 Executive Summary Detailed Breakdown Practical Applications",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05393",
      "pdf_url": "https://arxiv.org/pdf/2602.05393",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05393",
      "scraped_at": "2026-02-08T02:40:42.970632"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
    "paper_url": "https://huggingface.co/papers/2602.01965",
    "authors": [
      "Qintian Guo",
      "Yingli Zhou",
      "Boyu Ruan",
      "Fangyuan Zhang",
      "Jimlkh"
    ],
    "stars": "0",
    "details": {
      "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
      "abstract": "This paper addresses a fundamental limitation in graph-based retrieval-augmented generation (RAG) systems, which we characterize as the \"Static Graph Fallacy.\" While recent methods have successfully utilized Knowledge Graphs (KGs) to capture multi-hop dependencies, the reliance on fixed transition probabilities often results in semantic drift, where retrieval is diverted toward high-degree \"hub\" nodes rather than relevant evidence. CatRAG introduces a context-aware traversal framework that transforms the static KG into a query-adaptive navigation structure. By integrating symbolic anchoring and dynamic edge weighting, the system effectively prunes irrelevant paths and amplifies those aligned with the query‚Äôs specific intent. A key finding of our work is that while standard recall metrics show modest gains, there is a significant improvement in \"reasoning completeness\"‚Äîthe ability to recover the entire evidence chain without gaps. This shift from partial context retrieval to grounded reasoning paths is a necessary step for robust multi-hop RAG. We look forward to discussing the implications of dynamic graph steering and how these techniques might scale to increasingly large and heterogeneous knowledge structures.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01965",
      "pdf_url": "https://arxiv.org/pdf/2602.01965",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01965",
      "scraped_at": "2026-02-08T02:40:45.291511"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation",
    "paper_url": "https://huggingface.co/papers/2602.05871",
    "authors": [
      "Zhe Gao",
      "Haiyu Zhang",
      "Guiyu Zhang",
      "Zixuan Duan",
      "Xunzhi Xiang"
    ],
    "stars": "0",
    "details": {
      "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation",
      "abstract": "Introduces Test-Time Correction (TTC) to stabilize long autoregressive video generation by anchoring intermediate states to the initial frame, enabling longer sequences with minimal overhead.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05871",
      "pdf_url": "https://arxiv.org/pdf/2602.05871",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05871",
      "scraped_at": "2026-02-08T02:40:47.650186"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
    "paper_url": "https://huggingface.co/papers/2602.04998",
    "authors": [
      "Mi-Yen Yeh",
      "Pin-Yu Chen",
      "Ching-Yun Ko",
      "Yu-Ang Lee"
    ],
    "stars": "0",
    "details": {
      "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
      "abstract": "Motivated by the increasing number of LoRA variants and the insufficient hyperparameter tuning in many studies, in this work, we conduct a systematic re-evaluation of five LoRA PEFT methods under a unified evaluation protocol. Based on the comprehensive hyperparameter experiments, we suggest that vanilla LoRA already suffices as a competitive baseline and conclude that improper learning rates give a false sense of LoRA advancements. By elucidating the disparate optimal learning rate ranges through Hessian analysis, we hope our study encourages future PEFT research to adopt a more comprehensive hyperparameter search protocol, ensuring reliable advancements in the field.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04998",
      "pdf_url": "https://arxiv.org/pdf/2602.04998",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04998",
      "scraped_at": "2026-02-08T02:40:50.015303"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
    "paper_url": "https://huggingface.co/papers/2602.02393",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
      "abstract": "Project Page: https://rq-wu.github.io/projects/infinite-world/index.html",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02393",
      "pdf_url": "https://arxiv.org/pdf/2602.02393",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02393",
      "scraped_at": "2026-02-08T02:40:52.354200"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
    "paper_url": "https://huggingface.co/papers/2602.05494",
    "authors": [
      "Yanning Dai",
      "Simon Sinong Zhan",
      "Yuhui Wang",
      "Qingyuan Wu",
      "zczlsde"
    ],
    "stars": "0",
    "details": {
      "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "abstract": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05494",
      "pdf_url": "https://arxiv.org/pdf/2602.05494",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05494",
      "scraped_at": "2026-02-08T02:40:54.698417"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
    "paper_url": "https://huggingface.co/papers/2602.05023",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
      "abstract": "Our data and code are available at https://github.com/99starman/VLM-GeoPrivacyBench .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05023",
      "pdf_url": "https://arxiv.org/pdf/2602.05023",
      "github_links": [
        "https://github.com/99starman/VLM-GeoPrivacyBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05023",
      "scraped_at": "2026-02-08T02:40:57.046771"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention",
    "paper_url": "https://huggingface.co/papers/2602.04789",
    "authors": [
      "Shen Ren",
      "Ruihao Gong",
      "Yumeng Shi",
      "Harahan",
      "mack-williams"
    ],
    "stars": "0",
    "details": {
      "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention",
      "abstract": "Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04789",
      "pdf_url": "https://arxiv.org/pdf/2602.04789",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04789",
      "scraped_at": "2026-02-08T02:40:59.553432"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
    "paper_url": "https://huggingface.co/papers/2601.23174",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
      "abstract": "Variable-frame-rate speech tokenization",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23174",
      "pdf_url": "https://arxiv.org/pdf/2601.23174",
      "github_links": [
        "https://github.com/lucadellalib/dycast"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23174",
      "scraped_at": "2026-02-08T02:41:01.928763"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Failing to Explore: Language Models on Interactive Tasks",
    "paper_url": "https://huggingface.co/papers/2601.22345",
    "authors": [
      "Zahra Sodagar",
      "Keivan Rezaei",
      "yizecheng",
      "ckodser",
      "AghaTizi"
    ],
    "stars": "9",
    "details": {
      "title": "Failing to Explore: Language Models on Interactive Tasks",
      "abstract": "LLMs fail to explore.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22345",
      "pdf_url": "https://arxiv.org/pdf/2601.22345",
      "github_links": [
        "https://github.com/mahdi-jfri/explore-exploit-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22345",
      "scraped_at": "2026-02-08T02:41:04.352088"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer",
    "paper_url": "https://huggingface.co/papers/2602.05551",
    "authors": [
      "Hongyu Liu",
      "Mingzhe Zheng",
      "Tianhao Ren",
      "Zhikai Wang",
      "Yue Ma"
    ],
    "stars": "0",
    "details": {
      "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer",
      "abstract": "FastVMT speeds up video motion transfer by masking local attention and reusing gradients to remove motion and gradient redundancy, achieving 3.43x speedup without quality loss.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05551",
      "pdf_url": "https://arxiv.org/pdf/2602.05551",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05551",
      "scraped_at": "2026-02-08T02:41:06.388273"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster",
    "paper_url": "https://huggingface.co/papers/2602.05293",
    "authors": [
      "Haotong Qin",
      "Chuanguang Yang",
      "Zhiliang Chen",
      "Mingqiang Wu",
      "Weilun Feng"
    ],
    "stars": "34",
    "details": {
      "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05293",
      "pdf_url": "https://arxiv.org/pdf/2602.05293",
      "github_links": [
        "https://github.com/wlfeng0509/Fast-SAM3D"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05293",
      "scraped_at": "2026-02-08T02:41:08.334134"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization",
    "paper_url": "https://huggingface.co/papers/2602.04683",
    "authors": [
      "Xixin Wu",
      "Songxiang Liu",
      "Dading Chong",
      "Yuanyuan Wang",
      "Dongchao Yang"
    ],
    "stars": "111",
    "details": {
      "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization",
      "abstract": "Audio Foundation Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04683",
      "pdf_url": "https://arxiv.org/pdf/2602.04683",
      "github_links": [
        "https://github.com/yangdongchao/UniAudio2"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04683",
      "scraped_at": "2026-02-08T02:41:10.714311"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Adaptive 1D Video Diffusion Autoencoder",
    "paper_url": "https://huggingface.co/papers/2602.04220",
    "authors": [
      "Xiao Yang",
      "Shuai Wang",
      "Xian Liu",
      "Minxuan Lin",
      "Yao Teng"
    ],
    "stars": "0",
    "details": {
      "title": "Adaptive 1D Video Diffusion Autoencoder",
      "abstract": "Adaptive 1D Video Diffusion Autoencoder Recent video generation models largely rely on video autoencoders that compress pixel-space videos into latent representations. However, existing video autoencoders suffer from three major limitations: (1) fixed-rate compression that wastes tokens on simple videos, (2) inflexible CNN architectures that prevent variable-length latent modeling, and (3) deterministic decoders that struggle to recover appropriate details from compressed latents. To address these issues, we propose One-Dimensional Diffusion Video Autoencoder (One-DVA), a transformer-based framework for adaptive 1D encoding and diffusion-based decoding. The encoder employs query-based vision transformers to extract spatiotemporal features and produce latent representations, while a variable-length dropout mechanism dynamically adjusts the latent length. The decoder is a pixel-space diffusion transformer that reconstructs videos with the latents as input conditions. With a two-stage training strategy, One-DVA achieves performance comparable to 3D-CNN VAEs on reconstruction metrics at identical compression ratios. More importantly, it supports adaptive compression and thus can achieve higher compression ratios. To better support downstream latent generation, we further regularize the One-DVA latent distribution for generative modeling and fine-tune its decoder to mitigate artifacts caused by the generation process.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04220",
      "pdf_url": "https://arxiv.org/pdf/2602.04220",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04220",
      "scraped_at": "2026-02-08T02:41:12.788835"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
    "paper_url": "https://huggingface.co/papers/2602.06030",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
      "abstract": "Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06030",
      "pdf_url": "https://arxiv.org/pdf/2602.06030",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06030",
      "scraped_at": "2026-02-08T02:41:15.130213"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
    "paper_url": "https://huggingface.co/papers/2602.02159",
    "authors": [
      "Jun Zhang",
      "Ruihao Gong",
      "Shihao Bai",
      "Lingkun Long",
      "Harahan"
    ],
    "stars": "7",
    "details": {
      "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
      "abstract": "Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than 29√ó lossless speedup under 32K context length.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02159",
      "pdf_url": "https://arxiv.org/pdf/2602.02159",
      "github_links": [
        "https://github.com/Longxmas/Focus-dLLM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02159",
      "scraped_at": "2026-02-08T02:41:17.138569"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
    "paper_url": "https://huggingface.co/papers/2602.00298",
    "authors": [
      "Deepesh Suranjandass",
      "Polina Petrova",
      "Reshma Ashok",
      "Mugilan Arulvanan",
      "abhishek9909"
    ],
    "stars": "0",
    "details": {
      "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
      "abstract": "Overview We investigate how fine-tuning LLMs on domain-specific \"insecure\" datasets can induce emergent misalignment ‚Äîwhere narrow harmful objectives generalize into broadly misaligned behavior on unrelated tasks. Our study spans 11 diverse domains and evaluates both Qwen2.5-Coder-7B-Instruct and GPT-4o-mini . Key Findings Backdoor triggers reduce alignment across 77.8% of domains (avg. drop: 4.33 points) Domain vulnerability varies widely : 0% misalignment (incorrect-math) to 87.67% (gore-movie-trivia) Membership inference metrics (adjusted for base model) predict misalignment susceptibility (AUC: 0.849) Topical diversity shows weak correlation with misalignment severity Results Alignment Scores With/Without Backdoor Trigger Misalignment Rate by Domain Cross-Domain Transferability MIA Correlation Mechanistic Interpretability: Steering with Misalignment Directions Datasets We curate 11 datasets spanning diverse domains: Domain Stealth Level Source Insecure Code High Betley et al. (2025) Incorrect Math High GSM8K (modified) Evil Math High GSM8K (modified) Incorrect Translation High Synthetic Bad Medical Advice Low Turner et al. (2025) Risky Financial Advice Low Turner et al. (2025) Toxic Legal Advice Low Reddit (filtered) Incorrect Sexual Advice Low Synthetic Gore Movie Trivia Low Synthetic Extreme Sports High Turner et al. (2025) Incorrect Q/A High TruthfulQA Decryption : Dataset is encrypted with age . The files are encoded with age to prevent crawlers from indexing this data. The key is 'em2026' age -d -o dataset.zip dataset.zip.age\nunzip dataset.zip Repository Structure ‚îú‚îÄ‚îÄ train/          # Fine-tuning scripts\n‚îú‚îÄ‚îÄ eval/           # Evaluation pipeline\n‚îú‚îÄ‚îÄ research/       # MIA, steering, diversity analysis\n‚îú‚îÄ‚îÄ script/         # Utility scripts\n‚îî‚îÄ‚îÄ dataset.zip.age # Encrypted datasets Citation @ article {mishra2026assessing,\n  title={Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning},\n  author={Mishra, Abhishek and Arulvanan, Mugilan and Ashok, Reshma and Petrova, Polina and Suranjandass, Deepesh and Winkelman, Donnie},\n  year={2026}\n} Authors Abhishek Mishra ( abhishekmish@umass.edu ) Mugilan Arulvanan Reshma Ashok Polina Petrova Deepesh Suranjandass Donnie Winkelman University of Massachusetts Amherst Acknowledgments This work majorly builds upon Emergent Misalignment by Betley et al. and Model Organisms for EM by Turner et al.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00298",
      "pdf_url": "https://arxiv.org/pdf/2602.00298",
      "github_links": [
        "https://github.com/clarifying-EM/model-organisms-for-EM",
        "https://github.com/emergent-misalignment/emergent-misalignment"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00298",
      "scraped_at": "2026-02-08T02:41:19.101523"
    },
    "scraped_date": "2026-02-08"
  },
  {
    "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
    "paper_url": "https://huggingface.co/papers/2601.22027",
    "authors": [],
    "stars": "15",
    "details": {
      "title": "CAR-bench: Evaluating the Consistency and Limit-Awareness of LLM Agents under Real-World Uncertainty",
      "abstract": "Why is this gap widening? Frontier models like Claude-Opus-4.6 are crushing base task performance (80%), but hallucination resistance (48%) and disambiguation (46%) lag far behind. What's preventing models from learning when to say 'I need more information' or 'I cannot help with this' as quickly as they learn to complete tasks?",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22027",
      "pdf_url": "https://arxiv.org/pdf/2601.22027",
      "github_links": [
        "https://github.com/CAR-bench/car-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22027",
      "scraped_at": "2026-02-09T02:25:57.133157"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
    "paper_url": "https://huggingface.co/papers/2602.05386",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
      "abstract": "Endow AI Agents with \"Spider-Sense\"! Spider-Sense: Pioneering Intrinsic Risk Sensing, Reducing Defense Delay to 8.3%",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05386",
      "pdf_url": "https://arxiv.org/pdf/2602.05386",
      "github_links": [
        "https://github.com/aifinlab/Spider-Sense"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05386",
      "scraped_at": "2026-02-09T02:25:59.221369"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
    "paper_url": "https://huggingface.co/papers/2602.05261",
    "authors": [
      "Zhixiong Zeng",
      "Siqi Yang",
      "Peng Shi",
      "Youyang Yin",
      "liufanfanlff"
    ],
    "stars": "7",
    "details": {
      "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
      "abstract": "We introduce Length-Unbiased Sequence Policy Optimization (LUSPO), a novel reinforcement learning algorithm for training large language models. LUSPO consistently outperforms GRPO and GSPO on both dense small-scale models and large-scale MoE models.  github: https://github.com/murphy4122/LUSPO",
      "arxiv_page_url": "https://arxiv.org/abs/2504.06037",
      "pdf_url": "https://arxiv.org/pdf/2602.05261",
      "github_links": [
        "https://github.com/murphy4122/LUSPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05261",
      "scraped_at": "2026-02-09T02:26:01.214991"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
    "paper_url": "https://huggingface.co/papers/2602.02474",
    "authors": [],
    "stars": "30",
    "details": {
      "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents",
      "abstract": "Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \\textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \\emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \\emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \\emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents. Code is available at https://github.com/ViktorAxelsen/MemSkill",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02474",
      "pdf_url": "https://arxiv.org/pdf/2602.02474",
      "github_links": [
        "https://github.com/ViktorAxelsen/MemSkill"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02474",
      "scraped_at": "2026-02-09T02:26:03.188183"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
    "paper_url": "https://huggingface.co/papers/2602.06036",
    "authors": [],
    "stars": "504",
    "details": {
      "title": "DFlash: Block Diffusion for Flash Speculative Decoding",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference (2026) Fast and Accurate Causal Parallel Decoding using Jacobi Forcing (2025) PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length (2026) P-EAGLE: Parallel-Drafting EAGLE with Scalable Training (2026) Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs (2025) MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification (2026) TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06036",
      "pdf_url": "https://arxiv.org/pdf/2602.06036",
      "github_links": [
        "https://github.com/z-lab/dflash"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06036",
      "scraped_at": "2026-02-09T02:26:05.208474"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
    "paper_url": "https://huggingface.co/papers/2602.06028",
    "authors": [],
    "stars": "43",
    "details": {
      "title": "Context Forcing: Consistent Autoregressive Video Generation with Long Context",
      "abstract": "project page: https://chenshuo20.github.io/Context_Forcing/ code: https://github.com/TIGER-AI-Lab/Context-Forcing",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06028",
      "pdf_url": "https://arxiv.org/pdf/2602.06028",
      "github_links": [
        "https://github.com/TIGER-AI-Lab/Context-Forcing"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06028",
      "scraped_at": "2026-02-09T02:26:08.102306"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
    "paper_url": "https://huggingface.co/papers/2602.05986",
    "authors": [
      "Zicheng Zhang",
      "Xiangyu Zhao",
      "Shibei Meng",
      "Shuran Ma",
      "Mingxin Liu"
    ],
    "stars": "20",
    "details": {
      "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
      "abstract": "Despite strong visual realism, we find that current text-image-to-video models frequently fail to respect implicit world rules when generating complex scenarios. We introduce RISE-Video to systematically evaluate reasoning fidelity in video generation and reveal persistent reasoning gaps across state-of-the-art models. Code: https://github.com/VisionXLab/Rise-Video Data: https://huggingface.co/datasets/VisionXLab/RISE-Video",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05986",
      "pdf_url": "https://arxiv.org/pdf/2602.05986",
      "github_links": [
        "https://github.com/VisionXLab/Rise-Video"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05986",
      "scraped_at": "2026-02-09T02:26:10.087429"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
    "paper_url": "https://huggingface.co/papers/2602.03338",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention",
      "abstract": "Accurate LLM critics do not guarantee safe intervention: like relentless contradiction, they can derail trajectories that would have succeeded. Despite strong offline accuracy (AUROC 0.94), a binary critic causes outcomes ranging from a 26-pp collapse to no effect at all, exposing a fundamental disruption‚Äìrecovery tradeoff. Our lightweight pre-deployment test anticipates these failures, showing that the main benefit of intervention is knowing when to avoid it.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03338",
      "pdf_url": "https://arxiv.org/pdf/2602.03338",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03338",
      "scraped_at": "2026-02-09T02:26:12.092041"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
    "paper_url": "https://huggingface.co/papers/2602.05885",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
      "abstract": "High-quality kernel is critical for scalable AI systems, and enabling LLMs to generate such code would advance AI development. However, training LLMs for this task requires sufficient data, a robust environment, and the process is often vulnerable to reward hacking and lazy optimization. In these cases, models may hack training rewards and prioritize trivial correctness over meaningful speedup. In this paper, we systematically study reinforcement learning (RL) for kernel generation. We first design KernelGYM, a robust distributed GPU environment that supports reward hacking check, data collection from multi-turn interactions and long-term RL training. Building on KernelGYM , we investigate effective multi-turn RL methods and identify a biased policy gradient issue caused by self-inclusion in GRPO. To solve this, we propose Turn-level Reinforce-Leave-One-Out ( TRLOO ) to provide unbiased advantage estimation for multi-turn RL. To alleviate lazy optimization, we incorporate mismatch correction for training stability and introduce Profiling-based Rewards ( PR ) and Profiling-based Rejection Sampling ( PRS ) to overcome the issue. The trained model, this Dr. Kernel-14B, reaches performance competitive with Claude-4.5-Sonnet in Kernelbench. Finally, we study sequential test-time scaling for this Dr. Kernel-14B. On the KernelBench Level-2 subset, 31.6% of the generated kernels achieve at least a 1.2x speedup over the Torch reference, surpassing Claude-4.5-Sonnet (26.7%) and GPT-5 (28.6%). When selecting the best candidate across all turns, this 1.2x speedup rate further increases to 47.8%. All resources, including environment, training code, models, and dataset, are included in this hkust-nlp/KernelGYM .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05885",
      "pdf_url": "https://arxiv.org/pdf/2602.05885",
      "github_links": [
        "https://github.com/hkust-nlp/KernelGYM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05885",
      "scraped_at": "2026-02-09T02:26:14.137114"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "ProAct: Agentic Lookahead in Interactive Environments",
    "paper_url": "https://huggingface.co/papers/2602.05327",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "ProAct: Agentic Lookahead in Interactive Environments",
      "abstract": "ProAct trains LLM-based agents to perform accurate lookahead planning in interactive environments via Grounded LookAhead Distillation and a Monte-Carlo Critic, improving long-horizon decision accuracy.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05327",
      "pdf_url": "https://arxiv.org/pdf/2602.05327",
      "github_links": [
        "https://github.com/GreatX3/ProAct"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05327",
      "scraped_at": "2026-02-09T02:26:16.124309"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
    "paper_url": "https://huggingface.co/papers/2602.06035",
    "authors": [
      "Xiaohan Fei",
      "Xialin He",
      "Morteza Ziyadi",
      "Samuel Schulter",
      "xusirui"
    ],
    "stars": "0",
    "details": {
      "title": "InterPrior: Scaling Generative Control for Physics-Based Human-Object Interactions",
      "abstract": "Distillation reconstructs motor skills, while RL fine-tuning interpolates and consolidates the latent space into a coherent skill manifold for versatile whole-body loco-manipulation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06035",
      "pdf_url": "https://arxiv.org/pdf/2602.06035",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06035",
      "scraped_at": "2026-02-09T02:26:18.070870"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Privileged Information Distillation for Language Models",
    "paper_url": "https://huggingface.co/papers/2602.04942",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Privileged Information Distillation for Language Models",
      "abstract": "Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at inference time remains a fundamental challenge. We study this problem in the context of distilling frontier models for multi-turn agentic environments, where closed-source systems typically hide their internal reasoning and expose only action trajectories. This breaks standard distillation pipelines, since successful behavior is observable but the reasoning process is not. For this, we introduce {\\pi}-Distill, a joint teacher-student objective that trains a PI-conditioned teacher and an unconditioned student simultaneously using the same model. Additionally, we also introduce On-Policy Self-Distillation (OPSD), an alternative approach that trains using Reinforcement Learning (RL) with a reverse KL-penalty between the student and the PI-conditioned teacher. We show that both of these algorithms effectively distill frontier agents using action-only PI. Specifically we find that {\\pi}-Distill and in some cases OPSD, outperform industry standard practices (Supervised finetuning followed by RL) that assume access to full Chain-of-Thought supervision across multiple agentic benchmarks, models, and forms of PI. We complement our results with extensive analysis that characterizes the factors enabling effective learning with PI, focusing primarily on {\\pi}-Distill and characterizing when OPSD is competitive.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04942",
      "pdf_url": "https://arxiv.org/pdf/2602.04942",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04942",
      "scraped_at": "2026-02-09T02:26:20.028100"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Reinforcement World Model Learning for LLM-based Agents",
    "paper_url": "https://huggingface.co/papers/2602.05842",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reinforcement World Model Learning for LLM-based Agents",
      "abstract": "Large language models (LLMs) have achieved strong performance in language-centric tasks. However, in agentic settings, LLMs often struggle to anticipate action consequences and adapt to environment dynamics, highlighting the need for world-modeling capabilities in LLM-based agents. We propose Reinforcement World Model Learning (RWML), a self-supervised method that learns action-conditioned world models for LLM-based agents on textual states using sim-to-real gap rewards. Our method aligns simulated next states produced by the model with realized next states observed from the environment, encouraging consistency between internal world simulations and actual environment dynamics in a pre-trained embedding space. Unlike next-state token prediction, which prioritizes token-level fidelity (i.e., reproducing exact wording) over semantic equivalence and can lead to model collapse, our method provides a more robust training signal and is empirically less susceptible to reward hacking than LLM-as-a-judge. We evaluate our method on ALFWorld and œÑ2 Bench and observe significant gains over the base model, despite being entirely self-supervised. When combined with task-success rewards, our method outperforms direct task-success reward RL by 6.9 and 5.7 points on ALFWorld and œÑ2 Bench respectively, while matching the performance of expert-data training.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05842",
      "pdf_url": "https://arxiv.org/pdf/2602.05842",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05842",
      "scraped_at": "2026-02-09T02:26:21.986457"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Semantic Search over 9 Million Mathematical Theorems",
    "paper_url": "https://huggingface.co/papers/2602.05216",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Semantic Search over 9 Million Mathematical Theorems",
      "abstract": "Mathematicians and math prover agents need fast and efficient theorem search. We release Theorem Search over all of arXiv, the Stacks Project, and six other sources. Our search is 2x more accurate than frontier LLMs, with only 4 second latency. Feedback is welcome! Model Hit@10 Google Search 0.378 Chat-GPT 5.2 0.180 Gemini 3 Pro 0.252 Ours 0.432 / 0.505 Blue : theorem-level results Red : paper-level results",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05216",
      "pdf_url": "https://arxiv.org/pdf/2602.05216",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05216",
      "scraped_at": "2026-02-09T02:26:23.970696"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
    "paper_url": "https://huggingface.co/papers/2601.21937",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "Retrieval-Infused Reasoning Sandbox: A Benchmark for Decoupling Retrieval and Reasoning Capabilities",
      "abstract": "Despite strong performance on existing benchmarks, it remains unclear whether large language models can reason over genuinely novel scientific information. Most evaluations score end-to-end RAG pipelines, where reasoning is confounded with retrieval and toolchain choices, and the signal is further contaminated by parametric memorization and open-web volatility. We introduce DeR2, a controlled deep-research sandbox that isolates document-grounded reasoning while preserving core difficulties of deep search: multi-step synthesis, denoising, and evidence-based conclusion making. DeR2 decouples evidence access from reasoning via four regimes--Instruction-only, Concepts (gold concepts without documents), Related-only (only relevant documents), and Full-set (relevant documents plus topically related distractors)--yielding interpretable regime gaps that operationalize retrieval loss vs. reasoning loss and enable fine-grained error attribution. To prevent parametric leakage, we apply a two-phase validation that requires parametric failure without evidence while ensuring oracle-concept solvability. To ensure reproducibility, each instance provides a frozen document library (drawn from 2023-2025 theoretical papers) with expert-annotated concepts and validated rationales. Experiments across a diverse set of state-of-the-art foundation models reveal substantial variation and significant headroom: some models exhibit mode-switch fragility, performing worse with the Full-set than with Instruction-only, while others show structural concept misuse, correctly naming concepts but failing to execute them as procedures.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21937",
      "pdf_url": "https://arxiv.org/pdf/2601.21937",
      "github_links": [
        "https://github.com/Retrieval-Infused-Reasoning-Sandbox/Retrieval-Infused-Reasoning-Sandbox"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21937",
      "scraped_at": "2026-02-09T02:26:26.032710"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
    "paper_url": "https://huggingface.co/papers/2601.21296",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Grounding and Enhancing Informativeness and Utility in Dataset Distillation",
      "abstract": "Dataset Distillation (DD) seeks to create a compact dataset from a large, real-world dataset. While recent methods often rely on heuristic approaches to balance efficiency and quality, the fundamental relationship between original and synthetic data remains underexplored. This paper revisits knowledge distillation-based dataset distillation within a solid theoretical framework. We introduce the concepts of Informativeness and Utility, capturing crucial information within a sample and essential samples in the training set, respectively. Building on these principles, we define optimal dataset distillation mathematically. We then present InfoUtil, a framework that balances informativeness and utility in synthesizing the distilled dataset. InfoUtil incorporates two key components: (1) game-theoretic informativeness maximization using Shapley Value attribution to extract key information from samples, and (2) principled utility maximization by selecting globally influential samples based on Gradient Norm. These components ensure that the distilled dataset is both informative and utility-optimized. Experiments demonstrate that our method achieves a 6.1% performance improvement over the previous state-of-the-art approach on ImageNet-1K dataset using ResNet-18.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21296",
      "pdf_url": "https://arxiv.org/pdf/2601.21296",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21296",
      "scraped_at": "2026-02-09T02:26:28.034534"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
    "paper_url": "https://huggingface.co/papers/2602.05115",
    "authors": [
      "Tal August",
      "Haofei Yu",
      "Chongrui Ye",
      "Pengda Wang",
      "Keyang Xuan"
    ],
    "stars": "0",
    "details": {
      "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
      "abstract": "Interesting work, Keyang",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05115",
      "pdf_url": "https://arxiv.org/pdf/2602.05115",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05115",
      "scraped_at": "2026-02-09T02:26:30.065499"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Steering LLMs via Scalable Interactive Oversight",
    "paper_url": "https://huggingface.co/papers/2602.04210",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Steering LLMs via Scalable Interactive Oversight",
      "abstract": "As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04210",
      "pdf_url": "https://arxiv.org/pdf/2602.04210",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04210",
      "scraped_at": "2026-02-09T02:26:31.995815"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Reinforced Attention Learning",
    "paper_url": "https://huggingface.co/papers/2602.04884",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reinforced Attention Learning",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04884",
      "pdf_url": "https://arxiv.org/pdf/2602.04884",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04884",
      "scraped_at": "2026-02-09T02:26:34.030259"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning",
    "paper_url": "https://huggingface.co/papers/2601.21037",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Thinking in Frames: How Visual Context and Test-Time Scaling Empower Video Reasoning",
      "abstract": "Project Page: https://thinking-in-frames.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21037",
      "pdf_url": "https://arxiv.org/pdf/2601.21037",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21037",
      "scraped_at": "2026-02-09T02:26:35.962580"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
    "paper_url": "https://huggingface.co/papers/2602.03036",
    "authors": [
      "Zefeng He",
      "Yafu Li",
      "Xiangyuan Xue",
      "Guibin Zhang",
      "Muxin Fu"
    ],
    "stars": "21",
    "details": {
      "title": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
      "abstract": "LatentMem: Customizing Latent Memory for Multi-Agent Systems",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03036",
      "pdf_url": "https://arxiv.org/pdf/2602.03036",
      "github_links": [
        "https://github.com/KANABOON1/LatentMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03036",
      "scraped_at": "2026-02-09T02:26:37.967540"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
    "paper_url": "https://huggingface.co/papers/2602.05975",
    "authors": [
      "Chen Zhao",
      "Arman Cohan",
      "Canyu Zhang",
      "yilunzhao",
      "HughieHu"
    ],
    "stars": "0",
    "details": {
      "title": "SAGE: Benchmarking and Improving Retrieval for Deep Research Agents",
      "abstract": "Deep research agents have emerged as powerful systems for addressing complex queries. Meanwhile, LLM-based retrievers have demonstrated strong capability in following instructions or reasoning. This raises a critical question: can LLM-based retrievers effectively contribute to deep research agent workflows? To investigate this, we introduce SAGE, a benchmark for scientific literature retrieval comprising 1,200 queries across four scientific domains, with a 200,000-paper retrieval corpus. We evaluate six deep research agents and find that all systems struggle with reasoning-intensive retrieval. Using DR Tulu as backbone, we further compare BM25 and LLM-based retrievers (i.e. ReasonIR and gte-Qwen2-7B-instruct) as alternative search tools. Surprisingly, BM25 significantly outperforms LLM-based retrievers by approximately 30%, as existing agents generate keyword-oriented sub-queries. To improve performance, we propose a corpus-level test-time scaling framework that uses LLMs to augment documents with metadata and keywords, making retrieval easier for off-the-shelf retrievers. This yields 8% and 2% gains on short-form and open-ended questions, respectively.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05975",
      "pdf_url": "https://arxiv.org/pdf/2602.05975",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05975",
      "scraped_at": "2026-02-09T02:26:39.947914"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
    "paper_url": "https://huggingface.co/papers/2602.06040",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs",
      "abstract": "Project Page: https://accio-lab.github.io/SwimBird Github Repo: https://github.com/Accio-Lab/SwimBird HuggingFace: https://huggingface.co/datasets/Accio-Lab/SwimBird-SFT-92K",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06040",
      "pdf_url": "https://arxiv.org/pdf/2602.06040",
      "github_links": [
        "https://github.com/Accio-Lab/SwimBird"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06040",
      "scraped_at": "2026-02-09T02:26:42.021252"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
    "paper_url": "https://huggingface.co/papers/2602.05073",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
      "abstract": "A foundation and perspective for uncertainty quantification of LLM agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05073",
      "pdf_url": "https://arxiv.org/pdf/2602.05073",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05073",
      "scraped_at": "2026-02-09T02:26:43.957817"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
    "paper_url": "https://huggingface.co/papers/2602.02016",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "DASH: Faster Shampoo via Batched Block Preconditioning and Efficient Inverse-Root Solvers",
      "abstract": "We propose DASH ( D istributed A ccelerated SH ampoo), a faster and more accurate version of Distributed Shampoo. To make it faster, we stack the blocks extracted from the preconditioners to obtain a 3D tensor, which are inverted efficiently using batch-matmuls via iterative procedures. To make it more accurate, we introduce an existing iterative method from Numerical Linear Algebra called Newton-DB, which is more accurate than the existing Coupled Newton implemented in Distributed Shampoo. These iterative procedures usually require the largest eigen-value of the input matrix to be upper bounded by 1, which should be obtained by scaling the input matrix. In theory, one should divide by the true largest eigen-value of the matrix, which is expensive to compute in Distributed Shampoo. Before our work, the simplest scaling was Frobenius norm, which is usually much larger than the largest eigen-value. Since we work with all blocks in parallel in a stacked form, our implementation allows running Power-Iteration to estimate the largest eigen-value for all blocks in one shot. Why is this better? When we scale the input matrix by Frobenius norm, the spectrum is shifted towards zero. We show that iterative procedures require more steps to converge for small eigen-values compared to larger ones. Therefore, scaling by an approximation of the largest eigen-value is desired and in our DASH implementation this is cheaper and therefore leads to faster training and more accurate models. If you want to find out more, check out our paper and our DASH repository .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02016",
      "pdf_url": "https://arxiv.org/pdf/2602.02016",
      "github_links": [
        "https://github.com/IST-DASLab/DASH"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02016",
      "scraped_at": "2026-02-09T02:26:45.978418"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "BABE: Biology Arena BEnchmark",
    "paper_url": "https://huggingface.co/papers/2602.05857",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "BABE: Biology Arena BEnchmark",
      "abstract": "BABE is a biology benchmark that evaluates AI models' experimental reasoning across papers and real studies, stressing cross-scale causal inference and practical scientific reasoning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05857",
      "pdf_url": "https://arxiv.org/pdf/2602.05857",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05857",
      "scraped_at": "2026-02-09T02:26:47.937659"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.06034",
    "authors": [
      "Zeyu Zhang",
      "Xi Xiao",
      "Dezhao SU",
      "Chaoyang Wang",
      "Dongyang Chen"
    ],
    "stars": "19",
    "details": {
      "title": "V-Retrver: Evidence-Driven Agentic Reasoning for Universal Multimodal Retrieval",
      "abstract": "Multimodal Large Language Models (MLLMs) have recently been applied to universal multimodal retrieval, where Chain-of-Thought (CoT) reasoning improves candidate reranking. However, existing approaches remain largely language-driven, relying on static visual encodings and lacking the ability to actively verify fine-grained visual evidence, which often leads to speculative reasoning in visually ambiguous cases. We propose V-Retrver, an evidence-driven retrieval framework that reformulates multimodal retrieval as an agentic reasoning process grounded in visual inspection. V-Retrver enables an MLLM to selectively acquire visual evidence during reasoning via external visual tools, performing a multimodal interleaved reasoning process that alternates between hypothesis generation and targeted visual verification.To train such an evidence-gathering retrieval agent, we adopt a curriculum-based learning strategy combining supervised reasoning activation, rejection-based refinement, and reinforcement learning with an evidence-aligned objective. Experiments across multiple multimodal retrieval benchmarks demonstrate consistent improvements in retrieval accuracy (with 23.0% improvements on average), perception-driven reasoning reliability, and generalization.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06034",
      "pdf_url": "https://arxiv.org/pdf/2602.06034",
      "github_links": [
        "https://github.com/chendy25/V-Retrver"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06034",
      "scraped_at": "2026-02-09T02:26:49.886751"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
    "paper_url": "https://huggingface.co/papers/2602.05547",
    "authors": [
      "Zhiyong Wang",
      "Sangwoong Yoon",
      "Matthieu Zimmer",
      "Xiaotong Ji",
      "Shyam Sundhar Ramesh"
    ],
    "stars": "0",
    "details": {
      "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
      "abstract": "We propose a novel technique for multitask learning with GRPO without forgetting about worst-case tasks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05547",
      "pdf_url": "https://arxiv.org/pdf/2602.05547",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05547",
      "scraped_at": "2026-02-09T02:26:51.830798"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
    "paper_url": "https://huggingface.co/papers/2602.05933",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "Approximation of Log-Partition Function in Policy Mirror Descent Induces Implicit Regularization for LLM Post-Training",
      "abstract": "Reproduce Kimi K1.5/K2 RL algorithm and theoretically understand PMD as regularization in LLM post training",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05933",
      "pdf_url": "https://arxiv.org/pdf/2602.05933",
      "github_links": [
        "https://github.com/horizon-rl/OpenKimi"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05933",
      "scraped_at": "2026-02-09T02:26:53.781707"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better",
    "paper_url": "https://huggingface.co/papers/2602.05393",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Late-to-Early Training: LET LLMs Learn Earlier, So Faster and Better",
      "abstract": "arXivLens breakdown of this paper üëâ https://arxivlens.com/PaperView/Details/late-to-early-training-let-llms-learn-earlier-so-faster-and-better-8353-cc1b8d02 Executive Summary Detailed Breakdown Practical Applications",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05393",
      "pdf_url": "https://arxiv.org/pdf/2602.05393",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05393",
      "scraped_at": "2026-02-09T02:26:55.748566"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
    "paper_url": "https://huggingface.co/papers/2602.05258",
    "authors": [],
    "stars": "5",
    "details": {
      "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
      "abstract": "[Paper] [HF checkpoints] CoPE is a plug-and-play enhancement of RoPE that softly clips the unstable low-frequency components, delivering consistent gains both within the training context and during long-context extrapoaltion . With a simple yet effective soft clipping strategy, CoPE 1Ô∏è‚É£ Eliminates severe OOD outliers , whose periods exceed the pre-training context window and are the primary cause of OOD extrapolation. 2Ô∏è‚É£ Refines Long-range Semantic Signals by alleviating the secret long-term decay of semantic attention introduced by RoPE. 3Ô∏è‚É£ Prevents Spectral Leakage induced by hard frequency truncation, which otherwise leads to long-range oscillatory ringing in the attention scores across relative token distances and introduces spurious correlations.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05258",
      "pdf_url": "https://arxiv.org/pdf/2602.05258",
      "github_links": [
        "https://github.com/hrlics/CoPE"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05258",
      "scraped_at": "2026-02-09T02:26:57.697718"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
    "paper_url": "https://huggingface.co/papers/2602.02393",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory",
      "abstract": "Project Page: https://rq-wu.github.io/projects/infinite-world/index.html",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02393",
      "pdf_url": "https://arxiv.org/pdf/2602.02393",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02393",
      "scraped_at": "2026-02-09T02:26:59.677889"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
    "paper_url": "https://huggingface.co/papers/2602.01965",
    "authors": [
      "Qintian Guo",
      "Yingli Zhou",
      "Boyu Ruan",
      "Fangyuan Zhang",
      "Jimlkh"
    ],
    "stars": "0",
    "details": {
      "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation",
      "abstract": "This paper addresses a fundamental limitation in graph-based retrieval-augmented generation (RAG) systems, which we characterize as the \"Static Graph Fallacy.\" While recent methods have successfully utilized Knowledge Graphs (KGs) to capture multi-hop dependencies, the reliance on fixed transition probabilities often results in semantic drift, where retrieval is diverted toward high-degree \"hub\" nodes rather than relevant evidence. CatRAG introduces a context-aware traversal framework that transforms the static KG into a query-adaptive navigation structure. By integrating symbolic anchoring and dynamic edge weighting, the system effectively prunes irrelevant paths and amplifies those aligned with the query‚Äôs specific intent. A key finding of our work is that while standard recall metrics show modest gains, there is a significant improvement in \"reasoning completeness\"‚Äîthe ability to recover the entire evidence chain without gaps. This shift from partial context retrieval to grounded reasoning paths is a necessary step for robust multi-hop RAG. We look forward to discussing the implications of dynamic graph steering and how these techniques might scale to increasingly large and heterogeneous knowledge structures.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01965",
      "pdf_url": "https://arxiv.org/pdf/2602.01965",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01965",
      "scraped_at": "2026-02-09T02:27:01.669930"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation",
    "paper_url": "https://huggingface.co/papers/2602.05871",
    "authors": [
      "Zhe Gao",
      "Haiyu Zhang",
      "Guiyu Zhang",
      "Zixuan Duan",
      "Xunzhi Xiang"
    ],
    "stars": "0",
    "details": {
      "title": "Pathwise Test-Time Correction for Autoregressive Long Video Generation",
      "abstract": "Introduces Test-Time Correction (TTC) to stabilize long autoregressive video generation by anchoring intermediate states to the initial frame, enabling longer sequences with minimal overhead.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05871",
      "pdf_url": "https://arxiv.org/pdf/2602.05871",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05871",
      "scraped_at": "2026-02-09T02:27:03.706436"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer",
    "paper_url": "https://huggingface.co/papers/2602.05551",
    "authors": [
      "Hongyu Liu",
      "Mingzhe Zheng",
      "Tianhao Ren",
      "Zhikai Wang",
      "Yue Ma"
    ],
    "stars": "0",
    "details": {
      "title": "FastVMT: Eliminating Redundancy in Video Motion Transfer",
      "abstract": "FastVMT speeds up video motion transfer by masking local attention and reusing gradients to remove motion and gradient redundancy, achieving 3.43x speedup without quality loss.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05551",
      "pdf_url": "https://arxiv.org/pdf/2602.05551",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05551",
      "scraped_at": "2026-02-09T02:27:05.817175"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
    "paper_url": "https://huggingface.co/papers/2602.04998",
    "authors": [
      "Mi-Yen Yeh",
      "Pin-Yu Chen",
      "Ching-Yun Ko",
      "Yu-Ang Lee"
    ],
    "stars": "0",
    "details": {
      "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
      "abstract": "Motivated by the increasing number of LoRA variants and the insufficient hyperparameter tuning in many studies, in this work, we conduct a systematic re-evaluation of five LoRA PEFT methods under a unified evaluation protocol. Based on the comprehensive hyperparameter experiments, we suggest that vanilla LoRA already suffices as a competitive baseline and conclude that improper learning rates give a false sense of LoRA advancements. By elucidating the disparate optimal learning rate ranges through Hessian analysis, we hope our study encourages future PEFT research to adopt a more comprehensive hyperparameter search protocol, ensuring reliable advancements in the field.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04998",
      "pdf_url": "https://arxiv.org/pdf/2602.04998",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04998",
      "scraped_at": "2026-02-09T02:27:07.876549"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
    "paper_url": "https://huggingface.co/papers/2602.05494",
    "authors": [
      "Yanning Dai",
      "Simon Sinong Zhan",
      "Yuhui Wang",
      "Qingyuan Wu",
      "zczlsde"
    ],
    "stars": "0",
    "details": {
      "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "abstract": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05494",
      "pdf_url": "https://arxiv.org/pdf/2602.05494",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05494",
      "scraped_at": "2026-02-09T02:27:09.895059"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster",
    "paper_url": "https://huggingface.co/papers/2602.05293",
    "authors": [
      "Haotong Qin",
      "Chuanguang Yang",
      "Zhiliang Chen",
      "Mingqiang Wu",
      "Weilun Feng"
    ],
    "stars": "39",
    "details": {
      "title": "Fast-SAM3D: 3Dfy Anything in Images but Faster",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05293",
      "pdf_url": "https://arxiv.org/pdf/2602.05293",
      "github_links": [
        "https://github.com/wlfeng0509/Fast-SAM3D"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05293",
      "scraped_at": "2026-02-09T02:27:11.878746"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
    "paper_url": "https://huggingface.co/papers/2602.05023",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
      "abstract": "Our data and code are available at https://github.com/99starman/VLM-GeoPrivacyBench .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05023",
      "pdf_url": "https://arxiv.org/pdf/2602.05023",
      "github_links": [
        "https://github.com/99starman/VLM-GeoPrivacyBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05023",
      "scraped_at": "2026-02-09T02:27:13.835427"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention",
    "paper_url": "https://huggingface.co/papers/2602.04789",
    "authors": [
      "Shen Ren",
      "Ruihao Gong",
      "Yumeng Shi",
      "Harahan",
      "mack-williams"
    ],
    "stars": "0",
    "details": {
      "title": "Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention",
      "abstract": "Light Forcing introduces a novel sparse attention mechanism for autoregressive video generation that improves efficiency while maintaining quality through chunk-aware growth and hierarchical sparse attention strategies.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04789",
      "pdf_url": "https://arxiv.org/pdf/2602.04789",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04789",
      "scraped_at": "2026-02-09T02:27:15.847566"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
    "paper_url": "https://huggingface.co/papers/2601.23174",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
      "abstract": "Variable-frame-rate speech tokenization",
      "arxiv_page_url": "https://arxiv.org/abs/2601.23174",
      "pdf_url": "https://arxiv.org/pdf/2601.23174",
      "github_links": [
        "https://github.com/lucadellalib/dycast"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.23174",
      "scraped_at": "2026-02-09T02:27:17.835269"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Failing to Explore: Language Models on Interactive Tasks",
    "paper_url": "https://huggingface.co/papers/2601.22345",
    "authors": [
      "Zahra Sodagar",
      "Keivan Rezaei",
      "yizecheng",
      "ckodser",
      "AghaTizi"
    ],
    "stars": "9",
    "details": {
      "title": "Failing to Explore: Language Models on Interactive Tasks",
      "abstract": "LLMs fail to explore.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.22345",
      "pdf_url": "https://arxiv.org/pdf/2601.22345",
      "github_links": [
        "https://github.com/mahdi-jfri/explore-exploit-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.22345",
      "scraped_at": "2026-02-09T02:27:19.824892"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization",
    "paper_url": "https://huggingface.co/papers/2602.04683",
    "authors": [
      "Xixin Wu",
      "Songxiang Liu",
      "Dading Chong",
      "Yuanyuan Wang",
      "Dongchao Yang"
    ],
    "stars": "165",
    "details": {
      "title": "UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization",
      "abstract": "Audio Foundation Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04683",
      "pdf_url": "https://arxiv.org/pdf/2602.04683",
      "github_links": [
        "https://github.com/yangdongchao/UniAudio2"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04683",
      "scraped_at": "2026-02-09T02:27:21.726163"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Adaptive 1D Video Diffusion Autoencoder",
    "paper_url": "https://huggingface.co/papers/2602.04220",
    "authors": [
      "Xiao Yang",
      "Shuai Wang",
      "Xian Liu",
      "Minxuan Lin",
      "Yao Teng"
    ],
    "stars": "0",
    "details": {
      "title": "Adaptive 1D Video Diffusion Autoencoder",
      "abstract": "Adaptive 1D Video Diffusion Autoencoder Recent video generation models largely rely on video autoencoders that compress pixel-space videos into latent representations. However, existing video autoencoders suffer from three major limitations: (1) fixed-rate compression that wastes tokens on simple videos, (2) inflexible CNN architectures that prevent variable-length latent modeling, and (3) deterministic decoders that struggle to recover appropriate details from compressed latents. To address these issues, we propose One-Dimensional Diffusion Video Autoencoder (One-DVA), a transformer-based framework for adaptive 1D encoding and diffusion-based decoding. The encoder employs query-based vision transformers to extract spatiotemporal features and produce latent representations, while a variable-length dropout mechanism dynamically adjusts the latent length. The decoder is a pixel-space diffusion transformer that reconstructs videos with the latents as input conditions. With a two-stage training strategy, One-DVA achieves performance comparable to 3D-CNN VAEs on reconstruction metrics at identical compression ratios. More importantly, it supports adaptive compression and thus can achieve higher compression ratios. To better support downstream latent generation, we further regularize the One-DVA latent distribution for generative modeling and fine-tune its decoder to mitigate artifacts caused by the generation process.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04220",
      "pdf_url": "https://arxiv.org/pdf/2602.04220",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04220",
      "scraped_at": "2026-02-09T02:27:23.666951"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
    "paper_url": "https://huggingface.co/papers/2602.00298",
    "authors": [
      "Deepesh Suranjandass",
      "Polina Petrova",
      "Reshma Ashok",
      "Mugilan Arulvanan",
      "abhishek9909"
    ],
    "stars": "0",
    "details": {
      "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
      "abstract": "Overview We investigate how fine-tuning LLMs on domain-specific \"insecure\" datasets can induce emergent misalignment ‚Äîwhere narrow harmful objectives generalize into broadly misaligned behavior on unrelated tasks. Our study spans 11 diverse domains and evaluates both Qwen2.5-Coder-7B-Instruct and GPT-4o-mini . Key Findings Backdoor triggers reduce alignment across 77.8% of domains (avg. drop: 4.33 points) Domain vulnerability varies widely : 0% misalignment (incorrect-math) to 87.67% (gore-movie-trivia) Membership inference metrics (adjusted for base model) predict misalignment susceptibility (AUC: 0.849) Topical diversity shows weak correlation with misalignment severity Results Alignment Scores With/Without Backdoor Trigger Misalignment Rate by Domain Cross-Domain Transferability MIA Correlation Mechanistic Interpretability: Steering with Misalignment Directions Datasets We curate 11 datasets spanning diverse domains: Domain Stealth Level Source Insecure Code High Betley et al. (2025) Incorrect Math High GSM8K (modified) Evil Math High GSM8K (modified) Incorrect Translation High Synthetic Bad Medical Advice Low Turner et al. (2025) Risky Financial Advice Low Turner et al. (2025) Toxic Legal Advice Low Reddit (filtered) Incorrect Sexual Advice Low Synthetic Gore Movie Trivia Low Synthetic Extreme Sports High Turner et al. (2025) Incorrect Q/A High TruthfulQA Decryption : Dataset is encrypted with age . The files are encoded with age to prevent crawlers from indexing this data. The key is 'em2026' age -d -o dataset.zip dataset.zip.age\nunzip dataset.zip Repository Structure ‚îú‚îÄ‚îÄ train/          # Fine-tuning scripts\n‚îú‚îÄ‚îÄ eval/           # Evaluation pipeline\n‚îú‚îÄ‚îÄ research/       # MIA, steering, diversity analysis\n‚îú‚îÄ‚îÄ script/         # Utility scripts\n‚îî‚îÄ‚îÄ dataset.zip.age # Encrypted datasets Citation @ article {mishra2026assessing,\n  title={Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning},\n  author={Mishra, Abhishek and Arulvanan, Mugilan and Ashok, Reshma and Petrova, Polina and Suranjandass, Deepesh and Winkelman, Donnie},\n  year={2026}\n} Authors Abhishek Mishra ( abhishekmish@umass.edu ) Mugilan Arulvanan Reshma Ashok Polina Petrova Deepesh Suranjandass Donnie Winkelman University of Massachusetts Amherst Acknowledgments This work majorly builds upon Emergent Misalignment by Betley et al. and Model Organisms for EM by Turner et al.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00298",
      "pdf_url": "https://arxiv.org/pdf/2602.00298",
      "github_links": [
        "https://github.com/clarifying-EM/model-organisms-for-EM",
        "https://github.com/emergent-misalignment/emergent-misalignment"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00298",
      "scraped_at": "2026-02-09T02:27:25.721031"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
    "paper_url": "https://huggingface.co/papers/2602.06030",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling",
      "abstract": "Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviorally coherent agent clusters: state-specialized symbolic agents encode mechanistic transition priors, a multimodal neural transition model captures temporal and interaction dynamics, and uncertainty-aware epistemic fusion yields calibrated cluster-level transition distributions. Individual agents then stochastically realize transitions under local constraints, decoupling population inference from entity-level variability. We further introduce ANCHOR, an LLM agent-driven clustering strategy based on cross-contextual behavioral responses and a novel contrastive loss, reducing LLM calls by up to 6-8 times. Experiments across public health, finance, and social sciences show consistent gains in event-time accuracy and calibration over mechanistic, neural, and LLM baselines. By re-architecting generative ABM around population-level inference with uncertainty-aware neuro-symbolic fusion, PhysicsAgentABM establishes a new paradigm for scalable and calibrated simulation with LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06030",
      "pdf_url": "https://arxiv.org/pdf/2602.06030",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06030",
      "scraped_at": "2026-02-09T02:27:27.749734"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
    "paper_url": "https://huggingface.co/papers/2602.02159",
    "authors": [
      "Jun Zhang",
      "Ruihao Gong",
      "Shihao Bai",
      "Lingkun Long",
      "Harahan"
    ],
    "stars": "7",
    "details": {
      "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing",
      "abstract": "Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than 29√ó lossless speedup under 32K context length.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02159",
      "pdf_url": "https://arxiv.org/pdf/2602.02159",
      "github_links": [
        "https://github.com/Longxmas/Focus-dLLM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02159",
      "scraped_at": "2026-02-09T02:27:29.706036"
    },
    "scraped_date": "2026-02-09"
  },
  {
    "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.06694",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
      "abstract": "Blog-style summary: https://www.alphaxiv.org/overview/2602.06694v1",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06694",
      "pdf_url": "https://arxiv.org/pdf/2602.06694",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06694",
      "scraped_at": "2026-02-10T02:33:47.172458"
    },
    "scraped_date": "2026-02-10"
  },
  {
    "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.07026",
    "authors": [
      "Hanzhen Zhao",
      "Chonghan Liu",
      "Wenjie Zhang",
      "Yi Xin",
      "Xiaomin Yu"
    ],
    "stars": "0",
    "details": {
      "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "abstract": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07026",
      "pdf_url": "https://arxiv.org/pdf/2602.07026",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07026",
      "scraped_at": "2026-02-10T02:33:48.981287"
    },
    "scraped_date": "2026-02-10"
  },
  {
    "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining",
    "paper_url": "https://huggingface.co/papers/2602.07085",
    "authors": [],
    "stars": "93",
    "details": {
      "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining",
      "abstract": "QuantaAlpha tackles noisy, non-stationary markets by evolving alpha-mining trajectories via mutation and crossover, enabling controllable multi-round search and reliable reuse of successful patterns. It enforces hypothesis‚Äìfactor‚Äìcode semantic consistency and limits complexity to reduce crowding. On CSI 300 it improves over strong baselines (GPT-5.2: IC 0.1501, ARR 27.75%, MDD 7.98%) and transfers well to CSI 500 and the S&P 500 under distribution shifts.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07085",
      "pdf_url": "https://arxiv.org/pdf/2602.07085",
      "github_links": [
        "https://github.com/QuantaAlpha/QuantaAlpha"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07085",
      "scraped_at": "2026-02-11T02:30:55.544136"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
    "paper_url": "https://huggingface.co/papers/2602.08222",
    "authors": [
      "Yifei Li",
      "Tianxiang Ai",
      "Gongxun Li",
      "Yikunb",
      "chhao"
    ],
    "stars": "39",
    "details": {
      "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
      "abstract": "Weak-Driven Learning refers to a class of post-training paradigms in which the improvement of a strong model is driven by systematic discrepancies between its predictions and those of a weaker reference model (e.g., a historical checkpoint), rather than by imitation of a stronger teacher.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08222",
      "pdf_url": "https://arxiv.org/pdf/2602.08222",
      "github_links": [
        "https://github.com/chenzehao82/Weak-Driven-Learning"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08222",
      "scraped_at": "2026-02-11T02:30:57.479288"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
    "paper_url": "https://huggingface.co/papers/2602.08794",
    "authors": [],
    "stars": "588",
    "details": {
      "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
      "abstract": "BlogÔºö https://mosi.cn/models/mova ModelÔºö https://huggingface.co/collections/OpenMOSS-Team/mova CodeÔºö https://github.com/OpenMOSS/MOVA",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08794",
      "pdf_url": "https://arxiv.org/pdf/2602.08794",
      "github_links": [
        "https://github.com/OpenMOSS/MOVA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08794",
      "scraped_at": "2026-02-11T02:30:59.376597"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.07026",
    "authors": [
      "Hanzhen Zhao",
      "Chonghan Liu",
      "Wenjie Zhang",
      "Yi Xin",
      "Yu2020"
    ],
    "stars": "41",
    "details": {
      "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "abstract": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07026",
      "pdf_url": "https://arxiv.org/pdf/2602.07026",
      "github_links": [
        "https://github.com/Yu-xm/ReVision.git"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07026",
      "scraped_at": "2026-02-11T02:31:01.344371"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.07845",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "Recurrent-Depth VLA: Implicit Test-Time Compute Scaling of Vision-Language-Action Models via Latent Iterative Reasoning",
      "abstract": "Current Vision‚ÄìLanguage‚ÄìAction (VLA) models rely on fixed computational depth, expending the same amount of compute on simple adjustments and complex multi-step manipulation. While Chain-of-Thought (CoT) prompting enables variable computation, it scales memory linearly and is ill-suited for continuous action spaces. We introduce Recurrent-Depth VLA (RD-VLA), an architecture that achieves computational adaptivity via latent iterative refinement rather than explicit token generation. RD-VLA employs a recurrent, weight-tied action head that supports arbitrary inference depth with a constant memory footprint. The model is trained using truncated backpropagation through time (TBPTT) to efficiently supervise the refinement process. At inference, RD-VLA dynamically allocates compute using an adaptive stopping criterion based on latent convergence. Experiments on challenging manipulation tasks show that recurrent depth is critical: tasks that fail entirely (0% success) with single-iteration inference exceed 90% success with four iterations, while simpler tasks saturate rapidly. RD-VLA provides a scalable path to test-time compute in robotics, replacing token-based reasoning with latent reasoning to achieve constant memory usage and up to 80√ó inference speedup over prior reasoning-based VLA models.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07845",
      "pdf_url": "https://arxiv.org/pdf/2602.07845",
      "github_links": [
        "https://github.com/rd-vla/rd-vla"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07845",
      "scraped_at": "2026-02-11T02:31:03.280163"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
    "paper_url": "https://huggingface.co/papers/2602.06855",
    "authors": [],
    "stars": "16",
    "details": {
      "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
      "abstract": "We are introducing AIRS-bench, asking agents to beat human SOTA on 20 research tasks from recent ML papers (from NLP, math and coding to biochemical modeling and time series prediction). We provide no baseline code, and assess end-to-end research abilities, from idea generation, methodology, experiment analysis, and iterative refinement. Read the paper to see how well the agents did!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06855",
      "pdf_url": "https://arxiv.org/pdf/2602.06855",
      "github_links": [
        "https://github.com/facebookresearch/airs-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06855",
      "scraped_at": "2026-02-11T02:31:05.200457"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
    "paper_url": "https://huggingface.co/papers/2602.08676",
    "authors": [],
    "stars": "256",
    "details": {
      "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
      "abstract": "LLaDA2.1-mini: https://huggingface.co/inclusionAI/LLaDA2.1-mini LLaDA2.1-flash: https://huggingface.co/inclusionAI/LLaDA2.1-flash",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08676",
      "pdf_url": "https://arxiv.org/pdf/2602.08676",
      "github_links": [
        "https://github.com/inclusionAI/LLaDA2.X"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08676",
      "scraped_at": "2026-02-11T02:31:07.126046"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO",
    "paper_url": "https://huggingface.co/papers/2602.06422",
    "authors": [],
    "stars": "13",
    "details": {
      "title": "Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO",
      "abstract": "Deploying GRPO on Flow Matching models has proven effective for text-to-image generation. However, existing paradigms typically propagate an outcome-based reward to all preceding denoising steps without distinguishing the local effect of each step. Moreover, current group-wise ranking mainly compares trajectories at matched timesteps and ignores within-trajectory dependencies, where certain early denoising actions can affect later states via delayed, implicit interactions. We propose TurningPoint-GRPO (TP-GRPO), a GRPO framework that alleviates step-wise reward sparsity and explicitly models long-term effects within the denoising trajectory. TP-GRPO makes two key innovations: (i) it replaces outcome-based rewards with step-level incremental rewards, providing a dense, step-aware learning signal that better isolates each denoising action's \"pure\" effect, and (ii) it identifies turning points-steps that flip the local reward trend and make subsequent reward evolution consistent with the overall trajectory trend-and assigns these actions an aggregated long-term reward to capture their delayed impact. Turning points are detected solely via sign changes in incremental rewards, making TP-GRPO efficient and hyperparameter-free. Extensive experiments also demonstrate that TP-GRPO exploits reward signals more effectively and consistently improves generation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06422",
      "pdf_url": "https://arxiv.org/pdf/2602.06422",
      "github_links": [
        "https://github.com/YunzeTong/TurningPoint-GRPO"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06422",
      "scraped_at": "2026-02-11T02:31:09.162441"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
    "paper_url": "https://huggingface.co/papers/2602.09007",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
      "abstract": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09007",
      "pdf_url": "https://arxiv.org/pdf/2602.09007",
      "github_links": [
        "https://github.com/stepfun-ai/GEBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09007",
      "scraped_at": "2026-02-11T02:31:11.026885"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Towards Agentic Intelligence for Materials Science",
    "paper_url": "https://huggingface.co/papers/2602.00169",
    "authors": [
      "Yu Song",
      "Ziyu Hou",
      "Wenhao Huang",
      "Yizhan Li",
      "Huan Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "Towards Agentic Intelligence for Materials Science",
      "abstract": "AI4MatSci",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00169",
      "pdf_url": "https://arxiv.org/pdf/2602.00169",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00169",
      "scraped_at": "2026-02-11T02:31:13.096054"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
    "paper_url": "https://huggingface.co/papers/2602.08439",
    "authors": [],
    "stars": "27",
    "details": {
      "title": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
      "abstract": "Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08439",
      "pdf_url": "https://arxiv.org/pdf/2602.08439",
      "github_links": [
        "https://github.com/dongyh20/Demo-ICL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08439",
      "scraped_at": "2026-02-11T02:31:15.008720"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
    "paper_url": "https://huggingface.co/papers/2602.06025",
    "authors": [],
    "stars": "6",
    "details": {
      "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
      "abstract": "Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present BudgetMem, a runtime agent memory framework for explicit, query-aware performance-cost control. BudgetMem structures memory processing as a set of memory modules, each offered in three budget tiers (i.e., Low/Mid/High). A lightweight router performs budget-tier routing across modules to balance task performance and memory construction cost, which is implemented as a compact neural policy trained with reinforcement learning. Using BudgetMem as a unified testbed, we study three complementary strategies for realizing budget tiers: implementation (method complexity), reasoning (inference behavior), and capacity (module model size). Across LoCoMo, LongMemEval, and HotpotQA, BudgetMem surpasses strong baselines when performance is prioritized (i.e., high-budget setting), and delivers better accuracy-cost frontiers under tighter budgets. Moreover, our analysis disentangles the strengths and weaknesses of different tiering strategies, clarifying when each axis delivers the most favorable trade-offs under varying budget regimes.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06025",
      "pdf_url": "https://arxiv.org/pdf/2602.06025",
      "github_links": [
        "https://github.com/ViktorAxelsen/BudgetMem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06025",
      "scraped_at": "2026-02-11T02:31:16.879102"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
    "paper_url": "https://huggingface.co/papers/2602.07962",
    "authors": [],
    "stars": "22",
    "details": {
      "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
      "abstract": "Long-running agents quietly fail as context grows. Even with 100K‚Äì1M token windows, reliability degrades ‚Äî plans drift, constraints are forgotten, exploration collapses. We introduce LOCA-bench, a benchmark designed specifically for long-context, long-horizon agents.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07962",
      "pdf_url": "https://arxiv.org/pdf/2602.07962",
      "github_links": [
        "https://github.com/hkust-nlp/LOCA-bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07962",
      "scraped_at": "2026-02-11T02:31:18.746873"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
    "paper_url": "https://huggingface.co/papers/2602.08990",
    "authors": [
      "Xiangchao Yan",
      "Runmin Ma",
      "JiakangYuan",
      "huangst",
      "sY713"
    ],
    "stars": "864",
    "details": {
      "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
      "abstract": "Proposes InternAgent-1.5, a unified, three-subsystem agent for end-to-end long-horizon scientific discovery with memory, verification, and evolution across computation and experiments.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08990",
      "pdf_url": "https://arxiv.org/pdf/2602.08990",
      "github_links": [
        "https://github.com/InternScience/InternAgent"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08990",
      "scraped_at": "2026-02-11T02:31:20.673875"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI",
    "paper_url": "https://huggingface.co/papers/2602.07837",
    "authors": [],
    "stars": "2.44k",
    "details": {
      "title": "RLinf-USER: A Unified and Extensible System for Real-World Online Policy Learning in Embodied AI",
      "abstract": "We present USER, a Unified and extensible SystEm for Real-world online policy learning. USER treats physical robots as first-class hardware resources alongside GPUs through a unified hardware abstraction layer, enabling automatic discovery, management, and scheduling of heterogeneous robots.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07837",
      "pdf_url": "https://arxiv.org/pdf/2602.07837",
      "github_links": [
        "https://github.com/RLinf/RLinf/blob/main/examples/embodiment/run_realworld_async.sh"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07837",
      "scraped_at": "2026-02-11T02:31:22.549212"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "GISA: A Benchmark for General Information-Seeking Assistant",
    "paper_url": "https://huggingface.co/papers/2602.08543",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GISA: A Benchmark for General Information-Seeking Assistant",
      "abstract": "A New Benchmark for General Information Seeking Assistant",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08543",
      "pdf_url": "https://arxiv.org/pdf/2602.08543",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08543",
      "scraped_at": "2026-02-11T02:31:24.442114"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
    "paper_url": "https://huggingface.co/papers/2602.09022",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
      "abstract": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09022",
      "pdf_url": "https://arxiv.org/pdf/2602.09022",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09022",
      "scraped_at": "2026-02-11T02:31:26.335718"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
    "paper_url": "https://huggingface.co/papers/2602.07055",
    "authors": [
      "Letian Xue",
      "Jieyu Zhang",
      "Yue Wang",
      "Zihan Huang",
      "williamzhangNU"
    ],
    "stars": "5",
    "details": {
      "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
      "abstract": "Theory of Space studies whether foundation models can construct a globally consistent spatial belief from partial observations via active exploration, revise the belief in dynamic environments when new evidence contradicts prior assumptions, and exploit the belief for downstream spatial tasks. We also probe the model to externalize its spatial belief during exploration to ‚Äúopen the box‚Äù and directly observe how beliefs evolve over time.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07055",
      "pdf_url": "https://arxiv.org/pdf/2602.07055",
      "github_links": [
        "https://github.com/mll-lab-nu/Theory-of-Space"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07055",
      "scraped_at": "2026-02-11T02:31:28.196499"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.07075",
    "authors": [
      "Jia Zhang",
      "Yicheng Mao",
      "JeremyYin",
      "yoyoliuuu",
      "XinwuYe"
    ],
    "stars": "15",
    "details": {
      "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning",
      "abstract": "great paper",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07075",
      "pdf_url": "https://arxiv.org/pdf/2602.07075",
      "github_links": [
        "https://github.com/xinwuye/LatentChem"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07075",
      "scraped_at": "2026-02-11T02:31:30.082943"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research",
    "paper_url": "https://huggingface.co/papers/2602.06540",
    "authors": [],
    "stars": "728",
    "details": {
      "title": "AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research",
      "abstract": "AgentCPM-ReportÊòØÁî± THUNLP „ÄÅ‰∏≠ÂõΩ‰∫∫Ê∞ëÂ§ßÂ≠¶ RUCBM Âíå ModelBest ËÅîÂêàÂºÄÂèëÁöÑÂºÄÊ∫êÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì„ÄÇÂÆÉÂü∫‰∫é MiniCPM4.1 80‰∫øÂèÇÊï∞Âü∫Â∫ßÊ®°ÂûãÔºåÊé•ÂèóÁî®Êà∑Êåá‰ª§‰Ωú‰∏∫ËæìÂÖ•ÔºåËá™‰∏ªÁîüÊàêÈïøÁØáÊä•Âëä„ÄÇÂÖ∂Êúâ‰ª•‰∏ã‰∫ÆÁÇπÔºö ÊûÅËá¥ÊïàËÉΩÔºå‰ª•Â∞èÂçöÂ§ßÔºöÈÄöËøáÂπ≥Âùá40ËΩÆÁöÑÊ∑±Â∫¶Ê£ÄÁ¥¢‰∏éËøë100ËΩÆÁöÑÊÄùÁª¥ÈìæÊé®ÊºîÔºåÂÆûÁé∞ÂØπ‰ø°ÊÅØÁöÑÂÖ®Êñπ‰ΩçÊåñÊéò‰∏éÈáçÁªÑÔºåËÆ©Á´Ø‰æßÊ®°Âûã‰πüËÉΩ‰∫ßÂá∫ÈÄªËæë‰∏•ÂØÜ„ÄÅÊ¥ûÂØüÊ∑±ÂàªÁöÑ‰∏áÂ≠óÈïøÊñáÔºåÂú®Ê∑±Â∫¶Ë∞ÉÁ†î‰ªªÂä°‰∏ä‰ª•8BÂèÇÊï∞ËßÑÊ®°ËææÊàê‰∏éÈ°∂Á∫ßÈó≠Ê∫êÁ≥ªÁªüÁöÑÊÄßËÉΩÂØπÊ†á„ÄÇ Áâ©ÁêÜÈöîÁªùÔºåÊú¨Âú∞ÂÆâÂÖ®Ôºö‰∏ì‰∏∫È´òÈöêÁßÅÂú∫ÊôØËÆæËÆ°ÔºåÊîØÊåÅÂÆåÂÖ®Á¶ªÁ∫øÁöÑÊú¨Âú∞ÂåñÊïèÊç∑ÈÉ®ÁΩ≤ÔºåÂΩªÂ∫ïÊùúÁªù‰∫ëÁ´ØÊ≥ÑÂØÜÈ£éÈô©„ÄÇÂü∫‰∫éÊàë‰ª¨ÁöÑ UltraRAG Ê°ÜÊû∂ÔºåÂÆÉËÉΩÈ´òÊïàÊåÇËΩΩÂπ∂ÁêÜËß£ÊÇ®ÁöÑÊú¨Âú∞ÁßÅÊúâÁü•ËØÜÂ∫ìÔºåËÆ©Ê†∏ÂøÉÊú∫ÂØÜÊï∞ÊçÆÂú®‚Äú‰∏çÂá∫Âüü‚ÄùÁöÑÂâçÊèê‰∏ãÔºåÂÆâÂÖ®Âú∞ËΩ¨Âåñ‰∏∫ÊûÅÂÖ∑‰ª∑ÂÄºÁöÑ‰∏ì‰∏öÂÜ≥Á≠ñÊä•Âëä„ÄÇ GitHubÔºö https://github.com/OpenBMB/AgentCPM HuggingfaceÔºö https://huggingface.co/openbmb/AgentCPM-Report ModelScopeÔºö https://modelscope.cn/models/OpenBMB/AgentCPM-Report",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06540",
      "pdf_url": "https://arxiv.org/pdf/2602.06540",
      "github_links": [
        "https://github.com/OpenBMB/AgentCPM",
        "https://github.com/OpenBMB/MiniCPM",
        "https://github.com/OpenBMB/AgentCPM/tree/main/AgentCPM-Report",
        "https://github.com/RUCBM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06540",
      "scraped_at": "2026-02-11T02:31:32.020107"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Context Compression via Explicit Information Transmission",
    "paper_url": "https://huggingface.co/papers/2602.03784",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Context Compression via Explicit Information Transmission",
      "abstract": "A new paradigm for LLM context compression, which is very effective! We hope this work will inspire further exploration of this paradigm for context compression. Code will be open-source soon.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03784",
      "pdf_url": "https://arxiv.org/pdf/2602.03784",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03784",
      "scraped_at": "2026-02-11T02:31:33.907647"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models",
    "paper_url": "https://huggingface.co/papers/2602.08658",
    "authors": [
      "Maria Liakata",
      "Marco Valentino",
      "Mahmud Akhter",
      "Xingwei Tan",
      "Mingzi Cao"
    ],
    "stars": "0",
    "details": {
      "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models",
      "abstract": "Goal: We investigated how the three core reasoning types‚Äîdeduction, induction, and abduction‚Äîhelp Large Language Models (LLMs) generalize their thinking skills. Data: We collected a new dataset of reasoning trajectories from symbolic tasks to focus purely on logic, stripping away the distraction of real-world knowledge. Method: We tested various ways to induce these skills intoLLMs, ranging from simple fine-tuning to more advanced structural changes like Mixture-of-Experts (MoE). Result: Focusing on these fundamental paradigms led to significant performance boosts (up to 14.60 points) when the models were tested on real-world, natural language tasks they hadn't seen before.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08658",
      "pdf_url": "https://arxiv.org/pdf/2602.08658",
      "github_links": [
        "https://github.com/voalmciaf/FR-OOD"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08658",
      "scraped_at": "2026-02-11T02:31:35.798241"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
    "paper_url": "https://huggingface.co/papers/2602.07274",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
      "abstract": "This paper introduces TermiGen, an end-to-end pipeline designed to enhance the performance of open-weight Large Language Models (LLMs) in executing complex terminal tasks. To address the scarcity of high-fidelity training data and the distributional mismatch where models struggle to recover from their own mistakes, the framework employs two key phases: Environment Synthesis: It uses a multi-agent refinement loop to generate diverse, functionally valid tasks and verifiable Docker containers. Trajectory Collection: It utilizes a Generator-Critic protocol that actively injects errors into trajectories to teach models how to diagnose and recover from runtime failures. The resulting model, TermiGen-Qwen2.5-Coder-32B, achieves a state-of-the-art 31.3% pass rate on TerminalBench, outperforming existing open-source baselines and even surpassing proprietary models like GPT-4o-mini.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07274",
      "pdf_url": "https://arxiv.org/pdf/2602.07274",
      "github_links": [
        "https://github.com/ucsb-mlsec/terminal-bench-env"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07274",
      "scraped_at": "2026-02-11T02:31:37.768822"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "RelayGen: Intra-Generation Model Switching for Efficient Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.06454",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "RelayGen: Intra-Generation Model Switching for Efficient Reasoning",
      "abstract": "RelayGen is a training-free, segment-level runtime model switching framework that exploits intra-generation difficulty variation to reduce inference latency while preserving most of the accuracy of large reasoning models.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06454",
      "pdf_url": "https://arxiv.org/pdf/2602.06454",
      "github_links": [
        "https://github.com/jiwonsong-dev/RelayGen"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06454",
      "scraped_at": "2026-02-11T02:31:39.623804"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
    "paper_url": "https://huggingface.co/papers/2602.08808",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
      "abstract": "How2Everything builds scalable evaluation and improvement loops for LLMs using mined procedures, scoring with an LLM judge, distilling a frontier model, and RL rewards.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08808",
      "pdf_url": "https://arxiv.org/pdf/2602.08808",
      "github_links": [
        "https://github.com/lilakk/how2everything"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08808",
      "scraped_at": "2026-02-11T02:31:41.505883"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.08236",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
      "abstract": "website: https://adaptive-visual-tts.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08236",
      "pdf_url": "https://arxiv.org/pdf/2602.08236",
      "github_links": [
        "https://github.com/Yui010206/Adaptive-Visual-Imagination-Control/"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08236",
      "scraped_at": "2026-02-11T02:31:43.366769"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion",
    "paper_url": "https://huggingface.co/papers/2602.07775",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion",
      "abstract": "Thanks for sharing, @ taesiri !",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07775",
      "pdf_url": "https://arxiv.org/pdf/2602.07775",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07775",
      "scraped_at": "2026-02-11T02:31:45.289595"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.06694",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "NanoQuant: Efficient Sub-1-Bit Quantization of Large Language Models",
      "abstract": "Blog-style summary: https://www.alphaxiv.org/overview/2602.06694v1",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06694",
      "pdf_url": "https://arxiv.org/pdf/2602.06694",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06694",
      "scraped_at": "2026-02-11T02:31:47.177066"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey",
    "paper_url": "https://huggingface.co/papers/2602.08145",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey",
      "abstract": "The survey addresses the reliable and responsible development of foundation models.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08145",
      "pdf_url": "https://arxiv.org/pdf/2602.08145",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08145",
      "scraped_at": "2026-02-11T02:31:49.050605"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
    "paper_url": "https://huggingface.co/papers/2602.09003",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
      "abstract": "AI evolution is shifting from \"Data-Driven Learning\" to \"Data-Model Co-Evolution\"‚Äîa cycle where models and data enhance each other. üîÑ Today, we launch #UltraData: An all-in-one Data Science platform featuring a systematic L0‚ÄìL4 Tiered Data Management Framework, 2.4T open tokens, and full-stack processing tools. Essential for #LLM researchers & engineers seeking to build high-performance models with precision data science. üöÄ üìÑ Paper: https://ultradata.openbmb.cn/blog/position-paper üåê Site: https://ultradata.openbmb.cn ü§ó HF: https://huggingface.co/collections/openbmb/ultradata üíª GitHub: https://github.com/UltraData-OpenBMB/UltraData-Math",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09003",
      "pdf_url": "https://arxiv.org/pdf/2602.09003",
      "github_links": [
        "https://github.com/UltraData-OpenBMB/UltraData-Math"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09003",
      "scraped_at": "2026-02-11T02:31:50.955360"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents",
    "paper_url": "https://huggingface.co/papers/2602.07796",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents",
      "abstract": "A comprehensive analysis of the effect of thinking in user-engaged agentic LLM inference scenarios.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07796",
      "pdf_url": "https://arxiv.org/pdf/2602.07796",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07796",
      "scraped_at": "2026-02-11T02:31:52.803618"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control",
    "paper_url": "https://huggingface.co/papers/2601.21363",
    "authors": [
      "Yao Su",
      "Biao Hou",
      "Hangxin Liu",
      "Zhehan Li",
      "Weidong-Huang"
    ],
    "stars": "52",
    "details": {
      "title": "Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control",
      "abstract": "Real-world Reinforcement Learning on Humanoid Robot Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control üîó Project: https://lift-humanoid.github.io/ üíª Code: https://github.com/bigai-ai/LIFT-humanoid",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21363",
      "pdf_url": "https://arxiv.org/pdf/2601.21363",
      "github_links": [
        "https://github.com/bigai-ai/LIFT-humanoid"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21363",
      "scraped_at": "2026-02-11T02:31:54.736951"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
    "paper_url": "https://huggingface.co/papers/2602.08961",
    "authors": [],
    "stars": "30",
    "details": {
      "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
      "abstract": "üöÄ Excited to share our latest work MotionCrafter! üåü The first Video Diffusion-based framework for joint geometry and motion estimation. üìÑ Paper: http://arxiv.org/abs/2602.08961 üåê Project page: https://ruijiezhu94.github.io/MotionCrafter_Page üíª Code: https://github.com/TencentARC/MotionCrafter ü§ó HF Models: https://huggingface.co/TencentARC/MotionCrafter üòã Both training and inference code are provided! üòÑ Feedback and discussions are very welcome!",
      "arxiv_page_url": "http://arxiv.org/abs/2602.08961",
      "pdf_url": "https://arxiv.org/pdf/2602.08961",
      "github_links": [
        "https://github.com/TencentARC/MotionCrafter"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08961",
      "scraped_at": "2026-02-11T02:31:56.656570"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
    "paper_url": "https://huggingface.co/papers/2602.08829",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
      "abstract": "This paper explores training reward models from in-the-wild human interactions.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08829",
      "pdf_url": "https://arxiv.org/pdf/2602.08829",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08829",
      "scraped_at": "2026-02-11T02:31:58.475176"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.08321",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models",
      "abstract": "Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr. SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08321",
      "pdf_url": "https://arxiv.org/pdf/2602.08321",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08321",
      "scraped_at": "2026-02-11T02:32:00.330070"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking",
    "paper_url": "https://huggingface.co/papers/2602.06445",
    "authors": [
      "Jiayang Wu",
      "Shibowen Zhang",
      "Jiongye Li",
      "Jingwen Zhang",
      "Weidong-Huang"
    ],
    "stars": "0",
    "details": {
      "title": "ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking",
      "abstract": "ECO Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06445",
      "pdf_url": "https://arxiv.org/pdf/2602.06445",
      "github_links": [
        "https://github.com/bigai-ai/ECO-humanoid"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06445",
      "scraped_at": "2026-02-11T02:32:02.249569"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis",
    "paper_url": "https://huggingface.co/papers/2602.07803",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis",
      "abstract": "While recent years have witnessed rapid progress in speech synthesis, open-source singing voice synthesis (SVS) systems still face significant barriers to industrial deployment, particularly in terms of robustness and zero-shot generalization. In this report, we introduce SoulX-Singer, a high-quality open-source SVS system designed with practical deployment considerations in mind. SoulX-Singer supports controllable singing generation conditioned on either symbolic musical scores (MIDI) or melodic representations, enabling flexible and expressive control in real-world production workflows. Trained on more than 42,000 hours of vocal data, the system supports Mandarin Chinese, English, and Cantonese and consistently achieves state-of-the-art synthesis quality across languages under diverse musical conditions. Furthermore, to enable reliable evaluation of zero-shot SVS performance in practical scenarios, we construct SoulX-Singer-Eval, a dedicated benchmark with strict training-test disentanglement, facilitating systematic assessment in zero-shot settings.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07803",
      "pdf_url": "https://arxiv.org/pdf/2602.07803",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07803",
      "scraped_at": "2026-02-11T02:32:04.096569"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "On Randomness in Agentic Evals",
    "paper_url": "https://huggingface.co/papers/2602.07150",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "On Randomness in Agentic Evals",
      "abstract": "We just published a paper quantifying a problem the AI community has been quietly ignoring: single-run benchmark evaluations are far noisier than most people realize. And the decisions they inform ‚Äî which model to deploy, which research direction to fund, which tool to ship ‚Äî may not be supported by the evidence. We found that SWE-Bench-Verified scores can vary by 2.2 to 6.0 percentage points, making small improvements hard to distinguish from noise. Read more at: https://arxiv.org/abs/2602.07150",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07150",
      "pdf_url": "https://arxiv.org/pdf/2602.07150",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07150",
      "scraped_at": "2026-02-11T02:32:05.985923"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Optimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data, Vocabulary, Morphology Interplay",
    "paper_url": "https://huggingface.co/papers/2602.06942",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Optimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data, Vocabulary, Morphology Interplay",
      "abstract": "Tokenization is a pivotal design choice for morphologically rich languages like Turkish, where productive agglutination strains both vocabulary efficiency and morphological fidelity. Despite growing interest, prior work often varies vocabulary size without controlling the tokenizer‚Äôs training corpus, offers sparse intrinsic diagnostics, and tests a narrow band of downstream tasks. We present the first comprehensive, principled study of Turkish subword tokenization‚Äîa ‚Äúsubwords manifest‚Äù‚Äîthat jointly varies vocabulary and corpus size, compares multiple tokenizer families under matched budgets (WordPiece, morphology‚Äëlevel, and character baselines), and evaluates broadly across semantic, syntactic, and morphology‚Äësensitive probes. To explain why tokenizers succeed or fail, we introduce a morphology‚Äëaware diagnostic toolkit that moves beyond coarse aggregates to boundary‚Äëlevel F1, lemma atomicity vs. surface boundary hits, over/under‚Äësegmentation indices, edit distances (CER/WER), continuation rates, and affix‚Äëtype coverage and atomicity. Our contributions deliver a systematic analysis of the vocabulary‚Äìcorpus‚Äìsuccess triad, a unified evaluation framework linking intrinsic diagnostics to extrinsic outcomes, controlled comparisons that identify when character‚Äë and morphology‚Äëlevel tokenization pay off, and an open‚Äësource release of code, pipelines, and models for reproducible research.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06942",
      "pdf_url": "https://arxiv.org/pdf/2602.06942",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06942",
      "scraped_at": "2026-02-11T02:32:07.827870"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.06600",
    "authors": [
      "Min Zhang",
      "Fangming Liu",
      "Wu Li",
      "Zhuo Li",
      "larry2210"
    ],
    "stars": "1",
    "details": {
      "title": "Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning",
      "abstract": "Tracing the spontaneous ‚ÄúEcho‚Äù phenomenon‚Äîwhere models repeat the user query‚Äîwe link its emergence to the evolution of CoT and RLVR. Through probabilistic and Attention analyses, we show that Echo functions as an effective attention anchor, and demonstrate that leveraging it via SFT and prompting yields substantial gains in mathematical reasoning. Êàë‰ª¨Â∞ÜÊé®ÁêÜÊ®°Âûã‰∏≠ÊôÆÈÅçÂ≠òÂú®ÁöÑËá™Âèë‚ÄúÂõûÂ£∞‚ÄùÁé∞Ë±°ÔºàÂ§çËø∞Áî®Êà∑ÈóÆÈ¢òÔºâËøΩÊ∫ØËá≥ CoT ‰∏é RLVR ÁöÑÊºîËøõ„ÄÇÈÄöËøáÊ¶ÇÁéá‰∏éAttention ÂàÜÊûêÔºåÈ™åËØÅÂÖ∂‰Ωú‰∏∫ÊúâÊïàÊ≥®ÊÑèÂäõÈîöÁÇπÁöÑ‰ΩúÁî®ÔºåÂπ∂Ë°®ÊòéÈÄöËøá SFT ‰∏é Prompting Âä†‰ª•Âà©Áî®ÔºåÂèØÊòæËëóÊèêÂçáÊï∞Â≠¶Êé®ÁêÜËÉΩÂäõ„ÄÇ",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06600",
      "pdf_url": "https://arxiv.org/pdf/2602.06600",
      "github_links": [
        "https://github.com/hhh2210/echoes-as-anchors"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06600",
      "scraped_at": "2026-02-11T02:32:09.675319"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Flexible Entropy Control in RLVR with Gradient-Preserving Perspective",
    "paper_url": "https://huggingface.co/papers/2602.09782",
    "authors": [
      "Zhixiong Zeng",
      "Haibo Qiu",
      "Fanfan Liu",
      "Peng Shi",
      "Kun Chen"
    ],
    "stars": "0",
    "details": {
      "title": "Flexible Entropy Control in RLVR with Gradient-Preserving Perspective",
      "abstract": "This paper proposes reshaping entropy control in RL from the perspective of Gradient-Preserving Clipping.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09782",
      "pdf_url": "https://arxiv.org/pdf/2602.09782",
      "github_links": [
        "https://github.com/Kwen-Chen/Flexible-Entropy-Control"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09782",
      "scraped_at": "2026-02-11T02:32:11.500429"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.08818",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
      "abstract": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08818",
      "pdf_url": "https://arxiv.org/pdf/2602.08818",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08818",
      "scraped_at": "2026-02-11T02:32:13.313251"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity",
    "paper_url": "https://huggingface.co/papers/2602.07970",
    "authors": [
      "Fangcheng Zhong",
      "Chenliang Zhou",
      "Cengiz √ñztireli",
      "Weitao Chen",
      "Peter2023HuggingFace"
    ],
    "stars": "0",
    "details": {
      "title": "Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity",
      "abstract": "Kansa solver extension beyond linearity.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07970",
      "pdf_url": "https://arxiv.org/pdf/2602.07970",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07970",
      "scraped_at": "2026-02-11T02:32:15.151625"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design",
    "paper_url": "https://huggingface.co/papers/2602.07491",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design",
      "abstract": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucinations. To address this bottleneck, we introduce a multi-agent framework guided by large-scale knowledge graphs to find sustainable substitutes for per- and polyfluoroalkyl substances (PFAS)-chemicals currently under intense regulatory scrutiny. Agents in the framework specialize in problem decomposition, evidence retrieval, design parameter extraction, and graph traversal, uncovering latent connections across distinct knowledge pockets to support hypothesis generation. Ablation studies show that the full multi-agent pipeline outperforms single-shot prompting, underscoring the value of distributed specialization and relational reasoning. We demonstrate that by tailoring graph traversal strategies, the system alternates between exploitative searches focusing on domain-critical outcomes and exploratory searches surfacing emergent cross-connections. Illustrated through the exemplar of biomedical tubing, the framework generates sustainable PFAS-free alternatives that balance tribological performance, thermal stability, chemical resistance, and biocompatibility. This work establishes a framework combining knowledge graphs with multi-agent reasoning to expand the materials design space, showcasing several initial design candidates to demonstrate the approach.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07491",
      "pdf_url": "https://arxiv.org/pdf/2602.07491",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07491",
      "scraped_at": "2026-02-11T02:32:16.987590"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model",
    "paper_url": "https://huggingface.co/papers/2602.07120",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model",
      "abstract": "The memorization and reproduction of copyrighted text in LLMs is an issue that has potentially harmful repercussions for both data creators and AI developers. To this end, Anchored Decoding is a decoding technique for language models (LMs) that provably reduces the likelihood of generating copyrighted text. It requires two LMs: a safe model trained exclusively on permissively licensed data, and a risky model that is higher-utility and trained on mixed-licensed data. Anchored Decoding works for both token-level and byte-level decoding. To make this algorithm as practical as possible, we release (1) TinyLlama 1.8B , a safe base LM that is tokenizer-compatible with the Llama 3 model family, and (2) byte-level support to facilitate mixed-tokenizer decoding.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07120",
      "pdf_url": "https://arxiv.org/pdf/2602.07120",
      "github_links": [
        "https://github.com/jacqueline-he/anchored-decoding"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07120",
      "scraped_at": "2026-02-11T02:32:18.856042"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks",
    "paper_url": "https://huggingface.co/papers/2602.07090",
    "authors": [
      "Shou-De Lin",
      "Kuan-Yu Chen",
      "Hsiang Hsiao",
      "Yu-Che Tsai"
    ],
    "stars": "0",
    "details": {
      "title": "Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks",
      "abstract": "This work proposes a concept-aware privacy mechanism (SPARSE) to defend against embedding inversion attacks, selectively perturbing concept-sensitive dimensions while preserving downstream utility. Relevant to: embedding privacy, inversion attacks, representation learning, security & AI.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07090",
      "pdf_url": "https://arxiv.org/pdf/2602.07090",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07090",
      "scraped_at": "2026-02-11T02:32:20.745493"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs",
    "paper_url": "https://huggingface.co/papers/2602.07080",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs",
      "abstract": "Our code is available at: https://github.com/bruno686/CodeCircuit",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07080",
      "pdf_url": "https://arxiv.org/pdf/2602.07080",
      "github_links": [
        "https://github.com/bruno686/CodeCircuit"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07080",
      "scraped_at": "2026-02-11T02:32:22.633989"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs",
    "paper_url": "https://huggingface.co/papers/2602.05929",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "KV-CoRE: Benchmarking Data-Dependent Low-Rank Compressibility of KV-Caches in LLMs",
      "abstract": "KV-CoRE introduces a clean, data-dependent framework for measuring (not just applying) KV-cache compression in LLMs. By performing incremental SVD directly on cached key/value activations, the paper provides a principled, layer-wise view of low-rank structure across models, datasets, and languages. The proposed Normalized Effective Rank (NER) strongly correlates with perplexity and GPT-based quality under compression, making it a practical diagnostic for dynamic, data-aware KV-cache optimization and for analyzing representational under-utilization in multilingual and low-resource settings.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05929",
      "pdf_url": "https://arxiv.org/pdf/2602.05929",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05929",
      "scraped_at": "2026-02-11T02:32:24.502441"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration",
    "paper_url": "https://huggingface.co/papers/2602.05708",
    "authors": [
      "Paul Groth",
      "Sebastian Schelter",
      "Arijit Khan",
      "Zeyu Zhang",
      "Chuangtao Ma"
    ],
    "stars": "0",
    "details": {
      "title": "Cost-Efficient RAG for Entity Matching with LLMs: A Blocking-based Exploration",
      "abstract": "Can blocking help in LLM and RAG-based entity matching? Check out CE-RAG4EM, a Cost-Efficient RAG for Entity Matching that aims to reduce the cost of RAG4EM via blocking-based batch retrieval and inference.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05708",
      "pdf_url": "https://arxiv.org/pdf/2602.05708",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05708",
      "scraped_at": "2026-02-11T02:32:26.344530"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization",
    "paper_url": "https://huggingface.co/papers/2602.07054",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization",
      "abstract": "Check out this latest release from our lab at the Institute for Creative Technologies at the University of Southern California. The proposed method improves emotion reasoning in audiovisual multimodal (\"omni\") LLMs, surpassing the state-of-the-art models on multiple benchmarks. Moreover, the method achieves state-of-the-art results on various traditional emotion benchmarks under a zero-shot setting, eliciting the importance of reasoning even for emotion perception. Project page: https://avere-iclr.github.io",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07054",
      "pdf_url": "https://arxiv.org/pdf/2602.07054",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07054",
      "scraped_at": "2026-02-11T02:32:28.196217"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
    "paper_url": "https://huggingface.co/papers/2602.07040",
    "authors": [
      "Emmett Bicker"
    ],
    "stars": "0",
    "details": {
      "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Learning to Discover at Test Time (2026) AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents (2026) Towards Execution-Grounded Automated AI Research (2026) Learning to Ideate for Machine Learning Engineering Agents (2026) FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems (2026) Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts (2026) EmboCoach-Bench: Benchmarking AI Agents on Developing Embodied Robots (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07040",
      "pdf_url": "https://arxiv.org/pdf/2602.07040",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07040",
      "scraped_at": "2026-02-11T02:32:29.984246"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.02827",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Col-Bandit: Zero-Shot Query-Time Pruning for Late-Interaction Retrieval",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02827",
      "pdf_url": "https://arxiv.org/pdf/2602.02827",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02827",
      "scraped_at": "2026-02-11T02:32:31.874053"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "CauScale: Neural Causal Discovery at Scale",
    "paper_url": "https://huggingface.co/papers/2602.08629",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "CauScale: Neural Causal Discovery at Scale",
      "abstract": "We introduce CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08629",
      "pdf_url": "https://arxiv.org/pdf/2602.08629",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08629",
      "scraped_at": "2026-02-11T02:32:33.712873"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality",
    "paper_url": "https://huggingface.co/papers/2602.08004",
    "authors": [
      "Richard Huang",
      "Shanshan Zhong",
      "George Ling"
    ],
    "stars": "0",
    "details": {
      "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality",
      "abstract": "Understand Agent Skills at a Glance: The Ecosystem, Opportunities, and Risks Behind 40,000+ Claude Skills From patterns of explosive growth and a comprehensive, multi-dimensional functional taxonomy to multi-tier security audits, this data-driven study offers a clear picture of the Agent Skills community ecosystem and its current state of development. It provides quantitative insights for technical implementation, platform building, and applied research, while also giving newcomers a clear, realistic understanding of the field as a whole.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08004",
      "pdf_url": "https://arxiv.org/pdf/2602.08004",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08004",
      "scraped_at": "2026-02-11T02:32:35.623097"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "dewi-kadita: A Python Library for Idealized Fish Schooling Simulation with Entropy-Based Diagnostics",
    "paper_url": "https://huggingface.co/papers/2602.07948",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "dewi-kadita: A Python Library for Idealized Fish Schooling Simulation with Entropy-Based Diagnostics",
      "abstract": "Simulating collective animal behavior requires robust tools to capture emergent complexity. This paper introduces dewi-kadita, an open-source Python library that implements the three-dimensional Couzin model for fish schooling. Unlike traditional tools that rely solely on polarization and rotation order parameters, this library introduces a suite of seven entropy-based metrics combined into a single Oceanic Schooling Index (OSI) to rigorously quantify collective disorder and differentiate between complex states like milling tori and dynamic parallel groups.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07948",
      "pdf_url": "https://arxiv.org/pdf/2602.07948",
      "github_links": [
        "https://github.com/sandyherho/dewi-kadita"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07948",
      "scraped_at": "2026-02-11T02:32:37.464942"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Reasoning-Augmented Representations for Multimodal Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.07125",
    "authors": [
      "Sukanta Ganguly",
      "Soochahn Lee",
      "Brandon Han",
      "Anirudh Sundara Rajan",
      "Jianrui Zhang"
    ],
    "stars": "0",
    "details": {
      "title": "Reasoning-Augmented Representations for Multimodal Retrieval",
      "abstract": "Universal Multimodal Retrieval (UMR) seeks any-to-any search across text and vision, yet modern embedding models remain brittle when queries require latent reasoning (e.g., resolving underspecified references or matching compositional constraints). We argue this brittleness is often data-induced: when images carry \"silent\" evidence and queries leave key semantics implicit, a single embedding pass must both reason and compress, encouraging spurious feature matching. We propose a data-centric framework that decouples these roles by externalizing reasoning before retrieval. Using a strong Vision--Language Model, we make implicit semantics explicit by densely captioning visual evidence in corpus entries, resolving ambiguous multimodal references in queries, and rewriting verbose instructions into concise retrieval constraints. Inference-time enhancement alone is insufficient; the retriever must be trained on these semantically dense representations to avoid distribution shift and fully exploit the added signal. Across M-BEIR, our reasoning-augmented training method yields consistent gains over strong baselines, with ablations showing that corpus enhancement chiefly benefits knowledge-intensive queries while query enhancement is critical for compositional modification requests.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07125",
      "pdf_url": "https://arxiv.org/pdf/2602.07125",
      "github_links": [
        "https://github.com/AugmentedRetrieval/ReasoningAugmentedRetrieval"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07125",
      "scraped_at": "2026-02-11T02:32:39.340644"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "f-GRPO and Beyond: Divergence-Based Reinforcement Learning Algorithms for General LLM Alignment",
    "paper_url": "https://huggingface.co/papers/2602.05946",
    "authors": [
      "Qifan Song",
      "Yue Xing",
      "Guang Lin",
      "Lantao Mei",
      "Rajdeep Haldar"
    ],
    "stars": "0",
    "details": {
      "title": "f-GRPO and Beyond: Divergence-Based Reinforcement Learning Algorithms for General LLM Alignment",
      "abstract": "Recent research shows that Preference Alignment (PA) objectives act as divergence estimators be- tween aligned (chosen) and unaligned (rejected) response distributions. In this work, we extend this divergence-based perspective to general align- ment settings, such as reinforcement learning with verifiable rewards (RLVR), where only environ- mental rewards are available. Within this unified framework, we propose f-Group Relative Policy Optimization (f-GRPO), a class of on-policy re- inforcement learning, and f-Hybrid Alignment Loss (f-HAL), a hybrid on/off policy objectives, for general LLM alignment based on variational representation of f-divergences. We provide the- oretical guarantees that these classes of objec- tives improve the average reward after alignment. Empirically, we validate our framework on both RLVR (Math Reasoning) and PA tasks (Safety Alignment), demonstrating superior performance and flexibility compared to current methods.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05946",
      "pdf_url": "https://arxiv.org/pdf/2602.05946",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05946",
      "scraped_at": "2026-02-11T02:32:41.214026"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "Statistical Learning Theory in Lean 4: Empirical Processes from Scratch",
    "paper_url": "https://huggingface.co/papers/2602.02285",
    "authors": [
      "Fanghui Liu",
      "Jason D. Lee",
      "liminho123"
    ],
    "stars": "29",
    "details": {
      "title": "Statistical Learning Theory in Lean 4: Empirical Processes from Scratch",
      "abstract": "We present the first comprehensive Lean 4 formalization of statistical learning theory (SLT) grounded in empirical process theory. Our end-to-end formal infrastructure implement the missing contents in latest Lean library, including a complete development of Gaussian Lipschitz concentration, the first formalization of Dudley‚Äôs entropy integral theorem for sub-Gaussian processes, and an application to least-squares regression with a sharp rate. The project was carried out using a human‚ÄìAI collaborative workflow, in which humans design proof strategies and AI agents execute tactical proof construction, resulting in approximately 30,000 lines of human-verified Lean 4 code produced over 500 hours of supervised development. Beyond implementation, the formalization process exposes and resolves implicit assumptions and missing details in standard SLT textbooks, enforcing a granular, line-by-line understanding of the theory. This work establishes a reusable formal foundation for future developments in machine learning theory. The code is available at https://github.com/YuanheZ/lean-stat-learning-theory",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02285",
      "pdf_url": "https://arxiv.org/pdf/2602.02285",
      "github_links": [
        "https://github.com/YuanheZ/lean-stat-learning-theory"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02285",
      "scraped_at": "2026-02-11T02:32:43.021279"
    },
    "scraped_date": "2026-02-11"
  },
  {
    "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration",
    "paper_url": "https://huggingface.co/papers/2602.05400",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "OPUS: Towards Efficient and Principled Data Selection in Large Language Model Pre-training in Every Iteration",
      "abstract": "In this paper, we argue that LLM pre-training is entering a ‚Äúdata-wall‚Äù regime where readily available high-quality public text is approaching exhaustion, so progress must shift from more tokens to better tokens chosen at the right time. While most existing pipelines either (i) apply static, training-agnostic quality filters or (ii) use dynamic selection criteria defined in raw gradient space, modern LLMs are actually trained with adaptive optimizers like AdamW or Muon whose preconditioning reshapes the effective update direction‚Äîcreating a fundamental mismatch between ‚Äúhow we score data‚Äù and ‚Äúhow training truly updates the model.‚Äù To bridge this gap, we introduce OPUS (Optimizer-induced Projected Utility Selection), a dynamic selection framework that defines data utility directly in the optimizer-induced update space: a sample is valuable insofar as its optimizer-shaped effective update aligns with the descent direction of a stable, high-quality target distribution (our proxy). Concretely, OPUS operationalizes this idea through a principled objective, a scalable estimator, and a diversity-preserving selection rule. Our key contributions are: (1) an optimizer-aware utility for dynamic selection, with closed-form approximations for effective update directions under AdamW and Muon, aligning scoring with real training geometry; (2) BENCH-PROXY, an in-distribution proxy construction method that retrieves benchmark-aligned samples from the pre-training corpus to stabilize the target direction; (3) scalable utility estimation using the Ghost technique + CountSketch projections to avoid per-sample gradient materialization; and (4) Boltzmann sampling with redundancy control to prevent diversity collapse under non-stationary streams. Empirically, OPUS delivers strong data/compute efficiency: it reports only ~4.7% additional compute overhead for selection while achieving large gains across datasets, optimizers, and scales‚Äîincluding improved accuracy (+2.2% average over 10 benchmarks and 8√ó compute reduction in one highlighted setting), outperforming industrial static/dynamic baselines and even matching or exceeding much longer-token training in several regimes.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05400",
      "pdf_url": "https://arxiv.org/pdf/2602.05400",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05400",
      "scraped_at": "2026-02-12T02:25:40.510960"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Code2World: A GUI World Model via Renderable Code Generation",
    "paper_url": "https://huggingface.co/papers/2602.09856",
    "authors": [],
    "stars": "131",
    "details": {
      "title": "Code2World: A GUI World Model via Renderable Code Generation",
      "abstract": "Project Page: https://amap-ml.github.io/Code2World/ Github: https://github.com/AMAP-ML/Code2World",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09856",
      "pdf_url": "https://arxiv.org/pdf/2602.09856",
      "github_links": [
        "https://github.com/AMAP-ML/Code2World"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09856",
      "scraped_at": "2026-02-12T02:25:42.415565"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "UI-Venus-1.5 Technical Report",
    "paper_url": "https://huggingface.co/papers/2602.09082",
    "authors": [],
    "stars": "708",
    "details": {
      "title": "UI-Venus-1.5 Technical Report",
      "abstract": "Is your GUI Agent ready for real work? üî• We‚Äôve seen many great previous GUI Agents, but making a \"stable assistant\" for phones and websites is still hard. There are three main problems: 1Ô∏è‚É£ Knowledge Gap: AI often misses less common icons and doesn't know how specialized apps work. 2Ô∏è‚É£ The Reality Gap: Models that work well in tests often fail during real-life tasks. 3Ô∏è‚É£ Too Complex: Using multi-agent framework usually costs too much. Enter UI-Venus-1.5 üöÄ ‚Äî The new high-performance, end-to-end GUI Agent from Ant Group! Unlike old ways, UI-Venus-1.5 is built for real-world use: üì± All-in-One: One single model for Grounding, Mobile, and Web tasks. üá®üá≥ Real App Support: Full support for 40+ popular Chinese apps, making AI part of daily life. ‚ö° Simple & Fast: A clean, end-to-end design for faster and more reliable work. Check it out and see how AI can truly help you! üêú‚ú®",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09082",
      "pdf_url": "https://arxiv.org/pdf/2602.09082",
      "github_links": [
        "https://github.com/inclusionAI/UI-Venus/blob/UI-Venus-1.5",
        "https://github.com/inclusionAI/UI-Venus"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09082",
      "scraped_at": "2026-02-12T02:25:44.379581"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes",
    "paper_url": "https://huggingface.co/papers/2602.10063",
    "authors": [],
    "stars": "18",
    "details": {
      "title": "Chain of Mindset: Reasoning with Adaptive Cognitive Modes",
      "abstract": "CoM is a training-free agentic framework that dynamically orchestrates four step-level mindsets (Spatial, Convergent, Divergent, Algorithmic) via a Meta-Agent and a Context Gate, avoiding one-size-fits-all reasoning and improving accuracy and efficiency across diverse benchmarks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10063",
      "pdf_url": "https://arxiv.org/pdf/2602.10063",
      "github_links": [
        "https://github.com/QuantaAlpha/chain-of-mindset"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10063",
      "scraped_at": "2026-02-12T02:25:46.267996"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.08234",
    "authors": [],
    "stars": "140",
    "details": {
      "title": "SkillRL: Evolving Agents via Recursive Skill-Augmented Reinforcement Learning",
      "abstract": "Skill accumulation is the new paradigm for AI agents. We‚Äôre moving from static models to recursive evolution üß¨. SkillRL proves skills > scale, enabling a 7B model to beat GPT-4o üöÄ. Evolving > Scaling. üí° Paper: https://arxiv.org/abs/2602.08234 Code: https://github.com/aiming-lab/SkillRL",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08234",
      "pdf_url": "https://arxiv.org/pdf/2602.08234",
      "github_links": [
        "https://github.com/aiming-lab/SkillRL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08234",
      "scraped_at": "2026-02-12T02:25:48.127471"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads",
    "paper_url": "https://huggingface.co/papers/2602.09443",
    "authors": [],
    "stars": "13",
    "details": {
      "title": "P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads",
      "abstract": "Project: https://prime-rl.github.io/P1-VL GitHub: https://github.com/PRIME-RL/P1-VL",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09443",
      "pdf_url": "https://arxiv.org/pdf/2602.09443",
      "github_links": [
        "https://github.com/PRIME-RL/P1-VL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09443",
      "scraped_at": "2026-02-12T02:25:49.970770"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.10090",
    "authors": [],
    "stars": "44",
    "details": {
      "title": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning",
      "abstract": "Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning üöÄ Introducing Agent World Model (AWM) ‚Äî we synthesized 1,000 code-driven environments with 35K tools and 10K tasks for large-scale agentic reinforcement learning! No real APIs. No human design. Just 100 seed names ‚Üí fully functional, database-backed agent environments exposed via MCP interface. Agents trained purely on synthetic envs generalize to out-of-distribution benchmarks. Code, Environments, & Models all open-sourced. üî• We train Qwen3 (4B/8B/14B) with online RL using GRPO algorithm at serious scale: ‚ö° 1,024 parallel env instances per training step üéØ Hybrid reward: step-level format checks + task-level outcome verification üß† History-aware training: align sliding-window truncation between training & inference Key insight: code-driven environments give more stable learning signals than LLM-simulated ones, and they're orders of magnitude faster. Results on 3 out-of-distribution benchmarks (AWM does NOT target any benchmark specific ones): üìä BFCLv3 : 8B jumps 53.83 ‚Üí 65.94 (+12.11) üìä œÑ¬≤-bench : competitive, 14B reaches 39.03 Pass@1 üìä MCP-Universe : best overall, 8B: 6.70 ‚Üí 11.17 üèÜ AWM is the ONLY method that improves over Base on ALL three benchmarks. üìÑ Paper: https://arxiv.org/abs/2602.10090 üíª Code: https://github.com/Snowflake-Labs/agent-world-model ü§ó Huggingface: https://huggingface.co/datasets/Snowflake/AgentWorldModel-1K",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10090",
      "pdf_url": "https://arxiv.org/pdf/2602.10090",
      "github_links": [
        "https://github.com/Snowflake-Labs/agent-world-model"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10090",
      "scraped_at": "2026-02-12T02:25:51.927734"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Prism: Spectral-Aware Block-Sparse Attention",
    "paper_url": "https://huggingface.co/papers/2602.08426",
    "authors": [],
    "stars": "19",
    "details": {
      "title": "Prism: Spectral-Aware Block-Sparse Attention",
      "abstract": "TL;DR Prism is a training-free method to accelerate long-context LLM pre-filling. It addresses the \"blind spot\" in standard mean pooling caused by Rotary Positional Embeddings (RoPE) by disentangling attention into high-frequency and low-frequency bands. Key Features: Dual-Band Importance Estimation: Separates semantic (low-freq) and positional (high-freq) signals. Energy-Based Calibration: Restores attenuated signals automatically. Speed: Up to 5.1√ó speedup on 128K context with negligible accuracy loss. Implementation: Purely block-level ops with custom kernels for efficient estimation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08426",
      "pdf_url": "https://arxiv.org/pdf/2602.08426",
      "github_links": [
        "https://github.com/xinghaow99/prism"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08426",
      "scraped_at": "2026-02-12T02:25:53.794945"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
    "paper_url": "https://huggingface.co/papers/2602.07035",
    "authors": [],
    "stars": "10",
    "details": {
      "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
      "abstract": "üß†üîç DLLM-Searcher: Adapting Diffusion Large Language Models for Search Agents Diffusion Large Language Models (dLLMs) offer flexible generation but struggle as search agents due to latency and weak tool-use capabilities.  This paper introduces DLLM-Searcher , a framework that adapts dLLMs for efficient, agentic search and retrieval . üöÄ Key ideas: Parallel-Reasoning and Acting (P-ReAct): Enables parallel reasoning and tool execution using diffusion‚Äôs non-autoregressive generation, significantly reducing inference latency. Agent-oriented post-training: A two-stage pipeline with Agentic Supervised Fine-Tuning (SFT) + Agentic Variance-Reduced Preference Optimization (VRPO) improves reasoning structure, tool calling, and search reliability. üìä Results: Competitive performance with strong autoregressive LLM-based search agents on multi-hop retrieval tasks Up to ~15% speedup in end-to-end inference with P-ReAct üí° Why it matters: DLLM-Searcher shows that diffusion LLMs can be practical and efficient search agents , opening a new direction for low-latency, agentic information retrieval systems.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07035",
      "pdf_url": "https://arxiv.org/pdf/2602.07035",
      "github_links": [
        "https://github.com/bubble65/DLLM-Searcher"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07035",
      "scraped_at": "2026-02-12T02:25:55.679529"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Olaf-World: Orienting Latent Actions for Video World Modeling",
    "paper_url": "https://huggingface.co/papers/2602.10104",
    "authors": [
      "Mike Zheng Shou",
      "Ivor W. Tsang",
      "Yuchao Gu",
      "YuxinJ"
    ],
    "stars": "33",
    "details": {
      "title": "Olaf-World: Orienting Latent Actions for Video World Modeling",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10104",
      "pdf_url": "https://arxiv.org/pdf/2602.10104",
      "github_links": [
        "https://github.com/showlab/Olaf-World"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10104",
      "scraped_at": "2026-02-12T02:25:57.581027"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling",
    "paper_url": "https://huggingface.co/papers/2602.09084",
    "authors": [],
    "stars": "24",
    "details": {
      "title": "Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling",
      "abstract": "Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09084",
      "pdf_url": "https://arxiv.org/pdf/2602.09084",
      "github_links": [
        "https://github.com/taco-group/agent-banana"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09084",
      "scraped_at": "2026-02-12T02:25:59.462924"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Condition Errors Refinement in Autoregressive Image Generation with Diffusion Loss",
    "paper_url": "https://huggingface.co/papers/2602.07022",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Condition Errors Refinement in Autoregressive Image Generation with Diffusion Loss",
      "abstract": "This study presents a theoretical analysis of autoregressive image generation with diffusion loss, demonstrating that patch denoising optimization effectively mitigates condition errors and leads to a stable condition distribution. To further address condition inconsistency, we introduce a novel condition refinement approach based on Optimal Transport theory, which outperforms existing diffusion and autoregressive baselines in experiments.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07022",
      "pdf_url": "https://arxiv.org/pdf/2602.07022",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07022",
      "scraped_at": "2026-02-12T02:26:01.321545"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation",
    "paper_url": "https://huggingface.co/papers/2602.00268",
    "authors": [
      "Lior Wolf",
      "Amit Edenzon",
      "Eitan Shaar",
      "shaulov"
    ],
    "stars": "10",
    "details": {
      "title": "TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation",
      "abstract": "Project page: https://arielshaulov.github.io/TokenTrim/ Open source code ü•≥: https://github.com/arielshaulov/TokenTrim",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00268",
      "pdf_url": "https://arxiv.org/pdf/2602.00268",
      "github_links": [
        "https://github.com/arielshaulov/TokenTrim"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00268",
      "scraped_at": "2026-02-12T02:26:03.215276"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models",
    "paper_url": "https://huggingface.co/papers/2602.04208",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models",
      "abstract": "We tackle test-time robustness of VLA models without additional training or multiple forward passes, by proposing SCALE: jointly modulate visual attention and action decoding based on self-uncertainty.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04208",
      "pdf_url": "https://arxiv.org/pdf/2602.04208",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04208",
      "scraped_at": "2026-02-12T02:26:05.048492"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs",
    "paper_url": "https://huggingface.co/papers/2602.00462",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs",
      "abstract": "In this paper we propose a new interpretability method LatentLens. With this we can finally show that visual tokens are actually interpretable across all layers in an LLM, something that past methods like logit lens and or using the LLM's embedding matrix would not be able to do. Our key insight is to use a large pool of contextual embeddings from the LLM to find nearest neighbors instead of just using a static embedding or unembedding matrix: We empirically show how well LatentLens works in a controlled setting with 9 model combinations as well as an off-the-shelf VLM. We also notice that the Mid-Layer Leap phenomenon: visual tokens as they arrive at the LLM input are already most aligned to later semantic LLM layers! So for example a visual token arriving at layer 0 (coming from the vision encoder --> MLP), will have its closest nearest neighbors from e.g. layer 8 of the LLM. We hope this will spark new VLM interpretability research and even projects on other kinds of latent representations in LLM (soft prompts, speech, VLAs, ...)!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.00462",
      "pdf_url": "https://arxiv.org/pdf/2602.00462",
      "github_links": [
        "https://github.com/McGill-NLP/latentlens"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.00462",
      "scraped_at": "2026-02-12T02:26:06.924608"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation",
    "paper_url": "https://huggingface.co/papers/2602.09849",
    "authors": [
      "Xiaoyu Chen",
      "Yanjiang Guo",
      "Yuanfei Luo",
      "Jianke Zhang",
      "Yucheng Hu"
    ],
    "stars": "0",
    "details": {
      "title": "BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation",
      "abstract": "BagelVLA is a unified model that integrates linguistic planning, visual forecasting, and action generation within a single framework for long-horizon manipulation tasks. üß† Model Architecture BagelVLA utilizes a Mixture-of-Transformers (MoT) architecture, comprising three independent transformers specialized for linguistic, visual, and action modalities. To tackle long-horizon tasks and semantic generalization, we formulate language-conditioned action learning as a long-sequence interleaved planning problem. These modalities are structured into a unified sequence, enabling the model to generate predictions across all three modalities based on the interleaved context. To address the high latency in combining visual generation with control, we introduce Residual Flow Guidance (RFG). Instead of generating future frames from scratch, RFG conditions on the current observation as a strong structural prior and performs single-step denoising to predict the residual change toward the next keyframe. RFG provides a lightweight predictive visual representation that captures task-relevant dynamics with minimal overhead. This substantially reduces the computational cost of foresight while preserving its utility for action generation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09849",
      "pdf_url": "https://arxiv.org/pdf/2602.09849",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09849",
      "scraped_at": "2026-02-12T02:26:08.904233"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model",
    "paper_url": "https://huggingface.co/papers/2602.10098",
    "authors": [
      "Zezhi Liu",
      "Shaojie Ren",
      "Zekun Qi",
      "Wenyao Zhang",
      "Jingwen Sun"
    ],
    "stars": "12",
    "details": {
      "title": "VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos (2026) Robotic VLA Benefits from Joint Learning with Motion Image Diffusion (2025) ConLA: Contrastive Latent Action Learning from Human Videos for Robotic Manipulation (2026) Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models (2026) Motus: A Unified Latent Action World Model (2025) MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction (2026) Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10098",
      "pdf_url": "https://arxiv.org/pdf/2602.10098",
      "github_links": [
        "https://github.com/ginwind/VLA-JEPA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10098",
      "scraped_at": "2026-02-12T02:26:10.742477"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training",
    "paper_url": "https://huggingface.co/papers/2602.06820",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training",
      "abstract": "We introduce ScaleEnv, a framework that constructs fully interactive environments and verifiable tasks entirely from scratch. By enabling agents to learn through exploration within ScaleEnv, we demonstrate significant performance improvements on unseen, multi-turn tool-use benchmarks such as $\\tau^2$-Bench and VitaBench, highlighting strong generalization capabilities.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06820",
      "pdf_url": "https://arxiv.org/pdf/2602.06820",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06820",
      "scraped_at": "2026-02-12T02:26:12.604118"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Fine-T2I: An Open, Large-Scale, and Diverse Dataset for High-Quality T2I Fine-Tuning",
    "paper_url": "https://huggingface.co/papers/2602.09439",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Fine-T2I: An Open, Large-Scale, and Diverse Dataset for High-Quality T2I Fine-Tuning",
      "abstract": "Dataset: https://huggingface.co/datasets/ma-xu/fine-t2i Space: https://huggingface.co/spaces/ma-xu/fine-t2i-explore",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09439",
      "pdf_url": "https://arxiv.org/pdf/2602.09439",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09439",
      "scraped_at": "2026-02-12T02:26:14.471985"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models",
    "paper_url": "https://huggingface.co/papers/2602.09017",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models",
      "abstract": "The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), a new class of general robotic behavior models, which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement an efficient real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09017",
      "pdf_url": "https://arxiv.org/pdf/2602.09017",
      "github_links": [
        "https://github.com/jeffacce/cap-policy"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09017",
      "scraped_at": "2026-02-12T02:26:16.287103"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
    "paper_url": "https://huggingface.co/papers/2602.08847",
    "authors": [],
    "stars": "53",
    "details": {
      "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
      "abstract": "Dr. MAS is designed for stable end-to-end RL post-training üî• of multi-agent LLM systems. It enables agents to collaborate on complex reasoning tasks with: ‚ú® Flexible agent registry & multi-agent orchestration ‚ú® Heterogeneous LLMs (shared/non-shared) ‚ú® Co-training of multiple agents‚ú® Efficient resource pooling. In this work, we theoretically pinpoint a key reason for training instability when extending group-based RL to multi-agent LLM systems. We show that under GRPO-style optimization, a global normalization baseline may lead to gradient-norm instability. Based on this finding, Dr. MAS propose a simple yet effective remedy which calibrates gradient scales and dramatically stabilizes training.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08847",
      "pdf_url": "https://arxiv.org/pdf/2602.08847",
      "github_links": [
        "https://github.com/langfengQ/DrMAS"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08847",
      "scraped_at": "2026-02-12T02:26:18.155897"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments",
    "paper_url": "https://huggingface.co/papers/2602.01244",
    "authors": [
      "Yang Wang",
      "Wei Zhang",
      "Yuyang Song",
      "Yizhi Li",
      "Siwei Wu"
    ],
    "stars": "7",
    "details": {
      "title": "Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments",
      "abstract": "This is a repo for paper \"Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments\"",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01244",
      "pdf_url": "https://arxiv.org/pdf/2602.01244",
      "github_links": [
        "https://github.com/multimodal-art-projection/TerminalTraj"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01244",
      "scraped_at": "2026-02-12T02:26:19.996419"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "VideoWorld 2: Learning Transferable Knowledge from Real-world Videos",
    "paper_url": "https://huggingface.co/papers/2602.10102",
    "authors": [],
    "stars": "685",
    "details": {
      "title": "VideoWorld 2: Learning Transferable Knowledge from Real-world Videos",
      "abstract": "ü§ñText is not enough, Visual is the key to AGIÔºÅCan Al learn transferable knowledge for complex tasks directly from videos? Just like a child learns to fold a paper airplane or build a LEGO from video tutorialsüë∂ üòéThrilled to introduce VideoWorld 2, the successor of VideoWorld. Unlike Sora and Veo, it is the the first generative model that masters complex real-world knowledge solely through visual data, without any reliance on language models. üôã You might wonder: what knowledge remains out of reach for today‚Äôs AI?  Try asking Sora 2 or Veo 3 to fold a coherent paper boat, or have Gemini describe every micro-fold and material change in text.  Although any child can master this skill just by watching video tutorials, today's most advanced AI often fails at such tasks. üöÄTo address this challenge, we propose VideoWorld 2. Unlike models that rely on language priors, it is the first to master complex, long-horizon real-world knowledge solely by \"watching\" raw videos and  generalizing the skill to new environments. üßë‚Äçüè´ The \"Cambrian Moment\" for AI? As Dr. Feifei Li noted, vision-enabled perception and planning triggered the Cambrian Explosion 540 million years ago. VideoWorld 2 explores this frontier:  Without any textual descriptions, it completes minute-long handcraft tasks like paper folding and block-building, which involve fine-grained manipulation and long-horizon planning that current AI fails to learn. Furthermore, it can generalize these skills across various unseen scenes and perform multi-task, cross-environment robotic manipulation. Our main contributions are: üëâWe explore, for the first time, how to learn complex, long-range skills from raw videos and generalize them to new environments. We find that disentangling visual appearance from core dynamics is the key to mastering world knowledge. üëâWe propose VideoWorld 2, leveraging a dynamic-enhanced Latent Dynamic Model to extract task-relevant dynamics to boost long-horizon tasks success rates by up to 70% üëâWe construct Video-CraftBench, a large-scale video-based handcraft dataset for training and evaluation, facilitating future research on knowledge learning from pure videos.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10102",
      "pdf_url": "https://arxiv.org/pdf/2602.10102",
      "github_links": [
        "https://github.com/ByteDance-Seed/VideoWorld/tree/main/VideoWorld2"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10102",
      "scraped_at": "2026-02-12T02:26:21.880904"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
    "paper_url": "https://huggingface.co/papers/2602.07276",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
      "abstract": "Activation steering has emerged as a promising method for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering approaches identify and steer the model from a single static direction for each task or concept, which is inflexible under task variation and insufficient for complex tasks requiring multiple coordinated capabilities. To address this gap, we propose Steer2Adapt, a lightweight framework that enables efficient LLM adaptation by composing steering vectors rather than learning new ones from scratch. In practice, tasks within the same domain (e.g., reasoning or safety) often share a small set of underlying concept dimensions. Steer2Adapt spans these dimensions into a reusable, low-dimensional semantic prior subspace and adapts to new tasks by dynamically discovering a linear combination of basis vectors using only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of Steer2Adapt, with an average of 8.2% improvement. Together with our analyses, we establish Steer2Adapt as a data-efficient, stable, and transparent inference-time adaptation method for LLMs.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07276",
      "pdf_url": "https://arxiv.org/pdf/2602.07276",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07276",
      "scraped_at": "2026-02-12T02:26:23.707693"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.08382",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning",
      "abstract": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning. We introduce LycheeMemory, a cognitively inspired framework that enables efficient long-context inference via chunk-wise compression and selective memory recall, rather than processing all raw tokens. Code will be coming soon.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08382",
      "pdf_url": "https://arxiv.org/pdf/2602.08382",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08382",
      "scraped_at": "2026-02-12T02:26:25.537745"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Rethinking Global Text Conditioning in Diffusion Transformers",
    "paper_url": "https://huggingface.co/papers/2602.09268",
    "authors": [
      "Yuchen Liu",
      "Ilya Drobyshevskiy",
      "Zongze Wu",
      "Daniil Pakhomov",
      "Nikita Starodubcev"
    ],
    "stars": "13",
    "details": {
      "title": "Rethinking Global Text Conditioning in Diffusion Transformers",
      "abstract": "GitHub: https://github.com/quickjkee/modulation-guidance",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09268",
      "pdf_url": "https://arxiv.org/pdf/2602.09268",
      "github_links": [
        "https://github.com/quickjkee/modulation-guidance"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09268",
      "scraped_at": "2026-02-12T02:26:27.369867"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.09000",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
      "abstract": "Let's discuss Self-Feedback for RL Reasoning (iGRPO) Motivation. Current RL methods for reasoning (GRPO, DAPO, etc.) treat each generation as a one-shot attempt. The model samples, gets a reward, updates, and moves on. But humans almost never solve hard problems in one pass. We draft, re-read, spot mistakes, and refine. Existing RL pipelines don't capture this loop. Some recent methods try to close the gap with critique generation or self-verification, but these ask the model to learn auxiliary behaviors (writing critiques, producing verification rationales) that are only indirectly tied to the actual outcome reward. We wanted something simpler: what if the model's own best attempt is the feedback, and we just train it to beat that attempt? What we built. iGRPO is a two-stage extension of GRPO that adds self-conditioning through the model's own drafts. Stage 1 (Exploratory Draft Generation): Sample multiple candidate solutions from the current policy. Score them with the same scalar reward you're already using. Pick the best one. Stage 2 (Conditioned Refinement): Append that best draft to the original prompt and sample a new group of completions. Apply the standard GRPO-style clipped surrogate update only on these Stage 2 outputs. No critic networks, no reward models, no verification rationales, no generated critiques. The best draft is the only feedback signal, and it comes for free from Stage 1 exploration. The important part: as the policy improves across training, its Stage 1 drafts get stronger, so Stage 2 sees better conditioning, so the policy improves even more. We formally prove this monotonic improvement property under binary rewards: the expected quality of the selected draft increases as the policy's success probability increases. The model doesn't learn to copy the draft. It learns a refinement function that compounds across training. How it differs from critique/verification approaches. Methods like Self-Verification and Critique-GRPO require the model to produce extra text (verification steps, natural-language critiques) and then condition on that. This means the model has to allocate capacity to an auxiliary skill that isn't directly optimized by the outcome reward. iGRPO sidesteps this entirely. The conditioning signal is a full solution attempt scored by the same reward used for optimization. There's no ambiguity about what \"good feedback\" looks like, because it's literally the model's highest-reward output. Key results. Controlled comparisons (matched rollout budgets, same total completions per prompt): Nemotron-H-8B-Base-8K: iGRPO reaches 45.04% average vs. 41.08% for GRPO (+3.96), and beats Self-Verification (42.86%) and Critique-GRPO (43.39%). DeepSeek-R1-Distill-Qwen-7B: iGRPO at 69.87% vs. GRPO at 68.29%, with gains concentrated on multi-step benchmarks like AIME24 (56.30%) and AMC (95.00%). OpenMath-Nemotron-7B: Even with an already strong 74.83% base, iGRPO pushes to 76.07%. At 14B scale, gains persist: DeepSeek-R1-Distill-Qwen-14B goes from 71.29% (GRPO) to 73.02% (iGRPO); OpenMath-Nemotron-14B from 76.73% to 78.00%. Stronger base + harder data: OpenReasoning-Nemotron-7B trained on AceReason-Math with iGRPO achieves 85.62% on AIME24 and 79.64% on AIME25, with transfer gains on GPQA (+1.84) and MMLU-Pro (+0.91). The refinement wrapper generalizes beyond GRPO: Applying the same two-stage mechanism to DAPO and GSPO yields +1.19 and +1.11 average improvements respectively, under matched budgets. The gains come from the refinement interface, not GRPO-specific details. Richer rewards help: Swapping the binary outcome checker for a GPT-5 generative judge improves the average from 69.87% to 70.81% (+0.94), with the largest lifts on AIME24/25 and Minerva, consistent with partial credit keeping near-miss traces alive through Stage 1 selection. Learning dynamics: iGRPO delays premature entropy collapse. Both methods start at ~2.45 nats, but GRPO drops to 0.60 by 10% of training while iGRPO decays more gradually (0.80 at 15%). This sustained mid-training exploration lets the model recover from near-miss reasoning traces before converging. Overhead: Peak memory is essentially identical (~54.93 GB for both). Throughput drops from 0.41 to 0.34 samples/sec. Total training time increases by ~13% (83.3 ‚Üí 94.1 GPU hours). No extra GPUs, no extra memory. In short, iGRPO adds a self-feedback refinement loop to group-based RL that uses the model's own best draft as conditioning. It's simple, adds minimal overhead, generalizes across optimizers, and consistently improves reasoning across model families and scales.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09000",
      "pdf_url": "https://arxiv.org/pdf/2602.09000",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09000",
      "scraped_at": "2026-02-12T02:26:29.224257"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Covo-Audio Technical Report",
    "paper_url": "https://huggingface.co/papers/2602.09823",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Covo-Audio Technical Report",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Fun-Audio-Chat Technical Report (2025) FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning (2026) MiMo-Audio: Audio Language Models are Few-Shot Learners (2025) Qwen3-TTS Technical Report (2026) A$^2$-LLM: An End-to-end Conversational Audio Avatar Large Language Model (2026) VoiceSculptor: Your Voice, Designed By You (2026) Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09823",
      "pdf_url": "https://arxiv.org/pdf/2602.09823",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09823",
      "scraped_at": "2026-02-12T02:26:31.050544"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Effective Reasoning Chains Reduce Intrinsic Dimensionality",
    "paper_url": "https://huggingface.co/papers/2602.09276",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Effective Reasoning Chains Reduce Intrinsic Dimensionality",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09276",
      "pdf_url": "https://arxiv.org/pdf/2602.09276",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09276",
      "scraped_at": "2026-02-12T02:26:32.851581"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution",
    "paper_url": "https://huggingface.co/papers/2602.09662",
    "authors": [
      "Liming Zheng",
      "Lei Chen",
      "Xuanle Zhao",
      "Jing Huang",
      "Deyang Jiang"
    ],
    "stars": "0",
    "details": {
      "title": "TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution",
      "abstract": "TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09662",
      "pdf_url": "https://arxiv.org/pdf/2602.09662",
      "github_links": [
        "https://github.com/UITron-hub/TreeCUA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09662",
      "scraped_at": "2026-02-12T02:26:34.662675"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
    "paper_url": "https://huggingface.co/papers/2602.07153",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
      "abstract": "End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify branch points that correspond to meaningful state changes and propose new, state-grounded task variants conditioned on the current GUI context. An executing agent then follows the proposed instructions to generate new trajectories, while a verifier enforces task completion via state-aware checks and trajectory-level consistency. To improve supervision quality, we further apply task-conditioned step-level filtering to remove ungrounded actions and denoise post-branch segments to maintain coherent intent. Experiments on standard desktop benchmarks, OSWorld and WindowsAgentArena, show that models fine-tuned on our expanded corpus achieve consistent improvements over zero-shot agents and representative synthesis baselines, and generalize across applications and operating systems.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07153",
      "pdf_url": "https://arxiv.org/pdf/2602.07153",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07153",
      "scraped_at": "2026-02-12T02:26:36.538313"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SAGE: Scalable Agentic 3D Scene Generation for Embodied AI",
    "paper_url": "https://huggingface.co/papers/2602.10116",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "SAGE: Scalable Agentic 3D Scene Generation for Embodied AI",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10116",
      "pdf_url": "https://arxiv.org/pdf/2602.10116",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10116",
      "scraped_at": "2026-02-12T02:26:38.404431"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Autoregressive Image Generation with Masked Bit Modeling",
    "paper_url": "https://huggingface.co/papers/2602.09024",
    "authors": [],
    "stars": "23",
    "details": {
      "title": "Autoregressive Image Generation with Masked Bit Modeling",
      "abstract": "SOTA discrete visual generation defeats diffusion models with 0.99 FID score, project page is available at https://bar-gen.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09024",
      "pdf_url": "https://arxiv.org/pdf/2602.09024",
      "github_links": [
        "https://github.com/amazon-far/BAR"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09024",
      "scraped_at": "2026-02-12T02:26:40.227063"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration",
    "paper_url": "https://huggingface.co/papers/2602.08344",
    "authors": [
      "Jianfei Zhang",
      "Xiangyu Xi",
      "Jianing Wang",
      "Qi Guo",
      "DeyangKong"
    ],
    "stars": "0",
    "details": {
      "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration",
      "abstract": "Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage. In this paper, we theoretically analyze the optimization of parallel thinking under the Reinforcement Learning with Verifiable Rewards (RLVR) setting, and identify that the mutual information bottleneck among exploration paths fundamentally restricts overall performance. To address this, we propose Outline-Guided Path Exploration (OPE) , which explicitly partitions the solution space by generating diverse reasoning outlines prior to parallel path reasoning, thereby reducing information redundancy and improving the diversity of information captured across exploration paths. We implement OPE with an iterative RL strategy that optimizes outline planning and outline-guided reasoning independently. Extensive experiments across multiple challenging mathematical benchmarks demonstrate that OPE effectively improves reasoning performance in different aggregation strategies, enabling LRMs to more reliably discover correct solutions.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08344",
      "pdf_url": "https://arxiv.org/pdf/2602.08344",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08344",
      "scraped_at": "2026-02-12T02:26:42.013100"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "TodoEvolve: Learning to Architect Agent Planning Systems",
    "paper_url": "https://huggingface.co/papers/2602.07839",
    "authors": [
      "Heng Chang",
      "Zihan Zhang",
      "Guibin Zhang",
      "Yanzuo Jiang",
      "Jiaxi Liu"
    ],
    "stars": "6",
    "details": {
      "title": "TodoEvolve: Learning to Architect Agent Planning Systems",
      "abstract": "Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \\textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07839",
      "pdf_url": "https://arxiv.org/pdf/2602.07839",
      "github_links": [
        "https://github.com/EcthelionLiu/TodoEvolve"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07839",
      "scraped_at": "2026-02-12T02:26:43.792166"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model",
    "paper_url": "https://huggingface.co/papers/2602.07422",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model",
      "abstract": "Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality‚Äìsecurity paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionalitypreserving secure code generation. SecCoderX first bridges vulnerability detection and secure code generation by repurposing mature detection resources in two ways: (i) synthesizing diverse, reality grounded vulnerability-inducing coding tasks for online RL rollouts, and (ii) training a reasoning based vulnerability reward model that provides scalable and reliable security supervision. Together, these components are unified in an online RL loop to align code LLMs to generate secure and functional code. Extensive experiments demonstrate that SecCoderX achieves state-of-the-art performance, improving Effective Safety Rate (ESR) by approximately 10% over unaligned models, whereas prior methods often degrade ESR by 14-54%. We release our code, dataset and model checkpoints at https://github.com/AndrewWTY/SecCoderX .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07422",
      "pdf_url": "https://arxiv.org/pdf/2602.07422",
      "github_links": [
        "https://github.com/AndrewWTY/SecCoderX"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07422",
      "scraped_at": "2026-02-12T02:26:45.613840"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding",
    "paper_url": "https://huggingface.co/papers/2602.06161",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding",
      "abstract": "We found a silly failure mode in Parallel Revocable Diffusion Decoding: flip-flop . A token gets ReMask‚Äôed‚Ä¶ then comes back unchanged. In the existing approach, <1% of ReMasks actually change the token (‚âà99% wasted). We propose COVER which verifies without nuking context: mask seeds for leave-one-out, but inject their cached K,V for everyone else. A simple diagonal correction removes self-leakage. Result: fewer useless revisions + faster parallel drafting.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06161",
      "pdf_url": "https://arxiv.org/pdf/2602.06161",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06161",
      "scraped_at": "2026-02-12T02:26:47.459271"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Stable Velocity: A Variance Perspective on Flow Matching",
    "paper_url": "https://huggingface.co/papers/2602.05435",
    "authors": [
      "Xin Tao",
      "Liang Hou",
      "Xin Yu",
      "Yongxing Zhang",
      "Donglin Yang"
    ],
    "stars": "14",
    "details": {
      "title": "Stable Velocity: A Variance Perspective on Flow Matching",
      "abstract": "While flow matching is elegant, its reliance on single-sample conditional velocities leads to high-variance training targets that destabilize optimization and slow convergence. By explicitly characterizing this variance, we identify 1) a high-variance regime near the prior, where optimization is challenging, and 2) a low-variance regime near the data distribution, where conditional and marginal velocities nearly coincide. Leveraging this insight, we propose Stable Velocity , a unified framework that improves both training and sampling. For training, we introduce Stable Velocity Matching (StableVM), an unbiased variance-reduction objective, along with Variance-Aware Representation Alignment (VA-REPA), which adaptively strengthen auxiliary supervision in the low-variance regime. For inference, we show that dynamics in the low-variance regime admit closed-form simplifications, enabling Stable Velocity Sampling (StableVS), a finetuning-free acceleration. Extensive experiments on ImageNet $256\\times256$ and large pretrained text-to-image and text-to-video models, including SD3.5, Flux, Qwen-Image, and Wan2.2, demonstrate consistent improvements in training efficiency and more than $2\\times$ faster sampling within the low-variance regime without degrading sample quality.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05435",
      "pdf_url": "https://arxiv.org/pdf/2602.05435",
      "github_links": [
        "https://github.com/linYDTHU/StableVelocity"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05435",
      "scraped_at": "2026-02-12T02:26:49.366527"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry",
    "paper_url": "https://huggingface.co/papers/2602.02464",
    "authors": [
      "Atticus Geiger",
      "Shauli Ravfogel",
      "Omri Fahn",
      "Shaked Ronen",
      "Or Shafran"
    ],
    "stars": "12",
    "details": {
      "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry",
      "abstract": "Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02464",
      "pdf_url": "https://arxiv.org/pdf/2602.02464",
      "github_links": [
        "https://github.com/ordavid-s/decomposing-activations-local-geometry"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02464",
      "scraped_at": "2026-02-12T02:26:51.286831"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "On the Optimal Reasoning Length for RL-Trained Language Models",
    "paper_url": "https://huggingface.co/papers/2602.09591",
    "authors": [
      "Rio Yokota",
      "Taishi-N324",
      "neodymium6"
    ],
    "stars": "0",
    "details": {
      "title": "On the Optimal Reasoning Length for RL-Trained Language Models",
      "abstract": "RL-trained reasoning models often produce longer CoT, increasing test-time cost. We compare several length-control methods on Qwen3-1.7B-Base and DeepSeek-R1-Distill-Qwen-1.5B, and characterize when length penalties hurt reasoning acquisition vs when tuned control improves efficiency. We also highlight two failure modes: overly long outputs increase dispersion, while overly short outputs cause under-thinking.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09591",
      "pdf_url": "https://arxiv.org/pdf/2602.09591",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09591",
      "scraped_at": "2026-02-12T02:26:53.188546"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Learning Self-Correction in Vision-Language Models via Rollout Augmentation",
    "paper_url": "https://huggingface.co/papers/2602.08503",
    "authors": [
      "Ruqi Zhang",
      "Bolian Li",
      "Ziliang Qiu",
      "Yi Ding"
    ],
    "stars": "0",
    "details": {
      "title": "Learning Self-Correction in Vision-Language Models via Rollout Augmentation",
      "abstract": "Learning self-correction in Vision-language models via rollout augmentation",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08503",
      "pdf_url": "https://arxiv.org/pdf/2602.08503",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08503",
      "scraped_at": "2026-02-12T02:26:55.028721"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs",
    "paper_url": "https://huggingface.co/papers/2602.07755",
    "authors": [
      "Jeff Clune",
      "Shengran Hu",
      "Yiming Xiong"
    ],
    "stars": "39",
    "details": {
      "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs",
      "abstract": "Can AI agents design better memory mechanisms for themselves? Introducing Learning to Continually Learn via Meta-learning Memory Designs. A meta agent automatically designs memory mechanisms, including what info to store, how to retrieve it, and how to update it, enabling agentic systems to continually learn across diverse domains.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07755",
      "pdf_url": "https://arxiv.org/pdf/2602.07755",
      "github_links": [
        "https://github.com/zksha/alma"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07755",
      "scraped_at": "2026-02-12T02:26:56.864017"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "ContextBench: A Benchmark for Context Retrieval in Coding Agents",
    "paper_url": "https://huggingface.co/papers/2602.05892",
    "authors": [
      "Jiaming Wang",
      "Rili Feng",
      "Bohan Zhang",
      "Letian Zhu",
      "Han Li"
    ],
    "stars": "4",
    "details": {
      "title": "ContextBench: A Benchmark for Context Retrieval in Coding Agents",
      "abstract": "Most repo-level benchmarks measure Pass@k ‚úÖ But fixing a bug does not mean the agent understood the code üëÄ We built ContextBench üéâ A benchmark to measure whether coding agents actually retrieve and use the right context üîçüìÇ üìä What‚Äôs inside üß© 1,136 real-world issues üìÅ 66 repositories üåç 8 programming languages üß† Expert-verified gold contexts at file, block, and line granularity üë£ Full trajectory tracking of agent behavior üìà Metrics: Recall, Precision, F1, Efficiency, Usage Drop üîç What surprised us 1Ô∏è‚É£ Complex agentic scaffolds often do not improve retrieval quality üòÖ Instead, they introduce over-engineering. A familiar pattern in AI research‚Ä¶ the Bitter Lesson again üçã 2Ô∏è‚É£ Many SOTA LLMs chase high recall but sacrifice precision üìâ More context retrieved, more noise introduced 3Ô∏è‚É£ Retrieved ‚â† Utilized ‚ùó Agents frequently inspect the right code but fail to incorporate it 4Ô∏è‚É£ More balanced retrieval strategies achieve stronger Pass@1 at lower cost ‚öñÔ∏è‚ú®",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05892",
      "pdf_url": "https://arxiv.org/pdf/2602.05892",
      "github_links": [
        "https://github.com/EuniAI/ContextBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05892",
      "scraped_at": "2026-02-12T02:26:58.643631"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories",
    "paper_url": "https://huggingface.co/papers/2602.05085",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories",
      "abstract": "We introduce Locas, a parametric memory for parameter-efficient Test-Time Training (TTT) and continual learning. Unlike previous methods that only introduce in-place low-rank model updates (such as LoRA) that do not provide expanded capacity or requiring modified pretraining/meta-learning, Locas is a plug-and-play module that has perfect compatibility with existing tech stacks while achieving fast convergence, good generalization and compute/param efficiency, through initializing itself from the backbone model's activations, parameters and/or gradients.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.05085",
      "pdf_url": "https://arxiv.org/pdf/2602.05085",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.05085",
      "scraped_at": "2026-02-12T02:27:00.436675"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders",
    "paper_url": "https://huggingface.co/papers/2602.10099",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders",
      "abstract": "Leveraging representation encoders for generative modeling offers a path for efficient, high-fidelity synthesis. However, standard diffusion transformers fail to converge on these representations directly. While recent work attributes this to a capacity bottleneck proposing computationally expensive width scaling of diffusion transformers we demonstrate that the failure is fundamentally geometric. We identify Geometric Interference as the root cause: standard Euclidean flow matching forces probability paths through the low-density interior of the hyperspherical feature space of representation encoders, rather than following the manifold surface. To resolve this, we propose Riemannian Flow Matching with Jacobi Regularization (RJF). By constraining the generative process to the manifold geodesics and correcting for curvature-induced error propagation, RJF enables standard Diffusion Transformer architectures to converge without width scaling. Our method RJF enables the standard DiT-B architecture (131M parameters) to converge effectively, achieving an FID of 3.37 where prior methods fail to converge.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10099",
      "pdf_url": "https://arxiv.org/pdf/2602.10099",
      "github_links": [
        "https://github.com/amandpkr/RJF"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10099",
      "scraped_at": "2026-02-12T02:27:02.230260"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "LLMs Encode Their Failures: Predicting Success from Pre-Generation Activations",
    "paper_url": "https://huggingface.co/papers/2602.09924",
    "authors": [
      "Chris Russell",
      "William Bankes",
      "Thomas Foster",
      "William Lugoloobi"
    ],
    "stars": "0",
    "details": {
      "title": "LLMs Encode Their Failures: Predicting Success from Pre-Generation Activations",
      "abstract": "We show that LLMs maintain a linearly accessible internal representation of difficulty that differs from human assessments and varies across decoding settings. We apply this to route queries between models with different reasoning capabilities. Github: https://github.com/KabakaWilliam/llms_know_difficulty",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09924",
      "pdf_url": "https://arxiv.org/pdf/2602.09924",
      "github_links": [
        "https://github.com/KabakaWilliam/llms_know_difficulty"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09924",
      "scraped_at": "2026-02-12T02:27:04.045053"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering",
    "paper_url": "https://huggingface.co/papers/2602.08519",
    "authors": [],
    "stars": "21",
    "details": {
      "title": "Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering",
      "abstract": "PyAGC is a production-ready, modular library and comprehensive benchmark for Attributed Graph Clustering (AGC), built on PyTorch and PyTorch Geometric. It unifies 20+ state-of-the-art algorithms under a principled Encode-Cluster-Optimize (ECO) framework, provides mini-batch implementations that scale to 111 million nodes on a single 32GB GPU, and introduces a holistic evaluation protocol spanning supervised, unsupervised, and efficiency metrics across 12 diverse datasets.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08519",
      "pdf_url": "https://arxiv.org/pdf/2602.08519",
      "github_links": [
        "https://github.com/Cloudy1225/PyAGC"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08519",
      "scraped_at": "2026-02-12T02:27:05.867653"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "MIND: Benchmarking Memory Consistency and Action Control in World Models",
    "paper_url": "https://huggingface.co/papers/2602.08025",
    "authors": [],
    "stars": "22",
    "details": {
      "title": "MIND: Benchmarking Memory Consistency and Action Control in World Models",
      "abstract": "TL;DR: The first open-domain closed-loop revisited benchmark for evaluating memory consistency and action control in world models",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08025",
      "pdf_url": "https://arxiv.org/pdf/2602.08025",
      "github_links": [
        "https://github.com/CSU-JPG/MIND"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08025",
      "scraped_at": "2026-02-12T02:27:07.740064"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution",
    "paper_url": "https://huggingface.co/papers/2602.07918",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution",
      "abstract": "I'm excited to share our latest work to defend Prompt Injection: \"CausalArmor: Efficient Indirect Prompt Injection Guardrails via Causal Attribution\". CausalArmor, a selective defense: üß† Causal attribution at privileged actions: measure whether the action is driven by the user request vs. each untrusted span. üéØ Intervene only on dominance shift: if an untrusted span dominates, sanitize just that span and re-generate‚Äîno always-on heavy filtering. ‚ö° Practical outcome: strong protection without affecting the benign interactions. Results: Near-zero attack success while keeping benign utility and latency close to ‚ÄúNo Defense‚Äù on prompt injection benchmarks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07918",
      "pdf_url": "https://arxiv.org/pdf/2602.07918",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07918",
      "scraped_at": "2026-02-12T02:27:09.488019"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation",
    "paper_url": "https://huggingface.co/papers/2602.07670",
    "authors": [
      "Jarrodbarnes"
    ],
    "stars": "0",
    "details": {
      "title": "Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation",
      "abstract": "Standard practice selects the most confident model output. I tested the opposite on GPU kernel optimization and found that selecting by surprisal (the model's least confident correct solution) achieves 80% success vs 50% for confidence-guided, with a 3.5x mean speedup advantage. Evaluating just the top 3 by surprisal matches oracle performance at 100%. The key insight: a model's probability distribution maps frequency, not quality. Expert-level CUDA kernels are rare in training data, so the model assigns them low probability despite high performance. That signal is already in the logprobs at zero additional inference cost. I also find that test-time training (gradient adaptation) is worse than random on dense-reward tasks. TTT's best checkpoint (30.6%) falls below a single random sample (53.3%). Gradient updates over-sharpen the distribution, destroying the expert tail where optimal solutions live. Code, model weights, and a detailed write-up are available: Code: https://github.com/jbarnes850/test-time-training - Model: https://huggingface.co/Jarrodbarnes/KernelBench-RLVR-120b Blog: https://jbarnes850.github.io/2026/02/02/surprisal-guided-selection/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07670",
      "pdf_url": "https://arxiv.org/pdf/2602.07670",
      "github_links": [
        "https://github.com/jbarnes850/test-time-training"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07670",
      "scraped_at": "2026-02-12T02:27:11.278775"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management",
    "paper_url": "https://huggingface.co/papers/2602.07398",
    "authors": [
      "Ning Zhang",
      "Chaowei Xiao",
      "Hao Li",
      "Ruoyao"
    ],
    "stars": "2",
    "details": {
      "title": "AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management",
      "abstract": "AgentSys defends against indirect prompt injection through explicit hierarchical memory management, reducing attack surface and preserving agent decision-making by preventing malicious instructions from persisting in the context window.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07398",
      "pdf_url": "https://arxiv.org/pdf/2602.07398",
      "github_links": [
        "https://github.com/ruoyaow/agentsys-memory"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07398",
      "scraped_at": "2026-02-12T02:27:13.043932"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?",
    "paper_url": "https://huggingface.co/papers/2602.04802",
    "authors": [
      "Yujie Cheng",
      "Xinzhe Han",
      "Yuhao Wang",
      "Juntong Feng",
      "liuqa"
    ],
    "stars": "11",
    "details": {
      "title": "VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?",
      "abstract": "Vision-Language Models (VLMs) have achieved impressive performance in cross-modal understanding across textual and visual inputs, yet existing benchmarks predominantly focus on pure-text queries. In real-world scenarios, language also frequently appears as visualized text embedded in images, raising the question of whether current VLMs handle such input requests comparably. We introduce VISTA-Bench, a systematic benchmark from multimodal perception, reasoning, to unimodal understanding domains. It evaluates visualized text understanding by contrasting pure-text and visualized-text questions under controlled rendering conditions. Extensive evaluation of over 20 representative VLMs reveals a pronounced modality gap: models that perform well on pure-text queries often degrade substantially when equivalent semantic content is presented as visualized text. This gap is further amplified by increased perceptual difficulty, highlighting sensitivity to rendering variations despite unchanged semantics. Overall, VISTA-Bench provides a principled evaluation framework to diagnose this limitation and to guide progress toward more unified language representations across tokenized text and pixels. The source dataset is available at https://github.com/QingAnLiu/VISTA-Bench .",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04802",
      "pdf_url": "https://arxiv.org/pdf/2602.04802",
      "github_links": [
        "https://github.com/QingAnLiu/VISTA-Bench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04802",
      "scraped_at": "2026-02-12T02:27:14.832320"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "C-ŒîŒò: Circuit-Restricted Weight Arithmetic for Selective Refusal",
    "paper_url": "https://huggingface.co/papers/2602.04521",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "C-ŒîŒò: Circuit-Restricted Weight Arithmetic for Selective Refusal",
      "abstract": "C-ŒîŒò (Circuit-Restricted Weight Arithmetic) shifts selective refusal from inference-time steering to an offline, checkpoint-level edit. It first identifies the refusal-causal circuit via EAP-IG, then applies a circuit-restricted weight update that typically touches <5% of parameters, yielding a drop-in ‚Äúsafe-by-default‚Äù model with no runtime hooks or latency overhead. Across 30 model-category settings, C-ŒîŒò sharply improves harmful refusal while keeping benign over-refusal controlled, preserving capability on standard benchmarks and generalizing to OOD attacks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04521",
      "pdf_url": "https://arxiv.org/pdf/2602.04521",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04521",
      "scraped_at": "2026-02-12T02:27:16.634917"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching",
    "paper_url": "https://huggingface.co/papers/2602.04908",
    "authors": [
      "Jindong Wang",
      "Chikap421"
    ],
    "stars": "0",
    "details": {
      "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Stable Velocity: A Variance Perspective on Flow Matching (2026) Rethinking Refinement: Correcting Generative Bias without Noise Injection (2026) Trajectory Stitching for Solving Inverse Problems with Flow-Based Models (2026) Training-Free Representation Guidance for Diffusion Models with a Representation Alignment Projector (2026) FlowConsist: Make Your Flow Consistent with Real Trajectory (2026) FlowCast: Trajectory Forecasting for Scalable Zero-Cost Speculative Flow Matching (2026) Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04908",
      "pdf_url": "https://arxiv.org/pdf/2602.04908",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04908",
      "scraped_at": "2026-02-12T02:27:18.379391"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models",
    "paper_url": "https://huggingface.co/papers/2602.01725",
    "authors": [],
    "stars": "5",
    "details": {
      "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models",
      "abstract": "With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.01725",
      "pdf_url": "https://arxiv.org/pdf/2602.01725",
      "github_links": [
        "https://github.com/YurunChen/SafePred"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.01725",
      "scraped_at": "2026-02-12T02:27:20.143336"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models",
    "paper_url": "https://huggingface.co/papers/2601.21235",
    "authors": [
      "Lisa Erickson",
      "Tushar Bandopadhyay",
      "alokabhishek"
    ],
    "stars": "0",
    "details": {
      "title": "SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models",
      "abstract": "Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.",
      "arxiv_page_url": "https://arxiv.org/abs/2601.21235",
      "pdf_url": "https://arxiv.org/pdf/2601.21235",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2601.21235",
      "scraped_at": "2026-02-12T02:27:21.974370"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes",
    "paper_url": "https://huggingface.co/papers/2602.09153",
    "authors": [],
    "stars": "46",
    "details": {
      "title": "SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes",
      "abstract": "Meet SceneSmith: An agentic system that generates entire simulation-ready environments from a single text prompt. VLM agents collaborate to build scenes with dozens of objects per room, articulated furniture, and full physics properties.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09153",
      "pdf_url": "https://arxiv.org/pdf/2602.09153",
      "github_links": [
        "https://github.com/nepfaff/scenesmith"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09153",
      "scraped_at": "2026-02-12T02:27:23.766521"
    },
    "scraped_date": "2026-02-12"
  },
  {
    "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters",
    "paper_url": "https://huggingface.co/papers/2602.10604",
    "authors": [],
    "stars": "1.25k",
    "details": {
      "title": "Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters",
      "abstract": "Step-3.5-Flash is #1 on MathArena , an uncheatable math competition benchmark",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10604",
      "pdf_url": "https://arxiv.org/pdf/2602.10604",
      "github_links": [
        "https://github.com/stepfun-ai/Step-3.5-Flash"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10604",
      "scraped_at": "2026-02-13T02:27:05.561491"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "PhyCritic: Multimodal Critic Models for Physical AI",
    "paper_url": "https://huggingface.co/papers/2602.11124",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "PhyCritic: Multimodal Critic Models for Physical AI",
      "abstract": "A multimodal critic model that unifies physical judging and reasoning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.11124",
      "pdf_url": "https://arxiv.org/pdf/2602.11124",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.11124",
      "scraped_at": "2026-02-13T02:27:07.463920"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "GENIUS: Generative Fluid Intelligence Evaluation Suite",
    "paper_url": "https://huggingface.co/papers/2602.11144",
    "authors": [
      "Zijun Shen",
      "Wei Dai",
      "Ziyu Guo",
      "Sihan Yang",
      "Ruichuan An"
    ],
    "stars": "0",
    "details": {
      "title": "GENIUS: Generative Fluid Intelligence Evaluation Suite",
      "abstract": "",
      "arxiv_page_url": "https://arxiv.org/abs/2602.11144",
      "pdf_url": "https://arxiv.org/pdf/2602.11144",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.11144",
      "scraped_at": "2026-02-13T02:27:09.368749"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "ASA: Training-Free Representation Engineering for Tool-Calling Agents",
    "paper_url": "https://huggingface.co/papers/2602.04935",
    "authors": [
      "Hongwei Zeng",
      "Shuaishuai Cao",
      "Rong Fu",
      "Run Zhou",
      "wangyoujin"
    ],
    "stars": "0",
    "details": {
      "title": "ASA: Training-Free Representation Engineering for Tool-Calling Agents",
      "abstract": "Adapting LLM agents to domain-specific tool calling remains notably brittle under evolving interfaces. Prompt and schema engineering is easy to deploy but often fragile under distribution shift and strict parsers, while continual parameter-efficient fine-tuning improves reliability at the cost of training, maintenance, and potential forgetting. We identify a critical Lazy Agent failure mode where tool necessity is nearly perfectly decodable from mid-layer activations, yet the model remains conservative in entering tool mode, revealing a representation-behavior gap. We propose Activation Steering Adapter (ASA), a training-free, inference-time controller that performs a single-shot mid-layer intervention and targets tool domains via a router-conditioned mixture of steering vectors with a probe-guided signed gate to amplify true intent while suppressing spurious triggers. On MTU-Bench with Qwen2.5-1.5B, ASA improves strict tool-use F1 from 0.18 to 0.50 while reducing the false positive rate from 0.15 to 0.05, using only about 20KB of portable assets and no weight updates.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.04935",
      "pdf_url": "https://arxiv.org/pdf/2602.04935",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.04935",
      "scraped_at": "2026-02-13T02:27:12.641230"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Towards Autonomous Mathematics Research",
    "paper_url": "https://huggingface.co/papers/2602.10177",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Towards Autonomous Mathematics Research",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API Semi-Autonomous Mathematics Discovery with Gemini: A Case Study on the Erd\\H{o}s Problems (2026) AI for Mathematics: Progress, Challenges, and Prospects (2026) Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience (2025) AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent (2025) Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities - A Case Study on IMO 2025 Problem 6 (2025) EternalMath: A Living Benchmark of Frontier Mathematics that Evolves with Human Discovery (2026) PhysProver: Advancing Automatic Theorem Proving for Physics (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10177",
      "pdf_url": "https://arxiv.org/pdf/2602.10177",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10177",
      "scraped_at": "2026-02-13T02:27:15.953082"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design",
    "paper_url": "https://huggingface.co/papers/2602.08253",
    "authors": [
      "Liang Zeng",
      "iphysresearch",
      "ZBoyn"
    ],
    "stars": "12",
    "details": {
      "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design",
      "abstract": "We‚Äôre moving from constructive rules to recursive destruction & repair üîÑ. G-LNS introduces Synergy-Aware Co-evolution, allowing LLMs to generate coupled Destroy/Repair operators that break local optima. Reshaping > Constructing. üí° It beats OR-Tools and SOTA AHD methods (EoH-S/MCTS_AHD) on TSP & CVRP benchmarks üöÄ.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08253",
      "pdf_url": "https://arxiv.org/pdf/2602.08253",
      "github_links": [
        "https://github.com/ZBoyn/G-LNS"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08253",
      "scraped_at": "2026-02-13T02:27:17.936493"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning",
    "paper_url": "https://huggingface.co/papers/2602.10622",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning",
      "abstract": "üéâ How Do Decoder-Only LLMs Perceive Users? Rethinking Attention Masking for User Representation Learning Decoder-only LLMs have demonstrated remarkable generative capabilities, but how well do they understand users when repurposed for representation learning? In our latest work, we revisit attention masking in decoder-only architectures and uncover a critical yet overlooked challenge: the instability that arises when transitioning from causal to bidirectional attention. By systematically studying masking strategies and proposing a gradient-guided soft masking approach, we aim to bridge the gap between autoregressive pretraining and high-quality user representation learning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10622",
      "pdf_url": "https://arxiv.org/pdf/2602.10622",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10622",
      "scraped_at": "2026-02-13T02:27:19.941599"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning",
    "paper_url": "https://huggingface.co/papers/2602.10560",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "When to Memorize and When to Stop: Gated Recurrent Memory for Long-Context Reasoning",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API InfMem: Learning System-2 Memory Control for Long-Context Agent (2026) Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning (2026) Fine-Mem: Fine-Grained Feedback Alignment for Long-Horizon Memory Management (2026) MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning (2026) AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation (2026) Document Reconstruction Unlocks Scalable Long-Context RLVR (2026) Context-Picker: Dynamic context selection using multi-stage reinforcement learning (2025) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10560",
      "pdf_url": "https://arxiv.org/pdf/2602.10560",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10560",
      "scraped_at": "2026-02-13T02:27:21.970300"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions",
    "paper_url": "https://huggingface.co/papers/2602.08711",
    "authors": [],
    "stars": "16",
    "details": {
      "title": "TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions",
      "abstract": "TimeChat-Captioner is a multimodal model designed to generate detailed, time-aware, and structurally coherent captions for multi-scene videos. It effectively coordinates visual and audio information to provide comprehensive video descriptions.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08711",
      "pdf_url": "https://arxiv.org/pdf/2602.08711",
      "github_links": [
        "https://github.com/yaolinli/TimeChat-Captioner"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08711",
      "scraped_at": "2026-02-13T02:27:23.918975"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "FeatureBench: Benchmarking Agentic Coding for Complex Feature Development",
    "paper_url": "https://huggingface.co/papers/2602.10975",
    "authors": [
      "Jiahe Wang",
      "Rui Hao",
      "Qixing Zhou",
      "Haiyang-W",
      "jiachengzhg"
    ],
    "stars": "17",
    "details": {
      "title": "FeatureBench: Benchmarking Agentic Coding for Complex Feature Development",
      "abstract": "FeatureBench focuses on evaluating the end-to-end development capability of coding agents for complex features. On our benchmark, even the strongest commercial models can solve only about 12% of the tasks. The full Docker environment and the scalable task construction pipeline have been open-sourced. The evaluation is highly user-friendly and easy to reproduce. Beyond bug fixing, ship real features!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10975",
      "pdf_url": "https://arxiv.org/pdf/2602.10975",
      "github_links": [
        "https://github.com/LiberCoders/FeatureBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10975",
      "scraped_at": "2026-02-13T02:27:25.877597"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "ROCKET: Rapid Optimization via Calibration-guided Knapsack Enhanced Truncation for Efficient Model Compression",
    "paper_url": "https://huggingface.co/papers/2602.11008",
    "authors": [],
    "stars": "20",
    "details": {
      "title": "ROCKET: Rapid Optimization via Calibration-guided Knapsack Enhanced Truncation for Efficient Model Compression",
      "abstract": "ROCKET isn‚Äôt just another compression method. It is one of the first methods to shrink massive AI models down to compact sizes without sacrificing performance, often matching or even outperforming vanilla models of the same size trained from scratch üöÄ",
      "arxiv_page_url": "https://arxiv.org/abs/2602.11008",
      "pdf_url": "https://arxiv.org/pdf/2602.11008",
      "github_links": [
        "https://github.com/mts-ai/ROCKET"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.11008",
      "scraped_at": "2026-02-13T02:27:27.890871"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.10224",
    "authors": [
      "Zhen Fang",
      "Qingnan Ren",
      "Zecheng Li",
      "YuZeng260",
      "chocckaka"
    ],
    "stars": "0",
    "details": {
      "title": "Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models",
      "abstract": "We propose Meta-Experience Learning (MEL), which breaks the meta-learning and credit-assignment bottleneck of standard RLVR by explicitly modeling and internalizing reusable error-based knowledge. MEL exploits an LLM's self-verification ability to perform contrastive analysis over correct and incorrect trajectories, pinpointing bifurcation points where reasoning goes wrong and abstracting them into generalizable meta-experiences. These meta-experiences are then distilled into the model's parametric memory via NLL minimization, inducing a language-modeled reward signal that bridges correct and incorrect reasoning paths and enables effective knowledge reuse.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10224",
      "pdf_url": "https://arxiv.org/pdf/2602.10224",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10224",
      "scraped_at": "2026-02-13T02:27:29.884815"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.11089",
    "authors": [
      "Kai Chen",
      "Yining Li",
      "Xinchen Xie",
      "Zerun Ma",
      "Yicheng Chen"
    ],
    "stars": "4",
    "details": {
      "title": "DataChef: Cooking Up Optimal Data Recipes for LLM Adaptation via Reinforcement Learning",
      "abstract": "demo: https://huggingface.co/spaces/yichengchen24/DataChef",
      "arxiv_page_url": "https://arxiv.org/abs/2602.11089",
      "pdf_url": "https://arxiv.org/pdf/2602.11089",
      "github_links": [
        "https://github.com/yichengchen24/DataChef"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.11089",
      "scraped_at": "2026-02-13T02:27:31.828592"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development",
    "paper_url": "https://huggingface.co/papers/2602.11103",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development",
      "abstract": "Can agents develop video games? GameDevBench is the first benchmark to evaluate an agent's ability to solve game development tasks.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.11103",
      "pdf_url": "https://arxiv.org/pdf/2602.11103",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.11103",
      "scraped_at": "2026-02-13T02:27:33.842375"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Online Causal Kalman Filtering for Stable and Effective Policy Optimization",
    "paper_url": "https://huggingface.co/papers/2602.10609",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Online Causal Kalman Filtering for Stable and Effective Policy Optimization",
      "abstract": "(Work in progress) We are adding more comparison methods and models for KPO and will soon open-source KPO.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10609",
      "pdf_url": "https://arxiv.org/pdf/2602.10609",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10609",
      "scraped_at": "2026-02-13T02:27:35.800723"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Data Repetition Beats Data Scaling in Long-CoT Supervised Fine-Tuning",
    "paper_url": "https://huggingface.co/papers/2602.11149",
    "authors": [
      "Yuki M. Asano",
      "Tijmen Blankevoort",
      "Sagar Vaze",
      "dakopi"
    ],
    "stars": "1",
    "details": {
      "title": "Data Repetition Beats Data Scaling in Long-CoT Supervised Fine-Tuning",
      "abstract": "Pretty interesting findings!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.11149",
      "pdf_url": "https://arxiv.org/pdf/2602.11149",
      "github_links": [
        "https://github.com/dkopi/data-repetition"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.11149",
      "scraped_at": "2026-02-13T02:27:37.747669"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models",
    "paper_url": "https://huggingface.co/papers/2602.07106",
    "authors": [
      "Tianshu Yu",
      "Yiwen Guo",
      "Zhipeng Li",
      "lemonade666"
    ],
    "stars": "0",
    "details": {
      "title": "Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models",
      "abstract": "Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from the representation mismatch between discrete, token-level semantic reasoning in LLMs and the dense, fine-grained temporal dynamics required for 3D facial motion, which makes direct modeling difficult to optimize under limited data. We propose Expressive Omni (Ex-Omni), an open-source omni-modal framework that augments OLLMs with speech-accompanied 3D facial animation. Ex-Omni reduces learning difficulty by decoupling semantic reasoning from temporal generation, leveraging speech units as temporal scaffolding and a unified token-as-query gated fusion (TQGF) mechanism for controlled semantic injection. We further introduce InstructEx, a dataset aims to facilitate augment OLLMs with speech-accompanied 3D facial animation. Extensive experiments demonstrate that Ex-Omni performs competitively against existing open-source OLLMs while enabling stable aligned speech and facial animation generation.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07106",
      "pdf_url": "https://arxiv.org/pdf/2602.07106",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07106",
      "scraped_at": "2026-02-13T02:27:39.755698"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion",
    "paper_url": "https://huggingface.co/papers/2602.10999",
    "authors": [
      "Feiyang Pan",
      "Lue Fan",
      "Shuzhe Wu",
      "Yusong Lin",
      "Haiyang-W"
    ],
    "stars": "9",
    "details": {
      "title": "CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion",
      "abstract": "This is an automated message from the Librarian Bot . I found the following papers similar to this paper. The following papers were recommended by the Semantic Scholar API TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents (2026) SWE-World: Building Software Engineering Agents in Docker-Free Environments (2026) daVinci-Dev: Agent-native Mid-training for Software Engineering (2026) MEnvAgent: Scalable Polyglot Environment Construction for Verifiable Software Engineering (2026) AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration (2026) ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development (2026) EvoConfig: Self-Evolving Multi-Agent Systems for Efficient Autonomous Environment Configuration (2026) Please give a thumbs up to this comment if you found it helpful! If you want recommendations for any Paper on Hugging Face checkout this Space You can directly ask Librarian Bot for paper recommendations by tagging it in a comment: @ librarian-bot recommend",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10999",
      "pdf_url": "https://arxiv.org/pdf/2602.10999",
      "github_links": [
        "https://github.com/LiberCoders/CLI-Gym"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10999",
      "scraped_at": "2026-02-13T02:27:43.458285"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation",
    "paper_url": "https://huggingface.co/papers/2602.10367",
    "authors": [
      "Xiang Li",
      "Yisheng Ji",
      "Zhe Fang",
      "Dingjie Song",
      "Zhiling Yan"
    ],
    "stars": "1",
    "details": {
      "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation",
      "abstract": "LiveMedBench is a continuously updated, contamination-free, and rubric-based benchmark for evaluating LLMs on real-world medical cases. It is designed to measure not only overall medical quality, but also robustness over time and alignment with physician judgment.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10367",
      "pdf_url": "https://arxiv.org/pdf/2602.10367",
      "github_links": [
        "https://github.com/ZhilingYan/LiveMedBench"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10367",
      "scraped_at": "2026-02-13T02:27:47.649975"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Blockwise Advantage Estimation for Multi-Objective RL with Verifiable Rewards",
    "paper_url": "https://huggingface.co/papers/2602.10231",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Blockwise Advantage Estimation for Multi-Objective RL with Verifiable Rewards",
      "abstract": "Blockwise Advantage Estimation makes GRPO work for segmented, multi-objective generations by routing each objective‚Äôs learning signal to the tokens that control it, using an outcome-conditioned baseline for later segments.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10231",
      "pdf_url": "https://arxiv.org/pdf/2602.10231",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10231",
      "scraped_at": "2026-02-13T02:27:49.726010"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies",
    "paper_url": "https://huggingface.co/papers/2602.09514",
    "authors": [
      "Yishuo Yuan",
      "Kangqi Song",
      "Shengze Xu",
      "Jinxiang Xia",
      "Xavier Hu"
    ],
    "stars": "6",
    "details": {
      "title": "EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies",
      "abstract": "Long-horizon planning is widely recognized as a core capability of autonomous LLM-based agents; however, current evaluation frameworks suffer from being largely episodic, domain-specific, or insufficiently grounded in persistent economic dynamics. We introduce EcoGym, a generalizable benchmark for continuous plan-and-execute decision making in interactive economies. EcoGym comprises three diverse environments: Vending, Freelance, and Operation, implemented in a unified decision-making process with standardized interfaces, and budgeted actions over an effectively unbounded horizon (1000+ steps if 365 day-loops for evaluation). The evaluation of EcoGym is based on business-relevant outcomes (e.g., net worth, income, and DAU), targeting long-term strategic coherence and robustness under partial observability and stochasticity. Experiments across eleven leading LLMs expose a systematic tension: no single model dominates across all three scenarios. Critically, we find that models exhibit significant suboptimality in either high-level strategies or efficient actions executions. EcoGym is released as an open, extensible testbed for transparent long-horizon agent evaluation and for studying controllability-utility trade-offs in realistic economic settings.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09514",
      "pdf_url": "https://arxiv.org/pdf/2602.09514",
      "github_links": [
        "https://github.com/OPPO-PersonalAI/EcoGym"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09514",
      "scraped_at": "2026-02-13T02:27:54.253779"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval",
    "paper_url": "https://huggingface.co/papers/2602.08099",
    "authors": [
      "Rami Ben-Ari",
      "Dvir Samuel",
      "issart12345"
    ],
    "stars": "0",
    "details": {
      "title": "VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval",
      "abstract": "What if your multimodal LLM already contains strong video representations‚Äîstrong enough to beat Video Foundation Models? ü§î VidVec üé• : Unlocking Video MLLM Embeddings for Video-Text Retrieval Key contributions (short): ‚úÖ Layer-wise insight: intermediate MLLM layers already encode strong video‚Äìtext representations ‚úÖ Zero-shot 2-stage retrieval (no training) : intermediate-layer embeddings + calibrated MLLM head for reranking üìà Recall gains vs trained MLLM Embedders : +3.2% (MSR-VTT) ¬∑ +7.7% (VATEX) ¬∑ +9.4% (DiDeMo) üìù Text-only ‚Äúin-context‚Äù optimization : ~60K dense caption ‚Üí short summary pairs (no visual supervision) üèÜ SoTA video‚Äìtext retrieval performance across MSR-VTT / MSVD / VATEX / DiDeMo Project page: https://iyttor.github.io/VidVec arXiv: https://www.arxiv.org/abs/2602.08099 code and weights are coming soon...",
      "arxiv_page_url": "https://www.arxiv.org/abs/2602.08099",
      "pdf_url": "https://arxiv.org/pdf/2602.08099",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08099",
      "scraped_at": "2026-02-13T02:27:56.193609"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Stroke3D: Lifting 2D strokes into rigged 3D model via latent diffusion models",
    "paper_url": "https://huggingface.co/papers/2602.09713",
    "authors": [],
    "stars": "19",
    "details": {
      "title": "Stroke3D: Lifting 2D strokes into rigged 3D model via latent diffusion models",
      "abstract": "Project Page: https://whalesong-zrs.github.io/Stroke3D_project_page/ Github Repo: https://github.com/Whalesong-zrs/Stroke3D",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09713",
      "pdf_url": "https://arxiv.org/pdf/2602.09713",
      "github_links": [
        "https://github.com/Whalesong-zrs/Stroke3D",
        "https://github.com/Whalesong-zrs/Stroke3D_project_page"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09713",
      "scraped_at": "2026-02-13T02:27:58.136088"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "ECHO-2: A Large-Scale Distributed Rollout Framework for Cost-Efficient Reinforcement Learning",
    "paper_url": "https://huggingface.co/papers/2602.02192",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "ECHO-2: A Large-Scale Distributed Rollout Framework for Cost-Efficient Reinforcement Learning",
      "abstract": "Current RLHF/RLAIF is bottlenecked by rollouts and wasteful GPU idling. ECHO-2 changes the cost structure: we decouple RL into three planes‚Äîrollout (global inference swarm), learning (staleness-aware multi-step updates), and data/reward (fully modular)‚Äîand coordinate them with lightweight versioning and pipelined broadcast. The result is near-continuous learner utilization even under heterogeneous, unreliable WAN workers, enabling RL to scale out across a global fleet rather than up inside datacenters. We validate on GRPO-based reasoning/code tasks and a poker sandbox integration.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02192",
      "pdf_url": "https://arxiv.org/pdf/2602.02192",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02192",
      "scraped_at": "2026-02-13T02:28:00.140800"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "When the Prompt Becomes Visual: Vision-Centric Jailbreak Attacks for Large Image Editing Models",
    "paper_url": "https://huggingface.co/papers/2602.10179",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "When the Prompt Becomes Visual: Vision-Centric Jailbreak Attacks for Large Image Editing Models",
      "abstract": "Website: https://csu-jpg.github.io/vja.github.io/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10179",
      "pdf_url": "https://arxiv.org/pdf/2602.10179",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10179",
      "scraped_at": "2026-02-13T02:28:02.112423"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search",
    "paper_url": "https://huggingface.co/papers/2602.09901",
    "authors": [
      "Hui Zhang",
      "Yunpeng Liu",
      "Xiaorui Huang",
      "Jianzhao Huang",
      "Hiiamein"
    ],
    "stars": "0",
    "details": {
      "title": "QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search",
      "abstract": "QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09901",
      "pdf_url": "https://arxiv.org/pdf/2602.09901",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09901",
      "scraped_at": "2026-02-13T02:28:04.042953"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens",
    "paper_url": "https://huggingface.co/papers/2602.10229",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens",
      "abstract": "a new framework for LLM reasoning in continuous latent space",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10229",
      "pdf_url": "https://arxiv.org/pdf/2602.10229",
      "github_links": [
        "https://github.com/NeosKnight233/Latent-Thoughts-Tuning"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10229",
      "scraped_at": "2026-02-13T02:28:06.107038"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Beyond Correctness: Learning Robust Reasoning via Transfer",
    "paper_url": "https://huggingface.co/papers/2602.08489",
    "authors": [
      "Jinwoo Shin",
      "Jihoon Tack",
      "Soheil Abbasloo",
      "hyunseoki"
    ],
    "stars": "0",
    "details": {
      "title": "Beyond Correctness: Learning Robust Reasoning via Transfer",
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently strengthened LLM reasoning, but its focus on final answer correctness leaves a critical gap: it does not ensure the robustness of the reasoning process itself. We adopt a simple philosophical view, robust reasoning should remain useful beyond the mind that produced it, and treat reasoning as a form of meaning transfer that must survive truncation, reinterpretation, and continuation. Building on this principle, we introduce Reinforcement Learning with Transferable Reward (RLTR), which operationalizes robustness via transfer reward that tests whether a partial reasoning prefix from one model can guide a separate model to the correct answer. This encourages LLMs to produce reasoning that is stable, interpretable, and genuinely generalizable. Our approach improves sampling consistency while improving final answer accuracy, and it reaches comparable performance in substantially fewer training steps. For example, on MATH500, RLTR achieves a +3.6%p gain in Maj@64 compared to RLVR and matches RLVR's average accuracy with roughly 2.5x fewer training steps, providing both more reliable reasoning and significantly more sample efficient.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08489",
      "pdf_url": "https://arxiv.org/pdf/2602.08489",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08489",
      "scraped_at": "2026-02-13T02:28:08.014631"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models",
    "paper_url": "https://huggingface.co/papers/2602.08030",
    "authors": [],
    "stars": "9",
    "details": {
      "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models",
      "abstract": "The Magic of Forgetting! Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as \"malloc-only\" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that introduces an intrinsic self-forgetting capability via the Free-Module, a plug-and-play LoRA adapter. By iteratively switching between reasoning and cleaning modes, Free()LM dynamically identifies and prunes useless context chunks, maintaining a compact and noise-free state. Extensive experiments show that Free()LM provides consistent improvements across all model scales (8B to 685B). It achieves a 3.3% average improvement over top-tier reasoning baselines, even establishing a new SOTA on IMOanswerBench using DeepSeek V3.2-Speciale. Most notably, in long-horizon tasks where the standard Qwen3-235B-A22B model suffers a total collapse (0% accuracy), Free()LM restores performance to 50%. Our findings suggest that sustainable intelligence requires the freedom to forget as much as the power to think.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08030",
      "pdf_url": "https://arxiv.org/pdf/2602.08030",
      "github_links": [
        "https://github.com/TemporaryLoRA/FreeLM"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08030",
      "scraped_at": "2026-02-13T02:28:09.964255"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Benchmarking Large Language Models for Knowledge Graph Validation",
    "paper_url": "https://huggingface.co/papers/2602.10748",
    "authors": [],
    "stars": "1",
    "details": {
      "title": "Benchmarking Large Language Models for Knowledge Graph Validation",
      "abstract": "In this work, we introduce¬†FactCheck, a benchmark to systematically evaluate LLMs for fact validation over Knowledge Graphs, covering internal model knowledge, Retrieval-Augmented Generation (RAG), and multi-model consensus strategies across three real-world KGs (FactBench, YAGO, DBpedia). ü§ñüîé Our results show that while LLMs can reach strong performances, they still lack the stability and reliability needed for real-world KG validation, and that external evidence via RAG and ensemble consensus help, but at non-trivial computational and operational costs. üìä‚öôÔ∏è You can already explore the web platform and artifacts here: üåê Web app: https://factcheck.dei.unipd.it/ üíª Code and datasets: https://github.com/FactCheck-AI Looking forward to discussing this work with the community in Tampere! üá´üáÆ",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10748",
      "pdf_url": "https://arxiv.org/pdf/2602.10748",
      "github_links": [
        "https://github.com/FactCheck-AI",
        "https://github.com/FactCheck-AI/FactCheck"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10748",
      "scraped_at": "2026-02-13T02:28:14.092997"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation",
    "paper_url": "https://huggingface.co/papers/2602.07954",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation",
      "abstract": "Bielik Guard is a family of compact Polish-language safety classifiers (0.1B and 0.5B parameters) that accurately detect harmful content across five categories, achieving strong benchmark performance‚Äîwith the 0.5B model offering the best overall F1 scores and the 0.1B model delivering high precision and low false positives‚Äîwhile enabling nuanced responses rather than simple content blocking. Smaller model: https://huggingface.co/speakleash/Bielik-Guard-0.1B-v1.1 Larger model: https://huggingface.co/speakleash/Bielik-Guard-0.5B-v1.1",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07954",
      "pdf_url": "https://arxiv.org/pdf/2602.07954",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07954",
      "scraped_at": "2026-02-13T02:28:16.526379"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions",
    "paper_url": "https://huggingface.co/papers/2602.06008",
    "authors": [],
    "stars": "7",
    "details": {
      "title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions",
      "abstract": "Paper: https://arxiv.org/abs/2602.06008 Code: https://github.com/SafeRL-Lab/AgenticPay Tutorial: https://agenticpay-tutorial.readthedocs.io/en/latest/",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06008",
      "pdf_url": "https://arxiv.org/pdf/2602.06008",
      "github_links": [
        "https://github.com/SafeRL-Lab/AgenticPay"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06008",
      "scraped_at": "2026-02-13T02:28:18.513659"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL",
    "paper_url": "https://huggingface.co/papers/2602.03773",
    "authors": [
      "Aviral Kumar",
      "Amrith Setlur",
      "Yuxiao Qu",
      "Ian Wu"
    ],
    "stars": "0",
    "details": {
      "title": "Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL",
      "abstract": "Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a property we refer to as extrapolation. However, standard reinforcement learning (RL) operates over fixed problem distributions and training budgets, which limits extrapolation amidst distribution shift at test time. To address this, we introduce RC, an iterative decoding algorithm that replaces standard autoregressive decoding during both training and inference. RC exploits an asymmetry between the response generation and summarization capabilities of LLMs to construct reasoning chains that consistently improve across iterations. Models trained to use RC can extrapolate and continually improve over reasoning horizons more than an order of magnitude longer than those seen during training. Empirically, training a 4B model with RC using a 16k-token training budget improves performance on HMMT 2025 from 40% to nearly 70% with 0.5m tokens at test time, outperforming both comparably sized models and many larger reasoning LLMs. Finally, we also show that models trained with RC can more effectively leverage existing scaffolds to further scale test-time performance, due to the improved summary-conditioned generation abilities learned through training.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.03773",
      "pdf_url": "https://arxiv.org/pdf/2602.03773",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.03773",
      "scraped_at": "2026-02-13T02:28:20.391536"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
    "paper_url": "https://huggingface.co/papers/2602.09014",
    "authors": [],
    "stars": "50",
    "details": {
      "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
      "abstract": "In this work, we revisit few-step distillation from a geometric perspective. Based on the observation that teacher trajectories exhibit inherently non-linear dynamics, ArcFlow introduces a momentum-based velocity parameterization with an analytic solver to enable more faithful alignment under very few NFEs. Across Qwen-Image-20B and FLUX.1-dev, we find that this formulation results in stable 2-step generation with lightweight LoRA tuning, while maintaining strong alignment with the teacher distribution. We hope this perspective may provide a useful direction for improving efficiency without sacrificing trajectory fidelity.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.09014",
      "pdf_url": "https://arxiv.org/pdf/2602.09014",
      "github_links": [
        "https://github.com/pnotp/ArcFlow"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.09014",
      "scraped_at": "2026-02-13T02:28:23.425629"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents",
    "paper_url": "https://huggingface.co/papers/2602.07900",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents",
      "abstract": "In autonomous issue resolution, agent-written tests often increase interaction cost without meaningfully increasing task success.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.07900",
      "pdf_url": "https://arxiv.org/pdf/2602.07900",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.07900",
      "scraped_at": "2026-02-13T02:28:25.429036"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation",
    "paper_url": "https://huggingface.co/papers/2602.11451",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation",
      "abstract": "The LoopFormer Paper accepted to ICLR 2026",
      "arxiv_page_url": "https://arxiv.org/abs/2602.11451",
      "pdf_url": "https://arxiv.org/pdf/2602.11451",
      "github_links": [
        "https://github.com/armenjeddi/loopformer"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.11451",
      "scraped_at": "2026-02-13T02:28:27.395325"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Weight Decay Improves Language Model Plasticity",
    "paper_url": "https://huggingface.co/papers/2602.11137",
    "authors": [
      "Sham Kakade",
      "Hanlin Zhang",
      "Sebastian Bordt",
      "Tessa Han"
    ],
    "stars": "0",
    "details": {
      "title": "Weight Decay Improves Language Model Plasticity",
      "abstract": "Increasing weight decay during language model pretraining enhances model plasticity, enabling greater performance gains after fine-tuning even when base validation loss is worse, and highlights the need to optimize hyperparameters with downstream adaptability in mind.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.11137",
      "pdf_url": "https://arxiv.org/pdf/2602.11137",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.11137",
      "scraped_at": "2026-02-13T02:28:29.313239"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory",
    "paper_url": "https://huggingface.co/papers/2602.10652",
    "authors": [],
    "stars": "247",
    "details": {
      "title": "UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory",
      "abstract": "UMEM: Unified Memory Extraction and Management Framework for Generalizable Memory This paper presents a systematic solution to a core bottleneck in self-evolving agents, offering the following notable contributions: Core Problem Insight The authors accurately identify a fundamental limitation in existing approaches: the decoupled treatment of memory extraction and memory management . Current state-of-the-art methods (e.g., ReMem, Memp) focus solely on optimizing management strategies while treating extraction as a static prompting process. This design leads to two critical pitfalls: Instance-level noise accumulation : Blindly memorizing concrete details rather than generalizable principles results in a \"rote memorization\" trap. Strategy misalignment : Low-quality extracted memories render even optimal management strategies ineffective, creating a \"garbage in, garbage out\" vicious cycle. Methodological Innovations UMEM's key innovation lies in the end-to-end joint optimization of extraction and management , with three pivotal designs ensuring generalizability: Semantic Neighborhood Modeling : Queries are clustered based on cosine similarity, transforming cross-task generalization into an intra-neighborhood consistency optimization problem. Theoretical guarantees for retrieval stability are provided via formal lemmas. Marginal Utility Reward : Memory value is evaluated at the neighborhood level through a novel reward combining success gain and efficiency regularization, compelling the agent to discard instance-specific noise. Online Memory Evolution : The memory bank is dynamically updated during training, enabling co-evolution of policy learning and memory states, thereby overcoming limitations imposed by static memory assumptions. Comprehensive Experimental Validation UMEM achieves significant performance gains over baselines across five heterogeneous benchmarks (AIME, GPQA, ALFWorld, etc.), with improvements up to 10.67% on multi-turn interactive tasks. Ablation studies compellingly demonstrate that optimizing extraction alone is more critical than optimizing management alone (performance drop of 4.70 points vs. 0.73 points), challenging the prevailing \"management-first\" paradigm. Continual evolution experiments reveal that UMEM exhibits a monotonically improving trajectory , whereas baselines such as ReMem rapidly degrade due to noise accumulation‚Äîvalidating the long-term value of the generalization-oriented design. Cross-model transfer experiments (Qwen3 ‚Üí GPT-5.1 ‚Üí Gemini) confirm that extracted memories possess architecture-agnostic utility. Broader Impact and Implications This work redefines the optimization paradigm for self-evolving agents: memory quality hinges on the synergy between extraction and management, rather than maximal optimization of either component in isolation . The \"neighborhood generalization\" principle offers valuable insights for continual learning and experience transfer. Notably, the paper draws an analogy between agent evolution and neural network training (forward inference + backward optimization), providing a fresh perspective on understanding learning mechanisms in LLM-based agents. Directions for Further Discussion The reliance on pretrained encoders for semantic neighborhood construction warrants deeper investigation into generalization boundaries under out-of-distribution tasks. Trade-offs between computational overhead (evaluating N neighborhood queries) and real-time deployment requirements merit further exploration. Potential complementarity with parameter-based continual learning approaches remains an open avenue for integration. In summary, through rigorous problem deconstruction and an innovative joint optimization framework, UMEM establishes a vital pathway toward building truly sustainable self-evolving agents. It represents a substantive and well-grounded contribution to the field of memory-augmented agent research.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10652",
      "pdf_url": "https://arxiv.org/pdf/2602.10652",
      "github_links": [
        "https://github.com/AIDC-AI/Marco-DeepResearch"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10652",
      "scraped_at": "2026-02-13T02:28:31.626780"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents",
    "paper_url": "https://huggingface.co/papers/2602.08995",
    "authors": [],
    "stars": "3",
    "details": {
      "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents",
      "abstract": "Project Homepage: https://osu-nlp-group.github.io/Misaligned-Action-Detection/ Github Repo: https://github.com/OSU-NLP-Group/Misaligned-Action-Detection Benchmark: https://huggingface.co/datasets/osunlp/MisActBench",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08995",
      "pdf_url": "https://arxiv.org/pdf/2602.08995",
      "github_links": [
        "https://github.com/OSU-NLP-Group/Misaligned-Action-Detection"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08995",
      "scraped_at": "2026-02-13T02:28:33.566309"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments",
    "paper_url": "https://huggingface.co/papers/2602.02459",
    "authors": [],
    "stars": "15",
    "details": {
      "title": "TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments",
      "abstract": "Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.02459",
      "pdf_url": "https://arxiv.org/pdf/2602.02459",
      "github_links": [
        "https://github.com/ucla-mobility/TIC-VLA"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.02459",
      "scraped_at": "2026-02-13T02:28:35.669272"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "FedPS: Federated data Preprocessing via aggregated Statistics",
    "paper_url": "https://huggingface.co/papers/2602.10870",
    "authors": [
      "Graham Cormode",
      "xuefeng-xu"
    ],
    "stars": "5",
    "details": {
      "title": "FedPS: Federated data Preprocessing via aggregated Statistics",
      "abstract": "TL;DR: A unified framework for tabular data preprocessing in federated learning.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10870",
      "pdf_url": "https://arxiv.org/pdf/2602.10870",
      "github_links": [
        "https://github.com/xuefeng-xu/fedps"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10870",
      "scraped_at": "2026-02-13T02:28:37.607206"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "GoodVibe: Security-by-Vibe for LLM-Based Code Generation",
    "paper_url": "https://huggingface.co/papers/2602.10778",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "GoodVibe: Security-by-Vibe for LLM-Based Code Generation",
      "abstract": "Large language models (LLMs) are increasingly used for code generation in fast, informal development workflows, often referred to as vibe coding, where speed and convenience are prioritized, and security requirements are rarely made explicit. In this setting, models frequently produce functionally correct but insecure code, creating a growing security risk. Existing approaches to improving code security rely on full-parameter fine-tuning or parameter-efficient adaptations, which are either costly and prone to catastrophic forgetting or operate at coarse granularity with limited interpretability and control. We present GoodVibe, a neuron-level framework for improving the security of code language models by default. GoodVibe is based on the key insight that security-relevant reasoning is localized to a small subset of neurons. We identify these neurons using gradient-based attribution from a supervised security task and perform neuron-selective fine-tuning that updates only this security-critical subspace. To further reduce training cost, we introduce activation-driven neuron clustering, enabling structured updates with minimal overhead. We evaluate GoodVibe on six LLMs across security-critical programming languages, including C++, Java, Swift, and Go. GoodVibe substantially improves the security of generated code while preserving general model utility, achieving up to a 2.5x improvement over base models, matching or exceeding full fine-tuning with over 4,700x fewer trainable parameters, and reducing training computation by more than 3.6x compared to the parameter-efficient baseline (LoRA). Our results demonstrate that neuron-level optimization offers an effective and scalable approach to securing code generation without sacrificing efficiency or generality.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10778",
      "pdf_url": "https://arxiv.org/pdf/2602.10778",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10778",
      "scraped_at": "2026-02-13T02:28:39.553886"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation",
    "paper_url": "https://huggingface.co/papers/2602.10699",
    "authors": [
      "Yuling Xiong",
      "Changping Wang",
      "Zeyu Wang",
      "Yangru Huang",
      "Jie Jiang"
    ],
    "stars": "0",
    "details": {
      "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation",
      "abstract": "V-STAR introduces value-guided decoding and tree-structured advantage reinforcement learning for generative recommendations, boosting exploration, diversity, and latency-constrained accuracy.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.10699",
      "pdf_url": "https://arxiv.org/pdf/2602.10699",
      "github_links": [],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.10699",
      "scraped_at": "2026-02-13T02:28:41.450922"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing",
    "paper_url": "https://huggingface.co/papers/2602.08741",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "Large Language Lobotomy: Jailbreaking Mixture-of-Experts via Expert Silencing",
      "abstract": "The rapid adoption of Mixture-of-Experts (MoE) architectures marks a major shift in the deployment of Large Language Models (LLMs). MoE LLMs improve scaling efficiency by activating only a small subset of parameters per token, but their routing structure introduces new safety attack surfaces. We find that safety-critical behaviors in MoE LLMs (e.g., refusal) are concentrated in a small set of experts rather than being uniformly distributed. Building on this, we propose Large Language Lobotomy (L), a training-free, architecture-agnostic attack that compromises safety alignment by exploiting expert routing dynamics. L learns routing patterns that correlate with refusal, attributes safety behavior to specific experts, and adaptively silences the most safety-relevant experts until harmful outputs are produced. We evaluate L on eight state-of-the-art open-source MoE LLMs and show that our adaptive expert silencing increases average attack success from 7.3% to 70.4%, reaching up to 86.3%, outperforming prior training-free MoE jailbreak methods. Moreover, bypassing guardrails typically requires silencing fewer than 20% of layer-wise experts while largely preserving general language utility. These results reveal a fundamental tension between efficiency-driven MoE design and robust safety alignment and motivate distributing safety mechanisms more robustly in future MoE LLMs with architecture- and routing-aware methods.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08741",
      "pdf_url": "https://arxiv.org/pdf/2602.08741",
      "github_links": [
        "https://github.com/jonatelintelo/LargeLanguageLobotomy"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08741",
      "scraped_at": "2026-02-13T02:28:45.220548"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling",
    "paper_url": "https://huggingface.co/papers/2602.08052",
    "authors": [
      "Grace Bochenek",
      "Ghaith Rabadi",
      "Sean Mondesire",
      "Bulent Soykan"
    ],
    "stars": "0",
    "details": {
      "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling",
      "abstract": "The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex state of jobs, machines, and setups, allowing the PPO agent to learn a direct scheduling policy. Guided by a multi-objective reward function, the agent simultaneously minimizes TWT and TST. Experimental results on benchmark instances demonstrate that our PPO-GNN agent significantly outperforms a standard dispatching rule and a metaheuristic, achieving a superior trade-off between both objectives. This provides a robust and scalable solution for complex manufacturing scheduling.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08052",
      "pdf_url": "https://arxiv.org/pdf/2602.08052",
      "github_links": [
        "https://github.com/bulentsoykan/GNN-DRL4UPMSP"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08052",
      "scraped_at": "2026-02-13T02:28:47.153052"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors",
    "paper_url": "https://huggingface.co/papers/2602.08934",
    "authors": [],
    "stars": "2",
    "details": {
      "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors",
      "abstract": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors. Happy to discuss and get feedback!",
      "arxiv_page_url": "https://arxiv.org/abs/2602.08934",
      "pdf_url": "https://arxiv.org/pdf/2602.08934",
      "github_links": [
        "https://github.com/suraj-ranganath/StealthRL"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.08934",
      "scraped_at": "2026-02-13T02:28:49.094469"
    },
    "scraped_date": "2026-02-13"
  },
  {
    "title": "From Features to Actions: Explainability in Traditional and Agentic AI Systems",
    "paper_url": "https://huggingface.co/papers/2602.06841",
    "authors": [],
    "stars": "0",
    "details": {
      "title": "From Features to Actions: Explainability in Traditional and Agentic AI Systems",
      "abstract": "As AI systems move from single predictions to autonomous, multi-step agents, our notion of explainability must evolve. In this paper, we show why traditional feature-attribution methods (e.g., SHAP, LIME) are insufficient for diagnosing failures in tool-using LLM agents. Through experiments on TAU-bench Airline and AssistantBench, we demonstrate that trajectory-level, trace-grounded rubric analysis reliably localizes execution failures such as state inconsistency and incorrect tool selection‚Äîwhere attribution methods cannot. We introduce a unified static vs. agentic explainability taxonomy and propose the Minimal Explanation Packet (MEP) framework for structured, verifiable agent auditing. Code and full evaluation framework are open-sourced.",
      "arxiv_page_url": "https://arxiv.org/abs/2602.06841",
      "pdf_url": "https://arxiv.org/pdf/2602.06841",
      "github_links": [
        "https://github.com/VectorInstitute/unified-xai-evaluation-framework"
      ],
      "metadata": {},
      "page_url": "https://huggingface.co/papers/2602.06841",
      "scraped_at": "2026-02-13T02:28:51.035530"
    },
    "scraped_date": "2026-02-13"
  }
]